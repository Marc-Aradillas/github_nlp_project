{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e801830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jongarcia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from env import github_token, github_username\n",
    "import acquire as aqr\n",
    "import prepare as prep\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a095474",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_val = aqr.REPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7838e197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repo_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd3f90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AtsushiSakai/PythonRobotics',\n",
       " 'kiloreux/awesome-robotics',\n",
       " 'NxRLab/ModernRobotics',\n",
       " 'mithi/robotics-coursework',\n",
       " 'onlytailei/CppRobotics',\n",
       " 'JdeRobot/RoboticsAcademy',\n",
       " 'pptacher/probabilistic_robotics',\n",
       " 'jslee02/awesome-robotics-libraries',\n",
       " 'petercorke/robotics-toolbox-python',\n",
       " 'Unity-Technologies/Unity-Robotics-Hub']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_val[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f692cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name where you want to save the list\n",
    "file_name = \"repo_names.json\"\n",
    "# Load the REPOS list from the JSON file\n",
    "with open(file_name, 'r') as file:\n",
    "    REPOS = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf7d812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hubotio/hubot',\n",
       " 'Le0nX/ModernRoboticsCpp',\n",
       " 'ros/ros_comm',\n",
       " 'PetoiCamp/OpenCat',\n",
       " 'cyberbotics/webots',\n",
       " 'CHH3213/chhRobotics',\n",
       " 'araffin/robotics-rl-srl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPOS[24:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df52502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(REPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0d2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = aqr.scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57dce49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'repo': 'AtsushiSakai/PythonRobotics',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': '<img src=\"https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true\" align=\"right\" width=\"300\" alt=\"header pic\"/>\\n\\n# PythonRobotics\\n![GitHub_Action_Linux_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/Linux_CI/badge.svg)\\n![GitHub_Action_MacOS_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/MacOS_CI/badge.svg)\\n![GitHub_Action_Windows_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/Windows_CI/badge.svg)\\n[![Build status](https://ci.appveyor.com/api/projects/status/sb279kxuv1be391g?svg=true)](https://ci.appveyor.com/project/AtsushiSakai/pythonrobotics)\\n[![codecov](https://codecov.io/gh/AtsushiSakai/PythonRobotics/branch/master/graph/badge.svg)](https://codecov.io/gh/AtsushiSakai/PythonRobotics)\\n\\nPython codes for robotics algorithm.\\n\\n\\n# Table of Contents\\n   * [What is this?](#what-is-this)\\n   * [Requirements](#requirements)\\n   * [Documentation](#documentation)\\n   * [How to use](#how-to-use)\\n   * [Localization](#localization)\\n      * [Extended Kalman Filter localization](#extended-kalman-filter-localization)\\n      * [Particle filter localization](#particle-filter-localization)\\n      * [Histogram filter localization](#histogram-filter-localization)\\n   * [Mapping](#mapping)\\n      * [Gaussian grid map](#gaussian-grid-map)\\n      * [Ray casting grid map](#ray-casting-grid-map)\\n      * [Lidar to grid map](#lidar-to-grid-map)\\n      * [k-means object clustering](#k-means-object-clustering)\\n      * [Rectangle fitting](#rectangle-fitting)\\n   * [SLAM](#slam)\\n      * [Iterative Closest Point (ICP) Matching](#iterative-closest-point-icp-matching)\\n      * [FastSLAM 1.0](#fastslam-10)\\n   * [Path Planning](#path-planning)\\n      * [Dynamic Window Approach](#dynamic-window-approach)\\n      * [Grid based search](#grid-based-search)\\n         * [Dijkstra algorithm](#dijkstra-algorithm)\\n         * [A* algorithm](#a-algorithm)\\n         * [D* algorithm](#d-algorithm)\\n         * [D* Lite algorithm](#d-lite-algorithm)\\n         * [Potential Field algorithm](#potential-field-algorithm)\\n         * [Grid based coverage path planning](#grid-based-coverage-path-planning)\\n      * [State Lattice Planning](#state-lattice-planning)\\n         * [Biased polar sampling](#biased-polar-sampling)\\n         * [Lane sampling](#lane-sampling)\\n      * [Probabilistic Road-Map (PRM) planning](#probabilistic-road-map-prm-planning)\\n      * [Rapidly-Exploring Random Trees (RRT)](#rapidly-exploring-random-trees-rrt)\\n         * [RRT*](#rrt)\\n         * [RRT* with reeds-shepp path](#rrt-with-reeds-shepp-path)\\n         * [LQR-RRT*](#lqr-rrt)\\n      * [Quintic polynomials planning](#quintic-polynomials-planning)\\n      * [Reeds Shepp planning](#reeds-shepp-planning)\\n      * [LQR based path planning](#lqr-based-path-planning)\\n      * [Optimal Trajectory in a Frenet Frame](#optimal-trajectory-in-a-frenet-frame)\\n   * [Path Tracking](#path-tracking)\\n      * [move to a pose control](#move-to-a-pose-control)\\n      * [Stanley control](#stanley-control)\\n      * [Rear wheel feedback control](#rear-wheel-feedback-control)\\n      * [Linear–quadratic regulator (LQR) speed and steering control](#linearquadratic-regulator-lqr-speed-and-steering-control)\\n      * [Model predictive speed and steering control](#model-predictive-speed-and-steering-control)\\n      * [Nonlinear Model predictive control with C-GMRES](#nonlinear-model-predictive-control-with-c-gmres)\\n   * [Arm Navigation](#arm-navigation)\\n      * [N joint arm to point control](#n-joint-arm-to-point-control)\\n      * [Arm navigation with obstacle avoidance](#arm-navigation-with-obstacle-avoidance)\\n   * [Aerial Navigation](#aerial-navigation)\\n      * [drone 3d trajectory following](#drone-3d-trajectory-following)\\n      * [rocket powered landing](#rocket-powered-landing)\\n   * [Bipedal](#bipedal)\\n      * [bipedal planner with inverted pendulum](#bipedal-planner-with-inverted-pendulum)\\n   * [License](#license)\\n   * [Use-case](#use-case)\\n   * [Contribution](#contribution)\\n   * [Citing](#citing)\\n   * [Support](#support)\\n   * [Sponsors](#sponsors)\\n      * [JetBrains](#JetBrains)\\n      * [1Password](#1password)\\n   * [Authors](#authors)\\n\\n# What is this?\\n\\nThis is a Python code collection of robotics algorithms.\\n\\nFeatures:\\n\\n1. Easy to read for understanding each algorithm\\'s basic idea.\\n\\n2. Widely used and practical algorithms are selected.\\n\\n3. Minimum dependency.\\n\\nSee this paper for more details:\\n\\n- [\\\\[1808\\\\.10703\\\\] PythonRobotics: a Python code collection of robotics algorithms](https://arxiv.org/abs/1808.10703) ([BibTeX](https://github.com/AtsushiSakai/PythonRoboticsPaper/blob/master/python_robotics.bib))\\n\\n\\n# Requirements\\n\\nFor running each sample code:\\n\\n- [Python 3.11.x](https://www.python.org/)\\n \\n- [NumPy](https://numpy.org/)\\n \\n- [SciPy](https://scipy.org/)\\n \\n- [Matplotlib](https://matplotlib.org/)\\n \\n- [cvxpy](https://www.cvxpy.org/) \\n\\nFor development:\\n  \\n- [pytest](https://pytest.org/) (for unit tests)\\n  \\n- [pytest-xdist](https://pypi.org/project/pytest-xdist/) (for parallel unit tests)\\n  \\n- [mypy](http://mypy-lang.org/) (for type check)\\n  \\n- [sphinx](https://www.sphinx-doc.org/) (for document generation)\\n  \\n- [pycodestyle](https://pypi.org/project/pycodestyle/) (for code style check)\\n\\n# Documentation\\n\\nThis README only shows some examples of this project. \\n\\nIf you are interested in other examples or mathematical backgrounds of each algorithm, \\n\\nYou can check the full documentation online: [Welcome to PythonRobotics’s documentation\\\\! — PythonRobotics documentation](https://atsushisakai.github.io/PythonRobotics/index.html)\\n\\nAll animation gifs are stored here: [AtsushiSakai/PythonRoboticsGifs: Animation gifs of PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs)\\n\\n# How to use\\n\\n1. Clone this repo.\\n\\n   ```terminal\\n   git clone https://github.com/AtsushiSakai/PythonRobotics.git\\n   ```\\n\\n\\n2. Install the required libraries.\\n\\n- using conda :\\n\\n  ```terminal\\n  conda env create -f requirements/environment.yml\\n  ```\\n \\n- using pip :\\n\\n  ```terminal\\n  pip install -r requirements/requirements.txt\\n  ```\\n\\n\\n3. Execute python script in each directory.\\n\\n4. Add star to this repo if you like it :smiley:. \\n\\n# Localization\\n\\n## Extended Kalman Filter localization\\n\\n<img src=\"https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif\" width=\"640\" alt=\"EKF pic\">\\n\\nRef:\\n\\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/localization/extended_kalman_filter_localization_files/extended_kalman_filter_localization.html)\\n\\n## Particle filter localization\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif)\\n\\nThis is a sensor fusion localization with Particle Filter(PF).\\n\\nThe blue line is true trajectory, the black line is dead reckoning trajectory,\\n\\nand the red line is an estimated trajectory with PF.\\n\\nIt is assumed that the robot can measure a distance from landmarks (RFID).\\n\\nThese measurements are used for PF localization.\\n\\nRef:\\n\\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\\n\\n\\n## Histogram filter localization\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif)\\n\\nThis is a 2D localization example with Histogram filter.\\n\\nThe red cross is true position, black points are RFID positions.\\n\\nThe blue grid shows a position probability of histogram filter.  \\n\\nIn this simulation, x,y are unknown, yaw is known.\\n\\nThe filter integrates speed input and range observations from RFID for localization.\\n\\nInitial position is not needed.\\n\\nRef:\\n\\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\\n\\n# Mapping\\n\\n## Gaussian grid map\\n\\nThis is a 2D Gaussian grid mapping example.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif)\\n\\n## Ray casting grid map\\n\\nThis is a 2D ray casting grid mapping example.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif)\\n\\n## Lidar to grid map\\n\\nThis example shows how to convert a 2D range measurement to a grid map.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/lidar_to_grid_map/animation.gif)\\n\\n## k-means object clustering\\n\\nThis is a 2D object clustering with k-means algorithm.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif)\\n\\n## Rectangle fitting\\n\\nThis is a 2D rectangle fitting for vehicle detection.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif)\\n\\n\\n# SLAM\\n\\nSimultaneous Localization and Mapping(SLAM) examples\\n\\n## Iterative Closest Point (ICP) Matching\\n\\nThis is a 2D ICP matching example with singular value decomposition.\\n\\nIt can calculate a rotation matrix, and a translation vector between points and points.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif)\\n\\nRef:\\n\\n- [Introduction to Mobile Robotics: Iterative Closest Point Algorithm](https://cs.gmu.edu/~kosecka/cs685/cs685-icp.pdf)\\n\\n\\n## FastSLAM 1.0\\n\\nThis is a feature based SLAM example using FastSLAM 1.0.\\n\\nThe blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.\\n\\nThe red points are particles of FastSLAM.\\n\\nBlack points are landmarks, blue crosses are estimated landmark positions by FastSLAM.\\n\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif)\\n\\n\\nRef:\\n\\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\\n\\n- [SLAM simulations by Tim Bailey](http://www-personal.acfr.usyd.edu.au/tbailey/software/slam_simulations.htm)\\n\\n\\n# Path Planning\\n\\n## Dynamic Window Approach\\n\\nThis is a 2D navigation sample code with Dynamic Window Approach.\\n\\n- [The Dynamic Window Approach to Collision Avoidance](https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf)\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif)\\n\\n\\n## Grid based search\\n\\n### Dijkstra algorithm\\n\\nThis is a 2D grid based the shortest path planning with Dijkstra\\'s algorithm.\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif)\\n\\nIn the animation, cyan points are searched nodes.\\n\\n### A\\\\* algorithm\\n\\nThis is a 2D grid based the shortest path planning with A star algorithm.\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif)\\n\\nIn the animation, cyan points are searched nodes.\\n\\nIts heuristic is 2D Euclid distance.\\n\\n### D\\\\* algorithm\\n\\nThis is a 2D grid based the shortest path planning with D star algorithm.\\n\\n![figure at master · nirnayroy/intelligentrobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStar/animation.gif)\\n\\nThe animation shows a robot finding its path avoiding an obstacle using the D* search algorithm.\\n\\nRef:\\n\\n- [D* Algorithm Wikipedia](https://en.wikipedia.org/wiki/D*)\\n\\n### D\\\\* Lite algorithm\\n\\nThis algorithm finds the shortest path between two points while rerouting when obstacles are discovered. It has been implemented here for a 2D grid.\\n\\n![D* Lite](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStarLite/animation.gif)\\n\\nThe animation shows a robot finding its path and rerouting to avoid obstacles as they are discovered using the D* Lite search algorithm.\\n\\nRefs:\\n\\n- [D* Lite](http://idm-lab.org/bib/abstracts/papers/aaai02b.pd)\\n- [Improved Fast Replanning for Robot Navigation in Unknown Terrain](http://www.cs.cmu.edu/~maxim/files/dlite_icra02.pdf)\\n\\n### Potential Field algorithm\\n\\nThis is a 2D grid based path planning with Potential Field algorithm.\\n\\n![PotentialField](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif)\\n\\nIn the animation, the blue heat map shows potential value on each grid.\\n\\nRef:\\n\\n- [Robotic Motion Planning:Potential Functions](https://www.cs.cmu.edu/~motionplanning/lecture/Chap4-Potential-Field_howie.pdf)\\n\\n### Grid based coverage path planning\\n\\nThis is a 2D grid based coverage path planning simulation.\\n\\n![PotentialField](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif)\\n\\n## State Lattice Planning\\n\\nThis script is a path planning code with state lattice planning.\\n\\nThis code uses the model predictive trajectory generator to solve boundary problem.\\n\\nRef: \\n\\n- [Optimal rough terrain trajectory generation for wheeled mobile robots](http://journals.sagepub.com/doi/pdf/10.1177/0278364906075328)\\n\\n- [State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments](http://www.frc.ri.cmu.edu/~alonzo/pubs/papers/JFR_08_SS_Sampling.pdf)\\n\\n\\n### Biased polar sampling\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif)\\n\\n\\n### Lane sampling\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif)\\n\\n## Probabilistic Road-Map (PRM) planning \\n\\n![PRM](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif)\\n\\nThis PRM planner uses Dijkstra method for graph search.\\n\\nIn the animation, blue points are sampled points,\\n\\nCyan crosses means searched points with Dijkstra method,\\n\\nThe red line is the final path of PRM.\\n\\nRef:\\n\\n- [Probabilistic roadmap \\\\- Wikipedia](https://en.wikipedia.org/wiki/Probabilistic_roadmap)\\n\\n\\u3000\\u3000\\n\\n## Rapidly-Exploring Random Trees (RRT)\\n\\n### RRT\\\\*\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif)\\n\\nThis is a path planning code with RRT\\\\*\\n\\nBlack circles are obstacles, green line is a searched tree, red crosses are start and goal positions.\\n\\nRef:\\n\\n- [Incremental Sampling-based Algorithms for Optimal Motion Planning](https://arxiv.org/abs/1005.0416)\\n\\n- [Sampling-based Algorithms for Optimal Motion Planning](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.5503&rep=rep1&type=pdf)\\n\\n### RRT\\\\* with reeds-shepp path\\n\\n![Robotics/animation.gif at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif))\\n\\nPath planning for a car robot with RRT\\\\* and reeds shepp path planner.\\n\\n### LQR-RRT\\\\*\\n\\nThis is a path planning simulation with LQR-RRT\\\\*.\\n\\nA double integrator motion model is used for LQR local planner.\\n\\n![LQR_RRT](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif)\\n\\nRef:\\n\\n- [LQR\\\\-RRT\\\\*: Optimal Sampling\\\\-Based Motion Planning with Automatically Derived Extension Heuristics](http://lis.csail.mit.edu/pubs/perez-icra12.pdf)\\n\\n- [MahanFathi/LQR\\\\-RRTstar: LQR\\\\-RRT\\\\* method is used for random motion planning of a simple pendulum in its phase plot](https://github.com/MahanFathi/LQR-RRTstar)\\n\\n\\n## Quintic polynomials planning\\n\\nMotion planning with quintic polynomials.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif)\\n\\nIt can calculate a 2D path, velocity, and acceleration profile based on quintic polynomials.\\n\\nRef:\\n\\n- [Local Path Planning And Motion Control For Agv In Positioning](http://ieeexplore.ieee.org/document/637936/)\\n\\n## Reeds Shepp planning\\n\\nA sample code with Reeds Shepp path planning.\\n\\n![RSPlanning](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true)\\n\\nRef:\\n\\n- [15.3.2 Reeds\\\\-Shepp Curves](http://planning.cs.uiuc.edu/node822.html) \\n\\n- [optimal paths for a car that goes both forwards and backwards](https://pdfs.semanticscholar.org/932e/c495b1d0018fd59dee12a0bf74434fac7af4.pdf)\\n\\n- [ghliu/pyReedsShepp: Implementation of Reeds Shepp curve\\\\.](https://github.com/ghliu/pyReedsShepp)\\n\\n\\n## LQR based path planning\\n\\nA sample code using LQR based path planning for double integrator model.\\n\\n![RSPlanning](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true)\\n\\n\\n## Optimal Trajectory in a Frenet Frame \\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif)\\n\\nThis is optimal trajectory generation in a Frenet Frame.\\n\\nThe cyan line is the target course and black crosses are obstacles.\\n\\nThe red line is the predicted path.\\n\\nRef:\\n\\n- [Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame](https://www.researchgate.net/profile/Moritz_Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af.pdf)\\n\\n- [Optimal trajectory generation for dynamic street scenarios in a Frenet Frame](https://www.youtube.com/watch?v=Cj6tAQe7UCY)\\n\\n\\n# Path Tracking\\n\\n## move to a pose control\\n\\nThis is a simulation of moving to a pose control\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif)\\n\\nRef:\\n\\n- [P. I. Corke, \"Robotics, Vision and Control\" \\\\| SpringerLink p102](https://link.springer.com/book/10.1007/978-3-642-20144-8)\\n\\n\\n## Stanley control\\n\\nPath tracking simulation with Stanley steering control and PID speed control.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif)\\n\\nRef:\\n\\n- [Stanley: The robot that won the DARPA grand challenge](http://robots.stanford.edu/papers/thrun.stanley05.pdf)\\n\\n- [Automatic Steering Methods for Autonomous Automobile Path Tracking](https://www.ri.cmu.edu/pub_files/2009/2/Automatic_Steering_Methods_for_Autonomous_Automobile_Path_Tracking.pdf)\\n\\n\\n\\n## Rear wheel feedback control\\n\\nPath tracking simulation with rear wheel feedback steering control and PID speed control.\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif)\\n\\nRef:\\n\\n- [A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles](https://arxiv.org/abs/1604.07446)\\n\\n\\n## Linear–quadratic regulator (LQR) speed and steering control\\n\\nPath tracking simulation with LQR speed and steering control.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif)\\n\\nRef:\\n\\n- [Towards fully autonomous driving: Systems and algorithms \\\\- IEEE Conference Publication](http://ieeexplore.ieee.org/document/5940562/)\\n\\n\\n## Model predictive speed and steering control\\n\\nPath tracking simulation with iterative linear model predictive speed and steering control.\\n\\n<img src=\"https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif\" width=\"640\" alt=\"MPC pic\">\\n\\nRef:\\n\\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/path_tracking/model_predictive_speed_and_steering_control/model_predictive_speed_and_steering_control.html)\\n\\n- [Real\\\\-time Model Predictive Control \\\\(MPC\\\\), ACADO, Python \\\\| Work\\\\-is\\\\-Playing](http://grauonline.de/wordpress/?page_id=3244)\\n\\n## Nonlinear Model predictive control with C-GMRES\\n\\nA motion planning and path tracking simulation with NMPC of C-GMRES \\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif)\\n\\nRef:\\n\\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/path_tracking/cgmres_nmpc/cgmres_nmpc.html)\\n\\n\\n# Arm Navigation\\n\\n## N joint arm to point control\\n\\nN joint arm to a point control simulation.\\n\\nThis is an interactive simulation.\\n\\nYou can set the goal position of the end effector with left-click on the plotting area. \\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif)\\n\\nIn this simulation N = 10, however, you can change it.\\n\\n## Arm navigation with obstacle avoidance \\n\\nArm navigation with obstacle avoidance simulation.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif)\\n\\n\\n# Aerial Navigation\\n\\n## drone 3d trajectory following \\n\\nThis is a 3d trajectory following simulation for a quadrotor.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif)\\n\\n## rocket powered landing\\n\\nThis is a 3d trajectory generation simulation for a rocket powered landing.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif)\\n\\nRef:\\n\\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/aerial_navigation/rocket_powered_landing/rocket_powered_landing.html)\\n\\n# Bipedal\\n\\n## bipedal planner with inverted pendulum\\n\\nThis is a bipedal planner for modifying footsteps for an inverted pendulum.\\n\\nYou can set the footsteps, and the planner will modify those automatically.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif)\\n\\n# License \\n\\nMIT\\n\\n# Use-case\\n\\nIf this project helps your robotics project, please let me know with creating an issue.\\n\\nYour robot\\'s video, which is using PythonRobotics, is very welcome!!\\n\\nThis is a list of user\\'s comment and references:[users\\\\_comments](https://github.com/AtsushiSakai/PythonRobotics/blob/master/users_comments.md)\\n\\n# Contribution\\n\\nAny contribution is welcome!! \\n\\nPlease check this document:[How To Contribute — PythonRobotics documentation](https://atsushisakai.github.io/PythonRobotics/how_to_contribute.html)\\n\\n# Citing\\n\\nIf you use this project\\'s code for your academic work, we encourage you to cite [our papers](https://arxiv.org/abs/1808.10703) \\n\\nIf you use this project\\'s code in industry, we\\'d love to hear from you as well; feel free to reach out to the developers directly.\\n\\n# <a id=\"support\"></a>Supporting this project\\n\\nIf you or your company would like to support this project, please consider:\\n\\n- [Sponsor @AtsushiSakai on GitHub Sponsors](https://github.com/sponsors/AtsushiSakai)\\n\\n- [Become a backer or sponsor on Patreon](https://www.patreon.com/myenigma)\\n\\n- [One-time donation via PayPal](https://www.paypal.me/myenigmapay/)\\n\\nIf you would like to support us in some other way, please contact with creating an issue.\\n\\n## <a id=\"sponsors\"></a>Sponsors\\n\\n### <a id=\"JetBrains\"></a>[JetBrains](https://www.jetbrains.com/)\\n\\nThey are providing a free license of their IDEs for this OSS development.   \\n\\n### [1Password](https://github.com/1Password/1password-teams-open-source)\\n\\nThey are providing a free license of their 1Password team license for this OSS project.   \\n\\n\\n# Authors\\n\\n- [Contributors to AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics/graphs/contributors)\\n\\n'},\n",
       " {'repo': 'kiloreux/awesome-robotics',\n",
       "  'language': None,\n",
       "  'readme_contents': \"Awesome Robotics\\n================\\n\\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\\n\\nThis is a list of various books, courses and other resources for robotics. It's an attempt to gather useful material in one place for everybody who wants to learn more about the field.\\n\\n\\n### Courses ###\\n* [Artificial Intelligence for Robotics](https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373) **Udacity**\\n* [Robotics Nanodegree](https://www.udacity.com/course/robotics-software-engineer--nd209) **Udacity** :dollar:\\n* [Autonomous Mobile Robots](https://courses.edx.org/courses/course-v1:ETHx+AMRx+2T2019/5b151c51e8bf47c29d97f8a12369df17/) **edX**\\n* [Underactuated Robotics](http://underactuated.csail.mit.edu/underactuated.html) **MIT CSAIL**\\n* [Autonomous Mobile Robots](https://courses.edx.org/courses/ETHx/AMRx/1T2014/info) **edX**\\n* [Robot Mechanics and Control, Part I](https://www.edx.org/course/robot-mechanics-control-part-i-snux-snu446-345-1x) **edX**\\n* [Robot Mechanics and Control, Part II](https://www.edx.org/course/robot-mechanics-control-part-ii-snux-snu446-345-2x) **edX**\\n* [Autonomous Navigation for Flying Robots](https://www.edx.org/course/autonomous-navigation-flying-robots-tumx-autonavx-0) **edX**\\n* [Robotics Specialization by GRASP Lab](https://www.coursera.org/specializations/robotics) **Coursera** :dollar:\\n* [Control of Mobile Robots](https://www.coursera.org/course/conrob) **Coursera**\\n* [QUT Robot Academy](https://robotacademy.net.au/) **QUT**\\n* [Robotic vision](https://www.qut.edu.au/study/short-courses-and-professional-development/short-courses/robotic-vision) **QUT**\\n* [Introduction to robotics](http://ocw.mit.edu/courses/mechanical-engineering/2-12-introduction-to-robotics-fall-2005/) **MIT**\\n* [Robotics: Vision Intelligence and Machine Learning](https://www.edx.org/course/robotics-vision-intelligence-machine-pennx-robo2x) **edX**\\n* [Applied robot design](https://www.youtube.com/user/StanfordCS235/videos) **Stanford University**\\n* [Introduction to Robotics](https://see.stanford.edu/Course/CS223A) **Stanford University**\\n* [Introduction to Mobile Robotics](http://ais.informatik.uni-freiburg.de/teaching/ss16/robotics/index_en.php) **University of Freiburg**\\n* [Robotics](https://www.edx.org/micromasters/pennx-robotics) **edx** :dollar:\\n* [Columbia Robotics](https://www.edx.org/course/robotics-columbiax-csmm-103x-2) **edx** \\n* [Modern Robotics: Mechanics, Planning, and Control](https://www.coursera.org/specializations/modernrobotics?) **Coursera**\\n* [Hello (Real) World with ROS – Robot Operating System](https://www.edx.org/course/hello-real-world-with-ros-robot-operating-system-2) **edx**\\n* [Advanced Robotics](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/) **UCBerkeley**\\n* [Building Arduino robots and devices](https://www.coursera.org/learn/arduino) **Coursera**\\n* [Introduction to The Robot Operating System (ROS2)](https://www.coursera.org/projects/ros2-intro) **Coursera**\\n* [Modern Robotics: Mechanics, Planning, and Control Specialization](https://www.coursera.org/specializations/modernrobotics) **Coursera**\\n* [Become a Robotics Software Enginee](https://www.udacity.com/course/robotics-software-engineer--nd209) **Udacity**\\n* [Advanced Robotics](http://www.cs.berkeley.edu/~pabbeel/cs287-fa13/) **UC Berkeley**\\n\\n### Books ###\\n* [Probabilistic Robotics (Intelligent Robotics and Autonomous Agents series)](http://www.amazon.com/Probabilistic-Robotics-Intelligent-Autonomous-Agents/dp/0262201623/)  :dollar:\\n* [Introduction to Autonomous Mobile Robots (Intelligent Robotics and Autonomous Agents series)](http://www.amazon.com/Introduction-Autonomous-Mobile-Intelligent-Robotics/dp/0262015358/)  :dollar:\\n* [Springer Handbook of Robotics](https://www.amazon.com/Springer-Handbook-Robotics-Handbooks/dp/3319325507/)  :dollar:\\n* [Planning Algorithms](http://planning.cs.uiuc.edu/)\\n* [A gentle introduction to ROS](https://cse.sc.edu/~jokane/agitr/agitr-letter.pdf)\\n* [A Mathematical Introduction to Robotic Manipulation](http://www.cds.caltech.edu/~murray/mlswiki/?title=First_edition)\\n* [Learning Computing With Robots](http://wiki.roboteducation.org/Introduction_to_Computer_Science_via_Robots)\\n* [Robotics, Vision and Control: Fundamental Algorithms in MATLAB (Springer Tracts in Advanced Robotics)](http://www.amazon.com/Robotics-Vision-Control-Fundamental-Algorithms/dp/3642201431)  :dollar:\\n* [INTECH Books](http://www.intechopen.com/subjects/robotics)\\n* [Introduction to Autonomous Robots](https://github.com/correll/Introduction-to-Autonomous-Robots/releases)\\n* [Principles of Robot Motion: Theory, Algorithms, and Implementations ](https://www.amazon.com/Principles-Robot-Motion-Implementations-Intelligent/dp/0262033275):dollar:\\n* [Introduction to Modern Robotics: Mechanics, Planning, and Control](http://hades.mech.northwestern.edu/index.php/LynchAndPark) [[pdf](http://hades.mech.northwestern.edu/images/7/7f/MR.pdf)]\\n* [Programming Robots with ROS: A Practical Introduction to the Robot Operating System](https://www.amazon.com/Programming-Robots-ROS-Practical-Introduction/dp/1449323898/) :dollar:\\n* [Learning ROS for Robotics Programming](https://www.amazon.com/Learning-ROS-Robotics-Programming-Second/dp/1783987588) :dollar:\\n* [Mastering ROS for Robotics Programming](https://www.amazon.com/Mastering-Robotics-Programming-Lentin-Joseph/dp/1783551798) :dollar:\\n* [Behavior Trees in Robotics and AI: An Introduction](https://btirai.github.io/) [[pdf](https://arxiv.org/pdf/1709.00084)]\\n* [Automated Planning and Acting](http://projects.laas.fr/planning/) [[pdf](http://projects.laas.fr/planning/book.pdf)]\\n* [Robotics for Software Engineers](https://www.manning.com/books/robotics-for-software-engineers) :dollar:\\n\\n\\n### Software and Libraries ###\\n[**Gazebo**](http://gazebosim.org/)\\nRobot Simulator\\n\\n[**ROS**](http://www.ros.org/)\\nThe Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.\\n\\n[**ROS2**](https://index.ros.org/doc/ros2/)\\nROS2 is a new version of ROS with radical design changes and improvement over older ROS version.\\n\\n[**RobWork**](http://www.robwork.dk/apidoc/nightly/rw/)\\nRobWork is a collection of C++ libraries for simulation and control of robot systems. RobWork is used for research and education as well as for practical robot applications.\\n\\n[**MRPT**](http://www.mrpt.org/)\\nMobile Robot Programming Toolkit provides developers with portable and well-tested applications and libraries covering data structures and algorithms employed in common robotics research areas.\\n\\n[**Robotics Library**](http://www.roboticslibrary.org/)\\nThe Robotics Library (RL) is a self-contained C++ library for robot kinematics, motion planning and control. It covers mathematics, kinematics and dynamics, hardware abstraction, motion planning, collision detection, and visualization.\\n\\n[**Simbad**](http://simbad.sourceforge.net/)\\n2D/3D simulator in Java and Jython.\\n\\n[**Morse**](https://www.openrobots.org/wiki/morse/)\\nGeneral purpose indoor/outdoor 3D simulator.\\n\\n[**Carmen**](http://carmen.sourceforge.net/)\\nCARMEN is an open-source collection of software for mobile robot control. CARMEN is modular software designed to provide basic navigation primitives including: base and sensor control, logging, obstacle avoidance, localization, path planning, and mapping.\\n\\n[**Peekabot**](http://www.peekabot.org/)\\nPeekabot is a real-time, networked 3D visualization tool for robotics, written in C++. Its purpose is to simplify the visualization needs faced by a roboticist daily.\\n\\n[**YARP**](http://www.yarp.it/)\\nYet Another Robot Platform.\\n\\n[**V-REP**](http://www.coppeliarobotics.com/)\\nRobot simulator, 3D, source available, Lua scripting, APIs for C/C++, Python, Java, Matlab, URBI, 2 physics engines, full kinematic solver.\\n\\n[**Webots**](https://www.cyberbotics.com/overview)\\nWebots is a development environment used to model, program and simulate mobile robots.\\n\\n[**Drake**](http://drake.mit.edu/)\\nA planning, control and analysis toolbox for nonlinear dynamical systems.\\n\\n[**Neurorobotics Platform (NRP)**](https://neurorobotics.net/)\\nAn Internet-accessible simulation system that allows the simulation of robots controlled by spiking neural networks.\\n\\n[**The Player Project**](http://playerstage.sourceforge.net/)\\nFree Software tools for robot and sensor applications\\n\\n[**Open AI's Roboschool**](https://github.com/openai/roboschool)\\nOpen-source software for robot simulation, integrated with OpenAI Gym.\\n\\n[**ViSP**](http://visp.inria.fr/)\\nOpen-source visual servoing platform library, is able to compute control laws that can be applied to robotic systems.\\n\\n[**ROS Behavior Trees**](https://github.com/miccol/ROS-Behavior-Tree)\\nOpen-source library to create robot's behaviors in form of Behavior Trees running in ROS (Robot Operating System).\\n\\n[**g2core**](https://github.com/synthetos/g2)\\nOpen-source motion control software for CNC and Robotics, designed to run on Arduino Due class microcontrollers.\\n\\n[**ur5controller**](https://github.com/roboticsleeds/ur5controller)\\nOpen-source OpenRAVE controller for UR5 robot integrated with ROS.\\n\\n[**RBDL**](https://github.com/rbdl/rbdl)\\nOpen-source (zlib) C++ libray for both forward and inverse dynamics and kinematics. Also supports contacts and loops.\\n\\n[**Unity Robotics Hub**](https://github.com/Unity-Technologies/Unity-Robotics-Hub)\\nCentral repository for open-source Unity packages, tutorials, and other resources demonstrating how to use Unity for robotics simulations. Includes new support for ROS integration.\\n\\n### Papers ###\\n* [Optimization Based Controller Design and Implementation for the\\nAtlas Robot in the DARPA Robotics Challenge Finals](https://www.cs.cmu.edu/~cga/drc/ICHR15_0025_MS.pdf)\\n\\n\\n### Conferences ###\\n* [ACM/IEEE International Conference on Human Robot Interaction (HRI)](http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1040036)\\n* [CISM IFToMM Symposium on Robot Design, Dynamics and Control (RoManSy)](http://www.romansy2016.org/)\\n* [IEEE Conference on Decision and Controls (CDC)](http://ieeexplore.ieee.org/servlet/opac?punumber=1000188)\\n* [IEEE International Conference on Rehabilitation Robotics (ICORR)](http://www.rehabrobotics.org/)\\n* [IEEE International Conference on Robotics and Automation (ICRA)](http://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra)\\n* [IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)](http://www.iros.org/)\\n* [IEEE-RAS International Conference on Humanoid Robots (Humanoids)](http://ieeexplore.ieee.org/servlet/opac?punumber=1002042)\\n* [International Symposium of Robotic Research (ISRR)](http://ifrr.org/isrr.php)\\n* [International Symposium of Experimental Robotics (ISER)](http://ifrr.org/iser.php)\\n* [Robotica](http://www.ieee-ras.org/conferences-workshops/technically-co-sponsored/robotica)\\n* [Robotics: Science and Systems Conference (RSS)](http://www.roboticsconference.org/)\\n* [The International Workshop on the Algorithmic Foundations of Robotics (WAFR)](http://www.wafr.org/)\\n\\n\\n### Journals ###\\n* [Autonomous Robots](http://www.springer.com/engineering/robotics/journal/10514)\\n* [Bioinspiration & Biomimetics](http://iopscience.iop.org/journal/1748-3190)\\n* [Frontiers in Robotics and AI](http://journal.frontiersin.org/journal/robotics-and-ai)\\n* [IEEE Robotics & Automation Magazine](http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=100)\\n* [IEEE Transactions on Haptics](http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4543165)\\n* [IEEE Transactions on Robotics](http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8860)\\n* [IEEE/ASME Transactions on Mechatronics](http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=3516)\\n* [International Journal of Social Robotics](http://www.springer.com/engineering/robotics/journal/12369)\\n* [Journal of Field Robotics](http://www.journalfieldrobotics.org/Home.html)\\n* [Journal of Intelligent & Robotic Systems](http://www.springer.com/engineering/robotics/journal/10846)\\n* [Mechatronics](http://www.journals.elsevier.com/mechatronics)\\n* [Robotics and Computer-Integrated Manufacturing](http://www.journals.elsevier.com/robotics-and-computer-integrated-manufacturing)\\n* [Robotics and Autonomous Systems](http://www.journals.elsevier.com/robotics-and-autonomous-systems)\\n* [The International Journal of Robotics Research](http://www.ijrr.org/)\\n\\n\\n### Competitions ###\\n* [ICRA Robot Challenges](http://www.icra2017.org/conference/robot-challenges)\\n* [RobotChallenge](http://www.robotchallenge.org/)\\n* [DARPA Robotics Challenge](http://www.theroboticschallenge.org/)\\n* [European Robotics Challenges](http://www.euroc-project.eu/)\\n* [First Robotics Competition](http://www.firstinspires.org/robotics/frc)\\n* [VEX Robotics Competition](https://www.vexrobotics.com/)\\n* [RoboCup](http://www.robocup.org/)\\n* [RoboCupJunior](https://junior.robocup.org/)\\n* [Eurobot](http://www.eurobot.org/) International Students Robotics Contest\\n* [RoboMasters](https://www.robomaster.com/en-US)\\n* [RoboSoft, Grand Challenge](http://www.robosoftca.eu/)\\n* [Intelligent Ground Vehicle Competition](http://www.igvc.org/)\\n* [Robotex](https://robotex.ee/en/) The biggest robotics festival in Europe\\n* [First Lego League](https://www.firstlegoleague.org/)\\n\\n### Companies ###\\n* [Boston Dynamics](http://www.bostondynamics.com/) robotics R&D company, creator of the state of the art [Atlas](https://www.youtube.com/watch?v=rVlhMGQgDkY) and [Spot](https://www.youtube.com/watch?v=M8YjvHYbZ9w) robots\\n* [iRobot](http://www.irobot.com/) manufacturer of the famous [Roomba](https://en.wikipedia.org/wiki/Roomba) robotic vacuum cleaner\\n* [PAL Robotics](http://pal-robotics.com)\\n* [Aldebaran Robotics](https://www.aldebaran.com/en) creator of the [NAO robot](https://www.youtube.com/watch?v=nNbj2G3GmAo)\\n* [ABB Robotics](http://new.abb.com/products/robotics) the largest manufacturer of industrial robots\\n* [KUKA Robotics](http://www.kuka-robotics.com/en/) major manufacturer of industrial robots targeted at factory automation\\n* [FANUC](http://www.fanucamerica.com/) industrial robots manufacturer with the biggest install base\\n* [Rethink Robotics](http://www.rethinkrobotics.com/) creator of the collaborative robot [Baxter](https://www.youtube.com/watch?v=fCML42boO8c)\\n* [DJI](http://www.dji.com/) industry leader in drones for both commerical and industrial needs.\\n* [The construct sim](http://www.theconstructsim.com/)  A cloud based tool for building modern, future-proof robot simulations.\\n* [Fetch Robotics](http://www.fetchrobotics.com/) A robotics startup in San Jose, CA building the future of e-commerce fulfillment and R&D robots.\\n* [Festo Robotics](https://www.festo.com/) Festo is known for making moving robots that move like animals such as the sea gull like SmartBird, jellyfish, butterflies and kangaroos.\\n* [Neobotix](https://www.neobotix-robots.com/homepage) manufacturer of industrial, research and as well as custom mobile robots. \\n\\n### Misc ###\\n* [IEEE Spectrum Robotics](http://spectrum.ieee.org/robotics) robotics section of the IEEE Spectrum magazine\\n* [MIT Technology Review Robotics](https://www.technologyreview.com/c/robotics/) robotics section of the MIT Technology Review magazine\\n* [reddit robotics subreddit](https://www.reddit.com/r/robotics/)\\n* [RosCON conference (video talks included)](http://roscon.ros.org/2015/)\\n* [Carnegie Mellon Robotics Academy](http://education.rec.ri.cmu.edu/)\\n* [Let's Make Robots](http://letsmakerobots.com/)\\n* [How do I learn Robotics?](https://www.quora.com/How-do-I-learn-robotics)\\n* [Free NXT Lego MindStorms NXT-G code tutorials](http://www.drgraeme.net/DrGraeme-free-NXT-G-tutorials/ChV4.htm)\\n* [StackExachange Robotics community](https://robotics.stackexchange.com)\\n* [47 Programmable robotic kits](http://www.intorobotics.com/47-programmable-robotic-kits/)\\n* [Linorobot](https://linorobot.org/) A suite of DIY ROS compatible robots\\n* [Hexapod Robot Simulator](https://github.com/mithi/hexapod) - Solve and visualize hexapod robot inverse kinematics and gaits in the web\\n* [PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics) - Implementations of various robotics algorithms in python\\n\\n### Related awesome lists ###\\n* [Awesome Artificial Intelligence](https://github.com/owainlewis/awesome-artificial-intelligence)\\n* [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)\\n* [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning)\\n* [Awesome Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning)\\n* [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision)\\n* [Awesome Gazebo](https://github.com/fkromer/awesome-gazebo)\\n* [Awesome Reinforcement Learning](https://github.com/aikorea/awesome-rl/)\\n* [Awesome Robotics](https://github.com/ahundt/awesome-robotics)\\n* [Awesome Robotics Libraries](https://github.com/jslee02/awesome-robotics-libraries)\\n* [Awesome ROS2](https://github.com/fkromer/awesome-ros2)\\n* [Awesome RoboCupJunior Soccer](https://github.com/RoboCupJuniorTC/awesome-rcj-soccer)\\n\"},\n",
       " {'repo': 'NxRLab/ModernRobotics',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': \"# Modern Robotics:  Mechanics, Planning, and Control\\n# Code Library\\n\\nThis repository contains the code library accompanying [_Modern Robotics: \\nMechanics, Planning, and Control_](http://modernrobotics.org) (Kevin Lynch \\nand Frank Park, Cambridge University Press 2017). The \\n[user manual](/doc/MRlib.pdf) is in the doc directory.\\n\\nThe functions are available in:\\n\\n* Python\\n* MATLAB\\n* Mathematica\\n\\nEach function has a commented section above it explaining the inputs required for its use as well as an example of how it can be used and what the output will be. This repository also contains a pdf document that provides an overview of the available functions using MATLAB syntax. Functions are organized according to the chapter in which they are introduced in the book. Basic functions, such as functions to calculate the magnitude of a vector, normalize a vector, test if the value is near zero, and perform matrix operations such as multiplication and inverses, are not documented here.\\n\\nThe primary purpose of the provided software is to be easy to read and educational, reinforcing the concepts in the book. The code is optimized neither for efficiency nor robustness.\\n\\nSome unofficial versions in other languages are being developed:\\n* [C++ version](https://github.com/Le0nX/ModernRoboticsCpp)\\n* [Julia version](https://github.com/ferrolho/ModernRoboticsBook.jl)\\n* [Nim version](https://github.com/Nimbotics/ModernRoboticsNim)\\n\\nSome libraries built on ours:\\n* [KinematicsFromDescriptionTool](https://github.com/Interbotix/kinematics_from_description), which calculates the kinematics input parameters from a robot's URDF or robot_description parameter using ROS and Python3.\\n* [mr_urdf_loader](https://github.com/tjdalsckd/mr_urdf_loader), which generates `M`, `Slist`, `Blist`, `Mlist` and `Glist` parameters for kinematics and dynamics. It also provides UR5 simulation using `PyBullet`.\\n* [tf_rbdl](https://github.com/junhyeokahn/tf_rbdl#tf_rbdl), which refactors the Python version using the package `tensorflow`.\\n\\nAny contribution is welcomed but the maintenance team for this library here doesn't vouch for the reliability of those projects.\\n\"},\n",
       " {'repo': 'mithi/robotics-coursework',\n",
       "  'language': None,\n",
       "  'readme_contents': \"# [🐳](https://mithi.github.io/deep-blueberry) [☕️](https://ko-fi.com/minimithi) \\n\\n- If you want to use Arduino or Raspberry Pi to make robots, [this](./PROTOTYPING.md) short list might be helpful.\\n- Check [this](./BOOKS.MD) short list if you like reading textbooks.\\n- Here are [some pending links](https://github.com/mithi/robotics-coursework/issues/6) that might be someday be transfered in this document.\\n- If there's anything you think should be included here, you can submit an issue and I'll check it out.\\n\\n# Series of Courses\\n\\n- [♥️ Robot Academy][series1], Peter Corke, Queensland University of Technology\\n- [MIT Open Courseware: Robotics][series9] \\n- Coursera: [Robotics Specialization][series3], University of Pennsylvania\\n- Coursera: [Modern Robotics Specialization][series4] | [book][series11a] + [📺 channel][series11b], Northwestern University\\n- Coursera: [Self-Driving Cars][series10], University of Toronto\\n- :dollar: Udacity: [Robotics Nanodegree][series5]\\n- :dollar: Udacity: [Intro to Self-Driving Cars Nanodegree][series6b]\\n- :dollar: Udacity: [Self-Driving Car Nanodegree][series6]\\n- :dollar: Udacity: [Flying Car Nanodegree][series7]\\n- :dollar: Udacity: [Sensor Fusion Nanodegree][series12]\\n- :dollar: [The Construct: Robotics Developers Course Library][series8], Robot Ignite Academy\\n- :dollar: [Master's Certification Program in Autonomous Vehicles][series13], Skill Lync\\n\\n[series1]: http://robotacademy.net.au\\n[series3]: https://www.coursera.org/specializations/robotics\\n[series4]: https://www.coursera.org/specializations/modernrobotics\\n[series5]: https://www.udacity.com/robotics\\n[series6]: https://www.udacity.com/drive\\n[series6b]: https://www.udacity.com/course/intro-to-self-driving-cars--nd113\\n[series7]: https://www.udacity.com/course/flying-car-nanodegree--nd787\\n[series8]: https://www.theconstructsim.com/robotigniteacademy_learnros/ros-courses-library/\\n[series9]: https://ocw.mit.edu/search/ocwsearch.htm?q=robotics\\n[series10]: https://www.coursera.org/specializations/self-driving-cars\\n[series11a]: http://modernrobotics.org \\n[series11b]: https://www.youtube.com/playlist?list=PLggLP4f-rq02vX0OQQ5vrCxbJrzamYDfx\\n[series12]: https://www.udacity.com/course/sensor-fusion-engineer-nanodegree--nd313\\n[series13]: https://skill-lync.com/courses/masters-certification-program-autonomous-driving\\n\\n# Single Courses\\n- Udacity: [Artificial Intelligence for Robotics][course21], Sebastian Thrun\\n- EdX: [Self-Driving Cars with Duckietown][course40], ETHzurich\\n- EdX: [Autonomous Mobile Robots][course1], ETHZurich\\n- EdX: [Autonomous Navigation for Flying Robots][course2], Technische Universitat Munchen\\n- EdX: [Underactuated Robotics][course3], Massachusetts Institute of Technology\\n- EdX: [Robotics][course4], Columbia University in the city of New York\\n- EdX: Robot Mechanics and Control [Part I][course5] and [Part II][course6], Seoul National University\\n- EdX: [Robotics Foundations I - Robot Modeling][course7], Università degli Studi di Napoli Federico II\\n- EdX: [Robotics Foundation II - Robot Control][course41], Bruno Siciliano, Università degli Studi di Napoli Federico II\\n- EdX: [Robot Development][course42], Angelo Cangelosi, Università degli Studi di Napoli Federico II\\n- EdX: [Hello (Real) World with ROS – Robot Operating System][course8], Delft University of Technology\\n- Udemy: [ROS for Beginners: Basics, Motion and OpenCV][course30], Anish Koubaa\\n- Udemy: [ROS for Beginners II: Localization, Navigation and SLAM][course31], Anish Koubaa\\n- [Self-Driving Cars with ROS and Autoware][course27], Apex.AI\\n- [Autonomous Intelligent Systems][course10], Wolfram Burgard et al, University of Freiburg\\n- [Introduction to Robotics][course11], Oussama Khatib, Stanford Engineering Everywhere\\n- [Introduction to Aerial Robotics][course13], Kostas Alexis, University of Nevada\\n- [Deep-learning for Self-Driving Cars][course14], Lex Fridman, Massachusetts Institute of Technology\\n- [Advanced Robotics (CS 287)][course19], Pieter Abbeel, University of California at Berkeley\\n- [♥️ Underactuated Robotics][course20c] | [book][course20a] + [📺 channel][course20b], Russ Tedrake, Massachusetts Institute of Technology\\n- [Robotics Manipulation: Perception, Planning, and Control][course29] + [📺 channel][course29b], Russ Tedrake, Massachusetts Institute of Technology\\n- [Visual Navigation for Flying Robot][course22], Jürgen Sturm, Technical University of Munich\\n- [📺 SLAM playlist][course15], Cyrill Stachniss, University of Freiburg\\n- [📺 Robotics I][course16], De Luca, Universita di Roma\\n- [📺 SLAM Lectures][course18], Clause Brenne, Leibniz University Hannover\\n- [📺 Applied Robot Design (CS235)][course23], Reuben Brewer, Standford University\\n- [Robogrok: Robotics][course17a] + [📺 channel][course17b], Angela Sodemann\\n- [Autonomous Robots Lab: Autonomous Mobile Robot Design (and more)][course24], University of Nevada\\n- [MEAM 620: Robotics][course25], University of Pennsylvania\\n- [Robotics: Advanced Concepts and Analysis][course26], Ashitava Ghosal, Indian Institute of Science\\n- [Introduction to Robotics][course28], Burton Ma, York University \\n- [NPTEL: Introduction to Robotics][course32], IIT Madras\\n- [CMSC828T Vision, Planning And Control In Aerial Robotics][course33], Yiannis Aloimonos, University of Maryland\\n- [HKUST ELEC5660 Introduction to Aerial Robots][course34], Shaojie SHEN, Hong Kong University of Science and Technology\\n- [ENAE 788M: Hands On Autonomous Aerial Robotics][course35], Nitin Sanket, University of Maryland\\n- [📺 Evolutionary robotics][course43], Josh Bongard, University of Vermont\\n- [Programming for Robotics - ROS][course44], Edo Jelavić, Tom Lankhorst, Marco Hutter, ETHZurich\\n\\n[course1]: https://www.edx.org/course/autonomous-mobile-robots-ethx-amrx-2\\n[course2]: https://www.edx.org/course/autonomous-navigation-flying-robots-tumx-autonavx-0\\n[course3]: https://www.edx.org/course/underactuated-robotics-mitx-6-832x-0\\n[course4]: https://www.edx.org/course/robotics-columbiax-csmm-103x#!\\n[course5]: https://www.edx.org/course/robot-mechanics-control-part-i-snux-snu446-345-1x\\n[course6]: https://www.edx.org/course/robot-mechanics-control-part-ii-snux-snu446-345-2x\\n[course7]: https://www.edx.org/course/robotics-foundations-i-robot-modeling\\n[course8]: https://www.edx.org/course/hello-real-world-with-ros-robot-operating-system\\n[course9]: https://www.coursera.org/learn/mobile-robot\\n[course10]: http://ais.informatik.uni-freiburg.de/teaching/ss16/robotics/index_en.php\\n[course11]: https://see.stanford.edu/Course/CS223A\\n[course13]: http://www.kostasalexis.com/introduction-to-aerial-robotics.html\\n[course14]: http://selfdrivingcars.mit.edu/\\n[course15]: https://www.youtube.com/watch?v=V9qQc5X7O0k&list=PLgnQpQtFTOGQECnBvZSV61oxTrkPut-nc\\n[course16]: https://www.youtube.com/watch?v=pitZv3PuVMw&list=PLAQopGWlIcyaqDBW1zSKx7lHfVcOmWSWt\\n[course17a]: http://robogrok.com/index.html\\n[course17b]: https://www.youtube.com/user/asodemann3/videos\\n[course18]: https://www.youtube.com/watch?v=B2qzYCeT9oQ&list=PLpUPoM7Rgzi_7YWn14Va2FODh7LzADBSm\\n[course19]: https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/\\n[course20a]: http://underactuated.csail.mit.edu/underactuated.html\\n[course20b]: https://www.youtube.com/channel/UChfUOAhz7ynELF-s_1LPpWg/playlists\\n[course20c]: http://underactuated.csail.mit.edu/Spring2020/\\n[course21]: https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373\\n[course22]: https://vision.in.tum.de/teaching/ss2013/visnav2013\\n[course23]: https://www.youtube.com/user/StanfordCS235/videos\\n[course24]: https://www.autonomousrobotslab.com/education.html\\n[course25]: https://alliance.seas.upenn.edu/~meam620/wiki/index.php?n=Main.Projects\\n[course26]: https://nptel.ac.in/courses/112/108/112108093/#\\n[course27]: https://www.apex.ai/autoware-course\\n[course28]: https://www.eecs.yorku.ca/course_archive/2017-18/W/4421/\\n[course29]: http://manipulation.mit.edu/\\n[course29b]: https://www.youtube.com/watch?v=PGY-4LOPs7U\\n[course30]: https://www.udemy.com/course/ros-essentials/learn/\\n[course31]: https://www.udemy.com/course/ros-navigation/\\n[course32]: https://nptel.ac.in/courses/107/106/107106090/\\n[course33]: https://cmsc828t.github.io/\\n[course34]: https://gaowenliang.github.io/HKUST-ELEC5660-Introduction-to-Aerial-Robots/index.html\\n[course35]: http://prg.cs.umd.edu/enae788m\\n[course40]: https://www.edx.org/course/self-driving-cars-with-duckietown\\n[course41]: https://www.edx.org/course/robotics-foundation-ii-robot-control\\n[course42]: https://www.edx.org/course/developmental-robotics\\n[course43]: https://www.youtube.com/watch?v=CmiJIKxtEOE&list=PLAuiGdPEdw0inlKisMbjDypCbvcb_GBN9\\n[course44]: https://rsl.ethz.ch/education-students/lectures/ros.html\\n\\n# Hands-on and Blogs\\n- ♥️ Mithi's Hexapod Robot Simulator [Live Demo][h29] | [Source Code][h30] | [In Real Life][h36]\\n- [♥️ Akiyuki Kawaguchi][h19]\\n- [📺 OpenDog][h14] + [Mini Robot Dog][h27], James Bruton\\n- [Building a DIY Arduino drone][h8] + [📺 channel][h13], Joop Brokking\\n- [DIY Walkers][h10], Ben Vagle\\n- [PythonRobotics][h25], Atsushi Sakai\\n- [Spot Mini Mini][h33] + [Open Quadruped][h34]\\n- [Duckie Town: Minimal Autonomy Platforms][h35]\\n- [F1/10 (Penn Engineering)][h5] | [AutoRally (GeorgiaTech)][h32]\\n- [Donkey Car][h1] | [DIY Robocars][h2] | [Formula Pi][h17]\\n- [MIT Race Car][h3] | [MIT RaceCar Team 5 Documentation][h4]\\n- [Jetson Hacks][h6] | [:dollar: Racecar RJ][h7]\\n- [Prof Daniela Rus][h26] | [Sarah Tang][h28] | [Beatty Robotics][h18]\\n- [Andrew Dahdouh][h11] | [Oscar Liang][h12] | [Maurice Rahme][h31]\\n\\n[h1]: http://www.donkeycar.com/\\n[h2]: http://diyrobocars.com/\\n[h3]: https://mit-racecar.github.io\\n[h4]: https://mit-racecar.github.io/6.141-spring-2016-team-5-documentation/\\n[h5]: http://f1tenth.org/lectures\\n[h6]: https://www.jetsonhacks.com/category/robotics/\\n[h7]:https://racecarj.com/\\n[h8]: http://www.brokking.net/ymfc-32_main.html\\n[h9]: https://dojofordrones.com/\\n[h10]: https://www.diywalkers.com/\\n[h11]: https://realitybytes.blog/\\n[h12]: https://oscarliang.com/\\n[h13]: https://www.youtube.com/user/MacPuffdog/playlists\\n[h14]: https://www.youtube.com/watch?v=0BoPoWF_FwY&list=PLpwJoq86vov_PkA0bla0eiUTsCAPi_mZf\\n[h15]: https://mithi.github.io/robotics-blog/\\n[h16]: https://github.com/mithi/hexapod-robot-simulator\\n[h17]: https://www.formulapi.com/\\n[h18]: https://beatty-robotics.com/\\n[h19]: https://akiyuki.jp/en/\\n[h25]: https://github.com/AtsushiSakai/PythonRobotics\\n[h26]: http://danielarus.csail.mit.edu/index.php/projects/\\n[h27]: https://www.youtube.com/watch?v=DfBF26DaT-M\\n[h28]: https://www.sarahtang.net/\\n[h29]: https://hexapod.netlify.app/\\n[h30]: https://github.com/mithi/hexapod\\n[h31]: https://moribots.github.io/\\n[h32]: https://autorally.github.io/\\n[h33]: https://github.com/OpenQuadruped/spot_mini_mini\\n[h34]: https://github.com/adham-elarabawy/open-quadruped\\n[h35]: https://www.duckietown.org/\\n[h36]: https://github.com/mithi/hexapod-irl\\n\\n# Useful Concepts and Tools\\n- CAD Tools: [Autodesk Fusion 360][tools10] | [OnShape][tools12]\\n- [♥️ 🐳 Deep Learning][tools1]\\n- [Hackertools: The Missing Semester of Your CS Education][tools15], MIT Open Learning\\n- Kalman Filters: [Roger R. Labbe][tools2] | [Balzer82][tools11]\\n- Control Systems: [📺 Steve Brunton][tools3] | [📺 Brian Douglas][tools4] | [Tyler Veness][tool5]\\n- Algorithms and Data Structures, C++, Python, Octave\\n- [♥️ More courses](https://github.com/mithi/robotics-coursework/issues/6#issuecomment-629713457)\\n\\n[tools1]: https://mithi.github.io/deep-blueberry/\\n[tools2]: https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/\\n[tools3]: https://youtu.be/Pi7l8mMjYVE?list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m\\n[tools4]: https://www.youtube.com/user/ControlLectures/featured\\n[tools10]: https://www.autodesk.com/products/fusion-360/students-teachers-educators\\n[tools11]: https://github.com/balzer82/Kalman\\n[tools12]: https://www.onshape.com/\\n[tool5]: https://github.com/calcmogul/controls-engineering-in-frc\\n[tools15]: https://missing.csail.mit.edu/\\n\\n# Archived Courses\\n- EdX: [Robotics: Locomotion Engineering][course36], Dan Koditschek, University of Pennsylvania\\n- EdX: [Robotics: Dynamics and Control][course37], Vijay Kumar, University of Pennsylvania\\n- EdX: [Robotics: Vision Intelligence and Machine Learning][course38], Jianbo Shi, University of Pennsylvania\\n- EdX: [Robotics: Kinematics and Mathematical Foundations][course39], Camillo Taylor, University of Pennsylvania\\n- Coursera: Control of Mobile Robots, Magnus Egerstedt, Georgia Institute of technology\\n\\n\\n[course36]: https://www.edx.org/course/robotics-locomotion-engineering\\n[course37]: https://www.edx.org/course/robotics-dynamics-and-control\\n[course38]: https://www.edx.org/course/robotics-vision-intelligence-and-machine-learning\\n[course39]: https://www.edx.org/course/robotics-kinematics-and-mathematical-foundations\\n\\n\\n# Related Lists\\n| [Ahundt](https://github.com/ahundt/awesome-robotics)\\n| [Jslee02](https://github.com/jslee02/awesome-robotics-libraries)\\n| [Kiloreux](https://github.com/Kiloreux/awesome-robotics)\\n| [Msadowki](https://github.com/msadowski/awesome-weekly-robotics)\\n| [Protontypes](https://github.com/protontypes/awesome-robotic-tooling)\\n| [Fkromer](https://github.com/fkromer/awesome-ros2)\\n| [HarshMaithani](https://medium.com/@harshmaithani09/a-fast-introduction-to-robotics-v-2-0-6d07516e053f)\\n| [Kanster](https://github.com/kanster/awesome-slam)\\n| [Papers Related to Quadrotors](https://github.com/prgumd/prg_QuadrotorPapers)\\n\\n# Misc\\n| [Adafruit](https://adafruit.com/)\\n| [Instructables][related1]\\n| [Hackster][related2]\\n| [Thingiverse][related3] \\n| [Hackaday](https://hackaday.com/)\\n| [Sparkfun](https://www.sparkfun.com/)\\n| [Robotshop][related4]\\n| [Robotics Today][related5]\\n| [Reddit](https://www.reddit.com/r/robotics/)\\n| [Youtube](https://github.com/mithi/robotics-coursework/issues/6#issue-608400679)\\n| [Planet GBC](http://www.planet-gbc.com/)\\n| [Euro Bricks](https://www.eurobricks.com/forum/index.php?/forums/topic/117305-gbc-the-akiyuki-project/)\\n\\n[related1]: https://www.instructables.com/howto/robot/\\n[related2]: https://www.hackster.io/search?i=projects&q=robot\\n[related3]: https://www.thingiverse.com/search?q=robot\\n[related4]: https://www.robotshop.com/community/robot\\n[related5]: https://roboticstoday.github.io/watch.html\\n\\n\\n# [🐳](https://mithi.github.io/deep-blueberry) [☕️](https://ko-fi.com/minimithi)\\n\"},\n",
       " {'repo': 'onlytailei/CppRobotics',\n",
       "  'language': 'C++',\n",
       "  'readme_contents': '# CppRobotics\\n\\nThis is the cpp implementation of the [PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics)\\n\\n## Requirment\\n- cmake\\n- opencv 3.3\\n- Eigen 3\\n- [CppAD](https://www.coin-or.org/CppAD/Doc/install.htm) / [IPOPT](https://www.coin-or.org/Ipopt/documentation/node14.html) (*for MPC convex optimization*) [install tips](https://github.com/udacity/CarND-MPC-Quizzes/blob/master/install_Ipopt_CppAD.md)\\n- ~~ROS~~ (*~~To make the repo lightweight :)~~. Yet, we may still need it for 3D visualization.*)\\n\\n## Build\\n     $ mkdir build\\n     $ cd build\\n     $ cmake ../\\n     $ make -j 8\\n\\nFind all the executable files in ***build/bin***.\\n\\n# Table of Contents\\n* [Localization](#localization)\\n    * [Extended kalmam filter](#extended-kalman-filter-localization)\\n    * [Particle filter](#particle-filter-localization)\\n    * Histogram filter\\n* [Mapping](#mapping)\\n    * Gaussian grid map\\n* [SLAM](#SLAM)\\n    * FastSLAM 1.0\\n* [Path Planning](#path-planning)\\n    * [Dijkstra](#dijkstra)\\n    * [A Star](#a-star)\\n    * [RRT](#rrt)\\n    * [Dynamic Window Approach](#dynamic-window-approach)\\n    * [Model Predictive Trajectory Generator](#model-predictive-trajectory-generator)\\n    * [Cubic Spline Planner](#cubic-spline-planner)\\n    * [State Lattice Planner](#state-lattice-planner)\\n    * [Frenet Frame Trajectory](#frenet-frame-trajectory)\\n* [Path Tracking Control](#path-tracking-control)\\n    * [LQR Sterring Control](#lqr-steering-control)\\n    * [LQR Speed and Steering Control](#lqr-speed-and-steering-control)\\n    * [Model Predictive Speed and Steering Control](#mpc-speed-and-steering-control)\\n* [Aerial Navigation](#aerial-navigation)\\n     * Drone 3D Trajectory Following\\n     * Rocket Powered Landing\\n\\n# Localization\\n## Extended Kalman Filter Localization\\n* green line: the groundtruth trajectory\\n* black line: dead reckoning\\n* red points: observations (e.g. GPS)\\n* blue line: estimated positions\\n\\n<!-- ![ekf_gif](./gif/ekf.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/ekf.gif\" alt=\"ekf\" width=\"400\"/>\\n\\n[Probabilistic Robotics](http://www.probabilistic-robotics.org/)\\n\\n## Particle Filter Localization\\n* green line: the groundtruth trajectory\\n* black line: dead reckoning\\n* red points: landmarks\\n* blue line: estimated positions\\n\\n<!-- ![pf_gif](./gif/pf.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/pf.gif\" alt=\"pf\" width=\"400\"/>\\n\\n[Probabilistic Robotics](http://www.probabilistic-robotics.org/)\\n\\n# Path Planning\\n\\n## Dijkstra\\n* blue point: the start point\\n* red point: the goal point\\n<img src=\"https://ram-lab.com/file/tailei/gif/dijkstra.gif\" alt=\"dijkstra\" width=\"400\"/>\\n\\n## A star\\n* blue point: the start point\\n* red point: the goal point\\n<img src=\"https://ram-lab.com/file/tailei/gif/a_star.gif\" alt=\"a_star\" width=\"400\"/>\\n\\n## RRT\\n* red circle: the start point\\n* blue circle: the goal point\\n* black circle: obstacles\\n<img src=\"https://ram-lab.com/file/tailei/gif/rrt.gif\" alt=\"rrt\" width=\"400\"/>\\n\\n## Dynamic Window Approach\\n* blue circle: the target point\\n* red circle: the robot\\n\\n<!-- ![dwa_gif](./gif/dwa.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/dwa.gif\" alt=\"dwa\" width=\"400\"/>\\n\\n[The dynamic window approach to collision avoidance](https://ieeexplore.ieee.org/document/580977)\\n\\n## Model Predictive Trajectory Generator\\nThis part is based on the bicycle motion model.\\n* blue circle: the target point\\n* red circle: the initial point\\n\\n<!-- ![mptg_gif](./gif/mptg.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/mptg.gif\" alt=\"mptg\" width=\"400\"/>\\n\\n## Cubic Spline Planner\\n\\n<!-- ![mptg_gif](./gif/csp.png =500x) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/csp.png\" alt=\"csp\" width=\"400\"/>\\n\\n## State Lattice Planner\\n* blue circle: the target point\\n* red circle: the initial point\\n\\n<!-- ![mptg_gif](./gif/slp.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/slp.gif\" alt=\"slp\" width=\"400\"/>\\n\\n[State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments](https://www.ri.cmu.edu/pub_files/pub4/howard_thomas_2008_1/howard_thomas_2008_1.pdf)\\n\\n## Frenet Frame Trajectory\\n\\n* black line: the planned spline path\\n* red circle: the obstacle\\n* blue circle: the planned trajectory\\n* green circle: the real-time position of robot\\n\\n<img src=\"https://ram-lab.com/file/tailei/gif/frenet.gif\" alt=\"frenet\" width=\"400\"/>\\n\\n[Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame](https://www.researchgate.net/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame)\\n\\n\\n# Path Tracking Control\\n## LQR Steering Control\\n* black line: the planned spline path\\n* red circle: the position under lqr control\\n\\n<img src=\"https://ram-lab.com/file/tailei/gif/lqr_steering.gif\" alt=\"lqr_steering\" width=\"400\"/>\\n\\n\\n## LQR Speed and Steering Control\\n* black line: the planned spline path\\n* red circle: the position under lqr control\\n\\n<img src=\"https://ram-lab.com/file/tailei/gif/lqr_full.gif\" alt=\"lqr_full\" width=\"400\"/>\\n\\n\\n## MPC Speed and Steering Control\\n* black line: the planned spline path\\n* blue line: the passed path\\n* yellow cross: the reference trajectory for MPC    \\n(To compile this part, you need to uncomment the related lines in CMakeLists.txt and install [CppAD](https://www.coin-or.org/CppAD/Doc/install.htm) and [IPOPT](https://coin-or.github.io/Ipopt/).)\\n\\n<img src=\"https://ram-lab.com/file/tailei/gif/mpc.gif\" alt=\"mpc\" width=\"400\"/>\\n'},\n",
       " {'repo': 'JdeRobot/RoboticsAcademy',\n",
       "  'language': 'JavaScript',\n",
       "  'readme_contents': '<a href=\"https://jderobot.github.io/\"><img src=\"./img/logo.gif\" width=\"150\" align=\"right\" /></a>\\n\\n# RoboticsAcademy: Learn Robotics, Artificial Intelligence and Computer Vision\\n\\nJdeRobot Academy is an **open source**  platform that has a collection of exercises to learn robotics in a practical way. Gazebo simulator is the main tool required for testing with ROS. Its latest documentation (including installation recipes, current available exercises and illustrative videos) is on its <a href=\"https://jderobot.github.io/RoboticsAcademy\">webpage</a>.\\n\\nIf you are a contributor, please note that we use GitHub Pages and a Jekyll theme (MinimalMistakes) for Academy web page. Feel free to install Jekyll locally, so that, you can test your changes before submitting your pull-request.\\n\\n## How to contribute?\\n\\nTake a look at the [contributing](CONTRIBUTING.md) guide lines.\\n\\n\\n\\n## INDEX\\n- [Instructions for developers.][]\\n- [Client side.][] (Robotics Academy architecture)\\n- [Repository Architecture.][]\\n- [Generate a mini RADI.][]\\n- [Humble mini RADI structure.][]\\n- [Develop using volume binding.][]\\n\\n[Instructions for developers.]: ./docs/InstructionsForDevelopers.md\\n[Client side.]: ./docs/clientside.md\\n[Repository Architecture.]: ./docs/RepositoryArchitecture.md\\n[Generate a mini RADI.]: ./docs/generate_a_mini_radi.md\\n[Humble mini RADI structure.]: ./scripts/mini_RADI/README.md\\n[Develop using volume binding.]: ./docs/develop_binding_volumes.md\\n'},\n",
       " {'repo': 'pptacher/probabilistic_robotics',\n",
       "  'language': 'C++',\n",
       "  'readme_contents': '# probabilistic_robotics\\nI am working on detailed solutions of exercises of the book \"probabilistic robotics\". This is a work in progress, any helpful feedback is welcomed.\\n\\nI also deployed the fastslam nodejs/c++ app on google cloud [here](http://35.242.140.13:8080) (server running from 0000 to 0800 UTC).\\n\\n![alt text](https://github.com/pptacher/probabilistic_robotics/blob/master/ch12_the_sparse_extended_information_filter/seif.jpg)\\n***SEIF** algorithm running on Victoria Park dataset*\\n\\n\\n## references\\n\\n- *Probabilistic robotics*, *MIT press*, Sebastian Thrun, Wolfram Burgard and Dieter Fox, [Probabilistic Robotics](https://mitpress.mit.edu/books/probabilistic-robotics)\\n\\n- *Victoria Park dataset*, The University of Sidney, Eduardo Nebot, [Victoria Park dataset](http://www-personal.acfr.usyd.edu.au/nebot/victoria_park.htm)\\n'},\n",
       " {'repo': 'jslee02/awesome-robotics-libraries',\n",
       "  'language': None,\n",
       "  'readme_contents': '# Awesome Robotics Libraries\\n\\nA curated list of robotics simulators and libraries.\\n\\n#### Table of Contents\\n* [Simulators](#simulators)\\n* [Libraries](#libraries)\\n  * [Dynamics Simulation](#dynamics-simulation)\\n  * [Inverse Kinematics](#inverse-kinematics)\\n  * [Machine Learning](#machine-learning)\\n  * [Motion Planning and Control](#motion-planning-and-control)\\n  * [Optimization](#optimization)\\n  * [Robot Modeling](#robot-modeling)\\n  * [Robot Platform](#robot-platform)\\n  * [SLAM](#slam)\\n  * [Vision](#vision)\\n  * [Fluid](#fluid)\\n  * [Multiphysics](#multiphysics)\\n  * [Math](#math)\\n  * [ETC](#etc)\\n* [Other Awesome Lists](#other-awesome-lists)\\n* [Contributing](#contributing)\\n\\n## [Simulators](#awesome-robotics-libraries)\\n\\n###### Free or Open Source\\n\\n* [AI2-THOR](https://ai2thor.allenai.org/) - Python framework with a Unity backend, providing interaction, navigation, and manipulation support for household based robotic agents [[github](https://github.com/allenai/ai2thor) ![AI2-THOR](https://img.shields.io/github/stars/allenai/ai2thor.svg?style=flat&label=Star&maxAge=86400)]\\n* AirSim - Simulator based on Unreal Engine for autonomous vehicles [[github](https://github.com/Microsoft/AirSim) ![AirSim](https://img.shields.io/github/stars/Microsoft/AirSim.svg?style=flat&label=Star&maxAge=86400)]\\n* [ARGoS](https://www.argos-sim.info/) - Physics-based simulator designed to simulate large-scale robot swarms [[github](https://github.com/ilpincy/argos3) ![ilpincy/argos3](https://img.shields.io/github/stars/ilpincy/argos3.svg?style=flat&label=Star&maxAge=86400)]\\n* [ARTE](http://arvc.umh.es/arte/index_en.html) - Matlab toolbox focussed on robotic manipulators [[github](https://github.com/4rtur1t0/ARTE) ![4rtur1t0/ARTE](https://img.shields.io/github/stars/4rtur1t0/ARTE.svg?style=flat&label=Star&maxAge=86400)]\\n* [AVIS Engine](https://avisengine.com) - Autonomous Vehicles Intelligent simulation software, A Fast and robust simulator software for Autonomous vehicle development. [[github](https://github.com/AvisEngine/AVIS-Engine-Python-API) ![AvisEngine/AVIS-Engine-Python-API](https://img.shields.io/github/stars/AvisEngine/AVIS-Engine-Python-API.svg?style=flat&label=Star&maxAge=86400)]\\n* [CARLA](http://carla.org/) - Open-source simulator for autonomous driving research [[github](https://github.com/carla-simulator/carla) ![carla-simulator/carla](https://img.shields.io/github/stars/carla-simulator/carla.svg?style=flat&label=Star&maxAge=86400)]\\n* [CoppeliaSim](http://www.coppeliarobotics.com/) - Formaly V-REP. Virtual robot experimentation platform [[github](https://github.com/CoppeliaRobotics/CoppeliaSimLib) ![CoppeliaRobotics/CoppeliaSimLib](https://img.shields.io/github/stars/CoppeliaRobotics/CoppeliaSimLib.svg?style=flat&label=Star&maxAge=86400)]\\n* [Gazebo](http://gazebosim.org/) - Dynamic multi-robot simulator [[github](https://github.com/osrf/gazebo) ![osrf/gazebo](https://img.shields.io/github/stars/osrf/gazebo.svg?style=flat&label=Star&maxAge=86400)]\\n* [GraspIt!](http://graspit-simulator.github.io/) - Simulator for grasping research that can accommodate arbitrary hand and robot designs [[github](https://github.com/graspit-simulator/graspit) ![graspit](https://img.shields.io/github/stars/graspit-simulator/graspit.svg?style=flat&label=Star&maxAge=86400)]\\n* [Habitat-Sim](https://aihabitat.org/) - Simulation platform for research in embodied artificial intelligence [[github](https://github.com/facebookresearch/habitat-sim) ![facebookresearch/habitat-sim](https://img.shields.io/github/stars/facebookresearch/habitat-sim.svg?style=flat&label=Star&maxAge=86400)]\\n* [Hexapod Robot Simulator](https://hexapod.netlify.app/) - Open-source hexapod robot inverse kinematics and gaits visualizer [[github](https://github.com/mithi/hexapod) ![mithi/hexapod](https://img.shields.io/github/stars/mithi/hexapod.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ignition Gazebo](https://ignitionrobotics.org/home) - Open source robotics simulator [[github](https://github.com/ignitionrobotics/ign-gazebo) ![ignitionrobotics/ign-gazebo](https://img.shields.io/github/stars/ignitionrobotics/ign-gazebo.svg?style=flat&label=Star&maxAge=86400)]\\n* [Isaac](https://www.nvidia.com/en-us/deep-learning-ai/industries/robotics/) - Nvidia\\'s virtual simulator for robots\\n* [MORSE](http://morse-simulator.github.io/) - Modular open robots simulation engine [[github](https://github.com/morse-simulator/morse) ![morse](https://img.shields.io/github/stars/morse-simulator/morse.svg?style=flat&label=Star&maxAge=86400)]\\n* [Neurorobotics Platform](https://neurorobotics.net/) - Internet-accessible simulation of robots controlled by spiking neural networks [[bitbucket](https://bitbucket.org/hbpneurorobotics/neurorobotics-platform)]\\n* [PyBullet](https://docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA/edit#heading=h.2ye70wns7io3) - An easy to use simulator for robotics and deep reinforcement learning [[github](https://github.com/bulletphysics/bullet3) ![bullet3](https://img.shields.io/github/stars/bulletphysics/bullet3.svg?style=flat&label=Star&maxAge=86400)]\\n* [PyBullet_Industrial](https://pybullet-industrial.readthedocs.io/en/latest/) - A extension to PyBullet that allows for the simulation of various robotic manufacturing processes such as milling or 3D-printing. [[github](https://github.com/WBK-Robotics/pybullet_industrial) ![pybullet_industrial](https://img.shields.io/github/stars/WBK-Robotics/pybullet_industrial.svg?style=flat&label=Star&maxAge=86400)]\\n* [Robot Gui](http://robot.glumb.de/) - A three.js based 3D robot interface [[github](https://github.com/glumb/robot-gui) ![glumb/robot-gui](https://img.shields.io/github/stars/glumb/robot-gui.svg?style=flat&label=Star&maxAge=86400)]\\n* [Simbad](http://simbad.sourceforge.net/) - A Java 3D robot simulator, enables to write own robot controller with modifying environment using available sensors.\\n* [Unity](https://unity.com/solutions/automotive-transportation-manufacturing/robotics) - Popular game engine that now offers open-source tools, tutorials, and resources for robotics simulation [[github](https://github.com/Unity-Technologies/Unity-Robotics-Hub) ![Unity-Technologies/Unity-Robotics-Hub](https://img.shields.io/github/stars/Unity-Technologies/Unity-Robotics-Hub.svg?style=flat&label=Star&maxAge=86400)]\\n* [Webots](http://www.cyberbotics.com/) - Robot simulator that provides a complete development environment [[github](https://github.com/omichel/webots) ![omichel/webots](https://img.shields.io/github/stars/omichel/webots.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### Commercial\\n\\n* [Actin Simulation](http://www.energid.com/)\\n* [Artiminds](https://www.artiminds.com/) - Planning, programming, operation, analysis and optimization\\n* [Kineo](https://www.plm.automation.siemens.com/global/en/products/plm-components/kineo.html) - Path planning and trajectory optimization for industrial robotics and digital mock-up review applications\\n* [RobotDK](https://robodk.com/) - Simulation and OLP for robots\\n* [RobotStudio](http://new.abb.com/products/robotics/robotstudio)\\n* [Robot Virtual Worlds](http://www.robotvirtualworlds.com/)\\n* [Virtual Robotics Toolkit](https://www.virtualroboticstoolkit.com/)\\n* [Visual Components](https://www.visualcomponents.com/)\\n\\n###### Cloud\\n\\n* [AWS RoboMaker](https://aws.amazon.com/robomaker/) - Service that makes it easy to develop, test, and deploy intelligent robotics applications at scale\\n\\n## [Libraries](#awesome-robotics-libraries)\\n\\n### [Dynamics Simulation](#awesome-robotics-libraries)\\n\\n> :warning: The following table is not complete. Please feel free to report if you find something incorrect or missing.\\n\\n| Name | Models | Features | Languages | Licenses | Code | Popularity |\\n|:----:| ------ | -------- | --------- | -------- | ---- | ---------- |\\n| [ARCSim](http://graphics.berkeley.edu/resources/ARCSim/index.html) | soft |  | C++ | | |  |\\n| [Bullet](http://bulletphysics.org) | rigid, soft | ik, id, urdf, sdf | C++, Python | Zlib | [github](https://github.com/bulletphysics/bullet3) | ![bullet3](https://img.shields.io/github/stars/bulletphysics/bullet3.svg?style=flat&label=Star&maxAge=86400) |\\n| [CHRONO::ENGINE](http://chronoengine.info/) | rigid, soft, granular, fluid | ik, urdf | C++, Python | BSD-3-Clause | [github](https://github.com/projectchrono/chrono) | ![chrono](https://img.shields.io/github/stars/projectchrono/chrono.svg?style=flat&label=Star&maxAge=86400) |\\n| [DART](http://dartsim.github.io/) | rigid, soft | ik, id, plan, urdf, sdf | C++, Python | BSD-2-Clause | [github](https://github.com/dartsim/dart.git) | ![dart](https://img.shields.io/github/stars/dartsim/dart.svg?style=flat&label=Star&maxAge=86400) |\\n| [Drake](http://drake.mit.edu/) | rigid, aero, fluid | ik, trj-opt, plan | C++, Matlab | BSD-3-Clause | [github](https://github.com/RobotLocomotion/drake) | ![drake](https://img.shields.io/github/stars/RobotLocomotion/drake.svg?style=flat&label=Star&maxAge=86400) |\\n| [Flex](https://developer.nvidia.com/flex) | rigid, soft, particle, fluid  | | C++ | | [github](https://github.com/NVIDIAGameWorks/FleX) | ![NVIDIAGameWorks/FleX](https://img.shields.io/github/stars/NVIDIAGameWorks/FleX.svg?style=flat&label=Star&maxAge=86400) |\\n| [FROST](https://ayonga.github.io/frost-dev/index.html) | rigid  | | MATLAB | BSD-3-Clause | [github](https://github.com/ayonga/frost-dev) | ![ayonga/frost-dev](https://img.shields.io/github/stars/ayonga/frost-dev.svg?style=flat&label=Star&maxAge=86400) |\\n| [IBDS](http://www.interactive-graphics.de/index.php/downloads/12-ibds) | rigid, particle | | C++ | Zlib | | |\\n| idyntree | rigid | id | C++, Python, Matlab, Lua | LGPL-2.1 | [github](https://github.com/robotology/idyntree) | ![idyntree](https://img.shields.io/github/stars/robotology/idyntree.svg?style=flat&label=Star&maxAge=86400) |\\n| [KDL](http://www.orocos.org/kdl) | rigid | ik | C++ | LGPL-2.1 | [github](https://github.com/orocos/orocos_kinematics_dynamics) | ![orocos_kinematics_dynamics](https://img.shields.io/github/stars/orocos/orocos_kinematics_dynamics.svg?style=flat&label=Star&maxAge=86400) |\\n| kindr | rigid | (todo) | C++, Matlab | BSD-3-Clause | [github](https://github.com/ANYbotics/kindr) | ![kindr](https://img.shields.io/github/stars/ANYbotics/kindr.svg?style=flat&label=Star&maxAge=86400) |\\n| [Klampt](http://motion.pratt.duke.edu/klampt/) | (todo) | (todo) | C++, Python | BSD-3-Clause | [github](https://github.com/krishauser/Klampt) | ![Klampt](https://img.shields.io/github/stars/krishauser/Klampt.svg?style=flat&label=Star&maxAge=86400) |\\n| [LibrePilot](http://www.librepilot.org/site/index.html) | uav, vehicles | (todo) | C++ | GPL-3.0 | [bitbucket](https://bitbucket.org/librepilot/librepilot), [github](https://github.com/librepilot/LibrePilot) | ![LibrePilot](https://img.shields.io/github/stars/librepilot/LibrePilot.svg?style=flat&label=Star&maxAge=86400) |\\n| [MARS](http://rock-simulation.github.io/mars/) | (todo) | (todo) | C++, Python | LGPL-3.0 | [github](https://github.com/rock-simulation/mars) | ![mars](https://img.shields.io/github/stars/rock-simulation/mars.svg?style=flat&label=Star&maxAge=86400) |\\n| [MBDyn](https://www.mbdyn.org/) | (todo) | (todo) | C++ | GPL-2.1 | [download](https://www.mbdyn.org/?Software_Download) | |\\n| [MBSim](https://www.mbsim-env.de/mbsim/html/index.html) | (todo) | (todo) | C++ | (not specified) | [github](https://github.com/mbsim-env/mbsim) | ![mbsim-env/mbsim](https://img.shields.io/github/stars/mbsim-env/mbsim.svg?style=flat&label=Star&maxAge=86400) |\\n| [MBSlib](http://www.sim.informatik.tu-darmstadt.de/res/sw/mbslib) | (todo) | (todo) | C++ | LGPL-3.0 | [github](https://github.com/SIM-TU-Darmstadt/mbslib) | ![mbslib](https://img.shields.io/github/stars/SIM-TU-Darmstadt/mbslib.svg?style=flat&label=Star&maxAge=86400) |\\n| metapod | (todo) | (todo) | C++ | LGPL-3.0 | [github](https://github.com/laas/metapod) | ![metapod](https://img.shields.io/github/stars/laas/metapod.svg?style=flat&label=Star&maxAge=86400) |\\n| [Moby](http://physsim.sourceforge.net/index.html) | rigid | id | C++ | GPL-2.0 | [github](https://github.com/PositronicsLab/Moby) | ![Moby](https://img.shields.io/github/stars/PositronicsLab/Moby.svg?style=flat&label=Star&maxAge=86400) |\\n| [mrpt](http://www.mrpt.org/) | vehicle | slam, cv | C++, Python, Matlab | BSD-3-Clause | [github](https://github.com/MRPT/mrpt) | ![mrpt](https://img.shields.io/github/stars/MRPT/mrpt.svg?style=flat&label=Star&maxAge=86400) |\\n| [MuJoCo](http://www.mujoco.org/index.html) | (todo) | id | C++, Python | [licenses](https://www.roboti.us/license.html) | closed source | |\\n| [mvsim](http://wiki.ros.org/mvsim) | vehicle | (todo) | C++ | GPL-3.0 | [github](https://github.com/ual-arm-ros-pkg/mvsim) | ![ual-arm-ros-pkg/mvsim](https://img.shields.io/github/stars/ual-arm-ros-pkg/mvsim.svg?style=flat&label=Star&maxAge=86400) |\\n| [Newton Dynamics](http://newtondynamics.com/) | (todo) | (todo) | C++ | Zlib | [github](https://github.com/MADEAPPS/newton-dynamics) | ![newton-dynamics](https://img.shields.io/github/stars/MADEAPPS/newton-dynamics.svg?style=flat&label=Star&maxAge=86400) |\\n| [nphysics](http://nphysics.org/) | (todo) | (todo) | Rust | BSD-3-Clause | [github](https://github.com/sebcrozet/nphysics) | ![sebcrozet/nphysics](https://img.shields.io/github/stars/sebcrozet/nphysics.svg?style=flat&label=Star&maxAge=86400) |\\n| [ODE](http://www.ode.org/) | rigid | | C++ | LGPL-2.1 or BSD-3-Clause | [bitbucket](https://bitbucket.org/odedevs/ode) | |\\n| [OpenRAVE](http://www.openrave.org) | (todo) | (todo) | C++, Python | LGPL-3.0 | [github](https://github.com/rdiankov/openrave) | ![openrave](https://img.shields.io/github/stars/rdiankov/openrave.svg?style=flat&label=Star&maxAge=86400) |\\n| [pinocchio](https://stack-of-tasks.github.io/pinocchio/) | rigid | ik, id, urdf, analytical derivatives, code generation | C++, Python | BSD-2-Clause | [github](https://github.com/stack-of-tasks/pinocchio) | ![pinocchio](https://img.shields.io/github/stars/stack-of-tasks/pinocchio.svg?style=flat&label=Star&maxAge=86400) |\\n| PositionBasedDynamics | (todo) | (todo) | C++ | MIT | [github](https://github.com/InteractiveComputerGraphics/PositionBasedDynamics) | ![PositionBasedDynamics](https://img.shields.io/github/stars/InteractiveComputerGraphics/PositionBasedDynamics.svg?style=flat&label=Star&maxAge=86400) |\\n| [PhysX](https://docs.nvidia.com/gameworks/content/gameworkslibrary/physx/guide/Manual/Index.html) | (todo) | (todo) | C++ | unknown | [github](https://github.com/NVIDIAGameWorks/PhysX) | ![NVIDIAGameWorks/PhysX](https://img.shields.io/github/stars/NVIDIAGameWorks/PhysX.svg?style=flat&label=Star&maxAge=86400) |\\n| [PyDy](http://www.pydy.org/) | (todo) | (todo) | Python | BSD-3-Clause | [github](https://github.com/pydy/pydy) | ![pydy](https://img.shields.io/github/stars/pydy/pydy.svg?style=flat&label=Star&maxAge=86400) |\\n| [RBDL](https://rbdl.github.io/) | rigid | ik,id,urdf | C++, Python | Zlib | [github](https://github.com/rbdl/rbdl) | ![rbdl](https://img.shields.io/github/stars/rbdl/rbdl.svg?style=flat&label=Star&maxAge=86400) |\\n| RBDyn | rigid | (todo) | C++, Python | LGPL-3.0 | [github](https://github.com/jrl-umi3218/RBDyn) | ![RBDyn](https://img.shields.io/github/stars/jrl-umi3218/RBDyn.svg?style=flat&label=Star&maxAge=86400) |\\n| [RaiSim](https://slides.com/jeminhwangbo/raisim-manual) | (todo) | (todo) | C++ | [custom](https://github.com/leggedrobotics/raisimLib/blob/a9e7673569997f35c0bc7eb5d11bc4fa188e863c/LICENSE.md) | [github](https://github.com/leggedrobotics/raisimLib) | ![leggedrobotics/raisimLib](https://img.shields.io/github/stars/leggedrobotics/raisimLib.svg?style=flat&label=Star&maxAge=86400) |\\n| [ReactPhysics3d](http://www.reactphysics3d.com/) | (todo) | (todo) | C++ | Zlib | [github](https://github.com/DanielChappuis/reactphysics3d) | ![reactphysics3d](https://img.shields.io/github/stars/DanielChappuis/reactphysics3d.svg?style=flat&label=Star&maxAge=86400) |\\n| RigidBodyDynamics.jl | rigid | (todo) | Julia | MIT \"Expat\" | [github](https://github.com/JuliaRobotics/RigidBodyDynamics.jl) | ![RigidBodyDynamics.jl](https://img.shields.io/github/stars/JuliaRobotics/RigidBodyDynamics.jl.svg?style=flat&label=Star&maxAge=86400) |\\n| [Rigs of Rods](https://www.rigsofrods.org/) | rigid, soft, vehicle | (todo) | C++ | GPL-3.0 | [github](https://github.com/RigsOfRods/rigs-of-rods) | ![RigsOfRods/rigs-of-rods](https://img.shields.io/github/stars/RigsOfRods/rigs-of-rods.svg?style=flat&label=Star&maxAge=86400) |\\n| [Robopy](https://adityadua24.github.io/robopy/) | (todo) | (todo) | Python 3 | MIT | [github](https://github.com/adityadua24/robopy) | ![adityadua24/robopy](https://img.shields.io/github/stars/adityadua24/robopy.svg?style=flat&label=Star&maxAge=86400) |\\n| [robosuite](https://robosuite.ai/) | (todo) | (todo) | Python | MIT | [github](https://github.com/ARISE-Initiative/robosuite) | ![ARISE-Initiative/robosuite](https://img.shields.io/github/stars/ARISE-Initiative/robosuite.svg?style=flat&label=Star&maxAge=86400) |\\n| [Robotics Library](http://www.roboticslibrary.org/) | (todo) | (todo) | C++ | GPL-3.0 or BSD-2-Clause | [github](https://github.com/roboticslibrary/rl) | ![rl](https://img.shields.io/github/stars/roboticslibrary/rl.svg?style=flat&label=Star&maxAge=86400) |\\n| [RobWork](http://www.robwork.dk/apidoc/nightly/rw/index.html) | (todo) | (todo) | C++ | Apache-2.0 | [gitlab](https://gitlab.com/sdurobotics/RobWork) | |\\n| [siconos](http://siconos.gforge.inria.fr) | (todo) | (todo) | C++, Python | Apache-2.0 | [github](https://github.com/siconos/siconos) | ![siconos](https://img.shields.io/github/stars/siconos/siconos.svg?style=flat&label=Star&maxAge=86400) |\\n| [Simbody](https://simtk.org/home/simbody/) | rigid, molecules | id, urdf | C++ | Apache-2.0 | [github](https://github.com/simbody/simbody.git) | ![simbody](https://img.shields.io/github/stars/simbody/simbody.svg?style=flat&label=Star&maxAge=86400) |\\n| [SOFA](https://www.sofa-framework.org/) | rigid, soft, medical | (todo) | C++ | LGPL-2.1 | [github](https://github.com/sofa-framework/sofa) | ![sofa](https://img.shields.io/github/stars/sofa-framework/sofa.svg?style=flat&label=Star&maxAge=86400) |\\n| Tiny Differentiable Simulator | rigid | (todo) | C++, Python | Apache-2.0 | [github](https://github.com/google-research/tiny-differentiable-simulator) | ![google-research/tiny-differentiable-simulator](https://img.shields.io/github/stars/google-research/tiny-differentiable-simulator.svg?style=flat&label=Star&maxAge=86400) |\\n| [trep](http://murpheylab.github.io/trep/) | rigid | dm, trj-opt | C, Python | GPL-3.0 | [github](https://github.com/MurpheyLab/trep) | ![trep](https://img.shields.io/github/stars/MurpheyLab/trep.svg?style=flat&label=Star&maxAge=86400) |\\n| qu3e | rigid | - | C++ | Zlib | [github](https://github.com/RandyGaul/qu3e) | ![qu3e](https://img.shields.io/github/stars/RandyGaul/qu3e.svg?style=flat&label=Star&maxAge=86400) |\\n\\nFor simplicity, shortened names are used to represent the supported models and features as\\n\\n* Supported Models\\n  * rigid: rigid bodies\\n  * soft: soft bodies\\n  * aero: aerodynamics\\n  * granular: granular materials (like sand)\\n  * fluid: fluid dynamics\\n  * vehicles\\n  * uav: unmanned aerial vehicles (like drones)\\n  * medical\\n  * molecules\\n  * parallel: parallel mechanism (like Stewart platform)\\n\\n* Features on Simulation, Analysis, Planning, Control Design\\n  * dm: [discrete mechanics](https://www.cambridge.org/core/journals/acta-numerica/article/div-classtitlediscrete-mechanics-and-variational-integratorsdiv/C8F45478A9290DEC24E63BB7FBE3CEB5)\\n  * ik: [inverse kinematics](https://en.wikipedia.org/wiki/Inverse_kinematics) solvers (please find IK specialized packages in [this list](#inverse-kinematics))\\n  * id: [inverse dynamics](https://en.wikipedia.org/wiki/Inverse_dynamics)\\n  * slam: [simultaneous localization and mapping](https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping)\\n  * trj-opt: trajectory optimization\\n  * plan: motion planning algorithms\\n  * cv: computer vision\\n  * urdf: [urdf](http://wiki.ros.org/urdf) parser\\n  * sdf: [sdf](http://sdformat.org/) parser\\n\\n### [Inverse Kinematics](#awesome-robotics-libraries)\\n\\n  * IKBT - A python package to solve robot arm inverse kinematics in symbolic form [[github](http://github.com/uw-biorobotics/IKBT) ![uw-biorobotics/IKBT](https://img.shields.io/github/stars/uw-biorobotics/IKBT.svg?style=flat&label=Star&maxAge=86400)]\\n  * Lively - A highly configurable toolkit for commanding robots in mixed modalities [[github](https://github.com/Wisc-HCI/lively) ![Wisc-HCI/lively](https://img.shields.io/github/stars/Wisc-HCI/lively.svg?style=flat&label=Star&maxAge=86400)]\\n  * RelaxedIK - Real-time Synthesis of Accurate and Feasible Robot Arm Motion [[github](http://github.com/uwgraphics/relaxed_ik) ![uwgraphics/relaxed_ik](https://img.shields.io/github/stars/uwgraphics/relaxed_ik.svg?style=flat&label=Star&maxAge=86400)]\\n  * [Trip](https://trip-kinematics.readthedocs.io/en/main/index.html) - A python package that solves inverse kinematics of parallel-, serial- or hybrid-robots [[github](https://github.com/TriPed-Robot/TriP) ![TriPed-Robot/TriP](https://img.shields.io/github/stars/TriPed-Robot/TriP.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Machine Learning](#awesome-robotics-libraries)\\n\\n* [AllenAct](https://allenact.org/) - Python/PyTorch-based Research Framework for Embodied AI [[github](http://github.com/allenai/allenact) ![wichtounet/dll](https://img.shields.io/github/stars/allenai/allenact.svg?style=flat&label=Star&maxAge=86400)]\\n* DLL - Deep Learning Library (DLL) for C++ [[github](http://github.com/wichtounet/dll) ![wichtounet/dll](https://img.shields.io/github/stars/wichtounet/dll.svg?style=flat&label=Star&maxAge=86400)]\\n* [DyNet](https://dynet.readthedocs.io/en/latest/) - The Dynamic Neural Network Toolkit [[github](http://github.com/clab/dynet) ![clab/dynet](https://img.shields.io/github/stars/clab/dynet.svg?style=flat&label=Star&maxAge=86400)]\\n* [Fido](http://fidoproject.github.io/) - Lightweight C++ machine learning library for embedded electronics and robotics [[github](http://github.com/FidoProject/Fido) ![FidoProject/Fido](https://img.shields.io/github/stars/FidoProject/Fido.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ivy]([http://fidoproject.github.io/](https://lets-unify.ai/)) - Unified Machine Learning Framework [[github](http://github.com/unifyai/ivy) ![unifyai/ivy](https://img.shields.io/github/stars/unifyai/ivy.svg?style=flat&label=Star&maxAge=86400)]\\n* MiniDNN - A header-only C++ library for deep neural networks [[github](https://github.com/yixuan/MiniDNN) ![yixuan/MiniDNN](https://img.shields.io/github/stars/yixuan/MiniDNN.svg?style=flat&label=Star&maxAge=86400)]\\n* [mlpack](http://www.mlpack.org/) - Scalable C++ machine learning library [[github](http://github.com/mlpack/mlpack) ![mlpack/mlpack](https://img.shields.io/github/stars/mlpack/mlpack.svg?style=flat&label=Star&maxAge=86400)]\\n* [OpenAI Gym](https://gym.openai.com/) - Developing and comparing reinforcement learning algorithms [[github](http://github.com/openai/gym) ![gym](https://img.shields.io/github/stars/openai/gym.svg?style=flat&label=Star&maxAge=86400)]\\n  * gym-dart [[github](http://github.com/DartEnv/dart-env) ![dart-env](https://img.shields.io/github/stars/DartEnv/dart-env.svg?style=flat&label=Star&maxAge=86400)]\\n  * gym-gazebo [[github](http://github.com/erlerobot/gym-gazebo) ![dart-env](https://img.shields.io/github/stars/erlerobot/gym-gazebo.svg?style=flat&label=Star&maxAge=86400)]\\n* [RLLib](http://web.cs.miami.edu/home/saminda/rllib.html) - Temporal-difference learning algorithms in reinforcement learning [[github](http://github.com/samindaa/RLLib) ![samindaa/RLLib](https://img.shields.io/github/stars/samindaa/RLLib.svg?style=flat&label=Star&maxAge=86400)]\\n* [tiny-dnn](http://tiny-dnn.readthedocs.io/en/latest/) - Header only, dependency-free deep learning framework in C++14 [[github](http://github.com/tiny-dnn/tiny-dnn) ![tiny-dnn/tiny-dnn](https://img.shields.io/github/stars/tiny-dnn/tiny-dnn.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Motion Planning and Control](#awesome-robotics-libraries)\\n\\n* [AIKIDO](https://github.com/personalrobotics/aikido) - Solving robotic motion planning and decision making problems. [[github](https://github.com/personalrobotics/aikido) ![aikido](https://img.shields.io/github/stars/personalrobotics/aikido.svg?style=flat&label=Star&maxAge=86400)]\\n* Bioptim - Bioptim, a Python Framework for Musculoskeletal Optimal Control in Biomechanics [[github](https://github.com/pyomeca/bioptim) ![pyomeca/bioptim](https://img.shields.io/github/stars/pyomeca/bioptim.svg?style=flat&label=Star&maxAge=86400)]\\n* [CuiKSuite](http://www.iri.upc.edu/people/porta/Soft/CuikSuite2-Doc/html) - Applications to solve position analysis and path planning problems\\n* [Control Toolbox](https://ethz-adrl.github.io/ct/) - Open-Source C++ Library for Robotics, Optimal and Model Predictive Control [[github](https://github.com/ethz-adrl/control-toolbox) ![ethz-adrl/control-toolbox](https://img.shields.io/github/stars/ethz-adrl/control-toolbox.svg?style=flat&label=Star&maxAge=86400)]\\n* Crocoddyl - Optimal control library for robot control under contact sequence [[github](https://github.com/loco-3d/crocoddyl) ![loco-3d/crocoddyl](https://img.shields.io/github/stars/loco-3d/crocoddyl.svg?style=flat&label=Star&maxAge=86400)]\\n* Fields2Cover - Robust and efficient coverage paths for autonomous agricultural vehicles [[github](https://github.com/Fields2Cover/Fields2Cover) ![Fields2Cover/Fields2Cover](https://img.shields.io/github/stars/fields2cover/fields2cover.svg?style=flat&label=Star&maxAge=86400)]\\n* GPMP2 - Gaussian Process Motion Planner 2 [[github](https://github.com/gtrll/gpmp2) ![gtrll/gpmp2](https://img.shields.io/github/stars/gtrll/gpmp2.svg?style=flat&label=Star&maxAge=86400)]\\n* [HPP](https://humanoid-path-planner.github.io/hpp-doc/) - Path planning for kinematic chains in environments cluttered with obstacles [[github](https://github.com/humanoid-path-planner)]\\n* [MoveIt!](http://moveit.ros.org/) - Motion planning framework [[github](https://github.com/ros-planning/moveit) ![moveit](https://img.shields.io/github/stars/ros-planning/moveit.svg?style=flat&label=Star&maxAge=86400)]\\n* [OMPL](http://ompl.kavrakilab.org/) - Open motion planning library [[bitbucket](https://bitbucket.org/ompl/ompl), [github](https://github.com/ompl/ompl) ![ompl](https://img.shields.io/github/stars/ompl/ompl.svg?style=flat&label=Star&maxAge=86400)]\\n* OCS2 - Efficient continuous and discrete time optimal control implementation [[bitbucket](https://bitbucket.org/leggedrobotics/ocs2/src/master/)]\\n* pymanoid - Humanoid robotics prototyping environment based on OpenRAVE [[github](https://github.com/stephane-caron/pymanoid) ![stephane-caron/pymanoid](https://img.shields.io/github/stars/stephane-caron/pymanoid.svg?style=flat&label=Star&maxAge=86400)]\\n* ROS Behavior Tree - [[github](https://github.com/miccol/ROS-Behavior-Tree) ![miccol/ROS-Behavior-Tree](https://img.shields.io/github/stars/miccol/ROS-Behavior-Tree.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ruckig](https://github.com/pantor/ruckig) - Real-time, time-optimal and jerk-constrained online trajectory generation. [[github](https://github.com/pantor/ruckig) ![ruckig](https://img.shields.io/github/stars/pantor/ruckig.svg?style=flat&label=Star&maxAge=86400)]\\n* [The Kautham Project](https://sir.upc.es/projects/kautham/) - A robot simulation toolkit for motion planning [[github](https://github.com/iocroblab/kautham) ![kautham](https://img.shields.io/github/stars/iocroblab/kautham.svg?style=flat&label=Star&maxAge=86400)]\\n* [TOPP-RA](https://hungpham2511.github.io/toppra/) - Time-parameterizing robot trajectories subject to kinematic and dynamic constraints [[github](https://github.com/hungpham2511/toppra) ![hungpham2511/toppra](https://img.shields.io/github/stars/hungpham2511/toppra.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ungar](https://github.com/fdevinc/ungar) - Expressive and efficient implementation of optimal control problems using template metaprogramming [[github](https://github.com/fdevinc/ungar) ![fdevinc/ungar](https://img.shields.io/github/stars/fdevinc/ungar.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### Motion Optimizer\\n\\n* TopiCo - Time-optimal Trajectory Generation and Control [[github](https://github.com/AIS-Bonn/TopiCo) ![AIS-Bonn/TopiCo](https://img.shields.io/github/stars/AIS-Bonn/TopiCo.svg?style=flat&label=Star)]\\n* [towr](http://wiki.ros.org/towr) - A light-weight, Eigen-based C++ library for trajectory optimization for legged robots [[github](https://github.com/ethz-adrl/towr) ![ethz-adrl/towr](https://img.shields.io/github/stars/ethz-adrl/towr.svg?style=flat&label=Star&maxAge=86400)]\\n* TrajectoryOptimization - A fast trajectory optimization library written in Julia [[github](https://github.com/RoboticExplorationLab/TrajectoryOptimization.jl) ![RoboticExplorationLab/TrajectoryOptimization.jl](https://img.shields.io/github/stars/RoboticExplorationLab/TrajectoryOptimization.jl.svg?style=flat&label=Star&maxAge=86400)]\\n* [trajopt](http://rll.berkeley.edu/trajopt/doc/sphinx_build/html/) - Framework for generating robot trajectories by local optimization [[github](https://github.com/joschu/trajopt) ![joschu/trajopt](https://img.shields.io/github/stars/joschu/trajopt.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### Nearest Neighbor\\n\\n* [Cover-Tree](http://hunch.net/~jl/projects/cover_tree/cover_tree.html) - Cover tree data structure for quick k-nearest-neighbor search [[github](https://github.com/DNCrane/Cover-Tree) ![Cover-Tree](https://img.shields.io/github/stars/DNCrane/Cover-Tree.svg?style=flat&label=Star&maxAge=86400)]\\n  * [Faster cover trees](http://proceedings.mlr.press/v37/izbicki15.pdf) by Mike Izbicki et al., ICML 2015.\\n* [FLANN](http://www.cs.ubc.ca/research/flann/) - Fast Library for Approximate Nearest Neighbors [[github](https://github.com/mariusmuja/flann) ![flann](https://img.shields.io/github/stars/mariusmuja/flann.svg?style=flat&label=Star&maxAge=86400)]\\n* [nanoflann](http://www.cs.ubc.ca/research/flann/) - Nearest Neighbor search with KD-trees [[github](https://github.com/jlblancoc/nanoflann) ![nanoflann](https://img.shields.io/github/stars/jlblancoc/nanoflann.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### 3D Mapping\\n\\n* [libpointmatcher](http://libpointmatcher.readthedocs.io/en/latest/) - Iterative Closest Point library for 2-D/3-D mapping in Robotics [[github](https://github.com/ethz-asl/libpointmatcher) ![ethz-asl/libpointmatcher](https://img.shields.io/github/stars/ethz-asl/libpointmatcher.svg?style=flat&label=Star&maxAge=86400)]\\n* Octree - Fast radius neighbor search with an Octree [[github](https://github.com/jbehley/octree) ![jbehley/octree](https://img.shields.io/github/stars/jbehley/octree.svg?style=flat&label=Star&maxAge=86400)]\\n* [OctoMap](http://octomap.github.io/) - Efficient Probabilistic 3D Mapping Framework Based on Octrees [[github](https://github.com/OctoMap/octomap) ![octomap](https://img.shields.io/github/stars/OctoMap/octomap.svg?style=flat&label=Star&maxAge=86400)]\\n* [PCL](http://www.pointclouds.org/) - 2D/3D image and point cloud processing [[github](https://github.com/PointCloudLibrary/pcl) ![PointCloudLibrary/pcl](https://img.shields.io/github/stars/PointCloudLibrary/pcl.svg?style=flat&label=Star&maxAge=86400)]\\n* Treexy - Brutally fast, sparse, 3D Voxel Grid [[github](https://github.com/facontidavide/Treexy) ![Treexy](https://img.shields.io/github/stars/facontidavide/Treexy.svg?style=flat&label=Star&maxAge=86400)]\\n* voxblox - Flexible voxel-based mapping focusing on truncated and Euclidean signed distance fields [[github](https://github.com/ethz-asl/voxblox) ![voxblox](https://img.shields.io/github/stars/ethz-asl/voxblox.svg?style=flat&label=Star&maxAge=86400)]\\n* Utility Software\\n  * [Goxel](https://guillaumechereau.github.io/goxel/) - Free and open source 3D voxel editor [[github](https://github.com/guillaumechereau/goxel) ![guillaumechereau/goxel](https://img.shields.io/github/stars/guillaumechereau/goxel.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Optimization](#awesome-robotics-libraries)\\n\\n* [CasADi](https://github.com/casadi/casadi/wiki) - Symbolic framework for algorithmic differentiation and numeric optimization [[github](https://github.com/casadi/casadi) ![casadi](https://img.shields.io/github/stars/casadi/casadi.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ceres Solver](http://ceres-solver.org/) - Large scale nonlinear optimization library [[github](https://github.com/ceres-solver/ceres-solver) ![ceres-solver](https://img.shields.io/github/stars/ceres-solver/ceres-solver.svg?style=flat&label=Star&maxAge=86400)]\\n* eigen-qld - Interface to use the QLD QP solver with the Eigen3 library [[github](https://github.com/jrl-umi3218/eigen-qld) ![jrl-umi3218/eigen-qld](https://img.shields.io/github/stars/jrl-umi3218/eigen-qld.svg?style=flat&label=Star&maxAge=86400)]\\n* [EXOTica](http://wcms.inf.ed.ac.uk/ipab/slmc/research/EXOTica) - Generic optimisation toolset for robotics platforms [[github](https://github.com/ipab-slmc/exotica) ![ipab-slmc/exotica](https://img.shields.io/github/stars/ipab-slmc/exotica.svg?style=flat&label=Star&maxAge=86400)]\\n* hpipm - High-performance interior-point-method QP solvers (Ipopt, Snopt) [[github](https://github.com/giaf/hpipm) ![giaf/hpipm](https://img.shields.io/github/stars/giaf/hpipm.svg?style=flat&label=Star&maxAge=86400)]\\n* [HYPRE](https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods) - Parallel solvers for sparse linear systems featuring multigrid methods [[github](https://github.com/hypre-space/hypre) ![hypre-space/hypre](https://img.shields.io/github/stars/hypre-space/hypre.svg?style=flat&label=Star&maxAge=86400)]\\n* ifopt - An Eigen-based, light-weight C++ Interface to Nonlinear Programming Solvers (Ipopt, Snopt) [[github](https://github.com/ethz-adrl/ifopt) ![ifopt](https://img.shields.io/github/stars/ethz-adrl/ifopt.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ipopt](https://projects.coin-or.org/Ipopt) - Large scale nonlinear optimization library [[github](https://github.com/coin-or/Ipopt) ![Ipopt](https://img.shields.io/github/stars/coin-or/Ipopt.svg?style=flat&label=Star&maxAge=86400)]\\n* libcmaes - Blackbox stochastic optimization using the CMA-ES algorithm [[github](https://github.com/beniz/libcmaes) ![beniz/libcmaes](https://img.shields.io/github/stars/beniz/libcmaes.svg?style=flat&label=Star&maxAge=86400)]\\n* [limbo](http://www.resibots.eu/limbo/) - Gaussian processes and Bayesian optimization of black-box functions [[github](https://github.com/resibots/limbo) ![resibots/limbo](https://img.shields.io/github/stars/resibots/limbo.svg?style=flat&label=Star&maxAge=86400)]\\n* lpsolvers - Linear Programming solvers in Python with a unified API [[github](https://github.com/stephane-caron/lpsolvers) ![lpsolvers](https://img.shields.io/github/stars/stephane-caron/lpsolvers.svg?style=flat&label=Star&maxAge=86400)]\\n* [NLopt](http://ab-initio.mit.edu/wiki/index.php/NLopt) - Nonlinear optimization [[github](https://github.com/stevengj/nlopt) ![nlopt](https://img.shields.io/github/stars/stevengj/nlopt.svg?style=flat&label=Star&maxAge=86400)]\\n* [OptimLib](https://www.kthohr.com/optimlib.html) - Lightweight C++ library of numerical optimization methods for nonlinear functions [[github](https://github.com/kthohr/optim) ![kthohr/optim](https://img.shields.io/github/stars/kthohr/optim.svg?style=flat&label=Star&maxAge=86400)]\\n* [OSQP](https://osqp.org/) - The Operator Splitting QP Solver [[github](https://github.com/osqp/osqp) ![osqp/osqp](https://img.shields.io/github/stars/osqp/osqp.svg?style=flat&label=Star&maxAge=86400)]\\n* [Pagmo](https://esa.github.io/pagmo2/index.html) - Scientific library for massively parallel optimization [[github](https://github.com/esa/pagmo2) ![esa/pagmo2](https://img.shields.io/github/stars/esa/pagmo2.svg?style=flat&label=Star&maxAge=86400)]\\n* [ProxSuite](https://simple-robotics.github.io/proxsuite/) - The Advanced Proximal Optimization Toolbox [[github](https://github.com/Simple-Robotics/ProxSuite) ![Simple-Robotics/ProxSuite](https://img.shields.io/github/stars/Simple-Robotics/ProxSuite.svg?style=flat&label=Star&maxAge=86400)]\\n* [pymoo](https://www.egr.msu.edu/coinlab/blankjul/pymoo/) - Multi-objective Optimization in Python [[github](https://github.com/msu-coinlab/pymoo) ![msu-coinlab/pymoo](https://img.shields.io/github/stars/msu-coinlab/pymoo.svg?style=flat&label=Star&maxAge=86400)]\\n* qpsolvers - Quadratic Programming solvers in Python with a unified API [[github](https://github.com/stephane-caron/qpsolvers) ![qpsolvers](https://img.shields.io/github/stars/stephane-caron/qpsolvers.svg?style=flat&label=Star&maxAge=86400)]\\n* [RobOptim](http://roboptim.net/index.html) - Numerical Optimization for Robotics. [[github](https://github.com/roboptim/roboptim-core) ![roboptim/roboptim-core](https://img.shields.io/github/stars/roboptim/roboptim-core.svg?style=flat&label=Star&maxAge=86400)]\\n* [SCS](http://web.stanford.edu/~boyd/papers/scs.html) - Numerical optimization for solving large-scale convex cone problems [[github](https://github.com/cvxgrp/scs) ![scs](https://img.shields.io/github/stars/cvxgrp/scs.svg?style=flat&label=Star&maxAge=86400)]\\n* [SHOT](https://shotsolver.dev/shot/) - A solver for mixed-integer nonlinear optimization problems [[github](https://github.com/coin-or/SHOT) ![coin-or/SHOT](https://img.shields.io/github/stars/coin-or/SHOT.svg?style=flat&label=Star&maxAge=86400)]\\n* sferes2 - Evolutionary computation [[github](https://github.com/sferes2/sferes2) ![sferes2/sferes2](https://img.shields.io/github/stars/sferes2/sferes2.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Robot Modeling](#awesome-robotics-libraries)\\n\\n###### Robot Model Description Format\\n* [SDF](http://sdformat.org/) - XML format that describes objects and environments for robot simulators, visualization, and control ([bitbucket](https://bitbucket.org/osrf/sdformat))\\n* [urdf](http://wiki.ros.org/urdf) - XML format for representing a robot model [[github](https://github.com/ros/urdfdom) ![ros/urdfdom](https://img.shields.io/github/stars/ros/urdfdom.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### Utility to Build Robot Models\\n* [onshape-to-robot](https://github.com/Rhoban/onshape-to-robot) - Converting OnShape assembly to robot definition (SDF or URDF) through OnShape API [[github](https://github.com/Rhoban/onshape-to-robot) ![phobos](https://img.shields.io/github/stars/Rhoban/onshape-to-robot.svg?style=flat&label=Star&maxAge=86400)]\\n* phobos - Add-on for Blender creating URDF and SMURF robot models [[github](https://github.com/rock-simulation/phobos) ![phobos](https://img.shields.io/github/stars/rock-simulation/phobos.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Robot Platform](#awesome-robotics-libraries)\\n\\n* [AutoRally](http://autorally.github.io/) - High-performance testbed for advanced perception and control research [[github](https://github.com/autorally/autorally) ![autorally/autorally](https://img.shields.io/github/stars/autorally/autorally.svg?style=flat&label=Star&maxAge=86400)]\\n* [Linorobot](https://linorobot.org/) - ROS compatible ground robots [[github](https://github.com/linorobot/linorobot) ![linorobot/linorobot](https://img.shields.io/github/stars/linorobot/linorobot.svg?style=flat&label=Star&maxAge=86400)]\\n  * onine - Service Robot based on [Linorobot](https://github.com/linorobot/linorobot) and Braccio Arm [[github](https://github.com/grassjelly/onine) ![grassjelly/onine](https://img.shields.io/github/stars/grassjelly/onine.svg?style=flat&label=Star&maxAge=86400)]\\n* [Rock](https://www.rock-robotics.org/stable/) - Software framework for robotic systems\\n* [ROS](http://www.ros.org/) - Flexible framework for writing robot software [[github repos](http://wiki.ros.org/Tickets)]\\n* [ROS 2](https://github.com/ros2/ros2/wiki) - Version 2.0 of the Robot Operating System (ROS) software stack [[github repos](https://github.com/ros2)]\\n* [YARP](http://www.yarp.it/) - Communication and device interfaces applicable from humanoids to embedded devices [[github](https://github.com/robotology/yarp) ![robotology/yarp](https://img.shields.io/github/stars/robotology/yarp.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [SLAM](#awesome-robotics-libraries)\\n\\n* AprilSAM - Real-time smoothing and mapping [[github](https://github.com/xipengwang/AprilSAM) ![xipengwang/AprilSAM](https://img.shields.io/github/stars/xipengwang/AprilSAM.svg?style=flat&label=Star&maxAge=86400)]\\n* Cartographer - Real-time SLAM in 2D and 3D across multiple platforms and sensor configurations [[github](https://github.com/googlecartographer/cartographer) ![cartographer](https://img.shields.io/github/stars/googlecartographer/cartographer.svg?style=flat&label=Star&maxAge=86400)]\\n* [DSO](https://vision.in.tum.de/research/vslam/dso) - Novel direct and sparse formulation for Visual Odometry [[github](https://github.com/JakobEngel/dso) ![dso](https://img.shields.io/github/stars/JakobEngel/dso.svg?style=flat&label=Star&maxAge=86400)]\\n* ElasticFusion - Real-time dense visual SLAM system [[github](http://github.com/mp3guy/ElasticFusion) ![ElasticFusion](https://img.shields.io/github/stars/mp3guy/ElasticFusion.svg?style=flat&label=Star&maxAge=86400)]\\n* [fiducials](http://wiki.ros.org/fiducials) - Simultaneous localization and mapping using fiducial markers [[github](http://github.com/UbiquityRobotics/fiducials) ![UbiquityRobotics/fiducials](https://img.shields.io/github/stars/UbiquityRobotics/fiducials.svg?style=flat&label=Star&maxAge=86400)]\\n* GTSAM - Smoothing and mapping (SAM) in robotics and vision [[github](http://github.com/borglab/gtsam) ![borglab/gtsam](https://img.shields.io/github/stars/borglab/gtsam.svg?style=flat&label=Star&maxAge=86400)]\\n* Kintinuous - Real-time large scale dense visual SLAM system [[github](http://github.com/mp3guy/Kintinuous) ![Kintinuous](https://img.shields.io/github/stars/mp3guy/Kintinuous.svg?style=flat&label=Star&maxAge=86400)]\\n* [LSD-SLAM](https://vision.in.tum.de/research/vslam/lsdslam) - Real-time monocular SLAM [[github](http://github.com/tum-vision/lsd_slam) ![lsdslam](https://img.shields.io/github/stars/tum-vision/lsd_slam.svg?style=flat&label=Star&maxAge=86400)]\\n* ORB-SLAM2 - Real-time SLAM library for Monocular, Stereo and RGB-D cameras [[github](http://github.com/raulmur/ORB_SLAM2) ![ORB_SLAM2](https://img.shields.io/github/stars/raulmur/ORB_SLAM2.svg?style=flat&label=Star&maxAge=86400)]\\n* [RTAP-Map](http://introlab.github.io/rtabmap/) - RGB-D Graph SLAM approach based on a global Bayesian loop closure detector [[github](http://github.com/introlab/rtabmap) ![introlab/rtabmap](https://img.shields.io/github/stars/introlab/rtabmap.svg?style=flat&label=Star&maxAge=86400)]\\n* [SRBA](http://mrpt.github.io/srba/) - Solving SLAM/BA in relative coordinates with flexibility for different submapping strategies [[github](http://github.com/MRPT/srba) ![srba](https://img.shields.io/github/stars/MRPT/srba.svg?style=flat&label=Star&maxAge=86400)]\\n\\n#### SLAM Dataset\\n\\n* [Awesome SLAM Datasets](https://github.com/youngguncho/awesome-slam-datasets)\\n\\n### [Vision](#awesome-robotics-libraries)\\n\\n* [ViSP](http://visp.inria.fr/) - Visual Servoing Platform [[github](https://github.com/lagadic/visp) ![lagadic/visp](https://img.shields.io/github/stars/lagadic/visp.svg?style=flat&label=Star&maxAge=86400)]\\n* [BundleTrack](https://github.com/wenbowen123/BundleTrack) - 6D Pose Tracking for Novel Objects without 3D Models [[github](https://github.com/wenbowen123/BundleTrack) ![wenbowen123/BundleTrack](https://img.shields.io/github/stars/wenbowen123/BundleTrack.svg?style=flat&label=Star&maxAge=86400)]\\n* [se(3)-TrackNet](https://github.com/wenbowen123/iros20-6d-pose-tracking) - 6D Pose Tracking for Novel Objects without 3D Models [[github](https://github.com/wenbowen123/iros20-6d-pose-tracking) ![wenbowen123/iros20-6d-pose-tracking](https://img.shields.io/github/stars/wenbowen123/iros20-6d-pose-tracking.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Fluid](#awesome-robotics-libraries)\\n\\n* [Fluid Engine Dev - Jet](https://fluidenginedevelopment.org/) - Fluid simulation engine for computer graphics applications [[github](https://github.com/doyubkim/fluid-engine-dev) ![doyubkim/fluid-engine-dev](https://img.shields.io/github/stars/doyubkim/fluid-engine-dev.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Multiphysics](#awesome-robotics-libraries)\\n\\n* [Kratos](http://www.cimne.com/kratos/) - Framework for building parallel multi-disciplinary simulation software [[github](https://github.com/KratosMultiphysics/Kratos) ![KratosMultiphysics/Kratos](https://img.shields.io/github/stars/KratosMultiphysics/Kratos.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Math](#awesome-robotics-libraries)\\n\\n* Fastor - Light-weight high performance tensor algebra framework in C++11/14/17 [[github](https://github.com/romeric/Fastor) ![romeric/Fastor](https://img.shields.io/github/stars/romeric/Fastor.svg?style=flat&label=Star&maxAge=86400)]\\n* linalg.h - Single header public domain linear algebra library for C++11 [[github](https://github.com/sgorsten/linalg) ![sgorsten/linalg](https://img.shields.io/github/stars/sgorsten/linalg.svg?style=flat&label=Star&maxAge=86400)]\\n* manif - Small c++11 header-only library for Lie theory. [[github](https://github.com/artivis/manif) ![artivis/manif](https://img.shields.io/github/stars/artivis/manif.svg?style=flat&label=Star&maxAge=86400)]\\n* Sophus - Lie groups using Eigen [[github](https://github.com/strasdat/Sophus) ![strasdat/Sophus](https://img.shields.io/github/stars/strasdat/Sophus.svg?style=flat&label=Star&maxAge=86400)]\\n* SpaceVelAlg - Spatial vector algebra with the Eigen3 [[github](https://github.com/jrl-umi3218/SpaceVecAlg) ![jrl-umi3218/SpaceVecAlg](https://img.shields.io/github/stars/jrl-umi3218/SpaceVecAlg.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [ETC](#awesome-robotics-libraries)\\n\\n* fuse - General architecture for performing sensor fusion live on a robot [[github](https://github.com/locusrobotics/fuse) ![locusrobotics/fuse](https://img.shields.io/github/stars/locusrobotics/fuse.svg?style=flat&label=Star&maxAge=86400)]\\n* [Foxglove Studio](https://foxglove.dev) –\\xa0A fully integrated visualization and debugging desktop app for your robotics data. Combines functionality of tools like `rviz`, `rqt`, and more. Also available via [web app](https://studio.foxglove.dev).\\n\\n## [Other Awesome Lists](#awesome-robotics-libraries)\\n\\n* [Awesome Robotics](https://github.com/Kiloreux/awesome-robotics) (Kiloreux)\\n* [Awesome Robotics](https://github.com/ahundt/awesome-robotics) (ahundt)\\n* [Awesome Robotic Tooling](https://github.com/Ly0n/awesome-robotic-tooling)\\n* [Awesome Artificial Intelligence](https://github.com/owainlewis/awesome-artificial-intelligence)\\n* [Awesome Collision Detection](https://github.com/jslee02/awesome-collision-detection)\\n* [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)\\n* [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning)\\n* [Awesome Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning)\\n* [Awesome Gazebo](https://github.com/fkromer/awesome-gazebo)\\n* [Awesome Grasping](https://github.com/Po-Jen/awesome-grasping)\\n* [Awesome Human Robot Interaction](https://github.com/Po-Jen/awesome-human-robot-interaction)\\n* [PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics) - Python sample codes for robotics algorithms\\n* [Robotics Coursework](https://github.com/mithi/robotics-coursework) - A list of robotics courses you can take online\\n\\n## [Contributing](#awesome-robotics-libraries)\\n\\nContributions are very welcome! Please read the [contribution guidelines](https://github.com/jslee02/awesome-robotics-libraries/blob/master/CONTRIBUTING.md) first. Also, please feel free to report any error.\\n\\n## [License](#awesome-robotics-libraries)\\n\\n[![CC0](https://licensebuttons.net/p/zero/1.0/88x31.png)](http://creativecommons.org/publicdomain/zero/1.0/)\\n'},\n",
       " {'repo': 'petercorke/robotics-toolbox-python',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': '# Robotics Toolbox for Python\\n\\n[![A Python Robotics Package](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/py_collection.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n[![Powered by Spatial Maths](https://raw.githubusercontent.com/petercorke/spatialmath-python/master/.github/svg/sm_powered.min.svg)](https://github.com/petercorke/spatialmath-python)\\n[![QUT Centre for Robotics Open Source](https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg)](https://qcr.github.io)\\n\\n[![PyPI version](https://badge.fury.io/py/roboticstoolbox-python.svg)](https://badge.fury.io/py/roboticstoolbox-python)\\n[![Anaconda version](https://anaconda.org/conda-forge/roboticstoolbox-python/badges/version.svg)](https://anaconda.org/conda-forge/roboticstoolbox-python)\\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/roboticstoolbox-python.svg)\\n\\n[![Build Status](https://github.com/petercorke/robotics-toolbox-python/workflows/Test/badge.svg?branch=master)](https://github.com/petercorke/robotics-toolbox-python/actions?query=workflow%3ATest)\\n[![Coverage](https://codecov.io/gh/petercorke/robotics-toolbox-python/branch/master/graph/badge.svg)](https://codecov.io/gh/petercorke/robotics-toolbox-python)\\n[![PyPI - Downloads](https://img.shields.io/pypi/dw/roboticstoolbox-python)](https://pypistats.org/packages/roboticstoolbox-python)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\n<table style=\"border:0px\">\\n<tr style=\"border:0px\">\\n<td style=\"border:0px\">\\n<img src=\"https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/RobToolBox_RoundLogoB.png\" width=\"200\"></td>\\n<td style=\"border:0px\">\\nA Python implementation of the <a href=\"https://github.com/petercorke/robotics-toolbox-matlab\">Robotics Toolbox for MATLAB<sup>&reg;</sup></a>\\n<ul>\\n<li><a href=\"https://github.com/petercorke/robotics-toolbox-python\">GitHub repository </a></li>\\n<li><a href=\"https://petercorke.github.io/robotics-toolbox-python\">Documentation</a></li>\\n<li><a href=\"#6\">ICRA Paper</a></li>\\n<li><a href=\"https://github.com/petercorke/robotics-toolbox-python/wiki\">Wiki (examples and details)</a></li>\\n</ul>\\n</td>\\n</tr>\\n</table>\\n\\n<!-- <br> -->\\n\\n## Contents\\n\\n- [Synopsis](#1)\\n- [Getting going](#2)\\n- [Tutorials](#3)\\n- [Code Examples](#4)\\n- [Toolbox Research Applications](#5)\\n- [Toolbox ICRA Paper and Citation Info](#6)\\n- [Using the Toolbox in your Open Source Code?](#7)\\n- [Common Issues and Solutions](#8)\\n\\n<br>\\n\\n<a id=\\'1\\'></a>\\n\\n## Synopsis\\n\\nThis toolbox brings robotics-specific functionality to Python, and leverages\\nPython\\'s advantages of portability, ubiquity and support, and the capability of\\nthe open-source ecosystem for linear algebra (numpy, scipy), graphics\\n(matplotlib, three.js, WebGL), interactive development (jupyter, jupyterlab,\\nmybinder.org), and documentation (sphinx).\\n\\nThe Toolbox provides tools for representing the kinematics and dynamics of\\nserial-link manipulators - you can easily create your own in Denavit-Hartenberg\\nform, import a URDF file, or use over 30 supplied models for well-known\\ncontemporary robots from Franka-Emika, Kinova, Universal Robotics, Rethink as\\nwell as classical robots such as the Puma 560 and the Stanford arm.\\n\\nThe Toolbox contains fast implementations of kinematic operations. The forward\\nkinematics and the manipulator Jacobian can be computed in less than 1 microsecond\\nwhile numerical inverse kinematics can be solved in as little as 4 microseconds.\\n\\nThe toolbox also supports mobile robots with functions for robot motion models\\n(unicycle, bicycle), path planning algorithms (bug, distance transform, D\\\\*,\\nPRM), kinodynamic planning (lattice, RRT), localization (EKF, particle filter),\\nmap building (EKF) and simultaneous localization and mapping (EKF).\\n\\nThe Toolbox provides:\\n\\n- code that is mature and provides a point of comparison for other\\n  implementations of the same algorithms;\\n- routines which are generally written in a straightforward manner which\\n  allows for easy understanding, perhaps at the expense of computational\\n  efficiency;\\n- source code which can be read for learning and teaching;\\n- backward compatability with the Robotics Toolbox for MATLAB\\n\\nThe Toolbox leverages the [Spatial Maths Toolbox for Python](https://github.com/petercorke/spatialmath-python) to\\nprovide support for data types such as SO(n) and SE(n) matrices, quaternions, twists and spatial vectors.\\n\\n<br>\\n\\n<a id=\\'2\\'></a>\\n\\n## Getting going\\n\\nYou will need Python >= 3.6\\n\\n### Using pip\\n\\nInstall a snapshot from PyPI\\n\\n```shell script\\npip3 install roboticstoolbox-python\\n```\\n\\nAvailable options are:\\n\\n- `collision` install collision checking with [pybullet](https://pybullet.org)\\n\\nPut the options in a comma separated list like\\n\\n```shell script\\npip3 install roboticstoolbox-python[optionlist]\\n```\\n\\n[Swift](https://github.com/jhavl/swift), a web-based visualizer, is\\ninstalled as part of Robotics Toolbox.\\n\\n### From GitHub\\n\\nTo install the bleeding-edge version from GitHub\\n\\n```shell script\\ngit clone https://github.com/petercorke/robotics-toolbox-python.git\\ncd robotics-toolbox-python\\npip3 install -e .\\n```\\n\\n<br>\\n\\n<a id=\\'3\\'></a>\\n\\n## Tutorials\\n\\n<table style=\"border:0px\">\\n<tr style=\"border:0px\">\\n<td style=\"border:0px\"><a href=\"https://bit.ly/3ak5GDi\"><img src=\"https://github.com/jhavl/dkt/raw/main/img/article1.png\" width=\"400\"></a></td>\\n<td style=\"border:0px\"><a href=\"https://bit.ly/3ak5GDi\"><img src=\"https://github.com/jhavl/dkt/raw/main/img/article2.png\" width=\"400\"></a></td>\\n<td style=\"border:0px\">\\nDo you want to learn about manipulator kinematics, differential kinematics, inverse-kinematics and motion control? Have a look at our\\n<a href=\"https://bit.ly/3ak5GDi\">tutorial</a>.\\nThis tutorial comes with two articles to cover the theory and 12 Jupyter Notebooks providing full code implementations and examples. Most of the Notebooks are also Google Colab compatible allowing them to run online.\\n</td>\\n</tr>\\n</table>\\n\\n<br>\\n\\n<a id=\\'4\\'></a>\\n\\n## Code Examples\\n\\nWe will load a model of the Franka-Emika Panda robot defined by a URDF file\\n\\n```python\\nimport roboticstoolbox as rtb\\nrobot = rtb.models.Panda()\\nprint(robot)\\n\\n\\tERobot: panda (by Franka Emika), 7 joints (RRRRRRR), 1 gripper, geometry, collision\\n\\t┌─────┬──────────────┬───────┬─────────────┬────────────────────────────────────────────────┐\\n\\t│link │     link     │ joint │   parent    │              ETS: parent to link               │\\n\\t├─────┼──────────────┼───────┼─────────────┼────────────────────────────────────────────────┤\\n\\t│   0 │ panda_link0  │       │ BASE        │                                                │\\n\\t│   1 │ panda_link1  │     0 │ panda_link0 │ SE3(0, 0, 0.333) ⊕ Rz(q0)                      │\\n\\t│   2 │ panda_link2  │     1 │ panda_link1 │ SE3(-90°, -0°, 0°) ⊕ Rz(q1)                    │\\n\\t│   3 │ panda_link3  │     2 │ panda_link2 │ SE3(0, -0.316, 0; 90°, -0°, 0°) ⊕ Rz(q2)       │\\n\\t│   4 │ panda_link4  │     3 │ panda_link3 │ SE3(0.0825, 0, 0; 90°, -0°, 0°) ⊕ Rz(q3)       │\\n\\t│   5 │ panda_link5  │     4 │ panda_link4 │ SE3(-0.0825, 0.384, 0; -90°, -0°, 0°) ⊕ Rz(q4) │\\n\\t│   6 │ panda_link6  │     5 │ panda_link5 │ SE3(90°, -0°, 0°) ⊕ Rz(q5)                     │\\n\\t│   7 │ panda_link7  │     6 │ panda_link6 │ SE3(0.088, 0, 0; 90°, -0°, 0°) ⊕ Rz(q6)        │\\n\\t│   8 │ @panda_link8 │       │ panda_link7 │ SE3(0, 0, 0.107)                               │\\n\\t└─────┴──────────────┴───────┴─────────────┴────────────────────────────────────────────────┘\\n\\n\\t┌─────┬─────┬────────┬─────┬───────┬─────┬───────┬──────┐\\n\\t│name │ q0  │ q1     │ q2  │ q3    │ q4  │ q5    │ q6   │\\n\\t├─────┼─────┼────────┼─────┼───────┼─────┼───────┼──────┤\\n\\t│  qr │  0° │ -17.2° │  0° │ -126° │  0° │  115° │  45° │\\n\\t│  qz │  0° │  0°    │  0° │  0°   │  0° │  0°   │  0°  │\\n\\t└─────┴─────┴────────┴─────┴───────┴─────┴───────┴──────┘\\n```\\n\\nThe symbol `@` indicates the link as an end-effector, a leaf node in the rigid-body\\ntree (Python prompts are not shown to make it easy to copy+paste the code, console output is indented).\\nWe will compute the forward kinematics next\\n\\n```\\nTe = robot.fkine(robot.qr)  # forward kinematics\\nprint(Te)\\n\\n\\t0.995     0         0.09983   0.484\\n\\t0        -1         0         0\\n\\t0.09983   0        -0.995     0.4126\\n\\t0         0         0         1\\n```\\n\\nWe can solve inverse kinematics very easily. We first choose an SE(3) pose\\ndefined in terms of position and orientation (end-effector z-axis down (A=-Z) and finger\\norientation parallel to y-axis (O=+Y)).\\n\\n```python\\nfrom spatialmath import SE3\\n\\nTep = SE3.Trans(0.6, -0.3, 0.1) * SE3.OA([0, 1, 0], [0, 0, -1])\\nsol = robot.ik_LM(Tep)         # solve IK\\nprint(sol)\\n\\n\\t(array([ 0.20592815,  0.86609481, -0.79473206, -1.68254794,  0.74872915,\\n\\t\\t\\t2.21764746, -0.10255606]), 1, 114, 7, 2.890164057230228e-07)\\n\\nq_pickup = sol[0]\\nprint(robot.fkine(q_pickup))    # FK shows that desired end-effector pose was achieved\\n\\n\\t 1         -8.913e-05  -0.0003334  0.5996\\n\\t-8.929e-05 -1          -0.0004912 -0.2998\\n\\t-0.0003334  0.0004912  -1          0.1001\\n\\t 0          0           0          1\\n```\\n\\nWe can animate a path from the ready pose `qr` configuration to this pickup configuration\\n\\n```python\\nqt = rtb.jtraj(robot.qr, q_pickup, 50)\\nrobot.plot(qt.q, backend=\\'pyplot\\', movie=\\'panda1.gif\\')\\n```\\n\\n<p align=\"center\">\\n\\t<img src=\"./docs/figs/panda1.gif\">\\n</p>\\n\\nwhere we have specified the matplotlib `pyplot` backend. Blue arrows show the joint axes and the coloured frame shows the end-effector pose.\\n\\nWe can also plot the trajectory in the Swift simulator (a browser-based 3d-simulation environment built to work with the Toolbox)\\n\\n```python\\nrobot.plot(qt.q)\\n```\\n\\n<p align=\"center\">\\n\\t<img src=\"./docs/figs/panda2.gif\">\\n</p>\\n\\nWe can also experiment with velocity controllers in Swift. Here is a resolved-rate motion control example\\n\\n```python\\nimport swift\\nimport roboticstoolbox as rtb\\nimport spatialmath as sm\\nimport numpy as np\\n\\nenv = swift.Swift()\\nenv.launch(realtime=True)\\n\\npanda = rtb.models.Panda()\\npanda.q = panda.qr\\n\\nTep = panda.fkine(panda.q) * sm.SE3.Trans(0.2, 0.2, 0.45)\\n\\narrived = False\\nenv.add(panda)\\n\\ndt = 0.05\\n\\nwhile not arrived:\\n\\n    v, arrived = rtb.p_servo(panda.fkine(panda.q), Tep, 1)\\n    panda.qd = np.linalg.pinv(panda.jacobe(panda.q)) @ v\\n    env.step(dt)\\n\\n# Uncomment to stop the browser tab from closing\\n# env.hold()\\n```\\n\\n<p align=\"center\">\\n\\t<img src=\"./docs/figs/panda3.gif\">\\n</p>\\n\\n### Run some examples\\n\\nThe [`notebooks`](https://github.com/petercorke/robotics-toolbox-python/tree/master/notebooks) folder contains some tutorial Jupyter notebooks which you can browse on GitHub. Additionally, have a look in the [`examples`](https://github.com/petercorke/robotics-toolbox-python/tree/master/roboticstoolbox/examples) folder for many ready to run examples.\\n\\n<br>\\n\\n<a id=\\'5\\'></a>\\n\\n## Toolbox Research Applications\\n\\nThe toolbox is incredibly useful for developing and prototyping algorithms for research, thanks to the exhaustive set of well documented and mature robotic functions exposed through clean and painless APIs. Additionally, the ease at which a user can visualize their algorithm supports a rapid prototyping paradigm.\\n\\n### Publication List\\n\\nJ. Haviland, N. Sünderhauf and P. Corke, \"**A Holistic Approach to Reactive Mobile Manipulation**,\" in _IEEE Robotics and Automation Letters_, doi: 10.1109/LRA.2022.3146554. In the video, the robot is controlled using the Robotics toolbox for Python and features a recording from the [Swift](https://github.com/jhavl/swift) Simulator.\\n\\n[[Arxiv Paper](https://arxiv.org/abs/2109.04749)] [[IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/9695298)] [[Project Website](https://jhavl.github.io/holistic/)] [[Video](https://youtu.be/-DXBQPeLIV4)] [[Code Example](https://github.com/petercorke/robotics-toolbox-python/blob/master/roboticstoolbox/examples/holistic_mm_non_holonomic.py)]\\n\\n<p>\\n  <a href=\"https://youtu.be/-DXBQPeLIV4\">\\n    <img src=\"https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/holistic_youtube.png\" width=\"560\">\\n  </a>\\n</p>\\n\\nJ. Haviland and P. Corke, \"**NEO: A Novel Expeditious Optimisation Algorithm for Reactive Motion Control of Manipulators**,\" in _IEEE Robotics and Automation Letters_, doi: 10.1109/LRA.2021.3056060. In the video, the robot is controlled using the Robotics toolbox for Python and features a recording from the [Swift](https://github.com/jhavl/swift) Simulator.\\n\\n[[Arxiv Paper](https://arxiv.org/abs/2010.08686)] [[IEEE Xplore](https://ieeexplore.ieee.org/document/9343718)] [[Project Website](https://jhavl.github.io/neo/)] [[Video](https://youtu.be/jSLPJBr8QTY)] [[Code Example](https://github.com/petercorke/robotics-toolbox-python/blob/master/roboticstoolbox/examples/neo.py)]\\n\\n<p>\\n  <a href=\"https://youtu.be/jSLPJBr8QTY\">\\n    <img src=\"https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/neo_youtube.png\" width=\"560\">\\n  </a>\\n</p>\\n\\n**A Purely-Reactive Manipulability-Maximising Motion Controller**, J. Haviland and P. Corke. In the video, the robot is controlled using the Robotics toolbox for Python.\\n\\n[[Paper](https://arxiv.org/abs/2002.11901)] [[Project Website](https://jhavl.github.io/mmc/)] [[Video](https://youtu.be/Vu_rcPlaADI)] [[Code Example](https://github.com/petercorke/robotics-toolbox-python/blob/master/roboticstoolbox/examples/mmc.py)]\\n\\n<p>\\n  <a href=\"https://youtu.be/Vu_rcPlaADI\">\\n    <img src=\"https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/mmc_youtube.png\" width=\"560\">\\n  </a>\\n</p>\\n\\n<br>\\n\\n<br>\\n\\n<a id=\\'6\\'></a>\\n\\n## Toolbox ICRA Paper and Citation Info\\n\\nCheck out our ICRA 2021 paper on [IEEE Xplore](https://ieeexplore.ieee.org/document/9561366) or get the PDF from [Peter\\'s website](https://bit.ly/3ChcyNp).\\n\\nIf the toolbox helped you in your research, please cite\\n\\n```\\n@inproceedings{rtb,\\n  title={Not your grandmother’s toolbox--the Robotics Toolbox reinvented for Python},\\n  author={Corke, Peter and Haviland, Jesse},\\n  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},\\n  pages={11357--11363},\\n  year={2021},\\n  organization={IEEE}\\n}\\n```\\n\\n<br>\\n\\n<a id=\\'7\\'></a>\\n\\n## Using the Toolbox in your Open Source Code?\\n\\nIf you are using the Toolbox in your open source code, feel free to add our badge to your readme!\\n\\nFor the powered by robotics toolbox badge\\n\\n[![Powered by the Robotics Toolbox](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/rtb_powered.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n\\ncopy the following\\n\\n```\\n[![Powered by the Robotics Toolbox](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/rtb_powered.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n```\\n\\nFor the powered by python robotics badge\\n\\n[![Powered by Python Robotics](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/pr_powered.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n\\ncopy the following\\n\\n```\\n[![Powered by Python Robotics](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/pr_powered.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n```\\n\\n<br>\\n\\n<a id=\\'8\\'></a>\\n\\n## Common Issues and Solutions\\n\\nSee the common issues with fixes [here](https://github.com/petercorke/robotics-toolbox-python/wiki/Common-Issues).\\n'},\n",
       " {'repo': 'Unity-Technologies/Unity-Robotics-Hub',\n",
       "  'language': 'C#',\n",
       "  'readme_contents': '<p align=\"center\"><img src=\"images/warehouse.gif\"/></p>\\n\\n# Unity Robotics Hub\\n\\n<!-- [![Version](https://img.shields.io/github/v/tag/Unity-Technologies/Unity-Robotics-Hub)](https://github.com/Unity-Technologies/Unity-Robotics-Hub/releases) -->\\n[![License](https://img.shields.io/badge/license-Apache--2.0-green.svg)](LICENSE.md)\\n![ROS](https://img.shields.io/badge/ros-melodic-brightgreen)\\n![ROS](https://img.shields.io/badge/ros-noetic-brightgreen)\\n![ROS](https://img.shields.io/badge/ros2-foxy-brightgreen)\\n![Unity](https://img.shields.io/badge/unity-2020.2+-brightgreen)\\n\\nThis is a central repository for tools, tutorials, resources, and documentation for robotic simulation in Unity.\\n\\n> The contents of this repository are in active development. Its features and API are subject to significant change as development progresses.\\n\\n---\\n\\nWe\\'re currently working on lots of things! Please take a short moment fill out our [survey](https://unitysoftware.co1.qualtrics.com/jfe/form/SV_0ojVkDVW0nNrHkW) to help us identify what products and packages to build next.\\n\\n---\\n\\n## Introduction\\n\\nSimulation plays an important role in robotics development, and we’re here to ensure that roboticists can use Unity for these simulations. We\\'re starting off with a set of tools to make it easier to use Unity with existing ROS-based workflows. Try out some of our samples below to get started quickly.\\n\\n## Getting Started\\n### [Quick Installation Instructions](tutorials/quick_setup.md)\\n\\nBrief steps on installing the Unity Robotics packages.\\n\\n### [Pick-and-Place Tutorial](tutorials/pick_and_place/README.md)\\n\\nA complete end-to-end demonstration, including how to set up the Unity environment, how to import a robot from URDF, and how to set up two-way communication with ROS for control.\\n\\n### [Object Pose Estimation Tutorial](https://github.com/Unity-Technologies/Robotics-Object-Pose-Estimation)\\n\\nA complete end-to-end demonstration in which we collect training data in Unity and use that data to train a deep neural network to predict the pose of a cube. This model is then deployed in a simulated robotic pick-and-place task.\\n\\n### [Articulations Robot Demo](https://github.com/Unity-Technologies/articulations-robot-demo)\\n\\nA robot simulation demonstrating Unity\\'s new physics solver (no ROS dependency).\\n\\n### [**New!**] [Navigation 2 SLAM Example](https://github.com/Unity-Technologies/Robotics-Nav2-SLAM-Example)\\n\\nAn example simulation environment, integrated with ROS 2 and **[New!] Visualizations**, which enables the exercise of ROS 2\\'s Navigation 2 and slam_toolbox packages using a simulated Turtlebot 3.\\n\\n## Documentation\\n\\n| Tutorial | Description |\\n|---|---|\\n| [ROS–Unity Integration](tutorials/ros_unity_integration/README.md) | A set of component-level tutorials showing how to set up communication between ROS and Unity |\\n| [URDF Importer](tutorials/urdf_importer/urdf_tutorial.md) | Steps on using the Unity package for loading [URDF](http://wiki.ros.org/urdf) files |\\n| [**New!**] [Visualizations](https://github.com/Unity-Technologies/ROS-TCP-Connector/blob/main/com.unity.robotics.visualizations/Documentation~/README.md) | Usage instructions for adding visualizations for incoming and outgoing ROS messages |\\n\\n## Component Repos\\n\\n| Repo | Functionality |\\n|---|---|\\n| [ROS TCP Endpoint](https://github.com/Unity-Technologies/ROS-TCP-Endpoint) | ROS node for sending/receiving messages from Unity |\\n| [ROS TCP Connector](https://github.com/Unity-Technologies/ROS-TCP-Connector) | Unity package for sending, receiving, and visualizing messages from ROS |\\n| [URDF Importer](https://github.com/Unity-Technologies/URDF-Importer) | Unity package for loading [URDF](http://wiki.ros.org/urdf) files |\\n\\n\\n\\n## Additional Resources\\n\\n### Blog Posts and Talks\\n\\n- [**New!**] (October 4, 2021) Introducing: Unity Robotics Visualizations Package [blog post](https://blog.unity.com/manufacturing/Introducing-Unity-Robotics-Visualizations-Package)\\n- (August 13, 2021) Advance your robot autonomy with ROS 2 and Unity [blog post](https://blog.unity.com/manufacturing/advance-your-robot-autonomy-with-ros-2-and-unity)\\n- (March 2, 2021) Teaching robots to see with Unity [blog post](https://blogs.unity3d.com/2021/03/02/teaching-robots-to-see-with-unity/)\\n- (November 19, 2020) Robotics simulation in Unity is as easy as 1, 2, 3! [blog post](https://blogs.unity3d.com/2020/11/19/robotics-simulation-in-unity-is-as-easy-as-1-2-3/)\\n- (November 12, 2020)\\nUnite Now 2020: Simulating Robots with ROS and Unity [video](https://resources.unity.com/unitenow/onlinesessions/simulating-robots-with-ros-and-unity)\\n- (August 26, 2020)\\nAnnouncing Unity Robotic Simulation [blog post](https://unity.com/solutions/automotive-transportation-manufacturing/robotics)\\n- (May 20, 2020)\\nUse articulation bodies to easily prototype industrial designs with realistic motion and behavior [blog post](https://blogs.unity3d.com/2020/05/20/use-articulation-bodies-to-easily-prototype-industrial-designs-with-realistic-motion-and-behavior/)\\n\\n### More from Unity\\n\\n- [Unity Industrial Simulation](https://unity.com/products/unity-simulation)\\n- [Unity Computer Vision](https://unity.com/computer-vision)\\n- [Unity ML-Agents Toolkit](https://github.com/Unity-Technologies/ml-agents)\\n\\n## New Physics Features in Unity\\n### New Features\\n- **Contact Modification API** This API will allow users to define custom contact reactions, such as ignoring subsets of contact points, in order to help simulate holes, slippery surfaces, soft contacts, and more. It is available in Unity versions **2021.2a12+**. [Read more about the new Contact Modification API](https://forum.unity.com/threads/experimental-contacts-modification-api.924809/).\\n- **Collision detection modes exposed for ArticulationBody: discrete, sweep-based CCD, and speculative CCD**. New continuous collision detection (CCD) modes will ensure that fast-moving objects collide with objects, instead of tunneling or passing through those objects, which can happen in the default “discrete” mode. This API is available in Unity versions **2020.3.5f1+**. [Read more about continuous collision detection](https://docs.unity3d.com/2020.3/Documentation/ScriptReference/ArticulationBody-collisionDetectionMode.html).\\n\\n### Coming Soon\\nHere’s a peek into what our Physics Team is hard at work on…\\n\\n- **Wheel Collider shapes**. This feature will allow the user to specify the shape of the collider to be used for collision detection. Currently the collider shape is fixed to a cylinder, and collision detection is performed by casting a ray from the center of the cylinder. Custom shapes will improve the accuracy of simulating wheels over rough terrains, holes, etc. [Read more about Wheel Collider](https://docs.unity3d.com/Manual/class-WheelCollider.html).\\n- **Force/Torque Sensor API**. This API will allow users to get the force and torque acting on an articulation body (useful for simulating a force/torque sensor!), as well as to get the motor torque applied by an articulation drive.\\n- **Query primitives**. These simple, GameObject-less shapes allow for collision detection without requiring simulation (i.e., without calling Physics.Simulate). This feature will allow users to initialize objects in feasible locations, and can also be used for motion planning.\\n\\n## ROS 2\\nROS2 support is now available! You can get started by following [this tutorial](https://github.com/Unity-Technologies/Unity-Robotics-Hub/blob/main/tutorials/ros_unity_integration/publisher.md).\\n\\n## Community and Feedback\\n\\nThe Unity Robotics projects are open-source and we encourage and welcome contributions.\\nIf you wish to contribute, be sure to review our [contribution guidelines](CONTRIBUTING.md)\\nand [code of conduct](CODE_OF_CONDUCT.md).\\n\\n## Support\\n\\nFor questions or discussions about Unity Robotics package installations or how to best set up and integrate your robotics projects, please create a new thread on the [Unity Robotics forum](https://forum.unity.com/forums/robotics.623/) and make sure to include as much detail as possible.\\n\\nFor feature requests, bugs, or other issues, please file a [GitHub issue](https://github.com/Unity-Technologies/Unity-Robotics-Hub/issues) using the provided templates and the Robotics team will investigate as soon as possible.\\n\\nFor any other questions or feedback, connect directly with the\\nRobotics team at [unity-robotics@unity3d.com](mailto:unity-robotics@unity3d.com).\\n\\n## Newsletter\\nTo get notified about new updates and features, [sign up for our newsletter](https://create.unity3d.com/robotics-simulation-newsletter-sign-up)!\\n\\n## FAQs\\n[FAQs](faq.md)\\n\\n## License\\n[Apache License 2.0](LICENSE)\\n'},\n",
       " {'repo': 'petercorke/robotics-toolbox-matlab',\n",
       "  'language': 'MATLAB',\n",
       "  'readme_contents': \"[![Build Status](https://travis-ci.com/petercorke/robotics-toolbox-matlab.svg?branch=master)](https://travis-ci.com/petercorke/robotics-toolbox-matlab)\\n![Coverage](https://codecov.io/gh/petercorke/robotics-toolbox-matlab/branch/master/graph/badge.svg)\\n[![License: LGPL v3](https://img.shields.io/badge/License-LGPL%20v3-blue.svg)](https://www.gnu.org/licenses/lgpl-3.0)\\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/petercorke/robotics-toolbox-matlab/graphs/commit-activity)\\n[![GitHub stars](https://img.shields.io/github/stars/petercorke/robotics-toolbox-matlab.svg?style=social&label=Star&maxAge=2592000)](https://GitHub.com/petercorke/robotics-toolbox-matlab/stargazers/)\\n\\n\\n# Robotics Toolbox for MATLAB&reg; release 10\\n\\n---\\nFor support please use the [Google group forum](http://groups.google.com/group/robotics-tool-box?hl=en) rather than GitHub issues.  There are more people participating and you'll likely get a quicker response.  Checkout the [FAQ](https://petercorke.com/toolboxes/faq) before you post a question, it covers common problems that arise with incorrect MATLAB paths.\\n\\n---\\n\\n## Synopsis\\n\\nThis toolbox brings robotics specific functionality to MATLAB, exploiting the native capabilities of MATLAB (linear algebra, portability, graphics).\\n\\nThe Toolbox uses a very general method of representing the kinematics and dynamics of serial-link manipulators as MATLAB®  objects –  robot objects can be created by the user for any serial-link manipulator and a number of examples are provided for well known robots from Kinova, Universal Robotics, Rethink as well as classical robots such as the Puma 560 and the Stanford arm.\\n\\nThe toolbox also supports mobile robots with functions for robot motion models (unicycle, bicycle), path planning algorithms (bug, distance transform, D*, PRM), kinodynamic planning (lattice, RRT), localization (EKF, particle filter), map building (EKF) and simultaneous localization and mapping (EKF), and a Simulink model a of non-holonomic vehicle.  The Toolbox also including a detailed Simulink model for a quadrotor flying robot.\\n\\nAdvantages of the Toolbox are that:\\n\\n  * the code is mature and provides a point of comparison for other implementations of the same algorithms;\\n  * the routines are generally written in a straightforward manner which allows for easy understanding, perhaps at the expense of computational efficiency. If you feel strongly about computational efficiency then you can always rewrite the function to be more efficient, compile the M-file using the MATLAB compiler, or create a MEX version;\\n  * since source code is available there is a benefit for understanding and teaching.\\n  \\nThis Toolbox dates back to 1993 and significantly predates the [Robotics Systems Toolbox&reg;](https://www.mathworks.com/products/robotics.html) from MathWorks.  The former is free, open and not supported, while the latter is a fully supported commercial product.\\n\\n## Code Example\\n\\n```matlab\\n>> mdl_puma560\\n>> p560\\np560 = \\n\\nPuma 560 [Unimation]:: 6 axis, RRRRRR, stdDH, fastRNE            \\n - viscous friction; params of 8/95;                             \\n+---+-----------+-----------+-----------+-----------+-----------+\\n| j |     theta |         d |         a |     alpha |    offset |\\n+---+-----------+-----------+-----------+-----------+-----------+\\n|  1|         q1|          0|          0|     1.5708|          0|\\n|  2|         q2|          0|     0.4318|          0|          0|\\n|  3|         q3|    0.15005|     0.0203|    -1.5708|          0|\\n|  4|         q4|     0.4318|          0|     1.5708|          0|\\n|  5|         q5|          0|          0|    -1.5708|          0|\\n|  6|         q6|          0|          0|          0|          0|\\n+---+-----------+-----------+-----------+-----------+-----------+\\n \\n>> p560.fkine([0 0 0 0 0 0])  % forward kinematics\\nans = \\n         1         0         0    0.4521\\n         0         1         0     -0.15\\n         0         0         1    0.4318\\n         0         0         0         1\\n```\\n\\nWe can animate a path\\n\\n![Puma robot animation](doc/figs/move2ball.gif)\\n\\n```matlab\\nmdl_puma560\\n\\np = [0.8 0 0];\\nT = transl(p) * troty(pi/2);\\nqr(1) = -pi/2;\\nqqr = p560.ikine6s(T, 'ru');\\nqrt = jtraj(qr, qqr, 50);\\n\\nplot_sphere(p, 0.05, 'y');\\np560.plot3d(qrt, 'view', ae, 'movie', 'move2ball.gif');\\n```\\n\\n### Quadrotor animation\\n\\nMobile robot lifting off and hovering over a point following a circular trajectory, while also slowly turning.\\n\\n```matlab\\n>> sl_quadrotor\\n```\\n\\n![Quadrotor animation](doc/figs/quad.gif)\\n\\n### Mobile robot animation\\nCar-like mobile robot doing a 3-point turn computed using the Reeds-Shepp planner\\n\\n![Mobile robot particle filter animation](doc/figs/3point.gif)\\n\\n```matlab\\nq0 = [0 0 0]'; % initial configuration [x y theta]\\nqf = [0 0 pi]'; % final configuration\\nmaxcurv = 1/5;   % 5m turning circle\\nrs = ReedsShepp(q0, qf, maxcurv, 0.05)\\n\\n% set up a vehicle model for animation\\n[car.image,~,car.alpha] = imread('car2.png');\\ncar.rotation = 180; % degrees\\ncar.centre = [648; 173]; % pix\\ncar.length = 4.2; % m\\n\\n% setup the plot\\nclf; plotvol([-4 8 -6 6])\\na = gca;\\na.XLimMode = 'manual';\\na.YLimMode = 'manual';\\nset(gcf, 'Color', 'w')\\ngrid on\\na = gca;\\nxyzlabel\\n\\n% now animate\\nplot_vehicle(rs.path, 'model', car, 'trail', 'r:', 'movie', '3point.gif');\\n```\\n\\n### Particle filter localization animation\\n\\nMobile robot localizing from beacons using a particle filter.\\n\\n![Mobile robot particle filter animation](doc/figs/pf.gif)\\n\\n```matlab\\nV = diag([0.1, 1*pi/180].^2);\\nveh = Vehicle(V);\\nveh.add_driver( RandomPath(10) );\\nmap = Map(20, 10);\\nW = diag([0.1, 1*pi/180].^2);\\nL = diag([0.1 0.1]);\\nQ = diag([0.1, 0.1, 1*pi/180]).^2;\\n\\npf = ParticleFilter(veh, sensor, Q, L, 1000, 'movie', 'pf.mp4');\\npf.run(100);\\n```\\n\\nA fully commented version of this is provided in the LiveScript `demos/particlefilt.mlx`.\\n\\n## What's new\\n\\n* Travis CI is now running on the code base\\n* All code related to pose representation has been split out into the [Spatial Math Toolbox](https://github.com/petercorke/spatial-math).  This repo is now a dependency.\\n* `SerialLink` class has a `twists` method which returns a vector of `Twist` objects, one per joint.  This supports the product of exponential formulation for forward kinematics and Jacobians.\\n* a prototype URDF parser\\n\\n## Installation\\n\\n### Install from shared MATLAB Drive folder\\n\\nThis will work for MATLAB Online or MATLAB Desktop provided you have [MATLAB drive](https://www.mathworks.com/products/matlab-drive.html) setup.\\n\\n1. Click on the appropriate link below and an invitation to share will be emailed to the address associated with your MATLAB account:\\n\\n  * [RVC 2nd edition RTB10+MVTB4 (2017)](https://drive.matlab.com/sharing/e5e3ffef-f3d4-4f70-88a4-1ea0db0efb1a)\\n  * [RVC 1st edition: RTB9+MVTB3 (2011)](https://drive.matlab.com/sharing/0442fc1b-5b9e-45c8-abf9-54cbbd00082a)\\n\\n2. Accept the invitation.\\n3. A folder named RVC1  or RVC2 will appear in your MATLAB drive folder.\\n4. Use the MATLAB file browser and navigate to the folder RVCx/rvctools and double-click the script named startup_rvc.m\\n\\nNote that this is a combo-installation that includes the Machine Vision Toolbox (MVTB) as well.\\n\\n### Install from github\\n\\nYou need to have a recent version of MATLAB, R2016b or later.\\n\\nThe Robotics Toolbox for MATLAB has dependency on two other GitHub repositories: [`spatial-math`](https://github.com/petercorke/spatial-math) and [`toolbox-common-matlab`](https://github.com/petercorke/toolbox-common-matlab).  \\n\\nTo install the Toolbox on your computer from github follow these simple instructions.\\n\\nFrom the shell:\\n\\n```shell\\nmkdir rvctools\\ncd rvctools\\ngit clone https://github.com/petercorke/robotics-toolbox-matlab.git robot\\ngit clone https://github.com/petercorke/spatial-math.git smtb\\ngit clone https://github.com/petercorke/toolbox-common-matlab.git common\\nmake -C robot\\n```\\nThe last command builds the MEX files and Java class files. Then, from within MATLAB\\n```matlab\\n>> addpath rvctools/common  %  rvctools is the same folder as above\\n>> startup_rvc\\n```\\nThe second line sets up the MATLAB path appropriately but it's only for the current session.  You can either:\\n1. Repeat this everytime you start MATLAB\\n2. Add the MATLAB commands above to your `startup.m` file\\n3. Once you have run startup_rvc, run `pathtool` and push the `Save` button, this will save the path settings for subsequent sessions.\\n\\n\\n## Online resources:\\n\\n* [Home page](http://www.petercorke.com)\\n* [Discussion group](http://groups.google.com/group/robotics-tool-box?hl=en)\\n\\nPlease email bug reports, comments or code contribtions to me at rvc@petercorke.com\\n  \\n\\n## Contributors\\n\\nContributions welcome.  There's a user forum at http://tiny.cc/rvcforum\\n\\n## License\\n\\nThis toolbox is released under GNU LGPL.\\n\\n# Other MATLAB toolboxes for robotics\\n\\n* [Compliant joint toolbox](https://github.com/geez0x1/CompliantJointToolbox), MATLAB and Simulink blocks to simulate robots with compliant joints\\n* [ARTE: Robotics Toolbox for Education](http://arvc.umh.es/arte), a MATLAB toolbox focussed on industrial robotic manipulators, with rich 3D graphics, teach pendants and the ABB RAPID language.\\n* [RTB interface to V-REP](https://github.com/Rhys-Davies/rtb-sim), a MATLAB class-based interface to the V-REP robotics simulator.  Includes an implementation for the TRS task.\\n* [MATLAB Interface for Mobile Robots (US NPL)](http://faculty.nps.edu/yun/mri.html), a pure MATLAB toolbox for control of P3 mobile robots.\\n* [Kuka-Sunrise toolbox](https://github.com/Modi1987/KST-Kuka-Sunrise-Toolbox), A Toolbox used to control KUKA iiwa 7 R 800 robot from an external computer using MATLAB.\\n* [Robotics System Toolbox](https://au.mathworks.com/products/robotics.html), MathWorks proprietary.\\n\"},\n",
       " {'repo': 'AprilRobotics/apriltag',\n",
       "  'language': 'C',\n",
       "  'readme_contents': 'AprilTag 3\\n==========\\nAprilTag is a visual fiducial system popular in robotics research. This repository contains the most recent version of AprilTag, AprilTag 3, which includes a faster (>2x) detector, improved detection rate on small tags, flexible tag layouts, and pose estimation. AprilTag consists of a small C library with minimal dependencies.\\n\\nYou can find tag images for the pre-generated layouts [here](https://github.com/AprilRobotics/apriltag-imgs). We recommend using the tagStandard41h12 layout.\\n\\nTable of Contents\\n=================\\n- [Papers](#papers)\\n- [Install](#install)\\n  - [cmake](#cmake)\\n  - [make](#make)\\n- [Usage](#usage)\\n  - [Choosing a Tag Family](#choosing-a-tag-family)\\n  - [Getting Started with the Detector](#getting-started-with-the-detector)\\n    - [Python](#python)\\n    - [C](#c)\\n    - [Matlab](#matlab)\\n    - [Julia](#julia)\\n  - [Upgrading from AprilTag 2](#upgrading-from-aprilTag-2)\\n  - [OpenCV Integration](#opencv-integration)\\n  - [Tuning the Detector Parameters](#tuning-the-detector-parameters)\\n    - [Increasing speed.](#increasing-speed)\\n    - [Increasing detection distance.](#increasing-detection-distance)\\n  - [Pose Estimation.](#pose-estimation)\\n- [Debugging](#debugging)\\n- [Flexible Layouts](#flexible-layouts)\\n- [Support](#support)\\n\\nPapers\\n======\\nAprilTag is the subject of the following papers.\\n\\n[AprilTag: A robust and flexible visual fiducial system](https://april.eecs.umich.edu/papers/details.php?name=olson2011tags)\\n\\n[AprilTag 2: Efficient and robust fiducial detection](https://april.eecs.umich.edu/papers/details.php?name=wang2016iros)\\n\\n[Flexible Layouts for Fiducial Tags](https://april.eecs.umich.edu/papers/details.php?name=krogius2019iros)\\n\\nInstall\\n=======\\n\\nOfficially only Linux operating systems are supported, although users have had success installing on Windows too.\\n\\nThe default installation will place headers in /usr/local/include and shared library in /usr/local/lib. It also installs a pkg-config script into /usr/local/lib/pkgconfig and will install a python wrapper if python3 is installed.\\n\\n## cmake\\nIf you have CMake installed, then do:\\n```\\ncmake -B build -DCMAKE_BUILD_TYPE=Release\\ncmake --build build --target install\\n```\\nThis will build shared (\\\\*.so) libraries by default. If you need static (\\\\*.a) libraries set `BUILD_SHARED_LIBS` to `OFF`:\\n```\\ncmake -B build -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF\\ncmake --build build --target install\\n```\\n\\nIf you have Ninja (`sudo apt install ninja-build`) installed, you can use:\\n```\\ncmake -B build -GNinja -DCMAKE_BUILD_TYPE=Release\\ncmake --build build --target install\\n```\\nto generate and compile via the ninja build script. It will be much faster than with cmake\\'s default Makefile generator.\\n\\nYou can omit `--target install` if you only want to use this locally without installing.\\n\\n## make\\nOtherwise, we have a handwritten makefile you can use (be warned it will do slightly different things):\\n```\\nmake -j\\nsudo make install\\n```\\n\\nTo install to a different directory than /usr/local:\\n\\n    $ PREFIX=/some/path sudo make install\\n\\nUsage\\n=====\\n\\n## Choosing a Tag Family\\nFor the vast majority of applications, the tagStandard41h12 family will be the correct choice. You can find the images for the tags in the [apriltag-imgs repo](https://github.com/AprilRobotics/apriltag-imgs). Scale up the images in your favorite editor and print them out.\\n\\nSome heuristics for when to choose other tag families:\\n1. If you need more tags, use tagStandard52h13\\n2. If you need to maximize the use of space on a small circular object, use tagCircle49h12 (or tagCircle21h7).\\n3. If you want to make a recursive tag use tagCustom48h12.\\n4. If you want compatibility with the ArUcO detector use tag36h11\\n\\nIf none of these fit your needs, generate your own custom tag family [here](https://github.com/AprilRobotics/apriltag-generation).\\n\\n## Getting Started with the Detector\\n### Python\\n\\n    import cv2\\n    import numpy as np\\n    from apriltag import apriltag\\n\\n    imagepath = \\'test.jpg\\'\\n    image = cv2.imread(imagepath, cv2.IMREAD_GRAYSCALE)\\n    detector = apriltag(\"tagStandard41h12\")\\n\\n    detections = detector.detect(image)\\n\\nAlternately you can use the AprilTag python bindings created by [duckietown](https://github.com/duckietown/apriltags3-py).\\n\\n### C\\n\\n    image_u8_t* im = image_u8_create_from_pnm(\"test.png\");\\n    apriltag_detector_t *td = apriltag_detector_create();\\n    apriltag_family_t *tf = tagStandard41h12_create();\\n    apriltag_detector_add_family(td, tf);\\n    zarray_t *detections = apriltag_detector_detect(td, im);\\n\\n    for (int i = 0; i < zarray_size(detections); i++) {\\n        apriltag_detection_t *det;\\n        zarray_get(detections, i, &det);\\n\\n        // Do stuff with detections here.\\n    }\\n    // Cleanup.\\n    tagStandard41h12_destroy(tf);\\n    apriltag_detector_destroy(td);\\n\\n### Matlab\\n\\nProvided by third-party [here](https://github.com/alddiaz/MATLAB_AprilTag3).\\n\\n### Julia\\n\\nProvided by third-party [here](https://github.com/JuliaRobotics/AprilTags.jl)\\n\\n\\n## Upgrading from AprilTag 2\\nFor most use-cases this should be a drop in replacement.\\n\\n* The options refine_decode, refine_pose, and black_border have been removed.\\n* If you have generated your own families, you will need to regenerate the c code for those families. The java code however does not need to be regenerated so this should be quick and easy.\\n\\n\\n## OpenCV Integration\\n\\nNote that this library has no external dependencies. Most applications\\nwill require, at minimum, a method for acquiring images.\\n\\nSee example/opencv_demo.cc for an example of using AprilTag in C++ with OpenCV.\\nThis example application can be built by executing the following:\\n\\n    $ cd examples\\n    $ make opencv_demo\\n\\nImage data in a cv::Mat object can be passed to AprilTag without creating\\na deep copy. Simply create an image_u8_t header for the cv::Mat data buffer:\\n\\n    cv::Mat img;\\n\\n    image_u8_t img_header = { .width = img.cols,\\n        .height = img.rows,\\n        .stride = img.cols,\\n        .buf = img.data\\n    };\\n\\n\\n\\n## Tuning the Detector Parameters\\n### Increasing speed.\\nIncreasing the quad_decimate parameter will increase the speed of the detector at the cost of detection distance.  If you have extra cpu cores to throw at the problem then you can increase nthreads. If your image is somewhat noisy, increasing the quad_sigma parameter can increase speed.\\n\\n### Increasing detection distance.\\nFirst choose an example image and run the detector with debug=1 to generate the debug images. These show the detector\\'s output at each step in the detection pipeline.\\nIf the border of your tag is not being detected as a quadrilateral, decrease quad_decimate (all the way to 1 if necessary).\\nIf the border of the tag is detected then experiment with changing decode_sharpening.\\n\\n## Pose Estimation.\\nWe provide a method for computing the pose of the tag as follows (alternately use OpenCv\\'s Pnp solver with SOLVEPNP_IPPE_SQUARE). You will need to include the apriltag_pose.h header file and then call the estimate_tag_pose function as follows:\\n\\n    // First create an apriltag_detection_info_t struct using your known parameters.\\n    apriltag_detection_info_t info;\\n    info.det = det;\\n    info.tagsize = tagsize;\\n    info.fx = fx;\\n    info.fy = fy;\\n    info.cx = cx;\\n    info.cy = cy;\\n\\n    // Then call estimate_tag_pose.\\n    apriltag_pose_t pose;\\n    double err = estimate_tag_pose(&info, &pose);\\n    // Do something with pose.\\n    ...\\n\\nwhere the parameters are as follows:\\n* `det`: The tag detection struct (april_detection_t).\\n* `tagsize`: The size of the tag in meters. Each tag design has a black border and a white border, but some designs have the white border on the inside and some have the black border on the inside. The tagsize is thus measured from where the two borders meet, see the figure below for an example.\\n* `fx`, `fy`: The camera\\'s focal length (in pixels). For most cameras `fx` and `fy` will be equal or nearly so.\\n* `cx`, `cy`: The camera\\'s focal center (in pixels). For most cameras this will be approximately the same as the image center.\\n\\nNote: The tag size should not be measured from the outside of the tag. The tag size is defined as the distance between the detection corners, or alternately, the length of the edge between the white border and the black border. The following illustration marks the detection corners with red Xs and the tag size with a red arrow for a tag from the 48h12Custom tag family.\\n\\n ![The tag size is the width of the edge between the white and black borders.](tag_size_48h12.png)\\n\\n### Coordinate System\\nThe coordinate system has the origin at the camera center. The z-axis points from the camera center out the camera lens. The x-axis is to the right in the image taken by the camera, and y is down. The tag\\'s coordinate frame is centered at the center of the tag, with x-axis to the right, y-axis down, and z-axis into the tag.\\n\\nDebugging\\n=========\\n\\nYou can enable [AddressSanitizer](https://clang.llvm.org/docs/AddressSanitizer.html) to debug memory issues for Debug builds by setting the `ASAN` option:\\n```\\ncmake -B build -GNinja -DCMAKE_BUILD_TYPE=Debug -DASAN=ON\\ncmake --build build\\n```\\n\\nMostly you can then run your executables as usual and inspect the sanitiser output. If you get a message like `ASan runtime does not come first in initial library list; you should either link runtime to your application or manually preload it with LD_PRELOAD.` you have to preload the corresponding `libasan.so.5` like this:\\n```\\nLD_PRELOAD=/usr/lib/x86_64-linux-gnu/libasan.so.5 ./build/opencv_demo\\n```\\n\\nFlexible Layouts\\n================\\nAprilTag 3 supports a wide variety of possible tag layouts in addition to the classic layout supported in AprilTag 2. The tag\\'s data bits can now go outside of the tag border, and it is also possible to define layouts with \"holes\" inside of the tag border where there are no data bits. In this repo we have included:\\n\\n* Two families of the new standard layout. This layout adds a layer of data bits around the outside of the tag border, increasing data density, and the number of possible tags, at the cost of a slight decrease in detection distance.\\n* Two families of circular tags.\\n* One family which has a hole in the middle. This could be used for example for drone applications by placing different sized tags inside of each other to allow detection over a wide range of distances.\\n\\nYou can generate your own tag families using our other repo, [AprilTag-Generation](https://github.com/AprilRobotics/apriltag-generation).\\n\\n\\nSupport\\n=======\\nPlease create an issue on this GitHub for any questions instead of sending a private message. This allows other people with the same question to find your answer.\\n'},\n",
       " {'repo': 'qqfly/how-to-learn-robotics',\n",
       "  'language': None,\n",
       "  'readme_contents': '# 开源机器人学学习指南\\n\\n你可以在 GitBook 上阅读本文： [How to Learn Robotics](https://qiu6401.gitbook.io/how-to-learn-robotics)\\n\\n如果感觉 GitBook 阅读体验不好，也可以切换回 Github，看[第一版](https://github.com/qqfly/how-to-learn-robotics/tree/backup/all-in-one)。\\n\\n本项目写作时间很短，所以肯定有疏漏。因此放在这里作为一个开源项目，大家可以随时修改并提交 [Pull Request](https://github.com/qqfly/how-to-learn-robotics/pulls)；有问题也可以提 [Issues](https://github.com/qqfly/how-to-learn-robotics/issues)。\\n\\n目前本项目只有中文版本，但似乎有一些非中文读者希望能翻译成英文版本 [Issue 2](https://github.com/qqfly/how-to-learn-robotics/issues/2)。如有志愿者愿意参与英文翻译，欢迎随时与我联系[qrobotics [at] yeah [dot] net](mailto:qrobotics@yeah.net)。'},\n",
       " {'repo': 'microsoft/PromptCraft-Robotics',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': '# PromptCraft-Robotics\\n\\nThe PromptCraft-Robotics repository serves as a community for people to test and share interesting prompting examples for large language models (LLMs) within the robotics domain. We also provide a sample [robotics simulator](https://github.com/microsoft/PromptCraft-Robotics/tree/main/chatgpt_airsim) (built on Microsoft AirSim) with ChatGPT integration for users to get started.\\n\\nWe currently focus on OpenAI\\'s [ChatGPT](https://openai.com/blog/chatgpt/), but we also welcome examples from other LLMs (for example open-sourced models or others with API access such as [GPT-3](https://openai.com/api/) and Codex).\\n\\nUsers can contribute to this repository by submitting interesting prompt examples to the [Discussions](https://github.com/microsoft/PromptCraft-Robotics/discussions) section of this repository. A prompt can be submitted within different robotics categories such as [Manipulation](https://github.com/microsoft/PromptCraft-Robotics/discussions/categories/llm-manipulation), [Home Robotics](https://github.com/microsoft/PromptCraft-Robotics/discussions/categories/llm-home-robots), [Physical Reasoning](https://github.com/microsoft/PromptCraft-Robotics/discussions/categories/llm-physical-reasoning), among many others.\\nOnce submitted, the prompt will be reviewed by the community (upvote your favorites!) and added to the repository by a team of admins if it is deemed interesting and useful.\\nWe encourage users to submit prompts that are interesting, fun, or useful. We also encourage users to submit prompts that are not necessarily \"correct\" or \"optimal\" but are interesting nonetheless.\\n\\nWe encourage prompt submissions formatted as markdown, so that they can be easily transferred to the main repository. Please specify which LLM you used, and if possible provide other visuals of the model in action such as videos and pictures.\\n\\n## Paper, videos and citations\\n\\nBlog post: <a href=\"https://aka.ms/ChatGPT-Robotics\" target=\"_blank\">aka.ms/ChatGPT-Robotics</a>\\n\\nPaper: <a href=\"https://www.microsoft.com/en-us/research/uploads/prod/2023/02/ChatGPT___Robotics.pdf\" target=\"_blank\">ChatGPT for Robotics: Design Principles and Model Abilities\\n\\nVideo: <a href=\"https://youtu.be/NYd0QcZcS6Q\" target=\"_blank\">https://youtu.be/NYd0QcZcS6Q</a>\\n\\nIf you use this repository in your research, please cite the following paper:\\n\\n```\\n@techreport{vemprala2023chatgpt,\\nauthor = {Vemprala, Sai and Bonatti, Rogerio and Bucker, Arthur and Kapoor, Ashish},\\ntitle = {ChatGPT for Robotics: Design Principles and Model Abilities},\\ninstitution = {Microsoft},\\nyear = {2023},\\nmonth = {February},\\nurl = {https://www.microsoft.com/en-us/research/publication/chatgpt-for-robotics-design-principles-and-model-abilities/},\\nnumber = {MSR-TR-2023-8},\\n}\\n```\\n\\n## ChatGPT Prompting Guides & Examples\\n\\nThe list below contains links to the different robotics categories and their corresponding prompt examples. We welcome contributions to this repository to add more robotics categories and examples. Please submit prompt examples to the [Discussions](https://github.com/microsoft/PromptCraft-Robotics/discussions) page, or submit a pull request with your category and examples.\\n\\n* Embodied agent \\n  * [ChatGPT - Habitat, closed loop object navigation 1](examples/embodied_agents/visual_language_navigation_1.md)\\n  * [ChatGPT - Habitat, closed loop object navigation 2](examples/embodied_agents/visual_language_navigation_2.md)\\n  * [ChatGPT - AirSim, object navigation using RGBD](examples/embodied_agents/airsim_objectnavigation.md)\\n* Aerial robotics\\n  * [ChatGPT - Real robot: Tello deployment](examples/aerial_robotics/tello_example.md) | [Video Link](https://youtu.be/i5wZJFb4dyA)\\n  * [ChatGPT - AirSim turbine Inspection](examples/aerial_robotics/airsim_turbine_inspection.md) | [Video Link](https://youtu.be/38lA3U2J43w)\\n  * [ChatGPT - AirSim solar panel Inspection](examples/aerial_robotics/airsim_solarpanel_inspection.md)\\n  * [ChatGPT - AirSim obstacle avoidance](examples/aerial_robotics/airsim_obstacleavoidance.md) | [Video Link](https://youtu.be/Vn6NapLlHPE)\\n* Manipulation\\n  * [ChatGPT - Real robot: Picking, stacking, and building the MSFT logo](examples/manipulation/pick_stack_msft_logo.md) | [Video Link](https://youtu.be/wLOChUtdqoA)\\n  * [ChatGPT - Manipulation tasks](examples/manipulation/manipulation_zeroshot.md)\\n* Spatial-temporal reasoning\\n  * [ChatGPT - Visual servoing with basketball](examples/spatial_temporal_reasoning/visual_servoing_basketball.md)\\n\\n\\n## ChatGPT + Robotics Simulator\\n\\nWe provice a sample [AirSim](https://github.com/microsoft/AirSim) environment for users to test their ChatGPT prompts. The environment is a binary containing a sample inspection environment with assets such as wind turbines, electric towers, solar panels etc. The environment comes with a drone and interfaces with ChatGPT such that users can easily send commands in natural language. [[Simulator Link]](chatgpt_airsim/README.md)\\n\\nWe welcome contributions to this repository to add more robotics simulators and environments. Please submit a pull request with your simulator and environment.\\n\\n## Related resources\\n\\nBeyond the prompt examples here, we leave useful and related links to the use of large language models below:\\n\\n* [Read about the OpenAI APIs](https://openai.com/api/)\\n* [Azure OpenAI service](https://azure.microsoft.com/en-us/products/cognitive-services/openai-service)\\n* [OPT language model](https://huggingface.co/docs/transformers/model_doc/opt)\\n\\n## Contributing\\n\\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\\n\\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\\nprovided by the bot. You will only need to do this once across all repos using our CLA.\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n\\n## Trademarks\\n\\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \\ntrademarks or logos is subject to and must follow \\n[Microsoft\\'s Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\\nAny use of third-party trademarks or logos are subject to those third-party\\'s policies.\\n'},\n",
       " {'repo': 'ahundt/awesome-robotics',\n",
       "  'language': None,\n",
       "  'readme_contents': '# Awesome Robotics\\n\\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\\n\\nAwesome links, software libraries, [papers](papers.md), and other [intersting links](interesting.md) that are useful for robots.\\n\\n\\nRelevant Awesome Lists\\n----------------------\\n\\n- [Kiloreaux/awesome-robotics](https://github.com/Kiloreux/awesome-robotics) - Learn about Robotics.\\n- [Robotics Libraries](https://github.com/jslee02/awesome-robotics-libraries) - Another list of awesome robotics libraries.\\n- [Robotics Coursework](https://github.com/mithi/robotics-coursework) - A list of robotics courses you can take online\\n- [Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)\\n- [Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning) - Neural networks.\\n    - [TensorFlow](https://github.com/jtoy/awesome-tensorflow) - Library for machine intelligence.\\n    - [Papers](https://github.com/terryum/awesome-deep-learning-papers) - The most cited deep learning papers.\\n- [Deep Vision](https://github.com/kjw0612/awesome-deep-vision) - Deep learning for computer vision\\n- [Data Visualization](https://github.com/fasouto/awesome-dataviz) - See what your robot is doing with any programming language.\\n- [paperswithcode state of the art](https://paperswithcode.com/sota) - List of state of the art results on various machine learning benchmarks.\\n\\nSimulators\\n----------\\n\\n- [CoppeliaSim](coppeliarobotics.com/index.html) - Create, Simulate, any Robot. (formerly named V-REP)\\n- [Microsoft Airsim](https://github.com/Microsoft/AirSim) - Open source simulator based on Unreal Engine for autonomous vehicles from Microsoft AI & Research.\\n- [Bullet Physics SDK](https://github.com/bulletphysics/bullet3) - Real-time collision detection and multi-physics simulation for VR, games, visual effects, robotics, machine learning etc. Also see [pybullet](https://pybullet.org).\\n\\nVisualization, Video, Display, and Rendering\\n-----------------------\\n\\n - [Pangolin](https://github.com/stevenlovegrove/Pangolin) - A lightweight portable rapid development library for managing OpenGL display / interaction and abstracting video input.\\n- [PlotJuggler](https://github.com/facontidavide/PlotJuggler) - Quickly plot and re-plot data on the fly! Includes optional ROS integration.\\n- [Data Visualization](https://github.com/fasouto/awesome-dataviz) - A list of awesome data visualization tools.\\n\\nMachine Learning\\n----------------\\n\\n### TensorFlow related\\n\\n- [Keras](https://keras.io) - Deep Learning library for Python. Convnets, recurrent neural networks, and more. Runs on TensorFlow or Theano.\\n- [keras-contrib](https://github.com/farizrahman4u/keras-contrib) - Keras community contributions.\\n- [TensorFlow](tensorflow.org) - An open-source software library for Machine Intelligence.\\n- [recurrentshop](https://github.com/datalogai/recurrentshop) - Framework for building complex recurrent neural networks with Keras.\\n- [tensorpack](https://github.com/ppwwyyxx/tensorpack) - Neural Network Toolbox on TensorFlow.\\n- [tensorlayer](https://github.com/zsdonghao/tensorlayer) - Deep Learning and Reinforcement Learning Library for Researchers and Engineers.\\n- [TensorFlow-Examples](https://github.com/aymericdamien/TensorFlow-Examples) - TensorFlow Tutorial and Examples for beginners.\\n- [hyperas](https://github.com/maxpumperla/hyperas) - Keras + Hyperopt: A very simple wrapper for convenient hyperparameter optimization.\\n- [elephas](https://github.com/maxpumperla/elephas) - Distributed Deep learning with Keras & Spark\\n- [PipelineAI](https://github.com/fluxcapacitor/pipeline) - End-to-End ML and AI Platform for Real-time Spark and Tensorflow Data Pipelines.\\n- [sonnet](https://github.com/deepmind/sonnet) - Google Deepmind APIs on top of TensorFlow.\\n- [visipedia/tfrecords](https://github.com/visipedia/tfrecords) - Demonstrates the use of TensorFlow\\'s TFRecord data format.\\n\\n#### Image Segmentation\\n\\n- [tf-image-segmentation](https://github.com/warmspringwinds/tf-image-segmentation) - Image Segmentation framework based on Tensorflow and TF-Slim library.\\n- [Keras-FCN](https://github.com/aurora95/Keras-FCN)\\n\\n\\nLogging and Messaging\\n---------------------\\n\\n- [spdlog](https://github.com/gabime/spdlog) - Super fast C++ logging library.\\n- [lcm](https://github.com/lcm-proj/lcm) - Lightweight Communications and Marshalling, message passing and data marshalling for real-time systems where high-bandwidth and low latency are critical.\\n\\nTracking\\n--------\\n\\n- [simtrack](https://github.com/karlpauwels/simtrack) - A simulation-based framework for tracking.\\n- [ar_track_alvar](https://github.com/sniekum/ar_track_alvar) - AR tag tracking library for ROS.\\n- [artoolkit5](https://github.com/artoolkit/artoolkit5) - Augmented Reality Toolkit, which has excellent AR tag tracking software.\\n\\nRobot Operating System (ROS)\\n----------------------------\\n\\n- [ROS](ros.org) - Main ROS website.\\n- [ros2/design](https://github.com/ros2/design) - Design documentation for ROS 2.0 effort.\\n\\n\\nKinematics, Dynamics, Constrained Optimization\\n----------------------------------------------\\n\\n- [jrl-umi3218/Tasks](https://github.com/jrl-umi3218/Tasks) - Tasks is library for real time control of robots and kinematic trees using constrained optimization.\\n- [jrl-umi3218/RBDyn](https://github.com/jrl-umi3218/RBDyn) - RBDyn provides a set of classes and functions to model the dynamics of rigid body systems.\\n- [ceres-solver](https://github.com/ceres-solver/ceres-solver) - Solve Non-linear Least Squares problems with bounds constraints and general unconstrained optimization problems. Used in production at Google since 2010.\\n- [orocos_kinematics_dynamics](https://github.com/orocos/orocos_kinematics_dynamics) - Orocos Kinematics and Dynamics C++ library.\\n- [flexible-collsion-library](https://github.com/flexible-collision-library/fcl) - Performs three types of proximity queries on a pair of geometric models composed of triangles, integrated with ROS. \\n- [robot_calibration](https://github.com/mikeferguson/robot_calibration) - generic robot kinematics calibration for ROS\\n- [ruckig](https://github.com/pantor/ruckig) - Real-time, time-optimal and jerk-constrained online trajectory generation.\\n\\nCalibration\\n-----------\\n\\n- [handeye-calib-camodocal](https://github.com/jhu-lcsr/handeye_calib_camodocal) - generic robot hand-eye calibration.\\n- [robot_calibration](https://github.com/mikeferguson/robot_calibration) - generic robot kinematics calibration for ROS\\n- [kalibr](https://github.com/ethz-asl/kalibr) - camera and imu calibration for ROS\\n\\nReinforcement Learning\\n----------------------\\n\\n- [\"Good Robot!\": Efficient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer](https://github.com/jhu-lcsr/good_robot) - A real robot completes multi-step tasks after <20k simulated actions. [Good Robot on ArXiV](https://arxiv.org/abs/1909.11730) (disclaimer: @ahundt is first author)\\n- [TensorForce](https://github.com/reinforceio/tensorforce) - A TensorFlow library for applied reinforcement learning\\n- [gqcnn](https://github.com/BerkeleyAutomation/gqcnn) -  [Grasp Quality Convolutional Neural Networks (GQ-CNNs)](https://berkeleyautomation.github.io/gqcnn/info/info.html) for grasp planning using training datasets from the [Dexterity Network (Dex-Net)](https://berkeleyautomation.github.io/dex-net)\\n- [Guided Policy Search](https://github.com/cbfinn/gps) - Guided policy search (gps) algorithm and LQG-based trajectory optimization, meant to help others understand, reuse, and build upon existing work. \\n\\nDrivers for Sensors, Devices and Arms\\n-------------------------------------\\n\\n- [libfreenect2](https://github.com/OpenKinect/libfreenect2) - Open source drivers for the Kinect for Windows v2 and Xbox One devices.\\n- [iai_kinect2](https://github.com/code-iai/iai_kinect2) - Tools for using the Kinect One (Kinect v2) in ROS.\\n- [grl](https://github.com/ahundt/grl) - Generic Robotics Library: Cross platform drivers for Kuka iiwa and Atracsys FusionTrack with optional v-rep and ros drivers. Also has cross platform Hand Eye Calibration and Tool Tip Calibration.\\n\\nDatasets\\n--------\\n\\n- [CoSTAR Block Stacking Dataset](https://sites.google.com/site/costardataset) - Robot stacking colored children\\'s blocks (disclaimer: created by @ahundt)\\n- [shapestacks](http://shapestacks.robots.ox.ac.uk/#paper) - simulated stacks of colored children\\'s objects\\n- [pascal voc 2012](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/) - The classic reference image segmentation dataset.\\n- [openimages](https://github.com/openimages/dataset/) - Huge imagenet style dataset by Google.\\n- [COCO](mscoco.org) - Objects with segmentation, keypoints, and links to many other external datasets.\\n- [cocostuff](https://github.com/nightrome/cocostuff) - COCO additional full scene segmentation including backgrounds and annotator.\\n- [Google Brain Robot Data](https://sites.google.com/site/brainrobotdata/home) - Robotics datasets including grasping, pushing, and pouring.\\n- [Materials in Context](http://opensurfaces.cs.cornell.edu/publications/minc/) - Materials Dataset with real world images in 23 categories.\\n- [Dex-Net 2.0](http://bair.berkeley.edu/blog/2017/06/27/dexnet-2.0/) - 6.7 million pairs of synthetic point clouds and grasps with robustness labels.\\n\\n#### Dataset Collection\\n- [LabelFusion](labelfusion.csail.mit.edu) - \"A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes\" [code](https://github.com/RobotLocomotion/LabelFusion)\\n- [cocostuff](https://github.com/nightrome/cocostuff) - COCO additional full scene segmentation including backgrounds and annotator.\\n\\nLinear Algebra & Geometry\\n-------------------------\\n\\n- [Eigen](http://eigen.tuxfamily.org) - Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms.\\n- [Boost.QVM](https://github.com/boostorg/qvm) - Quaternions, Vectors, Matrices library for Boost.\\n- [Boost.Geometry](https://github.com/boostorg/geometry/) - Boost.Geometry contains instantiable geometry classes, but library users can also use their own.\\n- [SpaceVecAlg](https://github.com/jrl-umi3218/SpaceVecAlg) - Implementation of spatial vector algebra for 3D geometry with the Eigen3 linear algebra library.\\n- [Sophus](https://github.com/strasdat/Sophus) - C++ implementation of Lie Groups which are for 3D Geometry, using Eigen.\\n\\n\\nPoint Clouds\\n------------\\n\\n- [libpointmatcher](https://github.com/ethz-asl/libpointmatcher) - An \"Iterative Closest Point\" library robotics and 2-D/3-D mapping.\\n- [Point Cloud Library (pcl)](https://github.com/PointCloudLibrary/pcl) - The Point Cloud Library (PCL) is a standalone, large scale, open project for 2D/3D image and point cloud processing.\\n\\n\\n\\nSimultaneous Localization and Mapping (SLAM)\\n--------------------------------------------\\n\\n- [ElasticFusion](https://github.com/mp3guy/ElasticFusion) - Real-time dense visual SLAM system.\\n- [co-fusion](https://github.com/martinruenz/co-fusion) - Real-time Segmentation, Tracking and Fusion of Multiple Objects. Extends ElasticFusion.\\n- [Google Cartographer](https://github.com/googlecartographer/cartographer/) - Cartographer is a system that provides real-time simultaneous localization and mapping (SLAM) in 2D and 3D across multiple platforms and sensor configurations.\\n- [OctoMap](https://github.com/OctoMap/octomap) - An Efficient Probabilistic 3D Mapping Framework Based on Octrees. Contains the main OctoMap library, the viewer octovis, and dynamicEDT3D.\\n- [ORB_SLAM2](https://github.com/raulmur/ORB_SLAM2) - Real-Time SLAM for Monocular, Stereo and RGB-D Cameras, with Loop Detection and Relocalization Capabilities.\\n\\n\\n# License\\n\\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\\n'},\n",
       " {'repo': 'rwaldron/johnny-five',\n",
       "  'language': 'JavaScript',\n",
       "  'readme_contents': '![](https://github.com/rwaldron/johnny-five/raw/main/assets/sgier-johnny-five.png)\\n\\n# Johnny-Five\\n### The JavaScript Robotics Programming Framework\\n\\n<!-- \\n\\n    Hello!\\n\\n    Please don\\'t edit this file!\\n\\n    If you\\'d like to make changes to the readme contents, please make them in the tpl/.readme.md file. If you\\'d like to add an example: \\n\\n    1. Add the file in `eg/`\\n    2. Add a breadboard image in `docs/breadboards`\\n    3. Add an entry to `tpl/programs.json`. \\n    4. Generated the markdown with: `grunt examples`\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n-->\\n\\n\\n_Artwork by [Mike Sgier](http://msgierillustration.com)_\\n\\n[![Build, Lint, Test and Measure Coverage](https://github.com/rwaldron/johnny-five/actions/workflows/npm-grunt.yml/badge.svg)](https://github.com/rwaldron/johnny-five/actions)\\n[![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/hmke71k7uemtnami/branch/main?svg=true)](https://ci.appveyor.com/project/rwaldron/johnny-five)\\n[![Coverage Status](https://coveralls.io/repos/github/rwaldron/johnny-five/badge.svg?branch=main)](https://coveralls.io/github/rwaldron/johnny-five?branch=main)\\n[![Install Size](https://packagephobia.now.sh/badge?p=johnny-five)](https://packagephobia.now.sh/result?p=johnny-five)\\n[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg)](https://gitter.im/rwaldron/johnny-five)\\n\\n\\n\\n**Johnny-Five is an Open Source, Firmata Protocol based, IoT and Robotics programming framework, developed by the [Nodebots](https://twitter.com/nodebots) Community. Johnny-Five programs can be written for Arduino (all models), Electric Imp, Beagle Bone, Intel Galileo & Edison, Linino One, Pinoccio, pcDuino3, Raspberry Pi, Particle/Spark Core & Photon, Tessel 2, TI Launchpad and more!**\\n\\nJohnny-Five has grown from a passion project into a tool for inspiring learning and creativity for people of all ages, backgrounds, and from all across the world.\\n\\nJust interested in learning and building awesome things? You might want to start with the official [Johnny-Five website](http://johnny-five.io).\\n\\n* If you want to find the API documentation, [that’s right here](http://johnny-five.io/api/).\\n* Need to figure out what platform to use for a project? We put that stuff [here](http://johnny-five.io/platform-support/).\\n* Need inspiration for your next NodeBot? Check out the [examples](http://johnny-five.io/examples/).\\n* Want to stay up-to-date with projects in the community? [Check this out](http://johnny-five.io/articles/).\\n* Need NodeBots community or Johnny-Five project updates and announcements? [This](http://johnny-five.io/news/) is what you’re looking for.\\n\\n\\nJohnny-Five does not attempt to provide \"all the things\", but instead focuses on delivering robust, reality tested, highly composable APIs that behave consistently across all supported hardware platforms. Johnny-Five wants to be a baseline control kit for hardware projects, allowing you the freedom to build, grow and experiment with diverse JavaScript libraries of your own choice. Johnny-Five couples comfortably with:\\n\\n- Popular application libraries such as [Express.js](http://expressjs.com/) and [Socket.io](http://socket.io/).\\n- Fellow hardware projects like [ar-drone](https://github.com/felixge/node-ar-drone), [Aerogel](https://github.com/ceejbot/aerogel) and [Spheron](https://github.com/alchemycs/spheron)\\n- Bluetooth game controllers like [XBox Controller](https://github.com/andrew/node-xbox-controller) and [DualShock](https://github.com/rdepena/node-dualshock-controller)\\n- IoT frameworks, such as [Octoblu](http://www.octoblu.com/)\\n\\n...And that\\'s only a few of the many explorable possibilities. Check out these exciting projects: [node-pulsesensor](https://www.npmjs.org/package/node-pulsesensor), [footballbot-workshop-ui](https://www.npmjs.org/package/footballbot-workshop-ui), [nodebotui](https://www.npmjs.org/package/nodebotui), [dublin-disco](https://www.npmjs.org/package/dublin-disco), [node-slot-car-bot](https://www.npmjs.org/package/node-slot-car-bot), [servo-calibrator](https://www.npmjs.org/package/servo-calibrator), [node-ardx](https://www.npmjs.org/package/node-ardx), [nodebot-workshop](https://www.npmjs.org/package/nodebot-workshop), [phone-home](https://www.npmjs.org/package/phone-home), [purple-unicorn](https://www.npmjs.org/package/purple-unicorn), [webduino](https://www.npmjs.org/package/webduino), [leapduino](https://www.npmjs.org/package/leapduino), [lasercat-workshop](https://www.npmjs.org/package/lasercat-workshop), [simplesense](https://www.npmjs.org/package/simplesense), [five-redbot](https://www.npmjs.org/package/five-redbot), [robotnik](https://www.npmjs.org/package/robotnik), [the-blender](https://www.npmjs.org/package/the-blender)\\n\\n\\n**Why JavaScript?**\\n[NodeBots: The Rise of JavaScript Robotics](http://www.voodootikigod.com/nodebots-the-rise-of-js-robotics)\\n\\n## Hello Johnny\\n\\nThe ubiquitous \"Hello World\" program of the microcontroller and SoC world is \"blink an LED\". The following code demonstrates how this is done using the Johnny-Five framework.\\n\\n```javascript\\nconst { Board, Led } = require(\"johnny-five\");\\nconst board = new Board();\\n\\nboard.on(\"ready\", () => {\\n  // Create an Led on pin 13\\n  const led = new Led(13);\\n  // Blink every half second\\n  led.blink(500);\\n});\\n```\\n\\n<img src=\"https://github.com/rwaldron/johnny-five/raw/main/assets/led-blink.gif\">\\n\\n> Note: Node will crash if you try to run johnny-five in the node REPL, but board instances will create their own contextual REPL. Put your script in a file.\\n\\n\\n## Supported Hardware\\n\\nJohnny-Five has been tested on a variety of Arduino-compatible [Boards](https://github.com/rwaldron/johnny-five/wiki/Board).\\n\\nFor non-Arduino based projects, a number of platform-specific [IO Plugins](https://github.com/rwaldron/johnny-five/wiki/IO-Plugins) are available. IO Plugins allow Johnny-Five code to communicate with any non-Arduino based hardware in whatever language that platforms speaks!\\n\\n## Documentation\\n\\nDocumentation for the Johnny-Five API can be found [here](http://johnny-five.io/api/) and [example programs here](http://johnny-five.io/examples/).\\n\\n## Guidance\\n\\nNeed help? Ask a question on the [NodeBots Community Forum](http://forums.nodebots.io). If you just have a quick question or are interested in ongoing design discussions, join us in the [Johnny-Five Gitter Chat](https://gitter.im/rwaldron/johnny-five).\\n\\nFor step-by-step examples, including an electronics primer, check out [Arduino Experimenter\\'s Guide for NodeJS](http://node-ardx.org/) by [@AnnaGerber](https://twitter.com/AnnaGerber)\\n\\nHere is a list of [prerequisites](https://github.com/rwaldron/johnny-five/wiki/Getting-Started#prerequisites) for Linux, OSX or Windows.\\n\\nCheck out the [bluetooth guide](https://github.com/rwaldron/johnny-five/wiki/JY-MCU-Bluetooth-Serial-Port-Module-Notes) if you want to remotely control your robot.\\n\\n## Setup and Assemble Arduino\\n\\n- Recommended Starting Kit: [Sparkfun Inventor\\'s Kit](https://www.sparkfun.com/products/12001)\\n- Download [Arduino IDE](http://arduino.cc/en/main/software)\\n- Plug in your Arduino or Arduino compatible microcontroller via USB\\n- Open the Arduino IDE, select: File > Examples > Firmata > StandardFirmataPlus\\n    + StandardFirmataPlus is available in Firmata v2.5.0 or greater\\n- Click the \"Upload\" button.\\n\\nIf the upload was successful, the board is now prepared and you can close the Arduino IDE.\\n\\nFor non-Arduino projects, each IO Plugin\\'s repo will provide its own platform specific setup instructions.\\n\\n\\n## Hey you, here\\'s Johnny!\\n\\n#### Source Code:\\n\\n``` bash\\ngit clone git://github.com/rwaldron/johnny-five.git && cd johnny-five\\n\\nnpm install\\n```\\n\\n#### npm package:\\n\\nInstall the module with:\\n\\n```bash\\nnpm install johnny-five\\n```\\n\\n\\n## Example Programs\\n\\nTo get you up and running quickly, we provide a variety of examples for using each Johnny-Five component. One thing we’re especially excited about is the extensive collection of [Fritzing](http://fritzing.org/home/) diagrams you’ll find throughout the site. A huge part of doing any Johnny-Five project is handling the actual hardware, and we’ve included these as part of the documentation because we realised that instructions on how to write code to control a servo are insufficient without instructions on how to connect a servo!\\n\\nTo interactively navigate the examples, visit the [Johnny-Five examples](http://johnny-five.io/examples/) page on the official website. If you want to link directly to the examples in this repo, you can use one of the following links.\\n\\n**There are presently 362 example programs with code and diagrams!**\\n\\n<!--extract-start:examples-->\\n\\n### Board\\n- [Board - Basic Initialization](https://github.com/rwaldron/johnny-five/blob/main/docs/board.md)\\n- [Board - Cleanup in \\'exit\\' event](https://github.com/rwaldron/johnny-five/blob/main/docs/board-cleanup.md)\\n- [Board - Multiple in one program](https://github.com/rwaldron/johnny-five/blob/main/docs/board-multi.md)\\n- [Board - Specify Sampling Interval](https://github.com/rwaldron/johnny-five/blob/main/docs/board-sampling-interval.md)\\n- [Board - Specify port](https://github.com/rwaldron/johnny-five/blob/main/docs/board-with-port.md)\\n- [Custom Data Properties](https://github.com/rwaldron/johnny-five/blob/main/docs/custom-properties.md)\\n- [Pin](https://github.com/rwaldron/johnny-five/blob/main/docs/pin.md)\\n- [REPL](https://github.com/rwaldron/johnny-five/blob/main/docs/repl.md)\\n\\n### LED\\n- [LED](https://github.com/rwaldron/johnny-five/blob/main/docs/led.md)\\n- [LED - Blink](https://github.com/rwaldron/johnny-five/blob/main/docs/led-blink.md)\\n- [LED - Demo sequence](https://github.com/rwaldron/johnny-five/blob/main/docs/led-demo-sequence.md)\\n- [LED - Fade](https://github.com/rwaldron/johnny-five/blob/main/docs/led-fade.md)\\n- [LED - Fade callback](https://github.com/rwaldron/johnny-five/blob/main/docs/led-fade-callback.md)\\n- [LED - Fade with animation](https://github.com/rwaldron/johnny-five/blob/main/docs/led-fade-animation.md)\\n- [LED - PCA9685](https://github.com/rwaldron/johnny-five/blob/main/docs/led-PCA9685.md)\\n- [LED - Pulse](https://github.com/rwaldron/johnny-five/blob/main/docs/led-pulse.md)\\n- [LED - Pulse with animation](https://github.com/rwaldron/johnny-five/blob/main/docs/led-pulse-animation.md)\\n- [LED - Slider](https://github.com/rwaldron/johnny-five/blob/main/docs/led-slider.md)\\n- [LED - Tessel Servo Module](https://github.com/rwaldron/johnny-five/blob/main/docs/led-tessel-servo-module.md)\\n- [LEDs - An array of LEDs](https://github.com/rwaldron/johnny-five/blob/main/docs/led-array.md)\\n- [LEDs - Controlling an array of LEDs](https://github.com/rwaldron/johnny-five/blob/main/docs/led-array-controller.md)\\n\\n### LED: RGB\\n- [LED - RGB (Common Anode)](https://github.com/rwaldron/johnny-five/blob/main/docs/led-rgb-anode.md)\\n- [LED - RGB (Common Anode) PCA9685](https://github.com/rwaldron/johnny-five/blob/main/docs/led-rgb-anode-PCA9685.md)\\n- [LED - RGB Intensity](https://github.com/rwaldron/johnny-five/blob/main/docs/led-rgb-intensity.md)\\n- [LED - Rainbow](https://github.com/rwaldron/johnny-five/blob/main/docs/led-rainbow.md)\\n- [LED - Rainbow BlinkM](https://github.com/rwaldron/johnny-five/blob/main/docs/led-rgb-BLINKM.md)\\n\\n### LED: Digits & Matrix\\n- [LED - Digital Clock](https://github.com/rwaldron/johnny-five/blob/main/docs/led-digits-clock.md)\\n- [LED - Digital Clock, Dual Displays](https://github.com/rwaldron/johnny-five/blob/main/docs/led-digits-clock-dual.md)\\n- [LED - Digital Clock, HT16K33](https://github.com/rwaldron/johnny-five/blob/main/docs/led-digits-clock-HT16K33.md)\\n- [LED - Draw Matrix Characters Demo](https://github.com/rwaldron/johnny-five/blob/main/docs/led-chars-demo.md)\\n- [LED - Enumerate Matrix Characters & Symbols](https://github.com/rwaldron/johnny-five/blob/main/docs/led-enumeratechars.md)\\n- [LED - Matrix](https://github.com/rwaldron/johnny-five/blob/main/docs/led-matrix.md)\\n- [LED - Matrix Demo](https://github.com/rwaldron/johnny-five/blob/main/docs/led-matrix-tutorial.md)\\n- [LED - Matrix HT16K33](https://github.com/rwaldron/johnny-five/blob/main/docs/led-matrix-HT16K33.md)\\n- [LED - Matrix HT16K33 16x8](https://github.com/rwaldron/johnny-five/blob/main/docs/led-matrix-HT16K33-16x8.md)\\n\\n### Servo\\n- [Servo](https://github.com/rwaldron/johnny-five/blob/main/docs/servo.md)\\n- [Servo - Continuous](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-continuous.md)\\n- [Servo - Drive](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-drive.md)\\n- [Servo - Multi-Turn](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-multi-turn.md)\\n- [Servo - PCA9685](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-PCA9685.md)\\n- [Servo - Prompt](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-prompt.md)\\n- [Servo - Slider control](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-slider.md)\\n- [Servo - Tessel Servo Module](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-tessel-servo-module.md)\\n- [Servos - An array of servos](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-array.md)\\n\\n### GPS\\n- [GPS - Adafruit Ultimate GPS Breakout](https://github.com/rwaldron/johnny-five/blob/main/docs/gps-adafruit.md)\\n- [GPS - Default GPS](https://github.com/rwaldron/johnny-five/blob/main/docs/gps.md)\\n- [GPS - Hardware Serial](https://github.com/rwaldron/johnny-five/blob/main/docs/gps-hardware-serial.md)\\n- [GPS - Sparkfun GP-20U7](https://github.com/rwaldron/johnny-five/blob/main/docs/gps-GP-20U7.md)\\n\\n### Servo Animation\\n- [Servo - Animation](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-animation.md)\\n- [Servo - Leg Animation](https://github.com/rwaldron/johnny-five/blob/main/docs/servo-animation-leg.md)\\n\\n### Color\\n- [Color - EVShield EV3 (Code)](https://github.com/rwaldron/johnny-five/blob/main/docs/color-EVS_EV3.md)\\n- [Color - EVShield EV3 (Raw)](https://github.com/rwaldron/johnny-five/blob/main/docs/color-raw-EVS_EV3.md)\\n- [Color - EVShield NXT (Code)](https://github.com/rwaldron/johnny-five/blob/main/docs/color-EVS_NXT.md)\\n- [Color - ISL29125](https://github.com/rwaldron/johnny-five/blob/main/docs/color-ISL29125.md)\\n\\n### Motor\\n- [Motor](https://github.com/rwaldron/johnny-five/blob/main/docs/motor.md)\\n- [Motor - 3 pin](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-3-pin.md)\\n- [Motor - Adafruit DRV8871 DC Motor Driver Breakout](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-drv8871.md)\\n- [Motor - Brake](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-brake.md)\\n- [Motor - Current](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-current.md)\\n- [Motor - Directional](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-directional.md)\\n- [Motor - EVShield EV3](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-EVS_EV3.md)\\n- [Motor - EVShield NXT](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-EVS_NXT.md)\\n- [Motor - Enable Pin](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-enable.md)\\n- [Motor - GROVE_I2C_MOTOR_DRIVER](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-GROVE_I2C.md)\\n- [Motor - H-Bridge](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-hbridge.md)\\n- [Motor - LUDUS](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-LUDUS.md)\\n- [Motor - PCA9685](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-PCA9685.md)\\n- [Motor - Pololu VNH5019 Dual Motor Driver Breakout](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-vnh5019.md)\\n- [Motor - Sparkfun Dual H-bridge Edison Block](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-sparkfun-edison-hbridge.md)\\n- [Motor - Sparkfun TB6612FNG](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-TB6612FNG.md)\\n- [Motor - l298 Breakout](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-l298-breakout.md)\\n- [Motors - Dual H-Bridge](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-hbridge-dual.md)\\n\\n### Stepper Motor\\n- [Stepper - Driver](https://github.com/rwaldron/johnny-five/blob/main/docs/stepper-driver.md)\\n- [Stepper - Four Wire](https://github.com/rwaldron/johnny-five/blob/main/docs/stepper-four_wire.md)\\n- [Stepper - Sweep](https://github.com/rwaldron/johnny-five/blob/main/docs/stepper-sweep.md)\\n\\n### ESC & Brushless Motor\\n- [ESC - Bidirectional](https://github.com/rwaldron/johnny-five/blob/main/docs/esc-bidirectional.md)\\n- [ESC - Keypress controlled ESCs](https://github.com/rwaldron/johnny-five/blob/main/docs/esc-keypress.md)\\n- [ESC - PCA9685](https://github.com/rwaldron/johnny-five/blob/main/docs/esc-PCA9685.md)\\n\\n### Button / Switch\\n- [Button](https://github.com/rwaldron/johnny-five/blob/main/docs/button.md)\\n- [Button - Bumper](https://github.com/rwaldron/johnny-five/blob/main/docs/button-bumper.md)\\n- [Button - EVShield EV3](https://github.com/rwaldron/johnny-five/blob/main/docs/button-EVS_EV3.md)\\n- [Button - EVShield NXT](https://github.com/rwaldron/johnny-five/blob/main/docs/button-EVS_NXT.md)\\n- [Button - Options](https://github.com/rwaldron/johnny-five/blob/main/docs/button-options.md)\\n- [Button - Pullup](https://github.com/rwaldron/johnny-five/blob/main/docs/button-pullup.md)\\n- [Buttons - Collection w/ AT42QT1070](https://github.com/rwaldron/johnny-five/blob/main/docs/button-collection-AT42QT1070.md)\\n- [Switch](https://github.com/rwaldron/johnny-five/blob/main/docs/switch.md)\\n- [Switch - Magnetic Door](https://github.com/rwaldron/johnny-five/blob/main/docs/switch-magnetic-door.md)\\n- [Switch - Tilt SW-200D](https://github.com/rwaldron/johnny-five/blob/main/docs/switch-tilt-SW_200D.md)\\n- [Toggle Switch](https://github.com/rwaldron/johnny-five/blob/main/docs/toggle-switch.md)\\n\\n### Keypad\\n- [Keypad - 3x4 I2C Nano Backpack](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-3X4_I2C_NANO_BACKPACK.md)\\n- [Keypad - 4x4 I2C Nano Backpack](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-4X4_I2C_NANO_BACKPACK.md)\\n- [Keypad - VKEY](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-analog-vkey.md)\\n- [Keypad - Waveshare AD](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-analog-ad.md)\\n- [Touchpad - Grove QTouch](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-QTOUCH.md)\\n- [Touchpad - MPR121](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-MPR121.md)\\n- [Touchpad - MPR121, Sensitivity](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-MPR121-sensitivity.md)\\n- [Touchpad - MPR121QR2_SHIELD](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-MPR121QR2_SHIELD.md)\\n- [Touchpad - MPR121_KEYPAD](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-MPR121_KEYPAD.md)\\n- [Touchpad - MPR121_SHIELD](https://github.com/rwaldron/johnny-five/blob/main/docs/keypad-MPR121_SHIELD.md)\\n\\n### Relay\\n- [Relay](https://github.com/rwaldron/johnny-five/blob/main/docs/relay.md)\\n- [Relay - Collection](https://github.com/rwaldron/johnny-five/blob/main/docs/relay-collection.md)\\n- [Relay On Analog Pin](https://github.com/rwaldron/johnny-five/blob/main/docs/relay-on-analog-pin.md)\\n\\n### Shift Register\\n- [Shift Register](https://github.com/rwaldron/johnny-five/blob/main/docs/shift-register.md)\\n- [Shift Register - Common Anode Seven Segment controller](https://github.com/rwaldron/johnny-five/blob/main/docs/shift-register-seven-segment-anode.md)\\n- [Shift Register - Common Anode Seven segments, Chained](https://github.com/rwaldron/johnny-five/blob/main/docs/shift-register-daisy-chain-anode.md)\\n- [Shift Register - Seven Segment controller](https://github.com/rwaldron/johnny-five/blob/main/docs/shift-register-seven-segment.md)\\n- [Shift Register - Seven segments, Chained](https://github.com/rwaldron/johnny-five/blob/main/docs/shift-register-daisy-chain.md)\\n\\n### Infrared Reflectance\\n- [IR Motion](https://github.com/rwaldron/johnny-five/blob/main/docs/ir-motion.md)\\n- [IR Proximity](https://github.com/rwaldron/johnny-five/blob/main/docs/ir-proximity.md)\\n- [IR Reflectance](https://github.com/rwaldron/johnny-five/blob/main/docs/ir-reflect.md)\\n- [IR Reflectance Array](https://github.com/rwaldron/johnny-five/blob/main/docs/ir-reflect-array.md)\\n\\n### Proximity\\n- [Proximity](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity.md)\\n- [Proximity - EVShield EV3 (IR)](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-EVS_EV3_IR.md)\\n- [Proximity - EVShield EV3 (IR)](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-EVS_EV3_IR-alert.md)\\n- [Proximity - EVShield EV3 (Ultrasonic)](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-EVS_EV3_US.md)\\n- [Proximity - EVShield EV3 (Ultrasonic)](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-EVS_EV3_US-alert.md)\\n- [Proximity - GP2Y0A710K0F](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-GP2Y0A710K0F.md)\\n- [Proximity - HC-SR04](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-hcsr04.md)\\n- [Proximity - HC-SR04 (Analog)](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-hcsr04-analog.md)\\n- [Proximity - HC-SR04 I2C Backpack](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-hcsr04-i2c.md)\\n- [Proximity - LIDAR-Lite](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-lidarlite.md)\\n- [Proximity - MB1000](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-mb1000.md)\\n- [Proximity - MB1003](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-mb1003.md)\\n- [Proximity - MB1010](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-mb1010.md)\\n- [Proximity - MB1230](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-mb1230.md)\\n- [Proximity - SRF10](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-srf10.md)\\n\\n### Motion\\n- [Motion](https://github.com/rwaldron/johnny-five/blob/main/docs/motion.md)\\n- [Motion - GP2Y0A60SZLF](https://github.com/rwaldron/johnny-five/blob/main/docs/motion-GP2Y0A60SZLF.md)\\n- [Motion - GP2Y0D805Z0F](https://github.com/rwaldron/johnny-five/blob/main/docs/motion-gp2y0d805z0f.md)\\n- [Motion - GP2Y0D810Z0F](https://github.com/rwaldron/johnny-five/blob/main/docs/motion-gp2y0d810z0f.md)\\n- [Motion - GP2Y0D810Z0F](https://github.com/rwaldron/johnny-five/blob/main/docs/motion-gp2y0d815z0f.md)\\n\\n### Joystick\\n- [Joystick](https://github.com/rwaldron/johnny-five/blob/main/docs/joystick.md)\\n- [Joystick - Esplora](https://github.com/rwaldron/johnny-five/blob/main/docs/joystick-esplora.md)\\n- [Joystick - Pan + Tilt control](https://github.com/rwaldron/johnny-five/blob/main/docs/joystick-pantilt.md)\\n- [Joystick - Sparkfun Shield](https://github.com/rwaldron/johnny-five/blob/main/docs/joystick-shield.md)\\n\\n### LCD\\n- [Grove - RGB LCD Color Previewer](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-rgb-bgcolor-previewer.md)\\n- [LCD](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd.md)\\n- [LCD - Enumerate characters](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-enumeratechars.md)\\n- [LCD - I2C](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-i2c.md)\\n- [LCD - I2C PCF8574](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-i2c-PCF8574.md)\\n- [LCD - I2C Runner](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-i2c-runner.md)\\n- [LCD - Runner 16x2](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-runner.md)\\n- [LCD - Runner 20x4](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-runner-20x4.md)\\n- [LCD - Tessel 2 16x2](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-16x2-tessel.md)\\n- [Tessel 2 + Grove - RGB LCD Color Previewer](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-rgb-bgcolor-previewer-tessel.md)\\n- [Tessel 2 + Grove - RGB LCD Display](https://github.com/rwaldron/johnny-five/blob/main/docs/lcd-rgb-tessel-grove-JHD1313M1.md)\\n\\n### Compass/Magnetometer\\n- [Compass - Find north](https://github.com/rwaldron/johnny-five/blob/main/docs/magnetometer-north.md)\\n- [Compass - HMC5883L](https://github.com/rwaldron/johnny-five/blob/main/docs/compass-hmc5883l.md)\\n- [Compass - HMC6352](https://github.com/rwaldron/johnny-five/blob/main/docs/compass-hmc6352.md)\\n- [Compass - Logger](https://github.com/rwaldron/johnny-five/blob/main/docs/magnetometer-log.md)\\n- [Compass - MAG3110](https://github.com/rwaldron/johnny-five/blob/main/docs/compass-MAG3110.md)\\n- [Compass - MAG3110 on Tessel 2](https://github.com/rwaldron/johnny-five/blob/main/docs/compass-MAG3110-tessel.md)\\n- [Compass / Magnetometer](https://github.com/rwaldron/johnny-five/blob/main/docs/magnetometer.md)\\n\\n### Piezo\\n- [Piezo](https://github.com/rwaldron/johnny-five/blob/main/docs/piezo.md)\\n\\n### IMU/Multi\\n- [IMU - BNO055](https://github.com/rwaldron/johnny-five/blob/main/docs/imu-bno055.md)\\n- [IMU - BNO055 (Orientation)](https://github.com/rwaldron/johnny-five/blob/main/docs/imu-bno055-orientation.md)\\n- [IMU - LSM303C](https://github.com/rwaldron/johnny-five/blob/main/docs/imu-lsm303c.md)\\n- [IMU - MPU6050](https://github.com/rwaldron/johnny-five/blob/main/docs/imu-mpu6050.md)\\n- [Multi - BME280](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-BME280.md)\\n- [Multi - BMP085](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-bmp085.md)\\n- [Multi - BMP180](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-bmp180.md)\\n- [Multi - DHT11_I2C_NANO_BACKPACK](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-DHT11_I2C_NANO_BACKPACK.md)\\n- [Multi - DHT21_I2C_NANO_BACKPACK](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-DHT21_I2C_NANO_BACKPACK.md)\\n- [Multi - DHT22_I2C_NANO_BACKPACK](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-DHT22_I2C_NANO_BACKPACK.md)\\n- [Multi - HIH6130](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-HIH6130.md)\\n- [Multi - HTU21D](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-htu21d.md)\\n- [Multi - MPL115A2](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-mpl115a2.md)\\n- [Multi - MPL3115A2](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-mpl3115a2.md)\\n- [Multi - MS5611](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-MS5611.md)\\n- [Multi - SHT31D](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-sht31d.md)\\n- [Multi - SI7020](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-SI7020.md)\\n- [Multi - SI7021](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-SI7021.md)\\n- [Multi - TH02](https://github.com/rwaldron/johnny-five/blob/main/docs/multi-TH02.md)\\n\\n### Sensors\\n- [Accelerometer](https://github.com/rwaldron/johnny-five/blob/main/docs/accelerometer.md)\\n- [Accelerometer - ADXL335](https://github.com/rwaldron/johnny-five/blob/main/docs/accelerometer-adxl335.md)\\n- [Accelerometer - ADXL345](https://github.com/rwaldron/johnny-five/blob/main/docs/accelerometer-adxl345.md)\\n- [Accelerometer - LIS3DH](https://github.com/rwaldron/johnny-five/blob/main/docs/accelerometer-LIS3DH.md)\\n- [Accelerometer - MMA7361](https://github.com/rwaldron/johnny-five/blob/main/docs/accelerometer-mma7361.md)\\n- [Accelerometer - MMA8452](https://github.com/rwaldron/johnny-five/blob/main/docs/accelerometer-MMA8452.md)\\n- [Accelerometer - MPU6050](https://github.com/rwaldron/johnny-five/blob/main/docs/accelerometer-mpu6050.md)\\n- [Accelerometer - Pan + Tilt](https://github.com/rwaldron/johnny-five/blob/main/docs/accelerometer-pan-tilt.md)\\n- [Altimeter - BMP085](https://github.com/rwaldron/johnny-five/blob/main/docs/altimeter-BMP085.md)\\n- [Altimeter - BMP180](https://github.com/rwaldron/johnny-five/blob/main/docs/altimeter-BMP180.md)\\n- [Altimeter - MPL3115A2](https://github.com/rwaldron/johnny-five/blob/main/docs/altimeter-mpl3115a2.md)\\n- [Altimeter - MS5611](https://github.com/rwaldron/johnny-five/blob/main/docs/altimeter-MS5611.md)\\n- [Barometer - BMP085](https://github.com/rwaldron/johnny-five/blob/main/docs/barometer-BMP085.md)\\n- [Barometer - BMP180](https://github.com/rwaldron/johnny-five/blob/main/docs/barometer-BMP180.md)\\n- [Barometer - MPL115A2](https://github.com/rwaldron/johnny-five/blob/main/docs/barometer-mpl115a2.md)\\n- [Barometer - MPL3115A2](https://github.com/rwaldron/johnny-five/blob/main/docs/barometer-mpl3115a2.md)\\n- [Barometer - MS5611](https://github.com/rwaldron/johnny-five/blob/main/docs/barometer-MS5611.md)\\n- [Gyro](https://github.com/rwaldron/johnny-five/blob/main/docs/gyro.md)\\n- [Gyro - Analog LPR5150AL](https://github.com/rwaldron/johnny-five/blob/main/docs/gyro-lpr5150l.md)\\n- [Gyro - I2C MPU6050](https://github.com/rwaldron/johnny-five/blob/main/docs/gyro-mpu6050.md)\\n- [Hygrometer - DHT11_I2C_NANO_BACKPACK](https://github.com/rwaldron/johnny-five/blob/main/docs/hygrometer-DHT11_I2C_NANO_BACKPACK.md)\\n- [Hygrometer - DHT21_I2C_NANO_BACKPACK](https://github.com/rwaldron/johnny-five/blob/main/docs/hygrometer-DHT21_I2C_NANO_BACKPACK.md)\\n- [Hygrometer - DHT22_I2C_NANO_BACKPACK](https://github.com/rwaldron/johnny-five/blob/main/docs/hygrometer-DHT22_I2C_NANO_BACKPACK.md)\\n- [Hygrometer - HIH6130](https://github.com/rwaldron/johnny-five/blob/main/docs/hygrometer-HIH6130.md)\\n- [Hygrometer - HTU21D](https://github.com/rwaldron/johnny-five/blob/main/docs/hygrometer-htu21d.md)\\n- [Hygrometer - SHT31D](https://github.com/rwaldron/johnny-five/blob/main/docs/hygrometer-sht31d.md)\\n- [Hygrometer - SI7021](https://github.com/rwaldron/johnny-five/blob/main/docs/hygrometer-SI7021.md)\\n- [Hygrometer - TH02](https://github.com/rwaldron/johnny-five/blob/main/docs/hygrometer-TH02.md)\\n- [Sensor](https://github.com/rwaldron/johnny-five/blob/main/docs/sensor.md)\\n- [Sensor - Digital Microwave](https://github.com/rwaldron/johnny-five/blob/main/docs/sensor-digital-microwave.md)\\n- [Sensor - Flex sensor](https://github.com/rwaldron/johnny-five/blob/main/docs/flex.md)\\n- [Sensor - Force sensitive resistor](https://github.com/rwaldron/johnny-five/blob/main/docs/sensor-fsr.md)\\n- [Sensor - Microphone](https://github.com/rwaldron/johnny-five/blob/main/docs/microphone.md)\\n- [Sensor - Photoresistor](https://github.com/rwaldron/johnny-five/blob/main/docs/photoresistor.md)\\n- [Sensor - Potentiometer](https://github.com/rwaldron/johnny-five/blob/main/docs/potentiometer.md)\\n- [Sensor - Slide potentiometer](https://github.com/rwaldron/johnny-five/blob/main/docs/sensor-slider.md)\\n- [Thermometer - BMP085](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-bmp085.md)\\n- [Thermometer - BMP180](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-BMP180.md)\\n- [Thermometer - DHT11_I2C_NANO_BACKPACK](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-DHT11_I2C_NANO_BACKPACK.md)\\n- [Thermometer - DHT21_I2C_NANO_BACKPACK](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-DHT21_I2C_NANO_BACKPACK.md)\\n- [Thermometer - DHT22_I2C_NANO_BACKPACK](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-DHT22_I2C_NANO_BACKPACK.md)\\n- [Thermometer - DS18B20](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-ds18b20.md)\\n- [Thermometer - Dual DS18B20](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-dual-ds18b20.md)\\n- [Thermometer - HIH6130](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-HIH6130.md)\\n- [Thermometer - HTU21D](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-htu21d.md)\\n- [Thermometer - LM335](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-lm335.md)\\n- [Thermometer - LM35](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-lm35.md)\\n- [Thermometer - MAX31850](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-max31850k.md)\\n- [Thermometer - MCP9808](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-MCP9808.md)\\n- [Thermometer - MPL115A2](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-mpl115a2.md)\\n- [Thermometer - MPL3115A2](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-mpl3115a2.md)\\n- [Thermometer - MPU6050](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-mpu6050.md)\\n- [Thermometer - MS5611](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-MS5611.md)\\n- [Thermometer - SHT31D](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-sht31d.md)\\n- [Thermometer - SI7020](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-SI7020.md)\\n- [Thermometer - SI7021](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-SI7021.md)\\n- [Thermometer - TH02](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-TH02.md)\\n- [Thermometer - TMP102](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-tmp102.md)\\n- [Thermometer - TMP36](https://github.com/rwaldron/johnny-five/blob/main/docs/temperature-tmp36.md)\\n\\n### Expander\\n- [Expander - 74HC595](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-74HC595.md)\\n- [Expander - CD74HC4067, 16 Channel Analog Input Breakout](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-CD74HC4067_NANO_BACKPACK.md)\\n- [Expander - LIS3DH](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-LIS3DH.md)\\n- [Expander - MCP23008](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-MCP23008.md)\\n- [Expander - MCP23017](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-MCP23017.md)\\n- [Expander - MUXSHIELD2, Analog Sensors](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-MUXSHIELD2-analog-read.md)\\n- [Expander - MUXSHIELD2, Digital Input and Output](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-MUXSHIELD2-mixed.md)\\n- [Expander - PCA9685](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-PCA9685.md)\\n- [Expander - PCF8574](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-PCF8574.md)\\n- [Expander - PCF8575](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-PCF8575.md)\\n- [Expander - PCF8591](https://github.com/rwaldron/johnny-five/blob/main/docs/expander-PCF8591.md)\\n\\n### Photon Weather Shield\\n- [Photon Weather Shield: Moisture](https://github.com/rwaldron/johnny-five/blob/main/docs/sensor-photon-weather-shield-moisture.md)\\n\\n### Lego EVShield\\n- [Button - EVShield EV3](https://github.com/rwaldron/johnny-five/blob/main/docs/button-EVS_EV3.md)\\n- [Button - EVShield NXT](https://github.com/rwaldron/johnny-five/blob/main/docs/button-EVS_NXT.md)\\n- [Color - EVShield EV3 (Code)](https://github.com/rwaldron/johnny-five/blob/main/docs/color-EVS_EV3.md)\\n- [Color - EVShield EV3 (Raw)](https://github.com/rwaldron/johnny-five/blob/main/docs/color-raw-EVS_EV3.md)\\n- [Color - EVShield NXT (Code)](https://github.com/rwaldron/johnny-five/blob/main/docs/color-EVS_NXT.md)\\n- [Light - BH1750](https://github.com/rwaldron/johnny-five/blob/main/docs/light-ambient-BH1750.md)\\n- [Light - EVShield EV3 (Ambient)](https://github.com/rwaldron/johnny-five/blob/main/docs/light-ambient-EVS_EV3.md)\\n- [Light - EVShield EV3 (Reflected)](https://github.com/rwaldron/johnny-five/blob/main/docs/light-reflected-EVS_EV3.md)\\n- [Light - EVShield NXT (Ambient)](https://github.com/rwaldron/johnny-five/blob/main/docs/light-ambient-EVS_NXT.md)\\n- [Light - EVShield NXT (Reflected)](https://github.com/rwaldron/johnny-five/blob/main/docs/light-reflected-EVS_NXT.md)\\n- [Light - TSL2561](https://github.com/rwaldron/johnny-five/blob/main/docs/light-ambient-TSL2561.md)\\n- [Motor - EVShield EV3](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-EVS_EV3.md)\\n- [Motor - EVShield NXT](https://github.com/rwaldron/johnny-five/blob/main/docs/motor-EVS_NXT.md)\\n- [Proximity - EVShield EV3 (IR)](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-EVS_EV3_IR-alert.md)\\n- [Proximity - EVShield EV3 (Ultrasonic)](https://github.com/rwaldron/johnny-five/blob/main/docs/proximity-EVS_EV3_US-alert.md)\\n\\n### Intel Edison + Grove IoT Kit\\n- [Intel Edison + Grove - Accelerometer (ADXL345)](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-accelerometer-adxl345-edison.md)\\n- [Intel Edison + Grove - Accelerometer (MMA7660)](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-accelerometer-mma7660-edison.md)\\n- [Intel Edison + Grove - Air quality sensor](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-gas-tp401-edison.md)\\n- [Intel Edison + Grove - Barometer (BMP180)](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-barometer-edison.md)\\n- [Intel Edison + Grove - Button](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-button-edison.md)\\n- [Intel Edison + Grove - Compass (HMC588L)](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-compass-edison.md)\\n- [Intel Edison + Grove - Flame Sensor](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-flame-sensor-edison.md)\\n- [Intel Edison + Grove - Gas (MQ2)](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-gas-mq2-edison.md)\\n- [Intel Edison + Grove - Humidity & Temperature (TH02)](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-humidity-temperature-edison.md)\\n- [Intel Edison + Grove - I2C Motor Driver](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-i2c-motor-driver-edison.md)\\n- [Intel Edison + Grove - Joystick](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-joystick-edison.md)\\n- [Intel Edison + Grove - LED](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-led-edison.md)\\n- [Intel Edison + Grove - Light Sensor (TSL2561)](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-light-sensor-edison.md)\\n- [Intel Edison + Grove - Moisture Sensor](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-moisture-edison.md)\\n- [Intel Edison + Grove - Q Touch](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-q-touch.md)\\n- [Intel Edison + Grove - RGB LCD](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-lcd-rgb-edison.md)\\n- [Intel Edison + Grove - RGB LCD Color Previewer](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-lcd-rgb-bgcolor-previewer-edison.md)\\n- [Intel Edison + Grove - RGB LCD temperature display](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-lcd-rgb-temperature-display-edison.md)\\n- [Intel Edison + Grove - Relay](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-relay-edison.md)\\n- [Intel Edison + Grove - Rotary Potentiometer](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-rotary-potentiometer-edison.md)\\n- [Intel Edison + Grove - Servo](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-servo-edison.md)\\n- [Intel Edison + Grove - Touch](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-touch-edison.md)\\n\\n### Grove IoT Kit (Seeed Studio)\\n- [Grove - Button](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-button.md)\\n- [Grove - Joystick](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-joystick.md)\\n- [Grove - LED](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-led.md)\\n- [Grove - Motor (I2C Driver)](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-i2c-motor-driver.md)\\n- [Grove - RGB LCD](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-lcd-rgb.md)\\n- [Grove - RGB LCD temperature display](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-lcd-rgb-temperature-display.md)\\n- [Grove - Rotary Potentiometer](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-rotary-potentiometer.md)\\n- [Grove - Servo](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-servo.md)\\n- [Grove - Touch](https://github.com/rwaldron/johnny-five/blob/main/docs/grove-touch.md)\\n\\n### Micro Magician V2\\n- [Micro Magician V2 - Accelerometer](https://github.com/rwaldron/johnny-five/blob/main/docs/micromagician-accelerometer.md)\\n- [Micro Magician V2 - Motor](https://github.com/rwaldron/johnny-five/blob/main/docs/micromagician-motor.md)\\n- [Micro Magician V2 - Servo](https://github.com/rwaldron/johnny-five/blob/main/docs/micromagician-servo.md)\\n\\n### TinkerKit\\n- [TinkerKit - Accelerometer](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-accelerometer.md)\\n- [TinkerKit - Blink](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-blink.md)\\n- [TinkerKit - Button](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-button.md)\\n- [TinkerKit - Combo](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-combo.md)\\n- [TinkerKit - Continuous servo](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-continuous-servo.md)\\n- [TinkerKit - Gyro](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-gyroscope.md)\\n- [TinkerKit - Joystick](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-joystick.md)\\n- [TinkerKit - Linear potentiometer](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-linear-pot.md)\\n- [TinkerKit - Rotary potentiometer](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-rotary.md)\\n- [TinkerKit - Temperature](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-thermistor.md)\\n- [TinkerKit - Tilt](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-tilt.md)\\n- [TinkerKit - Touch](https://github.com/rwaldron/johnny-five/blob/main/docs/tinkerkit-touch.md)\\n\\n### Wii\\n- [Wii Classic Controller](https://github.com/rwaldron/johnny-five/blob/main/docs/classic-controller.md)\\n- [Wii Nunchuck](https://github.com/rwaldron/johnny-five/blob/main/docs/nunchuk.md)\\n\\n### Complete Bots / Projects\\n- [Bug](https://github.com/rwaldron/johnny-five/blob/main/docs/bug.md)\\n- [Kinect Robotic Arm Controller](https://github.com/rwaldron/johnny-five/blob/main/docs/kinect-arm-controller.md)\\n- [Laser Trip Wire](https://github.com/rwaldron/johnny-five/blob/main/docs/laser-trip-wire.md)\\n- [Line Follower](https://github.com/rwaldron/johnny-five/blob/main/docs/line-follower.md)\\n- [Lynxmotion Biped BRAT](https://github.com/rwaldron/johnny-five/blob/main/docs/brat.md)\\n- [Motobot](https://github.com/rwaldron/johnny-five/blob/main/docs/motobot.md)\\n- [Navigator](https://github.com/rwaldron/johnny-five/blob/main/docs/navigator.md)\\n- [Nodebot](https://github.com/rwaldron/johnny-five/blob/main/docs/nodebot.md)\\n- [Phoenix Hexapod](https://github.com/rwaldron/johnny-five/blob/main/docs/phoenix.md)\\n- [Radar](https://github.com/rwaldron/johnny-five/blob/main/docs/radar.md)\\n- [Robotic Claw](https://github.com/rwaldron/johnny-five/blob/main/docs/claw.md)\\n- [Whisker](https://github.com/rwaldron/johnny-five/blob/main/docs/whisker.md)\\n\\n### Component Plugin Template\\n- [Example plugin](https://github.com/rwaldron/johnny-five/blob/main/docs/plugin.md)\\n\\n### IO Plugins\\n- [Led Blink on Electric Imp](https://github.com/rwaldron/johnny-five/blob/main/docs/imp-io.md)\\n- [Led Blink on Intel Edison Arduino Board](https://github.com/rwaldron/johnny-five/blob/main/docs/edison-io-arduino.md)\\n- [Led Blink on Intel Edison Mini Board](https://github.com/rwaldron/johnny-five/blob/main/docs/edison-io-miniboard.md)\\n- [Led Blink on Intel Galileo Gen 2](https://github.com/rwaldron/johnny-five/blob/main/docs/galileo-io.md)\\n- [Led Blink on Raspberry Pi](https://github.com/rwaldron/johnny-five/blob/main/docs/raspi-io.md)\\n- [Led Blink on Spark Core](https://github.com/rwaldron/johnny-five/blob/main/docs/spark-io.md)\\n- [Led Blink on pcDuino3](https://github.com/rwaldron/johnny-five/blob/main/docs/pcduino-io.md)\\n\\n<!--extract-end:examples-->\\n\\n## Many fragments. Some large, some small.\\n\\n#### [Wireless Nodebot](http://jsfiddle.net/rwaldron/88M6b/show/light)\\n#### [Kinect Controlled Robot Arm](http://jsfiddle.net/rwaldron/XMsGQ/show/light/)\\n#### [Biped Nodebot](http://jsfiddle.net/rwaldron/WZkn5/show/light/)\\n#### [LCD Running Man](http://jsfiddle.net/rwaldron/xKwaU/show/light/)\\n#### [Slider Controlled Panning Servo](http://jsfiddle.net/rwaldron/kZakv/show/light/)\\n#### [Joystick Controlled Laser (pan/tilt) 1](http://jsfiddle.net/rwaldron/HPqms/show/light/)\\n#### [Joystick Controlled Laser (pan/tilt) 2](http://jsfiddle.net/rwaldron/YHb7A/show/light/)\\n#### [Joystick Controlled Claw](http://jsfiddle.net/rwaldron/6ZXFe/show/light/)\\n#### [Robot Claw](http://jsfiddle.net/rwaldron/CFSZJ/show/light/)\\n#### [Joystick, Motor & Led](http://jsfiddle.net/rwaldron/gADSz/show/light/)\\n#### [Build you own drone](http://github.com/darioodiaz/node-open-pilot/)\\n\\n\\n\\n## Make: JavaScript Robotics\\n\\n[![](http://ecx.images-amazon.com/images/I/91ae8ZZDQ2L.jpg)](http://shop.oreilly.com/product/0636920031390.do)\\n\\n\\n\\n\\n## Contributing\\nAll contributions must adhere to the [Idiomatic.js Style Guide](https://github.com/rwaldron/idiomatic.js),\\nby maintaining the existing coding style. Add unit tests for any new or changed functionality. Lint and test your code using [grunt](https://github.com/gruntjs/grunt).\\n\\n\\n## License\\nCopyright (c) 2012, 2013, 2014 Rick Waldron <waldron.rick@gmail.com>\\nLicensed under the MIT license.\\nCopyright (c) 2014, 2015 The Johnny-Five Contributors\\nLicensed under the MIT license.\\n'},\n",
       " {'repo': 'RobotLocomotion/drake',\n",
       "  'language': 'C++',\n",
       "  'readme_contents': '# Drake\\n\\nModel-Based Design and Verification for Robotics.\\n\\nPlease see the [Drake Documentation](https://drake.mit.edu) for more\\ninformation.\\n'},\n",
       " {'repo': 'google-research/robotics_transformer',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': '# Robotics Transformer\\n\\n*This is not an officially supported Google product.*\\n\\n\\nThis repository is a collection code files and artifacts for running\\nRobotics Transformer or RT-1.\\n\\n## Features\\n\\n* Film efficient net based image tokenizer backbone\\n* Token learner based compression of input tokens\\n* Transformer for end to end robotic control\\n* Testing utilities\\n\\n## Getting Started\\n\\n### Installation\\nClone the repo\\n```bash\\ngit clone https://github.com/google-research/robotics_transformer.git\\npip install -r robotics_transformer/requirements.txt\\npython -m robotics_transformer.tokenizers.action_tokenizer.test\\n```\\n\\n### Running Tests\\n\\nTo run RT-1 tests, you can clone the git repo and run\\n[bazel](https://bazel.build/):\\n\\n```bash\\ngit clone https://github.com/google_research/robotics_transformer.git\\ncd robotics_transformer\\nbazel test ...\\n```\\n\\n### Using trained checkpoints\\nCheckpoints are included in trained_checkpoints/ folder for three models:\\n1. [RT-1 trained on 700 tasks](trained_checkpoints/rt1main)\\n2. [RT-1 jointly trained on EDR and Kuka data](trained_checkpoints/rt1multirobot)\\n3. [RT-1 jointly trained on sim and real data](trained_checkpoints/rt1simreal)\\n\\nThey are tensorflow SavedModel files. Instructions on usage can be found [here](https://www.tensorflow.org/guide/saved_model)\\n\\n\\n## Future Releases\\n\\nThe current repository includes an initial set of libraries for early adoption.\\nMore components may come in future releases.\\n\\n## License\\n\\nThe Robotics Transformer library is licensed under the terms of the Apache\\nlicense.\\n'},\n",
       " {'repo': 'kornia/kornia',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': '<div align=\"center\">\\n<p align=\"center\">\\n  <img width=\"75%\" src=\"https://github.com/kornia/data/raw/main/kornia_banner_pixie.png\" />\\n</p>\\n\\n---\\n\\nEnglish | [简体中文](README_zh-CN.md)\\n\\n<!-- prettier-ignore -->\\n<a href=\"https://kornia.org\">Website</a> •\\n<a href=\"https://kornia.readthedocs.io\">Docs</a> •\\n<a href=\"https://colab.research.google.com/github/kornia/tutorials/blob/master/source/hello_world_tutorial.ipynb\">Try it Now</a> •\\n<a href=\"https://kornia.github.io/tutorials/\">Tutorials</a> •\\n<a href=\"https://github.com/kornia/kornia-examples\">Examples</a> •\\n<a href=\"https://kornia.github.io//kornia-blog\">Blog</a> •\\n<a href=\"https://join.slack.com/t/kornia/shared_invite/zt-csobk21g-CnydWe5fmvkcktIeRFGCEQ\">Community</a>\\n\\n[![PyPI python](https://img.shields.io/pypi/pyversions/kornia)](https://pypi.org/project/kornia)\\n[![pytorch](https://img.shields.io/badge/PyTorch_1.9.1+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/get-started/locally/)\\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENCE)\\n\\n[![PyPI version](https://badge.fury.io/py/kornia.svg)](https://pypi.org/project/kornia)\\n[![Downloads](https://static.pepy.tech/badge/kornia)](https://pepy.tech/project/kornia)\\n[![Slack](https://img.shields.io/badge/Slack-4A154B?logo=slack&logoColor=white)](https://join.slack.com/t/kornia/shared_invite/zt-csobk21g-2AQRi~X9Uu6PLMuUZdvfjA)\\n[![Twitter](https://img.shields.io/twitter/follow/kornia_foss?style=social)](https://twitter.com/kornia_foss)\\n\\n[![tests-cpu](https://github.com/kornia/kornia/actions/workflows/scheduled_test_cpu.yml/badge.svg?event=schedule&&branch=master)](https://github.com/kornia/kornia/actions/workflows/scheduled_test_cpu.yml)\\n[![codecov](https://codecov.io/gh/kornia/kornia/branch/master/graph/badge.svg?token=FzCb7e0Bso)](https://codecov.io/gh/kornia/kornia)\\n[![Documentation Status](https://readthedocs.org/projects/kornia/badge/?version=latest)](https://kornia.readthedocs.io/en/latest/?badge=latest)\\n[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/kornia/kornia/master.svg)](https://results.pre-commit.ci/latest/github/kornia/kornia/master)\\n\\n<a href=\"https://www.producthunt.com/posts/kornia?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-kornia\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=306439&theme=light\" alt=\"Kornia - Computer vision library for deep learning | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\\n\\n</p>\\n</div>\\n\\n*Kornia* is a differentiable computer vision library for [PyTorch](https://pytorch.org).\\n\\nIt consists of a set of routines and differentiable modules to solve generic computer vision problems. At its core, the package uses *PyTorch* as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions.\\n\\n<div align=\"center\">\\n  <img src=\"https://github.com/kornia/kornia/raw/master/docs/source/_static/img/hakuna_matata.gif\" width=\"75%\" height=\"75%\">\\n</div>\\n\\n<!--<div align=\"center\">\\n  <img src=\"http://drive.google.com/uc?export=view&id=1KNwaanUdY1MynF0EYfyXjDM3ti09tzaq\">\\n</div>-->\\n\\n## Overview\\n\\nInspired by existing packages, this library is composed by a subset of packages containing operators that can be inserted within neural networks to train models to perform image transformations, epipolar geometry, depth estimation, and low-level image processing such as filtering and edge detection that operate directly on tensors.\\n\\nAt a granular level, Kornia is a library that consists of the following components:\\n\\n| **Component**                                                                    | **Description**                                                                                                                       |\\n|----------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|\\n| [kornia](https://kornia.readthedocs.io/en/latest/index.html)                     | a Differentiable Computer Vision library, with strong GPU support                                                                     |\\n| [kornia.augmentation](https://kornia.readthedocs.io/en/latest/augmentation.html) | a module to perform data augmentation in the GPU                                                                                      |\\n| [kornia.color](https://kornia.readthedocs.io/en/latest/color.html)               | a set of routines to perform color space conversions                                                                                  |\\n| [kornia.contrib](https://kornia.readthedocs.io/en/latest/contrib.html)           | a compilation of user contrib and experimental operators                                                                              |\\n| [kornia.enhance](https://kornia.readthedocs.io/en/latest/enhance.html)           | a module to perform normalization and intensity transformation                                                                        |\\n| [kornia.feature](https://kornia.readthedocs.io/en/latest/feature.html)           | a module to perform feature detection                                                                                                 |\\n| [kornia.filters](https://kornia.readthedocs.io/en/latest/filters.html)           | a module to perform image filtering and edge detection                                                                                |\\n| [kornia.geometry](https://kornia.readthedocs.io/en/latest/geometry.html)         | a geometric computer vision library to perform image transformations, 3D linear algebra and conversions using different camera models |\\n| [kornia.losses](https://kornia.readthedocs.io/en/latest/losses.html)             | a stack of loss functions to solve different vision tasks                                                                             |\\n| [kornia.morphology](https://kornia.readthedocs.io/en/latest/morphology.html)     | a module to perform morphological operations                                                                                          |\\n| [kornia.utils](https://kornia.readthedocs.io/en/latest/utils.html)               | image to tensor utilities and metrics for vision problems                                                                             |\\n\\n## Installation\\n\\n### From pip:\\n\\n  ```bash\\n  pip install kornia\\n  pip install kornia[x]  # to get the training API !\\n  ```\\n\\n<details>\\n  <summary>Other installation options</summary>\\n\\n  #### From source:\\n\\n  ```bash\\n  python setup.py install\\n  ```\\n\\n  #### From source with symbolic links:\\n\\n  ```bash\\n  pip install -e .\\n  ```\\n\\n  #### From source using pip:\\n\\n  ```bash\\n  pip install git+https://github.com/kornia/kornia\\n  ```\\n\\n</details>\\n\\n\\n## Examples\\n\\nRun our Jupyter notebooks [tutorials](https://kornia.github.io/tutorials) to learn to use the library.\\n\\n<div align=\"center\">\\n  <a href=\"https://colab.research.google.com/github/kornia/tutorials/blob/master/source/hello_world_tutorial.ipynb\" target=\"_blank\">\\n    <img src=\"https://raw.githubusercontent.com/kornia/data/main/hello_world_arturito.png\" width=\"75%\" height=\"75%\">\\n  </a>\\n</div>\\n\\n:triangular_flag_on_post: **Updates**\\n- :white_check_mark: [Image Matching](https://kornia.readthedocs.io/en/latest/applications/image_matching.html) Integrated to [Huggingface Spaces](https://huggingface.co/spaces). See [Gradio Web Demo](https://huggingface.co/spaces/akhaliq/Kornia-LoFTR).\\n- :white_check_mark: [Face Detection](https://kornia.readthedocs.io/en/latest/applications/face_detection.html) Integrated to [Huggingface Spaces](https://huggingface.co/spaces). See [Gradio Web Demo](https://huggingface.co/spaces/frapochetti/blurry-faces).\\n\\n## Cite\\n\\nIf you are using kornia in your research-related documents, it is recommended that you cite the paper. See more in [CITATION](./CITATION.md).\\n\\n  ```bibtex\\n  @inproceedings{eriba2019kornia,\\n    author    = {E. Riba, D. Mishkin, D. Ponsa, E. Rublee and G. Bradski},\\n    title     = {Kornia: an Open Source Differentiable Computer Vision Library for PyTorch},\\n    booktitle = {Winter Conference on Applications of Computer Vision},\\n    year      = {2020},\\n    url       = {https://arxiv.org/pdf/1910.02190.pdf}\\n  }\\n  ```\\n\\n## Contributing\\nWe appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion. If you plan to contribute new features, utility functions or extensions, please first open an issue and discuss the feature with us. Please, consider reading the [CONTRIBUTING](./CONTRIBUTING.md) notes. The participation in this open source project is subject to [Code of Conduct](./CODE_OF_CONDUCT.md).\\n\\n\\n## Community\\n- **Forums:** discuss implementations, research, etc. [GitHub Forums](https://github.com/kornia/kornia/discussions)\\n- **GitHub Issues:** bug reports, feature requests, install issues, RFCs, thoughts, etc. [OPEN](https://github.com/kornia/kornia/issues/new/choose)\\n- **Slack:** Join our workspace to keep in touch with our core contributors and be part of our community. [JOIN HERE](https://join.slack.com/t/kornia/shared_invite/zt-csobk21g-2AQRi~X9Uu6PLMuUZdvfjA)\\n- For general information, please visit our website at www.kornia.org\\n\\n<a href=\"https://github.com/Kornia/kornia/graphs/contributors\">\\n  <img src=\"https://contrib.rocks/image?repo=Kornia/kornia\" width=\"75%\" height=\"75%\" />\\n</a>\\n\\nMade with [contrib.rocks](https://contrib.rocks).\\n'},\n",
       " {'repo': 'qboticslabs/ros_robotics_projects',\n",
       "  'language': 'JavaScript',\n",
       "  'readme_contents': '# ROS Robotics Projects\\n\\n#### [ROS Robotics Projects](http://rosrobots.com) \\n![book_cover](http://rosrobots.com/img/ebook.png\\n \"ROS Robotics Projects\")\\n\\n### Buy book\\n\\n* [PACKT](https://www.packtpub.com/hardware-and-creative/ros-robotics-projects)\\n* [Amazon.com](https://www.amazon.com/ROS-Robotic-Projects-Lentin-Joseph/dp/1783554711)\\n* [Amazon.in](https://www.amazon.in/ROS-Robotics-Projects-Lentin-Joseph-ebook/dp/B01MTJWNKI)\\n\\n\\n### Author\\n\\n* [Lentin Joseph](https://in.linkedin.com/in/lentinjoseph)\\n\\n### Installation\\nThe code is comaptible with ROS Kinetic and ROS Indigo. The detail installation instruction of each packages is mentioned on the book\\n\\n### Tutorials\\n* **Chapter 1:**  Getting Started with ROS Robotics Application Development\\n* **Chapter 2**:  Face Detection and Tracking Using ROS, OpenCV and Dynamixel Servos\\n* **Chapter 3**:  Building a Siri-Like Chatbot in ROS\\n* **Chapter 4**:  Controlling Embedded Boards Using ROS\\n* **Chapter 5**:  Teleoperate a Robot Using Hand Gestures\\n* **Chapter 6**:  Object Detection and Recognition\\n* **Chapter 7**:  Deep Learning Using ROS and TensorFlow\\n* **Chapter 8**:  ROS on MATLAB and Android\\n* **Chapter 9**:  Building an Autonomous Mobile Robot\\n* **Chapter 10**: Creating a Self-driving Car Using ROS!\\n* **Chapter 11**: Teleoperating Robot Using VR Headset and Leap Motion\\n* **Chapter 12**: Controlling Your Robots over the Web\\n\\n\\n\\n# Mastering ROS for Robotics Programming \\n\\n#### [Mastering ROS for Robotics Programming](http://mastering-ros.com) book tutorials source code\\n![book_cover](http://mastering-ros.com/images/section-image-1.jpg\\n \"Mastering ROS for Robotics Programming\")\\n\\n### Buy book\\n\\n* [PACKT](https://www.packtpub.com/hardware-and-creative/mastering-ros-robotics-programming)\\n* [Amazon.com](http://amzn.com/B0198DXFEW)\\n* [Amazon.in](http://www.amazon.in/dp/B0198DXFEW)\\n\\n\\n### Author\\n\\n* [Lentin Joseph](https://in.linkedin.com/in/lentinjoseph)\\n\\n### Installation\\nThe code is comaptible with ROS Jade and ROS Indigo. The detail installation instruction of each packages is mentioned on the book\\n\\n### Tutorials\\n* **Chapter 1:**  Introduction to ROS and its Package Management\\n* **Chapter 2**: Working with 3D Robot Modeling in ROS\\n* **Chapter 3**: Simulating Robots Using ROS and Gazebo\\n* **Chapter 4**: Using ROS MoveIt! and Navigation stack\\n* **Chapter 5**: Working with Pluginlib, Nodelets and Gazebo plugins\\n* **Chapter 6**: Writing ROS Controllers and Visualization plugins\\n* **Chapter 7**: Interfacing I/O boards, sensors and actuators to ROS\\n* **Chapter 8**: Programming Vision sensors using ROS, Open-CV and PCL\\n* **Chapter 9**: Building and interfacing a differential drive mobile robot hardware in ROS\\n* **Chapter 10**: Exploring advanced capabilities of ROS-MoveIt!\\n* **Chapter 11**: ROS for Industrial Robots\\n* **Chapter 12**: Troubleshooting and best practices in ROS\\n\\n\\n# Learning Robotics using Python \\n\\n#### [Learning Robotics using Python](http://learn-robotics.com) book tutorials source code\\n![book_cover](http://learn-robotics.com/images/section-image-1.jpg\\n \"Learning Robotics using Python\")\\n\\n### Buy book\\n\\n* [PACKT](https://www.packtpub.com/application-development/learning-robotics-using-python)\\n* [Amazon.com](http://amzn.com/1783287535)\\n* [Amazon.in](http://www.amazon.in/dp/B00YEVZ6UK)\\n\\n### Author\\n\\n* [Lentin Joseph](https://in.linkedin.com/in/lentinjoseph)\\n\\n### Installation\\nThe code is comaptible with ROS Jade and ROS Indigo. The detail installation instruction of each packages is mentioned on the book\\n\\n### Tutorials\\n* **Chapter 1**:  Introduction to Robotics\\n* **Chapter 2**: Mechanical design of a service Robot \\n* **Chapter 3**: Working with Robot Simulation using ROS and Gazebo\\n* **Chapter 4**: Designing Chefbot Hardware \\n* **Chapter 5**: Working with Robotic Actuators and Wheel Encoders \\n* **Chapter 6**: Working with Robotic Sensors \\n* **Chapter 7**: Programming Vision Sensors using Python and ROS \\n* **Chapter 8**: Working with Speech Recognition and Synthesis using Python and ROS\\n* **Chapter 9**: Applying Artificial Intelligence to Chefbot using Python\\n* **Chapter 10**: Integration of Chefbot hardware and interfacing it into ROS, using Python\\n* **Chapter 11**: Designing a GUI for a robot using QT and Python \\n* **Chapter 12**: The calibration and testing of Chefbot\\n\\n'},\n",
       " {'repo': 'vmayoral/ros-robotics-companies',\n",
       "  'language': 'Shell',\n",
       "  'readme_contents': '[![](https://img.shields.io/badge/ROS%20robotics%20companies-663-CCCCFF.svg)](https://github.com/vmayoral/ros-robotics-companies#active-companies) [![](https://img.shields.io/badge/ROS%20robotics%20companies%20acquired-21-9FE2BF.svg)](https://github.com/vmayoral/ros-robotics-companies#companies-acquired-closed-or-inactive) [![](https://img.shields.io/badge/ROS%20navigation%20users-61-40E0D0.svg)](https://github.com/vmayoral/ros-robotics-companies#navigation) [![](https://img.shields.io/badge/ROS%20manipulation%20users-53-6495ED.svg)](https://github.com/vmayoral/ros-robotics-companies#manipulation) [![](https://img.shields.io/badge/ROS%20perception%20users-140-FFBF00.svg)](https://github.com/vmayoral/ros-robotics-companies#perception)\\n\\n# ROS Robotics Companies\\n\\n[**Active companies**](#active-companies) ┃ [<ins>Acquired, closed or inactive</ins>](#companies-acquired-closed-or-inactive) | [Contribute](#contribute) | [`navigation` users](#navigation) | [`manipulation` users](#manipulation) | [`perception` users](#perception)\\n\\nA public list of companies that are known to use the Robot Operating System (ROS and ROS 2) or any of its related tools for development, to create products, to offer services or who ship ROS with or as part of their product(s). Ordered alphabetically. See [criteria](#criteria) for more details.\\n\\n### Active companies\\n<!-- !companies! -->\\n| Company | Description | Year Founded| \\n|---------|-------------|------|\\n| [Acceleration Robotics](https://accelerationrobotics.com) | Hardware Acceleration solutions for robots using ROS 2. Robot-specific processing unit ([`ROBOTCORE®`](https://accelerationrobotics.com/products.php)), FPGA and GPU hardware acceleration tools (e.g. [`ROBOTCORE®` Framework](https://accelerationrobotics.com/robotcore-framework.php)) and ROS 2 API-compatible robot Intellectual Property (IP) cores (`robot cores` such as [`ROBOTCORE®` Perception](https://accelerationrobotics.com/robotcore-perception.php) or [`ROBOTCORE®` Transform](https://accelerationrobotics.com/robotcore-transform.php)). | 2021 |\\n| [ACEINNA](http://www.aceinna.com/) | Create sensing solutions for the development of innovative [Inertial](https://www.aceinna.com/inertial-systems) Measurement Unit (IMU) and current [sensing](https://www.aceinna.com/current-sensors) technologies for cars, robots and other autonomous applications. ROS driver for Aceinna OpenRTK products (see [`aceinna_openrtk_ros_driver`](https://github.com/Aceinna/aceinna_openrtk_ros_driver))[^111]. | 2017 |\\n| [Accenture](https://www.accenture.com/in-en) | Offering robotics and edge computing consulting services around ROS. Hiring engineers with experience in ROS ([Edge Computing Application Lead](https://www.linkedin.com/jobs/view/3475376709/)). | 1989 |\\n| [Accerion](https://accerion.tech/) | Make infrastructure-free positioning technology for mobile robots and AGVs. Triton[^79], simplify high-performance AMR functions in logistics. ROS driver for Interfacing with Triton sensor  (see [`accerion-ros-node`](https://gitlab.com/accerion/accerion-ros-node)). | 2015 |\\n| [Accio Robotics](https://www.acciorobotics.com/) | Design and manufacture of state-of-the-art Robotics Automation solutions.  Hiring ROS engineers ([Robotics Software Engineer](https://angel.co/company/accio-robotics-1/jobs/1442403-robotics-software-engineer)). | 2019 |\\n| [Active8 Robots](http://www.active8robots.com) | Deliver automated solutions in robotics technologies and automation. They provide robotic automation for projects and common processes. Their products include robots, installation-ready automation cells, end-of-arm tooling, end-of-line automation, and so on. The company uses the ROS Manipulation stack (MoveIt) in the [AR10 Robotic Hand](https://moveit.ros.org/robots/). | 2013 | \\n| [ADASTEC](https://www.adastec.com/) | Deliver SAE Level-4 Automated Driving Software Platform for commercial vehicles to enable OEMs to develop modern, automated, shared, and connected commercial vehicles. Hiring ROS engineers ([Planning Software Engineer](https://kpm.metu.edu.tr/planning-software-engineer-adastec-teknoloji-as/)). | 2018 | \\n| [Addverb](https://addverb.com/) | Deliver automation solutions to improve intralogistics operations. Hiring ROS engineers ([Robotics Engineer](https://addverb.com/career/robotics-engineer/)). | 2016  | \\n| [Adinkra](https://adinkratech.com/) | Specializes in end-to-end robotics and AI product development with a focus on autonomous drones, high-fidelity simulation, and computer vision. Adinkra developed and deployed an advanced real-time perception system, retrained for an aerial perspective and built on [ROS2](https://adinkratech.com/case_studies/real-time-object-tracking-for-drones/). | 2020 |\\n| [ADLATUS Robotics GmbH](http://www.adlatus-robotics.com) | Designs and manufactures autonomous mobile robots for use in industrial environments such as manufacturing, logistics, and warehousing. ROS 2 drivers to develop and control their autonomous mobile robots (see [`adlatusrobotics`](https://github.com/adlatusrobotics)).  | 2015 | \\n| [ADLINK Technology](https://www.adlinktech.com/en/index) | Provide a wide range of embedded computing products and services to the test and measurement, automation and process control, gaming, communications, medical, network security, and transportation industries. ADLINK is using Navigation stack in their products like the [ROScube-X series](https://www.adlinktech.com/Products/Download.ashx?type=MDownload&isDatasheet=yes&file=1783%5CROScube-X_series_DS.pdf) of embedded systems for robots. ADLINK offers a [AMR visual SLAM navigation solution](https://www.adlinktech.com/en/kudan-amr-visual-slam). Empowering tracking in Autonomous Mobile Robots (AMRs). ROS2 Navigation (see [`Adlink-ROS/navigation2`](https://github.com/Adlink-ROS/navigation2)). | 1995 |\\n| [Advanced Micro Devices (AMD)](https://amd.com) | High-performance and adaptive computing leader, GPU, CPU and FPGA solutions. Kria SOMs feature ROS 2 support and provide hardware acceleration capabilities to roboticists. | 1969 |\\n| [Advanced Navigation](https://www.advancednavigation.com) | Specializes in the development of navigation technologies and robotics. ROS driver for Advanced Navigation [devices](https://www.advancednavigation.com/inertial-systems/) (see [`advanced_navigation_driver`](https://github.com/ros-drivers/advanced_navigation_driver)). | 2010 |\\n| [Aeolus Robotics](http://aeolusbot.com/) | Bring autonomous two-armed robots to service sectors. The company works around artificial intelligence, robotics, computer vision, and human-robot Interaction. Hiring ROS engineers ([Robotics developers](https://discourse.ros.org/t/robotics-mobility-vision-and-manipulation-positions-at-aeolus-robotics/1334)). | 2016 |\\n| [Aerobotix](http://aerobotix.net) | Robotic solutions for the aerospace and defense industries. Specialize in the creation of cutting-edge automated robotic solutions for high-value, high-precision components, aircraft, and vehicles. Aerobotix used ROS to handle all MIR motion[^113]. The company is [currently members](https://rosindustrial.org/current-members) of ROS-Industrial. | 2005 |\\n| [AeroVironment](https://avinc.com/) | Leader in the markets for small Unmanned Aircraft Systems, Tactical Missile Systems, High-Altitude Pseudo-Satellites and Commercial Information Systems.  Offer flexible software control options\\xa0including via ROS[^197][^198] | 1971 |\\n| [Aeva](http://www.aeva.com) | Develop a sensing and perception paradigm for autonomous machines. Hiring ROS engineers ([Senior Localization Engineer](https://www.aeva.com/career/?lv_jid=5eebfe09-4d72-4f59-a7bb-d39c8bebc7c6)). | 2017 | \\n| [AEye](https://www.aeye.ai/) | Create software-defined lidar solutions that enable advanced driver-assistance, vehicle autonomy, smart infrastructure, logistics and off-highway applications. Hiring ROS engineers ([ROS1 and ROS2 developer](https://discourse.ros.org/t/aeye-public-lidar-company-looking-for-ros1-and-ros2-developer/26493)). | 2013 |\\n| [AGCO](https://www.agcocorp.com/) | Global leader in the design, manufacture and distribution of smart solutions for sustainable agriculture. Hiring engineers with experience in ROS ([Systems Engineer (m/f/d) Logical Architecture](https://careers.agcocorp.com/job/Marktoberdorf-Systems-Engineer-%28mfd%29-Logical-Architecture/952146200/)). | 1990 |\\n| [AgileX Robotics](https://www.agilex.ai/?lang=en-us) | Develop a full line-up of  robotics UGV covering all terrains and payloads, including general UGV, indoor AGV, tracked UGV. The world’s first ROS2 mobile robot navigation open source education kit released[^377]. | 2016 |\\n| [AgriData Innovations](http://adinnovations.nl/) | Develop hardware and software solutions to improve the efficiency and effectiveness of greenhouses. Using state-of-the-art camera systems, data analysis software and presentation of actionable insights for data-driven greenhouse management. Hiring engineers with experience in ROS ([Embedded / Electrical Engineer](https://talents.yesdelft.com/careers/embedded-electrical-engineer-adi)). | 2018 | \\n| [Agrograde](https://agrograde.com/) | Automate the grading and sorting process of fruits and vegetables by using computer vision. Company worker works as a [ROS developer](https://www.linkedin.com/in/sayooj-p/?trk=public_profile_browsemap_profile-result-card_result-card_full-click&originalSubdomain=in). | 2018 | \\n| [AICA](https://aica.tech/) | Artificial Intelligence for Collaboration and Automation; a modular and intuitive robot programming framework of smart components for AI-based motion generation and compliant control. Their technology stack supports ROS2 and ros2_control interfaces (see [`AICA docker images`](https://github.com/aica-technology/docker-images)). | 2019 |\\n| [Aidrivers](https://www.aidrivers.ai/) | Accelerate autonomous mobility technology to meet industry needs for optimization, resilience, and safety for a sustainable future. Hiring ROS engineers ([Autonomy Engineer (Drive Control)](https://www.mycareersfuture.gov.sg/job/engineering/autonomy-engineer-aidrivers-singapore-49f864dfe7606b4428fd35464d97240d)). | 2018 | \\n| [Airbus](https://www.airbus.com/en) | Global leader in aeronautics, space and related services. Using ROS for various purposes and across divisions. Hiring ROS engineers ([Robotic Engineer](https://www.linkedin.com/jobs/view/3295097708/)). | 2011 |\\n| [Airvolute](https://www.airvolute.com/) | Drones and Aupilots with ROS based system for autonomous flight[^200][^201]. | 2020 |\\n| [Aivot](https://www.aivot.com/) | Build fast-learning and low-cost humanoid robots. ROS drivers for Aivot robots (see [`AivotRobotics`](https://github.com/AivotRobotics)). | 2017 | \\n| [Akara Robotics](https://www.akara.ai/) | Akara provides robots for disinfecting hospital rooms. The product Violet is an ultraviolet light robot, which is clinically proven to kill viruses, bacteria, and harmful germs. Akara Robotics is an AI-based robot with a mission of developing social assistance robots that can support staff and residents in retirement communities. Hiring ROS engineers ([Autonomous Navigation Engineer](https://discourse.ros.org/t/autonomous-navigation-engineer-akara-robotics/25166)).  | 2019 |\\n| [Alias Robotics](https://www.aliasrobotics.com/) | Robot cybersecurity products and services around ROS and ROS 2 systems[^192]. The company is a relevant contributor to the ROS 2 Security WG[^190][^191] and is also behind the Robot Immune System (RIS)[^1], an endpoint protection platform for robots that offers ROS and ROS 2  additional security layers. | 2018 |\\n| [AMP Robotics](http://amprobotics.com) | The use of automation and AI to modernize the recycling infrastructure worldwide. Recycling from mixed material streams is identified and sorted automatically by the high-speed robotics system AMP CortexTM. The AMP NeuronTM AI platform constantly improves itself by identifying materials and their recyclable nature. Hiring engineers with experience in ROS ([Mid-level Robot Software Engineer](https://wellfound.com/company/amp-robotics/jobs/1216296-mid-level-robot-software-engineer)). ROS drivers for AMP Robotics (see [`AMP-Robotics`](https://github.com/AMP-Robotics)). | 2015 |\\n| [Amsted Rail](http://www.amstedrail.com/) | Design of fully integrated freight car systems for the heavy haul rail market. The company is [currently members](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^132]. | 1977 |\\n| [Analog Devices](https://www.analog.com/en/index.html) | World leader in high-performance analog and digital electronics offering cutting-edge sensing, measurement, power management, communication, and signal processing technologies. They released and maintain ROS Drivers for some of their MEMS sensors (e.g. see ADIS16470). ROS node for Analog Devices Inc. Inertial Measurement Units (IMU) (see [`analogdevicesinc/adi_imu_ros`](https://github.com/analogdevicesinc/adi_imu_ros)). | 1965 |\\n| [Angel Robotics](https://angel-robotics.com/ko/) | Robotic technology company that offers wearable robotic devices for disabled people. Talk at [ROSCon 2022](https://roscon.ros.org/2022/): Wearable ROS: Development of wearable robot system using ROS 2 . The Angel Robotics ROS project (see [`angel_ros`](https://github.com/Angel-Robotics/angel_ros)). | 2017 | \\n| [Angsa Robotics](https://angsa-robotics.com) | Specializes in the development and production of industrial robots and automation equipment. The company\\'s products are used in a variety of industries, including automotive, electronics and food. Hiring ROS engineers ([Robotics Software Engineer](https://angsa-robotics.com/uploads/projects/2021_Software.pdf)). | 2019 | \\n| [Angulair](http://www.angulair.com) | Deliver solutions for defence, agriculture, high rise tower, windmill inspection etc using MAV based solutions with their power tethered drones. Hiring ROS engineers ([Embedded/ Firmware Engineer](https://www.angulair.com/job-embedded-firmware-engineer/)). | 2019 | \\n| [Ant Robotics](https://antrobotics.de/) | Develop autonomous platform solutions in various sectors. Their first robot platform helps in the agricultural field where they use image recognition and deep learning algorithms to precisely identify and remove harmful weeds among crops. Hiring ROS engineers ([ROS engineers](https://discourse.ros.org/t/fulltime-or-internship-in-navigation-for-outdoor-mobile-robot-in-agriculture/28714/1)). | 2021 | \\n| [ANYbotics](https://www.anybotics.com/) | Develop mobile robotics for industrial applications. The simulation software to extend ANYmal’s (four-legged robots) capabilities and interface through the ROS APIs and open-source ecosystem. ROS drivers for ANYbotics (see [`ANYbotics`](https://github.com/ANYbotics)). | 2016 |\\n| [Apex.AI](https://www.apex.ai/) | Specializes in developing operating systems for autonomous vehicles. Its software products are based on open-source software such as ROS or Eclipse iceoryx. [Apex.AI](https://www.apex.ai/) is a proud supporter of Open Robotics, ROS and ROSCon. | 2017 |\\n| [Apollo]( http://apollo.auto) | An open autonomous driving platform. The Apollo-platform solution under ROS directory (see [`apollo-platform`](https://github.com/ApolloAuto/apollo-platform)). Sponsor of the [ROScon](https://roscon.ros.org/2018/) 2018 [^169]. | 2017 | \\n| [Applanix Corporation](http://www.applanix.com) | Develop advanced products and scalable solutions that maximize productivity through Mobile Mapping and Positioning. ROS driver for Applanix hardware (see [`applanix_driver`](https://github.com/clearpathrobotics/applanix_driver))[^176]. | 1991 |\\n| [Apple](http://www.apple.com) | Design, manufacture, and market consumer electronics, personal computers, and software. Sponsor of the [ROScon](https://roscon.ros.org/2018/) in 2018. Seeking for ROS engineers[^276]. | 1976 | \\n| [Apptronik](https://apptronik.com/) | Builds and designs human-centered robotics systems. [Draco](https://apptronik.com/our-work/) is Apptronik’s first biped. The system can be a platform for any humanoid system, with easy integration between systems because of the open access to low level control software and libraries for RT Linux/ROS[^120] integration. | 2015 |\\n| [Aptiv](https://www.aptiv.com/) | Manufacturer of software-defined vehicles and solve mobility’s toughest challenges in autonomous driving. Hiring engineers with experience in ROS ([Software Engineer](https://www.aptiv.com/ja/%E6%8E%A1%E7%94%A8%E6%83%85%E5%A0%B1/%E6%A4%9C%E7%B4%A2%E3%82%B8%E3%83%A7%E3%83%96/%E3%82%AA%E3%83%BC%E3%83%97%E3%83%B3%E3%83%9D%E3%82%B8%E3%82%B7%E3%83%A7%E3%83%B3/J000640904)). | 1994 | \\n| [ARAV](https://www.arav.jp/) | Offer automated construction equipment. Sponsor of the [ROScon](https://roscon.ros.org/2022/) 2022. | 2020 | \\n| [Arbe](http://www.arberobotics.com) | Offers Real Time 4D Imaging Radar for autonomous driving. Hiring ROS engineers ([Software Tools Development Team Lead](https://arberobotics.com/careers/software-tools-development-team-lead-tel-aviv-israel/)). | 2015 | \\n| [ARC Specialties](http://www.arcspecialties.com) | Design and build automated manufacturing systems and custom equipment for joining, cladding, and other applications. The company is [currently members](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^131]. | 1983 |\\n| [Arche Robotics](http://archerobotics.com/) | Design, manufacture, and commercialize “people-centric” robotics systems across a wide variety of sectors. Company worker works as a [ROS developer](https://www.linkedin.com/in/kayracoskun/). | 2021 |\\n| [ARI](http://www.arifleet.com/) | Offer business, vehicle and driver management solutions to various industries. Hiring ROS engineers ([Robotic Software Engineer](https://in.indeed.com/viewjob?jk=f31146b9111f3ecb&tk=1gppq1pd4k998800&from=serp&vjs=3)). | 1948 | \\n| [Arm](https://www.arm.com/) | Design the technology building blocks that semiconductor designers, equipment manufacturers, and others use to create silicon chips and specialized compute systems. | 1990 |\\n| [ARM Institute](http://www.arminstitute.org) | Accelerate the development and adoption of innovative robotics technologies. Make robotics, autonomy and artificial intelligence more accessible to U.S. manufacturers. An analysis of how the ARM projects have used ROS[^114]. | 2017 |\\n| [ARTI](https://www.arti-robots.com) | Develop software for ground-bound autonomous mobile robots. Hiring engineers with experience in ROS ([Robotic Software Developer](https://arti-robots.com/about/)). | 2019 |\\n| [Artisense](https://www.artisense.ai) | Provide a globally leading 3D-vision technology, enabling vehicles, robots and UAVs navigate effectively in any space without GPS. Artisense provides ROS 1 and ROS 2 support, making it quick and simple for clients to work with our system [^175]. | 2016 |\\n| [Ascent Robotics](https://www.ascent.ai) | Develop intelligent solutions in industrial robotics and autonomous vehicles. Deliver software to achieve true machine autonomy. ROS drivers (see [`ascentai`](https://github.com/ascentai)). | 2016 |\\n| [Ascento Robotics](https://www.ascento.ch/) | Offers autonomous outdoor security patrol robots as a service. ROS drivers for Ascento Robotics (see [`ascento-robotics`](https://github.com/ascento-robotics)). | 2023 | \\n| [Asea Brown Boveri (ABB)](https://global.abb/group/en) | Provide power and automation technologies for smart grids, robotics, electric cars, renewable energy and motors. The company is [currently members](https://rosindustrial.org/current-members) of ROS-Industrial. | 1988 | \\n| [Asensus Surgical](https://asensus.com/) | Medical device company that digitizes the interface between the surgeon and the patient. Sponsor of the [ROScon](https://roscon.ros.org/2023/) 2023. ROSCon is a developers conference [^379]. | 2006 | \\n| [ASIMOV Robotics](http://www.asimovrobotics.com) | Supply Robot and machine vision systems, control and simulation software, navigation systems, educational robots, industrial robots, and sensors and sensor modules. The software system of some robots is written entirely in [ROS](http://wiki.ros.org/Robots/X-Terrabot). | 2012 |\\n| [Asimovo](https://asimovo.com/) | A cloud based platform for developing and testing robots and autonomous systems. Sponsor of the [ROScon](https://roscon.ros.org/2023/) 2023. ROSCon is a developers conference [^379]. | 2023 | \\n| [Atlas Robotics](https://www.atlas-robotics.com) | Fully autonomous L4 pallet trucks/stackers for indoor factories, making them as standalone products or autonomy kits. Hiring engineers with experience in ROS ([Software Engineer](https://www.atlas-robotics.com/software-engineer)). | 2021 |\\n| [AUBO Robotics](https://www.aubo-cobot.com/public/index3) | Manufacture lightweight collaborative robots. This repository is used to control real aubo\\'s MRA(module robot arm) by the ros control (see [`mra_ros_control`](https://github.com/AuboRobot/mra_ros_control))[^23]. | 2013 | \\n| [Auro](http://www.auro.ai) | Develop L4 autonomous driving technologies. ROS drivers (see [`Develop L4 autonomous driving technologies`](https://github.com/AuroAi)). | 2015 |\\n| [Auterion](https://auterion.com/) | Provide the ecosystem of software-defined drones, payloads, and third party applications within a platform based on open-source standards. Auterion driving [ROS 2](https://auterion.com/auterion-driving-ros-2-adoption-for-flying-robots/) adoption for flying robots. | 2017 |\\n| [Autobots INC](https://autobots-inc.com/) | Develop a wide range of products: [6 axis cobot](https://autobots-inc.com/cobots-1), desktop [robots for education](https://autobots-inc.com/educational-robots), [grippers](https://autobots-inc.com/electrical-grippers) and [robot simulation and control software](https://autobots-inc.com/simulation-software). Their electric grippers supported by [ROS](https://autobots-inc.com/electrical-grippers). | 2017 | \\n| [AutoCore.ai](https://autocore.ai/) | High Performance Functional Safety Middleware Platform for Intelligent Mobility at Scale. Development or migration of existing applications, or/and integration with AutoSAR as well as [ROS](https://autocore.ai/acsys.html)-based designs | 2018 | \\n| [AutomationWare](https://automationware.it) | Develops and produces mechatronic components for robotics solutions with the use of ROS and ROS 2. All of their collaborative robots are supplied with the installation of a basic [ROS package](https://automationware.it/ros-eng/?lang=en). | 2002 |\\n| [AutonomouStuff](http://www.autonomoustuff.com) | Provider of autonomy-enabling technologies that specializes in [perception sensors](https://autonomoustuff.com/products?para1=LiDAR), [GPS](https://autonomoustuff.com/products?para1=Mapping), and [computing](https://autonomoustuff.com/products?para1=Computing). ROS drivers for AutonomouStuff (see [`astuff`](https://github.com/astuff)). | 2010 |\\n| [Autoware Foundation](https://www.autoware.org/) | Is the world’s leading open-source software project for autonomous driving. Autoware is built on [Robot Operating System (ROS)](https://www.autoware.org/) and enables commercial deployment of autonomous driving in a broad range of vehicles and applications. | 2015 |\\n| [Avidbots](https://avidbots.com/) | Supporting autonomous cleaning robots. NEO is the smartest autonomous cleaning robot produced by Avidbots. NEO is used in industrial areas, shopping centers, hospitals, and colleges, among other places. Hiring ROS engineers ([Senior Software Developer](https://discourse.ros.org/t/multiple-software-jobs-available-avidbots/19493)). | 2014 |\\n| [AVL](https://www.avl.com/) | Develop and improves all kinds of powertrain systems and is acompetent partner to the engine and automotive industry. Simulation: In addition, develops and markets the simulation methods which are necessary for the development work. AVL Ajunic® controller platform for autonomous driving development, can be programmed with [ROS](https://www.avl.com/-/avl-adas-ecu). | 1948 | \\n| [Avnet](http://www.avnet.com) | Is a global technology solutions company. Sponsor of the [ROScon](https://roscon.ros.org/jp/2019/) JP 2019. ROSCon is a developers conference [^166]. | 1921 | \\n| [Avular](http://www.avular.com) | Accelerates the creation of mobile robot applications with their modular hardware and software building blocks (The Essentials) and their flying and driving robot platforms (The Pioneers). Hiring ROS engineers ([Control engineer for Mobile Robotics](https://avular.com/careers/control-engineer-for-mobile-robotics/)). | 2014 |\\n| [AWS RoboMaker](https://aws.amazon.com/robomaker/) | Cloud-based simulation service that enables robotics developers to run, scale, and automate simulation. Uses [ROS](https://aws.amazon.com/es/blogs/robotics/preparing-ros-application-and-simulation-containers-for-aws-robomaker/) to provide a standardized platform for building robotic applications. This makes it easier for developers to build, test, and deploy robotic applications using AWS infrastructure. | 2006 |\\n| [A&K Robotics](http://www.AandKrobotics.com) | Design electric micro-mobility platforms and self-driving robotic pods to help improve quality of life and positively impact the environment. Their autonomous robots empower people with limited mobility to travel and navigate long distances in places such as airports, malls and museums. An image processing pipeline for ROS for A&K Robotics (see [`akrobotics/image_pipeline`](https://github.com/akrobotics/image_pipeline)). | 2015 | \\n| [Badger Technologies](http://www.badger-technologies.com/) | Offer complete end-to-end solutions, from robot and software to store integration, maintenance and analytics. ROS drivers for Badger Technologies (see [`BadgerTechnologies`](https://github.com/orgs/BadgerTechnologies)). | 2017 | \\n| [Barnstorm Agtech](http://www.barnstormag.tech/) | Provide an open platform for precision and powered deployment of farm technology. Hiring ROS engineers ([PUNE Robotic Agtech R&D Engineering](https://in.joblum.com/job/pune-robotic-agtech-r-d-engineering/1194887)). | 2020 | \\n| [Barrett Technology](http://www.barrett.com) | Pioneer in collaborative robots that assist humans in their work. Robots made by Barrett, like WAM® and BURT®, use Barrett mechanisms, Puck® motor controllers, and open-source software to control their movements. ROS drivers for Barrett Technology (see [`BarrettTechnology`](https://github.com/BarrettTechnology)). | 1990 |\\n| [Bastian Solutions](http://www.bastiansolutions.com) | Is an independent material handling and robotics system integrator providing automated solutions for distribution and manufacturing. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^133]. | 1952 |\\n| [Beagle Systems](https://www.beaglesystems.com/) | Provide Drones-as-a-Service for powerline / pipeline inspections. ROS2 drivers for Beagle Systems (see [`BeagleSystems`](https://github.com/BeagleSystems)). | 2019 | \\n| [Beagle Technology](https://www.beagle-tech.com/) | Uses AI and robotics software to transform traditional farming equipment with unseen accuracy, flexibility and intelligence. Hiring engineers with experience in ROS ([Director of Robotics](https://www.linkedin.com/jobs/view/director-of-robotics-at-beagle-technology-inc-3328013334/)). | 2021 |\\n| [Bear Robotics](https://www.bearrobotics.ai) | Autonomous Mobile Robots (AMRs) for the food service and hospitality. Hiring engineers with experience in ROS ([Robotics Software Engineer - System](https://bear-robotics.breezy.hr/p/caf7e2f65bc3-robotics-software-engineer-system)). | 2017 |\\n| [BeeX](http://www.beex.sg) | Design and manufacture Hovering Autonomous Underwater Vehicles (HAUVs). Hiring ROS engineers ([Robotics Engineer](https://www.linkedin.com/jobs/view/3450366275/?trackingId=dmISwE%2Fec7opNOw8SXyAIA%3D%3D&refId=5f96468d-fe1c-43c3-add2-f4277af8dc38&midToken=AQGM4kLzCLjyIw&midSig=1c_8ZMaJF7WqA1&trk=eml-email_job_alert_digest_01-job_card-0-jobcard_body&trkEmail=eml-email_job_alert_digest_01-job_card-0-jobcard_body-null-2oh2sl~lddbm7j8~gr-null-null&eid=2oh2sl-lddbm7j8-gr)). | 2018 |\\n| [Beta Robots](https://beta-robots.com/) | Offer a comprehensive software solution for intralogistics applications using autonomous mobility robots (AMR/AGV). Company worker works as a [ROS developer (Development of robotics software)](https://www.linkedin.com/in/andreucorominasmurtra/?originalSubdomain=es). | 2016 |\\n| [Beyond Vision](https://beyond-vision.pt/) | Certified Drones Manufacturer for professional applications or complex operations. Develops custom AI algorithms to achieve fully autonomous operations. Creator of an [user-friendly platform](https://beyond-vision.pt/bexstream/) providing total remote control of drones using ROS (see [our documentation](https://docs.beyond-vision.pt/heifu/ros.html)). | 2013 |\\n| [Birds Eye Robotics](https://www.birdseyerobotics.com) | Agtech startup focusing on animal welfare and labor reduction in commercial poultry farms. Hiring ROS engineers ([ROS software developer](https://discourse.ros.org/t/ros-software-developer-nav2-birds-eye-robotics-omaha-ne/25571)). | 2021 |\\n| [Bitcraze AB](https://www.bitcraze.io) | They develop and manufacture a small quadcopter called the Crazyflie[^29]. They also develop and maintain a supporting infrastructure with various tools to enable the end users to modify the Crazyflie in any way they want. Bitcraze LPS ROS driver (see [`lps-ros`](https://github.com/bitcraze/lps-ros)). | 2012 | \\n| [Black Coffee Robotics](https://blackcoffeerobotics.com) | They consult and provide development services to robotics companies, primarily working with ROS/ROS2 based software stacks. ROS drivers for Black Coffee Robotics (see [`blackcoffeerobotics`](https://github.com/blackcoffeerobotics)). | 2019 |\\n| [BlackBerry QNX](https://blackberry.qnx.com/en) | Supplier of commercial operating systems, hypervisors, development tools, support and services, all purpose-built for critical embedded systems. BlackBerry QNX helps to take advantage of a real-time operating system (RTOS) integrated with ROS2[^128]. [ROS2 QNX Documentation](https://ros2-qnx-documentation.readthedocs.io/en/galactic/index.html). | 1980 |\\n| [Blickfeld](https://www.blickfeld.com/) | LiDAR Solutions for a safe and efficient world. This package provides an ROS node and a nodelet for publishing PointCloud2 messages from Blickfeld LiDAR devices (see [`Blickfeld ROS package`](https://docs.blickfeld.com/cube/v1.0.0/external/ros/driver-v1/README.html)). | 2017 |\\n| [Blue Atlas Robotics](https://blueatlasrobotics.com/) | Manufactures underwater inspection robots. Robots track underwater surfaces such as ship hulls using automatic distance-keeping in any orientation. Company worker works as a [ROS developer](https://www.linkedin.com/in/antonis-karageorgiou-4b925b134/?originalSubdomain=dk). | 2018 |\\n| [Blue Ocean Robotics](https://www.blue-ocean-robotics.com/) | Develop  professional service robots primarily in healthcare, hospitality, construction and agriculture. Hiring ROS engineers ([Robotics Software Developer](https://discourse.ros.org/t/robotics-software-developer-to-develop-uvd-robots-blue-ocean-robotics/24170)). | 2013 |\\n| [Blue River](http://www.bluerivertechnology.com) | Use of computer vision and robotics for agriculture. These robots are designed for the selection of which herbicides to use on each plant. Hiring ROS engineers ([Sr Perception Engineer](https://www.linkedin.com/jobs/view/3555808212/)). | 2011 |\\n| [Blue Robotics](https://bluerobotics.com) | Manufacturer of low-cost, high-performance components for marine robotics. [ROS](https://discuss.bluerobotics.com/t/ros-support-for-bluerov2/1550) support for [BlueROV2](https://bluerobotics.com/store/rov/bluerov2/). | 2014 \\n| [BlueSpace.ai](http://www.bluespace.ai) | Is an urban mobility company that develops autonomous vehicle technology. Bluespace’s patented [Dynamic Predictive Perception](https://www.bluespace.ai/technology) software allows an autonomous system to “see” the velocity of all objects and in all directions, xsens ROS2 driver (see [`bluespace_ai_xsens_ros_mti_driver`](https://github.com/bluespace-ai/bluespace_ai_xsens_ros_mti_driver)). | 2019 |\\n| [Bluewhale Robot](http://www.bwbot.org) | Has a solution for visual navigation. Bluewhale Robot has dedicated to providing ultra-cost-effective robotic autonomous mobile systems for use in products such as sweeper, service robots, security robots, industrial AGV and unmanned forklifts. ROS drivers for Bluewhale Robot (see [`BlueWhaleRobot`](https://github.com/BlueWhaleRobot)). | 2015 | \\n| [BMW Group](http://www.bmwgroup.com) | Manufacter automobiles and motorcycles and also provides premium financial and mobility services. Automated driving with ROS[^115] at BMW. | 1916 |\\n| [Boeing](http://www.boeing.com/) | Is an aerospace company that manufactures commercial jetliners, defense, space and security systems, and global services. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^134]. | 1916 |\\n| [Bosch](https://www.bosch.com/) | Global supplier of technology and services. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^135]. | 1886 | \\n| [Bossa Nova](http://www.bossanova.com) | Provide real-time, on-shelf product data for the global retail industry. Sponsor of the [ROScon](https://roscon.ros.org/2018/) 2018. ROSCon is a developers conference [^169]. | 2005 | \\n| [Boston Dynamics](bostondynamics.com) | Boston Dynamics uses ROS-derived tools in their development and leverages code from ROS drivers that ship in their resources to operate their robots. They don\\'t use the ROS message passing infrastructure directly, but a similar event-driven programming interface. Boston Dynamics robots have community drivers created by third parties which allow these robots to be first class participants of the ROS ecosystem (see [`spot_ros`](https://github.com/clearpathrobotics/spot_ros)). | 1992 |\\n| [BotBuilt](https://www.botbuilt.com/) | Creates construction components with robotic precision using AI and computer vision. Uses ROS and various ROS-related tools to build their robots. Hiring ROS engineers ([Senior Software Engineer](https://www.ycombinator.com/companies/botbuilt/jobs/8zZ1jOo-senior-software-engineer)). | 2020 |\\n| [BotsAndUs](https://www.botsandus.com/) | Captures real-time insights of warehouse operations using fully autonomous robots[^28] and Artificial Intelligence. The autonomous mobile and modular robots measure, track, and find goods across warehouses without workflow disruption. ROS Navigation stack, code for finding where the robot is and how it can get somewhere else (see [`navigation`](https://github.com/botsandus/navigation)). | 2015 |\\n| [Botsync](https://www.botsync.co) | Builds heavy duty autonomous mobile robots[^65] to help companies transit from manual operations to automation. ROS Drivers for communicating with Botsync AMR (see [`botsync`](https://github.com/botsync)). | 2017 | \\n| [Bowery Farming](http://boweryfarming.com) | The company uses innovative technologies, including robotics, artificial intelligence, and data analytics, to grow a wide range of leafy greens and herbs in a highly efficient and sustainable way. ROS 3D Robot Visualizer (see [`BoweryFarming`](https://github.com/BoweryFarming/rviz)). | 2015 | \\n| [Boxbot](http://www.boxbot.io) | Build automation systems for parcel delivery. Their product integrates robotics and autonomous technologies into a scalable end-to-end solution. ROS package containing drivers for NMEA devices (see [`nmea_navsat_driver`](https://github.com/boxbotinc/nmea_navsat_driver)). | 2016 |\\n| [Brain Corp](http://braincorp.com/) | Robotics and AI company that specializes in developing software for autonomous mobile robots (AMRs) used in industries such as retail, hospitality, and healthcare. ROS drivers for Brain Corporation (see [`braincorp`](https://github.com/braincorp)). | 2009 | \\n| [BrainGarden](https://www.braingarden.ai) | They apply their experience in artificial intelligence to the domain fields, e.g. computer vision manufacturing and smart systems assembly, medical imaging analysis, FashionTech, Creative AI, and more. ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for BrainGarden (see [`BrainGardenAI/depthimage_to_laserscan`](https://github.com/BrainGardenAI/depthimage_to_laserscan)). | 2017 |\\n| [BringAuto](http://bringauto.com/) | Offer  industrial delivery robots together with fleet management. They extending the experimentation facilities into robotic domains thorough standard Application Programming Interfaces (APIs) under Robot Operating System ([ROS](https://bringauto.com/en/5g-era/)). | 2019 | \\n| [Brisa Robótica](https://www.brisa.tech/) | Automate existing vehicles or develop new ones. Windrose[^69] is a solution to boost productivity in the supply chain. ROS Drivers (see [`brisa-robotics`](https://github.com/brisa-robotics)). | 2018 |\\n| [BSH Hausgeräte AG](https://www.bsh-group.com) | Produce and sell household appliances. Is one of the largest manufacturers of home appliances in the world. Hiring engineers with experience in ROS ([Software engineer (m/f/d) Robotics](https://jobs.bsh-group.de/27524-software-engineer-m-f-d-robotics/en/job.html?persisted_lang=en)). | 1967 | \\n| [Built Robotics](http://www.builtrobotics.com) | Transform excavators into fully autonomous trenching robots for the earthmoving industry. Sponsor of the [ROScon](https://roscon.ros.org/2018/) 2018. ROSCon is a developers conference [^169]. | 2016 | \\n| [Candela](https://candela.com/) | Long-range electric boats powered by ROS. Hiring engineers with experience in ROS ([Autonomous Driving Software Engineer](https://vakanser.se/jobb/autonomous+driving+software+engineer+4/)). | 2014 |\\n| [Canonical](https://canonical.com/) | Computer software company that markets commercial support and related services for Ubuntu and related projects. Hiring engineers with experience in ROS ([Software Engineer - Robotics](https://discourse.ros.org/t/software-engineer-robotics-canonical-remote/20807)). | 2004 |\\n| [Canvas](https://www.canvas.build/) | Develop robotic systems for the construction industry. The company\\'s robotic systems are designed to automate and optimize many of the labor-intensive and repetitive tasks involved in construction, such as material handling and installation. ROS drivers for Canvas robots (see [`Canvas-Construction`](https://github.com/Canvas-Construction)). | 2017 | \\n| [Capgemini Engineering](https://capgemini-engineering.com) | IT Services and IT Consulting. R&D services. Using ROS in their robotics activities. Hiring engineers with experience in ROS ([Senior Engineer](https://capgemini.taleo.net/careersection/1/jobdetail.ftl?job=070985)). | 1982 |\\n| [Capra Robotics](https://capra.ooo/) | Develop a  platform for outdoor mobile robots. [Capra Hircus](https://capra.ooo/benefits/) supports autonomous navigation, when driving autonomously the robot follows a given path. The software used by the robot is [ROS 2](https://capra.ooo/benefits/specifications/). | 2017 | \\n| [Carbon Robotics](https://carbonrobotics.com/) | Build innovative agricultural tools that empower farmers to operate more efficiently. Hiring engineers with experience in ROS ([Engineers](https://discourse.ros.org/t/multiple-software-hardware-openings-carbon-robotics/860)). | 2018 | \\n| [Carnegie Robotics](http://carnegierobotics.com) | Build reliable robotics products and smart sensors for defense, agriculture, mining, infrastructure and energy applications. ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Carnegie Robotics (see [`carnegieroboticsllc/vision_opencv`](https://github.com/carnegieroboticsllc/vision_opencv)). | 2010 | \\n| [Cartken](https://www.cartken.com/) | Serve a ROS-based autonomous robot platform designed to transport goods over short distances and in local neighborhoods. Hiring engineers with experience in ROS ([Embedded Robotics Engineer](https://lensa.com/embedded-robotics-engineer-jobs/oakland/jd/ffb218b2ec9696befa96e9f4845ce355)). | 2019 |\\n| [Caterpillar](https://www.caterpillar.com/en.html) | Manufacture construction and mining equipment, diesel and natural gas engines, industrial gas turbines. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^136]. | 1925 | \\n| [Cellula Robotics](https://www.cellula.com/) | Cellula specializes in the turnkey design and production of subsea robotic systems, including cruising and hovering autonomous underwater vehicles. Cellula uses ROS 1 and follows a paradigm of many small, simple, modular, configurable nodes. This allows the separation of software engineering and vehicle engineering / operation. Cellula uses the [UUV Simulator](https://uuvsimulator.github.io/) and is an active member of the [Maritime Robotics Working Group](https://discourse.ros.org/c/maritime/36) | 2001 | \\n| [Cepton](http://cepton.com/) | Develop [lidar-based](https://www.cepton.com/technology) solutions for [automotive](https://www.cepton.com/markets/overview), industrial, and mapping markets. Cepton ROS package (see [`cepton_ros`](https://github.com/ceptontech/cepton_ros)). | 2016 |\\n| [Chef Robotics](http://chefrobotics.ai) | Cooking robots powered by ROS. Hiring engineers with experience in ROS ([Solutions Architect](https://jobs.lever.co/ChefRobotics/e5963919-6cf7-453e-aa6e-5e5716b72177)). | 2019 |\\n| [CheungWon SFA](http://cwsfa.co.kr/) | Develop and manufacture various agricultural autonomous robots[^225] for the indoor smart farm. Registered as a partner of Doosan Robotics[^226] and OnRobot[^227]. ROS packages (see [`cwsfa`](https://github.com/cwsfa))[^103].| 2019 |\\n| [Clobot](https://www.clobot.co.kr/) | Is an autonomous robot service provider. They implement specialized robot services in consideration of the robot hardware and  operating environment. ROS drivers (see [`CLOBOT-Co-Ltd`](https://github.com/CLOBOT-Co-Ltd)). | 2017 |\\n| [CM Labs Simulations](http://www.cm-labs.com) | Software company that specializes in the development of simulation and training solutions for heavy equipment operators. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2001 | \\n| [Coalescent Mobile Robotics](https://cm-robotics.com/) | Develops and manufactures autonomous mobile robots to  automate the transportation process in the retail industry, both in store and in warehouse. The company\\'s tech stack is built on top of ROS2 with a heavy use of navigation2 and microROS. (see [`cmrobotics`](https://github.com/cmrobotics)). | 2018 |\\n| [COEX](https://coex.tech/) | Develop and manufacture of unmanned aerial vehicles. Multicopters[^27], developed by the company, are intended for the formation[^26], autonomous monitoring of territories and delivery of goods. ROS Drivers for communicating with COEX drones (see [`CopterExpress`](https://github.com/CopterExpress)). | 2014 | \\n| [Cognata](http://www.cognata.com) | Provide driving validation platform for the autonomous vehicles industry. [ROS](https://www.cognata.com/closed-loop-simulations/) integration enables thorough testing and evaluation of complex components such as perception and control stacks with Cognata scenarios, traffic and synthetic data. Hiring ROS engineers ([Software Engineer - Path Core Planning](https://boards.greenhouse.io/didi/jobs/4314438)) | 2016 |\\n| [Cognicept Systems](http://www.cognicept.systems) | Provide Human-in-the-loop (HITL) error handling with our telerobotic networking technology and human remote operators. ROS packages for automatic docking (see [`autodock`](https://github.com/cognicept-admin/autodock)). | 2018 |\\n| [Cogniteam](https://www.cogniteam.com/) | Develop artificial intelligence technologies for robots, working with companies on mapping, navigation and autonomous decision-making. Nimbus[^32] is the product that bring a Cloud-based robotic artifical intelligence solution. ROS Drivers for Cogniteam prodcuts (see [`cogniteam`](https://github.com/cogniteam)). | 2010 | \\n| [Cognizant](https://www.cognizant.com) | Provide digital, technology, consulting, and operations services to clients worldwide. Cognizant is one of the largest IT service providers. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 1994 | \\n| [Cohesive Robotics](https://cohesiverobotics.com/) | Creating smarter industrial automation to modernize manufacturing’s most common fabrication and finishing processes. The company\\'s first product is the Smart Finishing Workcell, a turnkey vision-based solution for sanding, grinding and more. The company\\'s tech stack is  ROS2 native and leverages `ros2_control` and various [ROS-Industrial](https://github.com/ros-industrial) efforts. | 2021 | \\n| [Collimator](http://www.collimator.ai) | Develop cloud-native engineering modeling and simulation software. Their simulation software allow to implement algorithms to service oriented architectures like [ROS](https://www.collimator.ai/industries/automotive). | 2020 | \\n| [Collins Aerospace](https://www.collinsaerospace.com/) | Aviation and Aerospace Component Manufacturing. Hiring engineers with experience in ROS ([Principal Physiological Monitoring Engineer](https://www.linkedin.com/jobs/view/3421337184/)). | 2018 |\\n| [Comau](http://www.comau.com) | Design advanced industrial automation systems, machinery, and robots for manufacturing and automotive industries. The company uses the ROS Manipulation stack (MoveIt) in the e.Do (see [`Comau/eDO_moveit`](https://github.com/Comau/eDO_moveit)). | 1973 | \\n| [Commonplace Robotics](https://cpr-robots.com/) | Develop, manufacture and distribute capable and cost-efficient robots for education, research and industry. Intuitive control software and open source driver complete their offering. Sources for hardware interface nodes and RViz pluing to run CPR robots with the ROS environment (see [`cpr_robot`](https://github.com/CPR-Robots/cpr_robot)). | 2011 | \\n| [Concurrent Real-Time](https://concurrent-rt.com/) | Provider of high-performance, real-time Linux software, hardware and professional services. Using ROS with RedHawk Linux on the NVIDIA Jetson TX2 [^110]. | 1966 |\\n| [Consciente Technologies](https://consciente.io/) | Develop and build robots, chips, and processors for real-world efficiencies. They work in development of model-based controllers for mobility or manipulation tasks, model prototyping, simulation, and functional testing on hardware. Hiring ROS engineers ([ROS Developer](https://www.naukri.com/recruiter-job-listings-ROS-Developer-Consciente-Technologies-Hyderabad-Secunderabad-0-to-3-years-14948870)). | 2021 | \\n| [Constructive Realities](http://constructiverealities.io) | Design and manufacture smart 3D camera systems on trusted edge platforms, delivering hardware accelerated sensor fusion systems oriented to reconstruction and spatial occupancy. PCL (Point Cloud Library) ROS interface stack for Constructive Realities (see [`constructiverealities/perception_pcl`](https://github.com/constructiverealities/perception_pcl)). | 2022 | \\n| [Continental](https://www.continental.com/en/) | Offers safe, efficient, intelligent and affordable solutions for vehicles, machines, traffic and transportation. ROS drivers for Continental (see [`continental`](https://github.com/continental)). | 1871 |\\n| [Corvus Robotics](https://www.corvus-robotics.com/) |  Solutions to oversee the movement of physical goods using autonomous drones for warehouses powered by ROS. Hiring engineers with experience in ROS ([Senior Software Engineer, Planning & Localization](https://wellfound.com/company/corvus-robotics/jobs/1701428-senior-software-engineer-planning-localization)). | 2017 |\\n| [CrossWing](http://www.crosswing.com) | Create a customizable robotics platform. A planning and control system for CrossWing Nav2[^57]robots (see [`catnav2`](https://github.com/timtro/catnav2)). | 2006 | \\n| [Crover](https://www.crover.tech) | Creator of the world\\'s first \\'granular drone\\' (i.e. a \\'CROVER\\'), in the sense of a device able to swim through bulk solids and powders, a.k.a. granular materials. The CROVER Grain Storage Management system is a robotic and automation tool primarily aimed at grain storage operators, such as farmers, grain merchants and cooperatives, helping them save money and maintain the quality of their stock. Hiring engineers with experience in ROS ([Robotics Engineer](https://discourse.ros.org/t/robotics-engineer-position-at-crover-ltd-edinburgh-scotland/13169)). | 2018 | \\n| [Cyberbotics](https://cyberbotics.com) | Develop the Webots[^220] open-source robot simulator, including ROS[^221] and ROS 2[^222] interfaces, robot simulations on the web at webots.cloud[^223] and robotbenchmark.net[^224]. | 1998 |\\n| [Cyberworks Robotics](https://www.cyberworksrobotics.com/) | An autonomous mobile robotics engineering company. Hiring ROS engineers ([ROBOTICS RESEARCH ENGINEERS](https://discourse.ros.org/t/open-positions-at-cyberworks-robotics/6313)). | 2008 | \\n| [Cyngn](https://www.cyngn.com/) | Autonomous Vehicle solutions and enterprise autonomy suite for industrial use cases across logistics, material handling, and mining. Hiring engineers with experience in ROS ([Senior Software Engineer](https://jobs.lever.co/cyngn/e83e6220-b3c2-47b9-80e9-e981518c3a3d)). | 2013 |\\n| [Dairy Robotics](http://dairyrobotics.ie/) | Design and manufacture an animal health monitoring devices and advanced robotic milking solution. Working system integrated with [ROS](http://dairyrobotics.ie/home_new/) complete. | 2021 | \\n| [Danlaw](http://www.danlawinc.com/) | Develop technology for smarter vehicles, safer roads, and more efficient cities.. Hiring engineers with experience in ROS ([Software Engineering Intern](https://www.simplyhired.com/job/noGNeD95GuAhNcPxGvKNI4FFu4IBFD6Z6Hy2XWPvUgZKBPlxUtByTQ)). | 1984 | \\n| [Dataspeed](https://www.dataspeedinc.com/) | Offer engineered hardware and software tools to researchers and developers working on mobility and robotics solutions. Dataspeed\\'s ADAS Kit (Advanced Driver Assistance Systems) provides research and development platform. ROS CAN driver for Dataspeed Drive-by-Wire Kit (see [`dataspeed_can_driver`](https://github.com/VT-ASIM-LAB/dataspeed_can_driver))[^24]. | 2008 | \\n| [DeepEdge](https://deepedge.ai) | The DeepEdge platform is an integrated deep learning development platform that enables developers and enterprises to build, train, optimize and deploy deep learning models and applications to a variety of edge hardware. DeepEdge is investing in the The Robot Operating System ([ROS](https://deepedge.ai/services/FalconServices/)) | 2018 | \\n| [DeepRoute.ai](http://www.deeproute.ai/) | Self-driving technology company committed to popularizing Robotaxis and advancing urban logistics utilizing medium duty trucks . Hiring engineers with experience in ROS ([Software Engineer Planning](https://jobs.workable.com/view/obntcbzgKDQso6HMTgxCHp/software-engineer-planning-in-fremont-at-deeproute.ai)). | 2019 | \\n| [DEKA](http://www.dekaresearch.com/) | Medical Equipment Manufacturing. Building various robots, including robotic chairs. Hiring engineers with experience in ROS ([Control Systems Engineer](https://deka.applytojob.com/apply/gykkA8hM7Z/Control-Systems-Engineer)). | 1982 |\\n| [Delivers.AI](https://delivers.ai/) | Design autonomous mobile robots to take food from the store to the buyers\\' homes. Hiring ROS engineers ([Embedded Software Engineer](https://delivers.ai/jobs.html)). | 2020 | \\n| [Delta Electronics](https://www.deltaww.com/en-US/index) | Manufacture custom power supply solutions for telecommunications, IT, industrial automation, and automotive applications. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^137]. | 1994 | \\n| [Demine Robotics](https://deminerobotics.com/) | Develop unmanned machines to make the demining process faster and safer. An image processing pipeline for ROS for Demine Robotics (see [`DemineRobotics/image_pipeline`](https://github.com/DemineRobotics/image_pipeline)). | 2016 | \\n| [DENSO](https://www.denso.com/us-ca/en/) | Supplier of advanced automotive technology, systems and components for major automakers. ROS drivers (see [`DENSORobot`](https://github.com/DENSORobot)). | 1947 |\\n| [Detect Technologies](http://www.detecttechnologies.com) | Company offer solutions to help energy companies optimize their operations, improve safety, and increase efficiency. Hiring ROS engineers ([Robotics Simulation Developer](https://www.hireshala.com/job/hKQjaqOX/)). | 2016 | \\n| [Dexai Robotic](https://www.dexai.com) | The company specializes in the fields of robotics, machine vision, machine learning, AI, food service, automation, and restaurant equipment. An image processing pipeline for ROS for Dexai Robotics (see [`DexaiRobotics/image_pipeline`](https://github.com/DexaiRobotics/image_pipeline)). | 2018 |\\n| [Dexory](http://dexory.com) | Develop robotics and AI logistics solutions to drive better business decisions. Through their DexoryView platform they automate data collection and build real time fed digital twin technology that unlocks insights across all levels of warehouse operations. | 2015 | \\n| [DF Automation & Robotics](https://www.dfautomation.com/) | Automation company that designs, manufactures, markets, and maintains Autonomous Mobile Robot[^77] (AMR) also known as Automated Guided Vehicles (AGV) for various kinds of industrial and commercial use. ROS drivers (see [`dfautomation`](https://github.com/dfautomation)). | 2012 |\\n| [Diamond Age](http://www.didiglobal.com) | Construction robotics company. Automating new home construction through robotics. Hiring engineers with experience in ROS ([Robotics & Software Engineer](https://www.wayup.com/i-j-Diamond-Age-3D-568376825315740/)). | 2018 |\\n| [Diligent Robotics](http://diligentrobots.com/) | Create collaborative robots that can learn from humans and have social intelligence, mobile manipulation, and human-guided learning capabilities. Moxi, a hospital robot assistant that assists clinical employees with administrative work, is the company\\'s first product. The robot uses machine learning for object recognition and grasping, as well as navigation software based on ROS [^109]. | 2017 |\\n| [DIMAAG-AI](https://dimaag-ai.com/) | Help businesses deploy self-healing AI solutions to transform the way they operate to improve efficiency, quality, and revenue. Hiring ROS engineers ([Autonomous vehicle software engineering lead](https://delivers.ai/jobs.html)). | 2018 | \\n| [DJI](enterprise.dji.com/) | Create and produce drone and camera technology for both professional and leisure use. Their aerial and camera stabilization devices completely alter how cameras are placed and moved. ROS packages for DJI onboard SDK (see [`Onboard-SDK-ROS`](https://github.com/dji-sdk/Onboard-SDK-ROS))[^108]. | 2006 |\\n| [Doosan](https://www.doosan.com/en) | Build power plants and industrial facilities, machine tools and automation systems, engines, bridges and construction equipment.  ROS Drivers for communicating with Doosan robots (see [`doosan-robotics`](https://github.com/doosan-robotics)). | 2012 | \\n| [Dorabot](https://www.dorabot.com/) | Utilize cutting-edge robotics and AI, such as computer vision, motion planning, mobility, and deep learning, to create automated warehouse solutions. ROS drivers (see [`dorabot`](https://github.com/dorabot)). | 2015 |\\n| [Draper](http://www.draper.com) | Defense and Space Manufacturing R&D company. Using ROS in their engineering efforts[^239] | 1932 |\\n| [DreamVu](http://www.dreamvu.com) | Develop omni-stereo camera hardware and software platform for unifying human and machine vision. This unoffical package creates a ros2 node which publishes the panoramic images and a point cloud from the DreamVU PAL camera (see [`ros2_pal_camera_node`](https://github.com/physar/ros2_pal_camera_node)). | 2017 |\\n| [DroneDeploy](https://www.dronedeploy.com/) | Provider of cloud-control software solutions for drones which include automated flight safety checks, workflows, and real-time mapping and data processing. Support ROS robots that use MAVlink [^107]. | 2013 |\\n| [dSPACE](http://www.dspace.com/) | Provider of hardware and software tools for developing and testing sophisticated electronic control systems. Connecting dSPACE real-time systems to the [Robot Operating System (ROS)](https://www.dspace.com/en/inc/home/products/sw/impsw/dspace_interface_blockset_ros.cfm). | 1988 | \\n| [Ducktrain](https://ducktrain.io/) | Provide vehicle platforms and automation technology. Using ROS in their robotics engineering activities[Senior Software Engineer](https://www.linkedin.com/in/nickfiege/?originalSubdomain=de). | 2018 | \\n| [Dyno Robotics](http://www.dynorobotics.se) | Develop custom robotics and AI solutions. Doing everything from natural language processing and outdoor navigation, to hardware construction and electronics. They have many [ROS](https://dynorobotics.se/ros/) projects under their belts, and have even created a popular ROS2 Unity integration. | 2018 | \\n| [E-COBOT](https://www.e-cobot.com) | Specialize in cobotics and artificial intelligence\\u200b solution. They design, manufacture and integrate on specification. | 2016 | \\n| [Easy Robotics](https://easyrobotics.biz/) | Manufacturer and provider of robotic solutions. Their ER200 robot is built out of MiR and UR robots, which are ROS-related. | 2015 |\\n| [EasyMile](http://www.easymile.com) | Provide software powering autonomous vehicles and smart mobility solutions. The [software](https://www.easymile.com/technology/how-it-works) for driverless solutions processes data fed by any platform’s sensor set, analyzes it, and teaches the vehicle how it is supposed to perform. ROS drivers fo EasyMile (see [`EasyMile`](https://github.com/EasyMile)). | 2014 |\\n| [Easymov Robotics](http://www.easymov.fr) | Specialized in conception of software and electronics for robotics. Easymov develop solutions to make R&D industrial engineers, robotics researchers and robot builders work easier and help them accelerate their workflow. Sponsor of the [ROScon](https://roscon.ros.org/fr/2019/)  2019. ROSCon is a developers conference [^168]. | 2015 | \\n| [eBots](http://www.ebots.com) | Electronic or computerized robots designed to perform specific tasks, often in industries such as manufacturing, healthcare, and logistics. Hiring ROS engineers ([Senior Robotics Engineer - Motion Planning](https://jobs.lever.co/eBots/3ba1a2ec-b29f-407e-ba51-1331a6a17886)). | 2017 |\\n| [EikonTech](http://www.eikontech.it) | Provider of engineering services intended to solve challenges in the field of electromagnetics. The company\\'s services use machine vision and deep learning algorithms in the strategifc domains to analyze large amounts of heterogeneous data collected through different sensors and provide insights to decision-makers. A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data for EikonTech (see [`eikontech/image_transport_plugins`](https://github.com/eikontech/image_transport_plugins)). | 2009 | \\n| [Ekumen](https://www.ekumenlabs.com/) | Specializes in providing software, mobile app development, embedded systems, and robotics solutions. ROS drivers (see [`ekumenlabs`](https://github.com/ekumenlabs)).| 2012 |\\n| [Elephant Robotics](https://www.elephantrobotics.com/en/) | Design and production of robotics, development and applications of operating system and intelligent manufacturing services in industry, commerce, education, scientific research, home and etc. myCobot ROS2 package (see [`mycobot_ros2`](https://github.com/elephantrobotics/mycobot_ros2)). | 2016 |\\n| [Elroy Air](http://elroyair.com) | Aerospace company that specializes in autonomous vertical takeoff and landing (VTOL) cargo drones. Hiring ROS engineers ([Software Engineer](https://startup.jobs/software-engineer-robotics-systems-elroy-air-3001732)). | 2016 | \\n| [Embark Trucks](http://embarktrucks.com/) | Develop self-driving truck [technology](https://embarktrucks.com/technology/) designed for freight and logistic services. ROS drivers (see [`embarktrucks`](https://github.com/embarktrucks)). | 2016 |\\n| [embotech](http://www.embotech.com/) | Make software for autonomous driving systems for private grounds and smart factories. Hiring engineers with experience in ROS ([Software developer](https://www.embotech.com/wp-content/uploads/Robotics_Software_Internship_Job_Ad_March2020.pdf)). | 2013 | \\n| [Emlid](https://emlid.com/) | Develop GNSS receivers suitable for land surveying, mapping, and navigation. General scheme of [ROS](https://docs.emlid.com/navio2/ros/) incorporated in Emlid Raspbian. | 2014 | \\n| [Enabled Robotics](https://www.enabled-robotics.com/) | Specializes in mobile manipulator robots that integrate mobile robots with robotic arms. The [ER-FLEX](https://www.enabled-robotics.com/erflex) is a collaborative mobile manipulator that comes with full [ROS](https://www.enabled-robotics.com/research) documentation. | 2016 |\\n| [Energid](https://www.energid.com) | Solve robotics challenges by offering software, products, and service. Robotics software simulates and regulates kinematics and dynamics for many kinds of robotics applications, and its 3D machine vision software allows autonomy. ROS plugins and applications for use with a ROS enabled Energid Actin SDK (see [`ActinROS`](https://github.com/Energid/ActinROS))[^106]. | 2001 |\\n| [Enova Robotics](https://www.enovarobotics.eu/) | Is a company specialized in mobile robot development and robotics R&D projects. The code running [Mini Lab](https://www.enovarobotics.eu/other-products/) was based on the [Robotics Operating System (ROS)](https://emtechmena.com/enova-robotics-tunisian-robots-global-demand/). | 2014 |\\n| [ENWAY](http://www.enway.ai) | Build the software platform to turn manual utility machines into autonomous utility machines. opencv_apps provides various nodes that run internally OpenCV\\'s functionalities and publish the result as ROS topics for ENWAY (see [`enwaytech/opencv_apps`](https://github.com/enwaytech/opencv_apps)). | 2017 | \\n| [eProsima](https://www.eprosima.com/) | Provides insight to develop distributed systems recommending the right DDS middleware products and supporting in all the stages of the development. ROS drivers for eProsima middleware (see [`eProsima`](https://github.com/eProsima))[^105]. | 2005 |\\n| [Ericsson](https://www.ericsson.com/en) | Provide a range of products and services for the telecoms industry, including network equipment, software, and professional services. The company use robots in its research and development division or in its manufacturing processes.. The ROS Middleware (rmw) Interface(see [`ros2-rmw`](https://github.com/Ericsson/ros2-rmw)). | 1876 |\\n| [Erthos](https://www.erthos.com/) | Solar power deployment platform. Behind “ErthBot” autonomous robot which cruises over and cleans the solar panels in our solar fields. Hiring ROS engineers ([Senior Software Engineer](https://discourse.ros.org/t/pre-ipo-solar-energy-company-erthos-seeking-senior-software-engineer-c-python-ros/26224)). | 2019 |\\n| [eSOL](http://www.esol.com) | Is a company in the fields of embedded systems and Industrial IoT that seeks to create a safer and better connected society using its innovative computer technologies. Sponsor of the [ROScon](https://roscon.ros.org/2022/). | 1975 | \\n| [Eternal Robotics](https://eternalrobotics.com/) | Provide robotics engineering, optimization, software, and product development services. Hiring ROS engineers ([Embedded Firmware Engineer](https://eternalrobotics.com/portfolio/firmware-engineer/)). | 2019 | \\n| [Eurogroep](http://www.eurogroep.com) | Industrial corporation devoted to the development, production, and sales of high-tech industrial equipment. Hiring ROS engineers ([ROS Programmeur](https://www.eurogroep.com/jobs/rosprogrammeur)). | 2005 |\\n| [EVAR](https://www.evar.co.kr/) | Develope autonomous EV recharging robot. Algorithm-agnostic computer vision message types for ROS for EVAR (see [`EvarClab/vision_msgs`](https://github.com/EvarClab/vision_msgs)). | 2016 | \\n| [Evitado Technologies](https://evitado.io/) | Develop temporarily installable collision avoidance systems using the industries latest sensor technologies. Hiring ROS engineers ([Software Engineer](https://evitado.io/careers/)). | 2019 | \\n| [Evocargo](http://www.evocargo.com/) | A zero-emissions cargo transportation service in supervised areas. Self-driving vehicles and advanced robotics technologies for efficient logistics. ROS drivers for Evocargo (see [`Evocargo`](https://github.com/Evocargo/ros-bag-migration)). | 2020 | \\n| [Expleo Group](https://expleo.com/global/en/) | A global engineering, technology and consulting service provider that partners with leading organisations to guide them through their business transformation, helping them achieve operational excellence and future-proof their businesses. Hiring ROS talent [^292]. | 1966 |\\n| [Eyeware](https://eyeware.tech) | Is an tech provider of eye tracking solutions for webcams and 3D cameras. Eyeware ROS utilities for 3D eye tracking (see [`eyeware-ros`](https://github.com/eyeware/eyeware-ros)). | 2016 |\\n| [eYs3D Microelectronics, Co.](https://www.eys3d.com/) | Is a silicon-centric and AI-enabling solutions provider specializing in computer vision and 3D sensor fusion processing for applications such as robotics and VR/AR systems. Sponsor of the [ROScon](https://roscon.ros.org/2022/). | 2016 | \\n| [e-con Systems](https://www.e-consystems.com) | Provide end-to-end camera solutions for applications including Autonomous Mobile Robots (AMRs), autonomous shopping, Point of Care (PoC) devices, smart traffic, autonomous agriculture & smart farming, sports broadcasting & analytics, life sciences, and more. ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for e-con Systems (see [`econsystems/vision_opencv`](https://github.com/econsystems/vision_opencv)). | 2003 | \\n| [E-TERRY](https://e-terry.de/) | Develop small-scale agricultural machinery. Hiring ROS engineers ([Software Engineer](https://e-terry.de/vacancies/)). | 2022 | \\n| [F&P Robotics](http://www.fp-robotics.com) | Develop humanoid robots for personal and professional use. [ROS-Package](https://www.fp-robotics.com/en/2016/12/ros-package-for-p-rob/) for P-Rob. | 2014 | \\n| [Fairmat](https://www.fairmat.tech/) | Bring a way to recycle carbon fiber composite. Use robotics to automate recycling processes. Hiring engineers with experience in ROS ([Vision Robotics R&D Engineer](https://www.linkedin.com/jobs/view/ing%C3%A9nieur%C2%B7e-r-d-robotique-vision-h-f-at-fairmat-3496425966/)). | 2020 |\\n| [FarmWise](http://farmwiselabs.com) | Provide technology-based services that allow farmers to streamline farm operations and increase food production efficiency.  Code for working with images in ROS (see [`image_common`](https://github.com/FarmWise/image_common)). | 2016 |\\n| [FastLogic](http://www.fastlogic.pl) | Provide technology and software solutions. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2012 | \\n| [FastSense](http://www.fastsense.tech) | Develop autonomus navigation solutions for in-door drones and wheeled robots and applied AI algorithms for data processing. ROS drivers for FastSense (see [`FastSense`](https://github.com/FastSense)). | 2017 | \\n| [Fieldwork Robotics](https://fieldworkrobotics.com/) | Develop selective, adaptive and modular harvesting robots operating in non-controllable agricultural environments. Hiring engineers with experience in ROS ([Field Deployment Robotics Engineer](https://www.linkedin.com/jobs/view/field-deployment-robotics-engineer-at-fieldwork-robotics-ltd-3527549034/?originalSubdomain=pt)). | 2016 |\\n| [Filics](http://www.filics.eu) | Develop autonomous mobile robots by reducing current solutions to a minimum. Their platform provides a simple, flexible and fast solution to automate all ground-based intra-logistics processes. ROS drivers for Filics (see [`FutureInLogistics`](https://github.com/FutureInLogistics)). | 2016 | \\n| [FireFly Automatix](https://fireflyautomatix.com) | Develop advanced robotics and automation solutions for industrial and commercial applications. They offer a wide range of services, including design and engineering, software development, system integration, and testing and validation. Their products and solutions are used in industries such as manufacturing, logistics, and agriculture. Hiring ROS engineers ([Robotics Software Engineer](https://www.wayup.com/i-j-FireFly-Automatix-405919514093302/)). | 2010 |\\n| [Fixposition](https://www.fixposition.com/) | Offer precise and compact positioning sensors for autonomous guidance systems. ROS2 drivers for Fixposition (see [`fixposition`](https://github.com/fixposition)). | 2017 | \\n| [Fixstars Corporation](https://www.fixstars.com/en) | Provide solutions that harness the high computing performance of multi-core technology. Sponsor of the [ROScon](https://roscon.ros.org/jp/2019/) JP 2019. ROSCon is a developers conference [^166]. | 2002 | \\n| [Fizyr](http://www.fizyr.com) | Design vision software product for automated picking and stacking items, parcels, depalletizing, and trailer unloading. PCL (Point Cloud Library) ROS interface stack for Fizyr (see [`fizyr-forks/perception_pcl`](https://github.com/fizyr-forks/perception_pcl)). | 2014 |\\n| [Flanders Make](http://www.flandersmake.be) | Work with companies and organizations in various industries, including automotive, aerospace, and medical devices, to help them incorporate innovative technologies and processes into their manufacturing operations. They offer proof-of-concept demonstrators, they allow to gauge feasibility, validate the cost-benefit analysis and ensure technology acceptance. For this, they use various unique software and hardware tools in this process like [ROS](https://www.flandersmake.be/en/research/services/human-robot-collaboration). | 2014 | \\n| [Flexiv](https://www.flexiv.com) | Building collaborative robotic arms with AI capabilities. So called adaptive robots. Uses ROS for development, offers ROS 2 drivers for their robot arm[^280] and commits to supporting ROS 2 full integration. | 2016 | \\n| [FloMobility](https://flomobility.com) | Flo Mobility is a vision-based autonomy technology company based out of Bangalore using ROS. It makes autonomy hardware and software with a sensor suite that can be retrofitted with any vehicle and equipment to make them autonomous. [FloEdge One](https://edge.flomobility.com/) is compatible with [ROS 2](https://edge.flomobility.com/faq/). Hiring ROS engineers ([Robotics Intern](https://www.linkedin.com/jobs/view/3439699021/?refId=UL%2BtF7fQSoGc5y9WHl6gLg%3D%3D&trackingId=UL%2BtF7fQSoGc5y9WHl6gLg%3D%3D)). | 2019 |\\n| [Flux Auto](https://fluxauto.xyz/) | Develop a software framework that allows developers to build self-driving cars. Hiring ROS engineers ([Control System Engineer](https://cutshort.io/job/Control-System-Engineer-Bengaluru-Bangalore-Flux-Auto-kC1ZJTCb)). | 2017 | \\n| [FlytBase](http://flytbase.com) | Provide unmanned aerial vehicle (UAV) or drone software solutions. Their offerings include a drone operating system, cloud-based fleet management, and a drone app marketplace. FlytOS is built on [ROS](https://flytbase.com/flytos/) (Robot Operating System) and Linux, making it an ideal platform for robust and scalable drone applications. | 2017 | \\n| [Formant](https://formant.io//) | Provide the analytics platform, which presents application data in a single Web-based user interface. Formant’s [cloud](https://formant.io/product/) software enables organizations to monitor robot fleets in real time [^84]. ROS package contains examples for integrating with the Formant agent in a ROS context (see [`formant-ros`](https://github.com/FormantIO/formant-ros)). | 2017 |\\n| [Forssea Robotics](http://www.forssea-robotics.fr) | Develop autonomous underwater robots (AUVs) for various applications, such as environmental monitoring, ocean exploration, and oil and gas inspection. ROS Drivers for Forssea Robotics (see [`forssea-robotics`](https://github.com/forssea-robotics)). | 2016 | \\n| [Fortem Technologies](http://www.fortemtech.com) | Provide real-time intrusion detection and detect-and-avoid solutions. Hiring ROS engineers ([UAV Systems Integration Engineer](https://portal.zoniac.com/jsp/careers/jobInformationDetails.jsp?publishToEditPage=1&jobId=529402&loginEmployeeId=0&companyId=1802&enableApply=Yes&fromApi=0)). | 2016 | \\n| [Foxglove](https://foxglove.dev/studio) | Open source robotics visualization and debugging tool that combines a list of ROS tools (see [`foxglove`](https://github.com/foxglove)).| 2021 |\\n| [Franka Emika](http://www.franka.de) | Develop advanced robotic systems for industrial and commercial applications. They are known for their lightweight collaborative robots, or cobots, which are designed to work alongside humans in a wide range of industries, including manufacturing, healthcare, and logistics. ROS drivers for Franka Emika (see [`frankaemika`](https://github.com/frankaemika)). | 2016 | \\n| [Gaia Platform](https://www.gaiaplatform.io/) | Create a platform for developing applications for Autonomous Machines. You can integrate multiple system components in a common setting, from machine learning functions to ROS-enabled actuator. And can run it all without the need for constant cloud connectivity. ROS drivers (see [`gaia-platform`](https://github.com/gaia-platform)).| 2017 |\\n| [Gaitech Robotics](https://www.gaitech.com/) | Integrating, distributing, manufacturing and supporting robotics products based on ROS. Promotion and education of ROS in Asia. Working in a Robot Nervous System for robotics research , education and product development within ROS Framework. ROS packages (see [`gaitech-robotics`](https://github.com/gaitech-robotics))[^103].| 2004 |\\n| [Gatik](http://www.gatik.ai) | Develop technology for autonomous light & medium duty trucks for B2B short-haul logistics. It specializes in the fields of artificial intelligence, automotive, and logistics. ROS communications-related packages (see [`ros_comm`](https://github.com/StarskyRobotics/ros_comm)). | 2017 |\\n| [GE](http://www.ge.com) | Industrial machinery manufacturing company. Hiring engineers with experience in ROS ([Lead Engineer - Autonomous Systems - Aerospace Research](https://www.linkedin.com/jobs/view/3533778141/?alternateChannel=search&refId=EYJR%2BPifQQW5TzWDJuKqPg%3D%3D&trackingId=8qZGnrcjBVosew643yGhJw%3D%3D&trk=d_flagship3_search_srp_jobs)). | 1892 |\\n| [Gecko Robotics](https://www.geckorobotics.com/) | Creates *Gecko* climbing robot which collects and makes useful physical data to protect critical infrastructure. Hiring engineers with experience in ROS ([Robotics Localization Engineer](https://www.ycombinator.com/companies/gecko-robotics/jobs/w3XAzwe-robotics-localization-engineer)). | 2013 |\\n| [Genrobotics](https://www.genrobotics.org) | Specialized in the design and development of robotic solutions. Combines the use of robotics and artificial intelligence. Hiring ROS engineers ([Robotic Software Engineer(ROS)](https://ksycjobs.kerala.gov.in/users/job_details/NDA1ODNfMg==)). | 2017 | \\n| [Gestalt Robotics](http://www.gestalt-robotics.com) | Software and solution provider working at the interface of industrial automation and artificial intelligence. Their cloud navigation is based on microservice architectures. They support modern microservice architectures and network them using standardized interfaces, efficient data management, and real-time optimization. They support, among other things, OPC UA, [ROS](https://www.gestalt-robotics.com/en/home), [ROS2](https://www.gestalt-robotics.com/en/home), Time Sensitive Networking, and Fieldbus systems. | 2016 |\\n| [Gideon](https://www.gideon.ai/) | Autonomous mobile robots that automate manual material-handling jobs in manufacturing, logistics, warehousing, and retail. Using ROS for general engineering and navigation aspects[^242]. Company worker works as a [ROS developer](https://www.linkedin.com/in/pevec-luka/).  | 2017 |\\n| [GIM Robotics](http://gimrobotics.fi/) | Deliver software that makes mobile working machines in all industries more intelligent, precise and efficient. Compatible with several supported interfaces such as: [ROS](https://gimrobotics.fi/offering/localisation/), ROS2, VDA5050 and Fleet Management Systems. | 2014 | \\n| [GITAI](http://gitai.tech/) | Develop humanoid robots for use in space. The goal is to create robots that can perform tasks that are too dangerous, difficult, or time-consuming for human astronauts to perform in space. Hiring ROS engineers ([Robotics Software Engineer](https://gitai.tech/jobs/robotics-software-engineer/)). | 2016 | \\n| [Glarus Technology](http://glarustech.com/) | Specialize in web, mobile, embedded, IoT, robotics, drone and automotive solutions. Hiring ROS engineers ([SENIOR ROBOTICS ENGINEER](http://glarustech.com/careers.html)). | 2018 | \\n| [Glidewell Laboratories](https://glidewelldental.com/) |  Manufacture dental implants and tooth replacement systems. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^138]. | 1970 | \\n| [Globotix](https://globotix.sg/) | Facilities management robotics solution focused on delivering customised solutions tailored to the needs of clients. Its unique modular system allows for multiple functionality to be integrated into the same base system whilst providing flexibility for the client to choose the best suite of tools suited to their requirements. Hiring engineers with experience in ROS ([ROBOTICS SOFTWARE ENGINEER](https://www.mycareersfuture.gov.sg/job/engineering/robotics-software-engineer-globotix-9ae3b549f2f3000c9cdcee3a0af25fe2)). | 2016 |\\n| [Gofore](http://www.gofore.com) | Provide software development, design, and consulting services to clients. It focuses on cloud, data analytics, and user experience design services. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2001 | \\n| [Greenroom Robotics](https://www.greenroomrobotics.com/) | Australian robotics company developing advanced maritime autonomy for vessels and AUVs as well as ROS-based perception pipelines for detecting, classifying, tracking and geolocating objects from land, sea or sky. ROS drivers for Greenroom Robotics (see [`Greenroom-Robotics`](https://github.com/Greenroom-Robotics)). | 2017 |\\n| [GrayMatter Robotics](https://www.graymatter-robotics.com/) | Develop robotic brains for industrial robots designed to allow them to transform into smart assistants for high-mix low-volume manufacturing applications. Hiring engineers with experience in ROS ([Field Application Engineer](https://boards.greenhouse.io/graymatterrobotics/jobs/4186323005)). | 2020 | \\n| [Greenzie](https://www.greenzie.com/) | Develops software for autonomous robotic lawn mowers. Its retrofit hardware kit and cloud-based software for commercial lawn mowers add self-driving to the existing equipment. ROS drivers for Greenzie software (see [`Greenzie`](https://github.com/Greenzie))[^102]. | 2018 |\\n| [GreyOrange](https://www.greyorange.com/) | Produces software and mobile robotics to modernize order fulfillment and optimize warehouse operations in real time. Their software runs on ROS[^199], and their robots are in their fourth or fifth generation. | 2012 |\\n| [Griffin](http://griffin.ethz.ch) | Develop a robot capable of gripping and manipulating objects in flight. ROS packages for the STOMP planner (see [`Griffin-Focus-Project/stomp_ros`](https://github.com/Griffin-Focus-Project/stomp_ros)). | 2020 | \\n| [GROOVE X](http://www.groove-x.com/) | Develop household robot that inspires real affection. Sponsor of the [ROScon](https://roscon.ros.org/jp/2018/) JP 2018. ROSCon is a developers conference [^170]. | 2015 | \\n| [GurumNetworks](https://gurum.cc/sol_robotics_eng) | Specializes in network solutions for data distribution service protocol software. [GurumDDS](https://gurum.cc/gurumdds_eng) is a DDS that supports the [robot operating system (ROS2)](https://gurum.cc/sol_robotics_eng) and provides a GurumDDS Routing Service (RS) optimized for remote communication with the robot. | 2014 |\\n| [Halodi Robotics](https://www.halodi.com/) | Produce humanoid robots. Cracking the code and engineered a safe solution (named [EVE](https://www.halodi.com/ever3)). ROS drivers for Halodi Robotics (see [`Halodi`](https://github.com/Halodi)). | 2015 |\\n| [Han\\'s Robot](https://www.hansrobot.net/index) | Manufacturing automation machinery based on ROS. ROS package for Han\\'s Robot (see [`hans-robot`](https://github.com/hans-robot))[^100].| 2017 |\\n| [Harting](http://www.harting.com) | Electronic manufacturing company that specializes in the fields of electrical, electronic and optical connection, transmission and networking, as well as in manufacturing, mechatronics and software creation. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^139]. | 1945 |\\n| [Hatchbed](https://hatchbed.com/) | Provide customized solutions and research and development for the dynamic global industries of self driving and autonomous vehicles, robotics, data analysis, AI and software systems. An image processing pipeline for ROS for Hatchbed (see [`hatchbed/image_pipeline`](https://github.com/hatchbed/image_pipeline)). | 2019 | \\n| [HAVELSAN](http://www.havelsan.com.tr) | Provide defense electronics, information technology, and simulation systems. It is mainly focused on the development of military software and systems, including simulation and training systems, air defense systems, command and control systems, and various software products. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 1082 | \\n| [HEBI Robotics](http://www.hebirobotics.com) | Build intelligent and connected modular building blocks for creating robotic solutions. Offer ROS APIs[^186] as well ad documentation and examples[^187]. | 2014 | \\n| [Helgen Technologies](https://www.helgen.tech) | Develop advanced navigation and guidance systems for a variety of industries. They use the Nav2 Stack to create autonomous navigation solutions for unmanned aerial vehicles (UAVs), autonomous underwater vehicles (AUVs), and ground vehicles (see [`Helgen-Tech/navigation2`](https://github.com/Helgen-Tech/navigation2)). | 2021 | \\n| [HelloWorld Robotics](https://www.helloworldrobotics.xyz/) | Design and build an autonomous delivery network and infrastructure to provide a smarter, cheaper and safer last mile delivery solution. ROS drivers for HelloWorld Robotics (see [`HelloWorldRobotics`](https://github.com/HelloWorldRobotics)). | 2019 | \\n| [Hello Robot](https://hello-robot.com/) | Design robots that help people in their homes and workplaces, it features open-source software with both Python and ROS interfaces, extensible and customizable hardware. ROS2-related code for the Stretch RE1 mobile manipulator from Hello Robot Inc (see [`stretch_ros2`](https://github.com/hello-robot/stretch_ros2))[^99]. | 2017 |\\n| [HERACLES Robotics](https://www.heracles-robotics.com/en) | Develop a navigation and autonomous system adapted to existing equipment to carry out earthmoving operations without a machine operator. Hiring ROS engineers ([engineers](https://www.linkedin.com/jobs/view/contr%C3%B4le-robotique-autonome-avec-apprentissage-par-renforcement-profond-at-heracles-robotics-3377947628/?originalSubdomain=fr)). | 2019 | \\n| [HERE Technologies](http://here.com) | Provide mapping and location-based services to businesses and individuals through its cloud-based platform. HERE Technologies\\' services include maps and location data, real-time traffic information, indoor and outdoor positioning, and location-based advertising. Company worker works as a [ROS developer](https://www.linkedin.com/in/kevin-qi-l-9abbb55/?trk=public_profile_browsemap).  | 1985 | \\n| [Hesai Technology](http://www.hesaitech.com/en) | Design [laser sensors](https://www.hesaitech.com/en/AT128) for robots and self-driving cars. ROS drivers for Hesai Technology sensors (see [`HesaiTechnology`](https://github.com/HesaiTechnology)). | 2014 |\\n| [Hexagon\\'s Autonomy & Positioning division](https://hexagon.com) | Global leader in software and hardware solutions. Their Positioning Intelligence division (Hexagon PI) acquired AutonomousStuff[^264] and leverages ROS in their automotive solutions. Hiring engineers with experience in ROS ([Autonomy Field Applications Engineer](https://www.linkedin.com/jobs/view/3328074287/?alternateChannel=search&refId=4xMUNZ1e0oVTxklhNaDLJA%3D%3D&trackingId=Plqkxp66PdCsTlQlKIcrKw%3D%3D&trk=d_flagship3_search_srp_jobs)). | 1992 |\\n| [Hippo Harvest](https://www.hippoharvest.com/) | A controlled environment agriculture (CEA) company that leverages plant science, machine learning and robotics to sustainably grow vegetables in greenhouse environments. Seeking for ROS roboticists to design, implement, deploy, and maintain software/systems for all things related to robotics/automation at their 150,000 square foot greenhouse in Pescadero, CA [^268] | 2019 |\\n| [Hiwonder](https://www.hiwonder.hk/) | Produce educational robotics kits for children and hobbyists. Hiwonder JetHexa [ROS](https://hiwonder.hk/products/hiwonder-jethexa-ros-hexapod-robot-kit-powered-by-jetson-nano-with-lidar-depth-camera-support-slam-mapping-and-navigation?variant=39876752638039) Hexapod Robot Kit, powered by NVIDIA Jetson Nano and based on ROS. | 2015 | \\n| [Hokuyo Automatic](http://www.hokuyo-aut.jp) | Is a developer of optical data transmission devices, photo sensors, auto counters, and automatic doors. A ROS node to provide access to SCIP 2.0-compliant Hokuyo laser range finders  (see [`hokuyo_node`](https://github.com/ros-drivers/hokuyo_node)). A driver for [Hokuyo 2D range sensors (LiDAR)](https://www.hokuyo-aut.jp/topics/detail.php?id=66) that works with [ROS2](https://github.com/UrgNetwork/urg_node2). | 1946 |\\n| [Honda Research Institute](https://usa.honda-ri.com/) | Research in Artificial Intelligence and intelligent systems. Sponsor of the [ROScon](https://roscon.ros.org/jp/2018/) JP 2018. ROSCon is a developers conference [^170]. | 2003 | \\n| [Honeybee Robotics](https://www.honeybeerobotics.com/) | Develop robotics systems for the space industry, includingactuators, drills, and sample collection systems for several Mars missions. ROS packages for interfacing with a NASA cFS system (see [`roscfs`](https://github.com/honeybee-robotics/roscfs))[^98]. | 1983 |\\n| [Honeywell](https://www.honeywell.com/) | Offer energy, safety, and security solutions and technologies. The company does have a presence in the robotics industry through its products and solutions for various applications. Drivers for Honeywell IMU (see [`hg_node`](http://wiki.ros.org/hg_node)). | 1906 | \\n| [HOPE Technik](https://www.hopetechnik.com/) | Deliver high performance engineering solutions. From creating a laparoscopic robot the size of a fingernail, to having autonomous robots run in global manufacturing plants. Hiring ROS engineers ([Software Engineer (Robotics)](https://nodeflair.com/jobs/hope-technik-software-engineer-robotics-49145)). | 2006 |\\n| [Humatics](http://www.humatics.com) | Create precise location and navigation data in places where these capabilities do not exist today to support multiple use cases in  manufacturing, transportation, robotics, surgical, and more.. ROS drivers for the Piksi RTK GPS module (see [`ethz_piksi_ros`](https://github.com/Humatics/ethz_piksi_ros)). | 2015 |\\n| [Husarion](https://husarion.com/#custom-robot) | A tech company which manufactures autonomous mobile robot platforms based on ROS & ROS 2 (see [`husarion`](https://github.com/husarion))[^97]. | 2013 |\\n| [Husarnet](https://husarnet.com/robotics.html) | Peer-to-peer VPN network dedicated for robots, autonomous vehicles and industry 4.0 applications. It provides secure data link between connected devices such as: robots, servers, laptops, cell phones, microcontrollers and more. ROS 2 and DDS Implementation [^96] | 2020 |\\n| [Hydromea](https://hydromea.com/) | Build a ecosystem of autonomous collaborating underwater drones to disrupt the submerged asset inspections in the offshore and onshore industries. Hiring engineers with experience in ROS ([Robotics Software Engineer](https://www.hydromea.com/jobs/robotics-software-engineer)). | 2014 | \\n| [Hyperspec AI](https://hyperspec.ai/) | Develop advanced driver assistance systems vision technology designed with real-time maps for scalable autonomy. Hiring engineers with experience in ROS ([ROS Developer Intern](https://www.linkedin.com/jobs/view/3724454141)). | 2019 | \\n| [Hyundai](https://www.hyundai.com/eu.html) | Automotive manufacturer with various vehicle lineups, brand vision, and global campaigns. ROS packages for Hyundai (see [`HYUNDAI-Robotics-Autonomous-Engineering`](https://github.com/HYUNDAI-Robotics-Autonomous-Engineering)). | 2000 |\\n| [IAV](https://www.iav.com/en/) | Develop computer app systems for the automotive industry. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^140]. | 1983 |\\n| [IBRobotics (Intelligent Behavior Robots)](http://www.ibrobotics.com) | With a focus on utilizing technologies such as [ROS/ROS2](http://www.ibrobotics.com/), C++, and Python, IBRobotics offers comprehensive solutions for clients looking to develop cutting-edge robotics systems. | 2020 |\\n| [iFollow](https://www.ifollow.fr/) | Develop collaborative autonomous robots for the logistics industry and the retail industry. ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for iFollow (see [`ifollow-robotics/depthimage_to_laserscan`](https://github.com/ifollow-robotics/depthimage_to_laserscan)). | 2017 | \\n| [Ignitarium](http://www.ignitarium.com) | Silicon and embedded systems solution provider offering cutting-edge engineering solutions in IC design, system design, embedded software, multimedia, AI, mobility software and application development. The company has [integration services](https://ignitarium.com/software/robotics/) experience in ROS, ROS 2 and Autoware. Rapid robot prototyping with ROS, [Webinar recording](https://ignitarium.com/rapid-robot-prototyping-with-ros-webinar-recording/). | 2012 |\\n| [IKNOWHOW SA](http://www.Iknowhow.com) | Provide software and services for the finance and insurance industries. Company worker works as a [ROS developer](https://www.linkedin.com/in/michalis-d-logothetis/?originalSubdomain=gr). Hiring engineers with experience in ROS ([Robotics Engineer](https://startup.jobs/robotics-engineer-ikh-2366220)). | 2004 | \\n| [Imandra](https://www.imandra.ai/) | Specializes in cloud-scale automated reasoning. Its platform is designed to deliver governance to algorithms[^116]. Imandra ROS (see [`imandra-ros`](https://github.com/imandra-ai/imandra-ros)). | 2014 |\\n| [inaho](https://en.inaho.co/) | Develop products and solutions that allow labour-saving and efficiency improvement in agriculture. Algorithm-agnostic computer vision message types for ROS for inaho (see [`teaminaho/vision_msgs`](https://github.com/teaminaho/vision_msgs)). | 2021 | \\n| [incubed IT](http://www.incubedIT.com) | Offer software solutions to operate autonomous, self-navigating[^82], and co-operative mobile shuttles. ROS2 Navigation Framework and System (see [`navigation2`](https://github.com/incubedIT/navigation2)). | 2011 |\\n| [Indoor Robotics](https://www.indoor-robotics.com/) | State-of-the-art automated security robot that combines the accuracy of sensors, visibility of cameras, the flexibility of drones, and mobility of humans. Hiring engineers with experience in ROS ([Senior Fullstack Engineer](https://www.indoor-robotics.com/careers/co/indoor-robotics/7E.634/senior-fullstack-engineer/all/)). | 2018 |\\n| [InDro Robotics](https://indrorobotics.ca/) | Market leader for ROS-guided autonomous remotely piloted aircraft systems and mobile robotics solutions. Their software documentation used includes information on Python3, the [Robotic Operating System](https://indro-robotics-documentation.readthedocs.io/en/main/) and Gazebo simulation tool. They included guides and tutorials on how to use these software. | 2014 |\\n| [Inertial Labs](http://www.inertiallabs.com) | Is supplies Inertial Navigation Systems, Orientation Systems, Motion Capture and Military Training Systems. ROS GNSS/INS driver for Inertial Labs positioning systems for the CARMA Platform (see [`inertiallabs_gnss_driver`](https://github.com/VT-ASIM-LAB/inertiallabs_gnss_driver))[^177]. | 2001 |\\n| [Inertial Sense](https://inertialsense.com) | Provide autonomy-as-a-service for robotics vehicles in outdoor applications. ROS node for InertialSense products (see [`inertial-sense-ros`](https://github.com/inertialsense/inertial-sense-ros))[^]. | 2013 |\\n| [Infineon](https://www.infineon.com/cms/en/) | Offer semiconductor solutions, microcontrollers, LED drivers, sensors and automotive and power management. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^141]. | 1999 |\\n| [Innok Robotics](https://www.innok-robotics.de/en/) | Make robots that assist humans in their work. Their robots facilitate the work of their customers and take dangerous work. The Innok Robotics AMR platform offers robots[^31] for indoor and outdoor jobs. ROS driver for the Innok Heros robot plattform (see [`innok_heros_driver`](https://github.com/innokrobotics/innok_heros_driver)). | 2012 | \\n| [Innoviz Technologies](http://www.innoviz.tech) | Manufacture [LiDAR](https://innoviz.tech/applications) sensors and [perception software](https://innoviz.tech/perception-software) that enables the mass-production of autonomous vehicles. InnovizPRO control interface support ROS[^130] drivers. | 2016 |\\n| [İnovasyon Mühendislik](https://www.inovasyonmuhendislik.com/en) | Company conducts R&D projects on indoor and outdoor positioning systems, intelligent vehicles, robotics and machine learning. The evarobot is a mobile robot platform. The evarobot software system is written entirely in ROS (see [`evarobot`](https://github.com/inomuh/evarobot)). | 2010 |\\n| [Intel](https://www.intel.com/content/www/us/en/homepage.html) | Silicon vendor. Create a robotics development environment for autonomous devices, which includes the ROS2 core as well as capability packages such as perception, planning, and control driver. Intel ROS Project to enable the object detection, 2D location, 3D location and tracking with GPU and Intel RealSense camera under ROS framework (see [`intel`](https://github.com/intel))[^95].| 1968 |\\n| [Intermodalics](http://www.intermodalics.eu) | Employs experts in the development of mathematical software and robotics. The business offers support for software for robot communication and control, artificial intelligence, and 2D and 3D machine vision. ROS drivers for Intermodalics (see [`Intermodalics`](https://github.com/Intermodalics)). | 2010 |\\n| [Intrinsic](https://intrinsic.ai/) | Robotics software and AI company at Alphabet (Google). Make industrial robotics accessible and usable for millions more businesses, entrepreneurs, and developers through AI and [ROS](https://www.therobotreport.com/intrinsic-acquires-ros-maker-open-source-robotics-corp/). | 2021 |\\n| [IR4 PTY LTD](http://www.ir4.com.au) | Provide technology solutions and consulting services to a variety of industries, including healthcare, financial services, and government. Hiring ROS engineers ([Robotics / Mechatronics Engineer](https://au.joblum.com/job/robotics-mechatronics-engineer/2486936)). | 2016 | \\n| [Iron Ox](https://ironox.com/) | Use robots and artificial intelligence to control plantations. With ROS interface they control LEDS, vision cameras and Cartographer, is a system that provides real-time simultaneous localization and mapping (SLAM) in 2D and 3D across multiple platforms and sensor configurations. ROS drivers for Iron Ox (see [`iron-ox`](https://github.com/iron-ox))[^93].| 2015 |\\n| [ISID](https://www.isid.co.jp/) | Is an IT service management company that provides private computer time-sharing service. Sponsor of the [ROScon](https://roscon.ros.org/jp/2019/) JP 2019. ROSCon is a developers conference [^166]. | 1975 | \\n| [Islington Robotica](https://www.islingtonrobotica.com/) | Build semi-autonomous machinery to serve the people and their industries  Mission is to build beautiful and intuitive semi autonomous machinery to serve the people and their needs. We want to create harmony between humans and humanoid technology to create a world that works. Hiring ROS engineers ([ROS Developer](https://www.owcareers.com/ros-developer-jobs-in-islington-robotica-united-states/3031151)). | 2019 | \\n| [IVEX](http://www.ivex.ai) | Develop safety co-pilot for autonomous cars. The company offers a cloud-based [platform](https://www.ivex.ai/products/safety-analytics-platform) for developers to get information about their system. ROS drivers (see [`IVEX-AI`](https://github.com/IVEX-AI)). | 2018 |\\n| [iXblue](http://www.ixblue.com) | Offer advanced navigation, photonics and maritime autonomy solutions. ROS driver for iXblue inertial sensors supporting StdBin protocol (see [`ixblue_ins_stdbin_driver`](https://github.com/ixblue/ixblue_ins_stdbin_driver)). | 1998 |\\n| [i3D robotics](http://www.i3drobotics.com/) | Develop 3D stereo vision technology to be used in machine vision applications. ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for i3D robotics (see [`i3drobotics/vision_opencv`](https://github.com/i3drobotics/vision_opencv)). | 2013 | \\n| [i-KINGTEC](https://ikingtec.com/) | Develop intelligent industrial drone and UAV systems. Hiring ROS engineers ([ROS R&D Engineer](https://ikingtec.com/en/recruit/)). | 2017 | \\n| [Jetbrain Robotics](https://jetbrain.ai) | Develop advanced robotic transportation solutions for multi speciality hospitals. Hiring ROS engineers ([Robot Software Developer](https://angel.co/company/jetbrain-robotics/jobs/1531460-robot-software-developer)). | 2018 | \\n| [John Deere](https://www.deere.com/en/index.html) | Manufacture agricultural, construction, and forestry machinery, diesel engines, drivetrains used in heavy equipment, and lawn care equipment. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^142]. | 1837 |\\n| [Johnson & Johnson](https://www.jnj.com/) | Develop medical devices, pharmaceuticals and consumer packaged goods. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^143]. | 1886 |\\n| [Jungheinrich PROFISHOP AG & Co. KG](http://www.jh-profishop.de/) | Provide material handling and warehouse technology solutions. The company offers a wide range of products, including forklifts, pallet trucks, stackers, and reach trucks, as well as automated storage and retrieval systems. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2006 | \\n| [Kamdhenu Robotics](https://kamdhenurobotics.com/) | Provide customized solutions for the development of ROS based robots. They offer robots, accessories related to robots that supports [ROS](https://kamdhenurobotics.com/shop/). | 2019 |\\n| [Kapernikov](http://www.kapernikov.com) | They apply data analytics and computer vision techniques to turn data streams into valuable information which in turn helps people or robots make the right decisions. A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data for Kapernikov (see [`Kapernikov/image_transport_plugins`](https://github.com/Kapernikov/image_transport_plugins)). | 2011 | \\n| [Karelics](https://karelics.fi) | Offer a construction site robot that is completely autonomous for site monitoring and many other applications. Hiring engineers with experience in ROS ([Robotics software developer](https://jakomo.fi/jobs/robotics-software-developer-karelics-oy-joensuu/)). Migrating Karelics Brain to [ROS 2](https://karelics.fi/the-challenges-of-migrating-karelics-brain-to-ros-2/). | 2019 | \\n| [KAWADA ROBOTICS CORPORATION](http://www.kawadarobot.co.jp/) | Develop humanoid robots that work with people. The highly workable [NEXTAGE](https://nextage.kawadarobot.co.jp/) hardware is now compatible with [ROS](https://www.kawadarobot.co.jp/en/products/). ROS-OpenRTM-based robot controller software for dual-armed robot Nextage (see [`rtmros_nextage`](https://github.com/tork-a/rtmros_nextage)). | 2013 |\\n| [Kawasaki](https://global.kawasaki.com) | The company produces a wide range of products, including motorcycles, trains, ships, aerospace equipment, and heavy machinery such as construction and mining equipment. In addition to these products, Kawasaki Heavy Industries is also involved in the production of power plants, robotics, and precision machinery. The company uses the ROS Manipulation stack (MoveIt) in the Duaro (see [`Kawasaki-Robotics/khi_robot`](https://github.com/Kawasaki-Robotics/khi_robot)). | 1896 | \\n| [KEBA Group](https://www.keba.com) | Work on new developments and industry solutions for industrial qutomation, banking and service automation and energy automation. Hiring engineers with experience in ROS ([Application Engineer](https://www.karriere.at/jobs/6696306)). Company worker works as a [ROS developer](https://www.linkedin.com/in/milica-todorovi%C4%87-376852233/?originalSubdomain=rs). [ROS](https://static1.squarespace.com/static/51df34b1e4b08840dcfd2841/t/5a3bb9ae0d9297c9cfb1d83d/1513863632419/19_Steffan.pdf)-I native robot controllers. | 1968 |\\n| [KEMARO AG](https://kemaro.ch/) | Produces autonomous mobile robots for industrial cleaning. Using ROS in their robotics engineering activities[Software Engineer](https://www.linkedin.com/in/linghao-zhang/?originalSubdomain=ch). | 2016 | \\n| [Keybotic](https://keybotic.com/) | Develop autonomous four-legged robots for monitoring, inspecting, and mapping of complex environments. Hiring ROS engineers ([Robot Navigation Engineer](https://discourse.ros.org/t/robot-navigation-engineer-keybotic-barcelona/28601)). | 2020 |\\n| [Kingdom Technologies](https://www.kingdom.garden/) | Develop robotic lawn mowers for large terrains. Hiring ROS engineers ([Robotics Software Engineer](https://discourse.ros.org/t/kingdom-technologies-are-hiring-a-robotics-software-engineer-in-glasgows-west-end/24526)). | 2018 | \\n| [Kinova Robotics](https://assistive.kinovarobotics.com/) | Design and manufacture robotics platforms and components that empowers people with disabilities to push beyond their current limitations. ROS packages for Jaco2[^33] and Mico robotic arms (see [`kinova-ros`](https://github.com/Kinovarobotics/kinova-ros)). | 2006 | \\n| [KiQ Robotics](https://kiq-robotics.co.jp/) | Develop autonomous robotic systems for the retail and e-commerce industries. Their technology is designed to automate various in-store operations, such as inventory management, order fulfillment, and customer service. ROS drivers for KiQ Robotics (see [`KiQ-Robotics`](https://github.com/KiQ-Robotics)). | 2019 | \\n| [Kittyhawk](http://kittyhawk.aero) | Construct a remotely piloted, electric single-person aircraft. With the intention of creating air taxis. ROS driver for Swift Navigation SBP devices (see [`swiftnav_ros`](https://github.com/KittyHawkCorp/swiftnav_ros)). | 2010 |\\n| [Kiwibot](https://www.kiwibot.com/) | Offer food delivery with robots for [campus colleges](https://www.kiwibot.com/college-campuses). ROS Drivers for communicating with Kiwibot robots (see [`kiwicampus`](https://github.com/kiwicampus)). | 2017 |\\n| [Klas](http://www.klasgroup.com/) | Offer communication hardware and software solutions for the government, public, and transport sectors. With [RAVEN](https://www.klasgroup.com/klas-unveils-raven-av-research-development-solutions/), developers can instantiate multiple ADE with [ROS2](https://www.klasgroup.com/wp-content/uploads/2022/06/Autoware_Auto_RAVEN_Deployment_eBook.pdf)/DDS that are seamlessly interconnected with the vehicle\\'s IP network of sensors and cameras, radars and ECUs on the CAN bus. | 1991 | \\n| [Klepsydra Technologies](http://www.klepsydra.org) | A professional software engineering and cloud computing tool for computationally intensive intelligent devices and embedded systems applications. It has a two-fold purpose: accelerate the development of complex embedded software, and optimise, or increase, the computational performance of the on-board software for complex tasks like sensor fusion or image processing. [Klepsydra’s benchmark](https://klepsydra.com/ros-benchmark/). On this occasion, ROS multithreading mechanisms and Klepsydra ROS plug-in were compared in an Odroid XU4 computer. | 2017 | \\n| [KPIT](https://www.kpit.com/) | Global partner to the automotive and mobility ecosystem for making software-defined vehicles a reality. Hiring ROS talent[^290] | 1990 |\\n| [KRONE Agriculture](https://www.krone-agriculture.com/) | Develop agricultural machinery. Their product range includes disc mowers, rotary tedders, rotary rakes, forage wagons and trailers. Agriculture companie KRONE rely on software from [Apex.AI for autonomous farming machines](https://www.apex.ai/krone-lemken?utm_campaign=Company&utm_content=262349469&utm_medium=social&utm_source=linkedin&hss_channel=lcp-18905061). | 1906 | \\n| [Kudan](https://www.kudan.io/) | Provides artificial perception technologies based on SLAM, to use in autonomous driving, robotics, AR/VR and smart cities. Turtlebot running ROS with 2D LiDAR, and added Kudan SLAM as a ROS navigation module [^92]. | 2010 |\\n| [KUKA](http://www.kuka.com) | Is a manufacturer of robotic systems, offering a wide range of industrial robots and robot systems. Hiring ROS engineers ([Robot Operating System Intern](https://www.linkedin.com/jobs/view/3253050338)). | 1898 |\\n| [Kyocera](https://global.kyocera.com/robotics/) | Supply industrial and automotive components, semiconductor packages, electronic devices, smart energy systems, printers, copiers and mobile phones. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^144]. | 1959 |\\n| [Labrador Systems](https://labradorsystems.com) | Robotics company building a new generation of assistive robots to improve the quality of people. Hiring ROS engineers ([Senior SLAM Engineer](https://discourse.ros.org/t/senior-slam-engineer-labrador-systems/27502)). | 2017 |\\n| [Lanner](https://www.lannerinc.com) | Hardware provider with design, engineering, and manufacturing services for advanced network appliances, ruggedized in-vehicle, industrial computers, power substation computers and edge AI appliances. Offers ROS 2 support through third party solutions in their embedded devices[^214]. Also leverages ROS 2 hardware acceleration solutions. | 1978 |\\n| [LeddarTech](http://www.leddartech.com) | Automotive solutions company that solves critical fusion and perception challenges for all levels of autonomy. ROS package exposing LeddarTech sensors based on the \"leddar\" Python module (see [`leddar_ros`](https://sdk.leddartech.com/v4.3/#/ROS?id=leddar_ros)). | 2007 | \\n| [LEJU ROBOTICS](http://www.lejurobot.com) | Intelligent humanoid robot company, which focus on researching and developing, marketing and manufacturing of robot. An image processing pipeline for ROS for LEJU ROBOTICS (see [`LejuRobotics/ros_image_pipeline`](https://github.com/LejuRobotics/ros_image_pipeline)). | 2016 |\\n| [Lely](https://www.lely.com/) | Create products for the agricultural sector. From milking robots, care products and automated feeding systems to barn cleaners. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^145]. | 1948 |\\n| [LEMKEN](https://lemken.com/) | One of the leading agricultural machinery manufacturers worldwide. Agriculture companie LEMKEN rely on software from [Apex.AI for autonomous farming machines](https://www.apex.ai/krone-lemken?utm_campaign=Company&utm_content=262349469&utm_medium=social&utm_source=linkedin&hss_channel=lcp-18905061). | 1780 | \\n| [Lemvos](http://www.lemvos.com) | Offer data-collection solutions to the waterborne sector. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2022 | \\n| [Leo Drive](http://www.leodrive.ai) | Leo Drive is an experienced full-stack autonomous vehicle company that develops scalable and reliable autonomous hardware and software products. Leo Drive adopted ROS2-based Autoware project as the software framework for technology development. ROS drivers for Leo Drive (see [`leo-drive`](https://github.com/leo-drive)). Hiring engineers with experience in ROS ([Sales Engineer](https://www.linkedin.com/jobs/view/3555151234/?refId=ikeNMrJz5mkKIhXlvjVRmg%3D%3D)). | 2015 |\\n| [Leo Rover](http://www.leorover.tech) | Is an open-source project that provides developers the tools they need to accelerate the process of building. [Leo Rover](https://www.leorover.tech/the-rover) is an outdoor Robotics Development Kit. ROS packages for Leo Rover (see [`leo_common`](https://github.com/LeoRover/leo_common)). | 2016 |\\n| [LexxPluss](https://lexxpluss.com/) | Design robots for logistics warehouses. Provide a robot that utilize autonomous driving mode and a guided driving. ROS driver for LexxPluss (see [`LexxPluss`](https://github.com/LexxPluss)). | 2020 |\\n| [LG (SVL Simulator)](https://www.svlsimulator.com/) | Simulation platform used for autonomous vehicle and robotic system development. ROS/ROS2 Multi-robot Simulator for Autonomous Vehicles  (see [`simulator`](https://github.com/lgsvl/simulator))[^91]. | 2018 |\\n| [LionsBot](http://www.lionsbot.com) | Create cleaning robots as a service for commercial, industrial, and public spaces. Mohan Rajesh Elara, from Lionsbot presented the talk on \\'The Rise of ROS Powered Maintenance Robots\\' during the ROS-Industrial Asia Pacific [^171]. | 2018 |\\n| [Livox LiDAR](https://www.livoxtech.com/) | Provide high-reliability LiDAR products that are high performance, low cost and ready to be put around the world. Livox device driver under Ros2, support Lidar [Mid-40](https://www.livoxtech.com/mid-40-and-mid-100), [Mid-70](https://www.livoxtech.com/mid-70), [Tele-15](https://www.livoxtech.com/mid-70), [Horizon](https://www.livoxtech.com/horizon), [Avia](https://www.livoxtech.com/avia) (see [`livox_ros2_driver`](https://github.com/Livox-SDK/livox_ros2_driver)). | 2016 |\\n| [Locus Robotics](https://locusrobotics.com/industry_solutions/industrial/) | Build autonomous mobile robots that work with hardware and software infrastructure to convert source code into executable packages that can be deployed to the robots from the cloud. ROS driver for Locus Robotics robots (see [`locusrobotics`](https://github.com/locusrobotics)). | 2014 |\\n| [LoopX](https://www.loopx.ai/) | Offers system solutions for autonomous vehicles, mining equipment manufacturers, and mining technology companies. ROS drivers for LoopX (see [`loopx-ai`](https://github.com/loopx-ai)). | 2022 | \\n| [LUCID Vision Labs](https://thinklucid.com) | Design and manufacture machine vision cameras and components that utilize the latest technologies. ROS drivers for LUCID Vision Labs (see [`lucidvisionlabs`](https://github.com/lucidvisionlabs)). | 2017 | \\n| [Lulav Space](https://lulav.space/) | Robotics company that specializes in GN&C, computer vision, and simulation. Sponsor of the [ROScon](https://roscon.ros.org/2023/) 2023. | 2021 | \\n| [Luminar Technologies](https://www.luminartech.com) | Is an autonomous vehicle and lidar [technology](https://www.luminartech.com/technology/) company for passenger cars, commercial trucking and robo-taxi. ROS drivers for Luminar (see [`luminartech`](https://github.com/luminartech)). | 2012 |\\n| [LuxAI](http://luxai.com) | Robotic solutions for education, health-care and entertainment. Their mission is to make robots that work improving the health and education of people. Repository contains the LuxAI QTrobot[^56] open-source softwares and the relevant ROS messages (see [`software`](https://github.com/luxai-qtrobot/software)). | 2016 | \\n| [Luxolis](https://luxolis.ai/) | Offer software and hardware solutions to enable individuals and organizations to use 3D technology. Hiring engineers with experience in ROS ([Robotics Software Engineer (ROS)](https://www.linkedin.com/jobs/view/3723322615)). | 2020 | \\n| [Luxonis](https://www.luxonis.com/) | Develops human-Level perception in embedded systems with permissive open-source MIT-licensed hardware, software, and AI-training. ROS Drivers for DepthAI software [DepthAI](https://www.luxonis.com/applications) (see [`luxonis`](https://github.com/luxonis)). | 2018 |\\n| [Machani Robotics](https://www.machanirobotics.com/) | Build humanoids an their brains. Hiring ROS engineers ([Robotics And Embedded Hardware](https://www.yuvajobs.com/jobs-vacancy-robotics-and-embedded-hardware-internship-in-bangalore-at-machani-robotics-machani-robotics-14627935.html)). | 2020 |\\n| [Magazino GmbH](https://www.magazino.eu/?lang=en) | Creates and constructs mobile, perception-controlled robots for intralogistics. Individual objects can be located using 2D and 3D cameras and identified on the shelf using Magazinos technology. This technology was created with warehouses in mind. ROS Drivers for communicating with Magazino robots (see [`magazino`](https://github.com/magazino))[^90]. | 2014 |\\n| [Magna International](https://www.magna.com/) | Mobility tech company and auto supplier that engages in body exteriors, structures, power, vision, and seating. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^146]. | 1957 |\\n| [Makai Ocean Engineering](https://www.makai.com/) | Specialize in ocean engineering and technology development. Include underwater technology, renewable energy, deep-sea mining, and ocean thermal energy conversion (OTEC). Hiring ROS engineers ([Robotics and Software Test Engineer](https://discourse.ros.org/t/robotics-and-software-test-engineer-autonomous-systems-makai-ocean-engineering/29926)). | 1973 |\\n| [MakarenaLabs SRL](https://www.makarenalabs.com/) | The company offers software design, development, analysis with cutting-edge technologies, hardware acceleration with Xilinx FPGA tools, embedded system design. [MuseBox](https://musebox.it/) is a real-time machine learning system designed for real-time AV Broadcasting applications. You can also connect the core system to your industrial system through a standard protocol like [ROS](https://www.makarenalabs.com/musebox/). | 2016 | \\n| [Mamezou Co](https://www.mamezou.com/) | Offer computerization and optimization of IoT systems in the business and AI area. Sponsor of the [ROScon](https://roscon.ros.org/jp/2019/) JP 2019. ROSCon is a developers conference [^166]. | 2000 | \\n| [MangDang](https://mangdang.store/) | Specializes in the research, development, and production of robot products. They launched their first Robot Operating System (ROS) based quadruped robot (robot with four legs), named Mini Pupper in 2021. Sponsor of the [ROScon](https://roscon.ros.org/2023/) 2023. | 2020 | \\n| [MAN TRUCK & BUS INDIA](https://www.mantruckandbusindia.com/) | Manufacture and sell a range of commercial vehicles, including trucks, buses, and engines, for various applications in the Indian market. Hiring ROS engineers ([Technical expert](https://www.mantruckandbusindia.com/jobs-1/technical-expert-autonomous-driving.html)). | 1915 | \\n| [Marel](http://www.marel.com) | Manufactures and provides equipment, systems, software and services to the poultry, meat and fish processing industries. Hiring engineers with experience in ROS ([Senior Software Engineer](https://jobs.marel.com/es/es/job/14732/Senior-Software-Engineer-Robotics)).  | 1983 |\\n| [Maria Medical Technology](http://www.mmt.ae) | Develop a laser and energy-based aesthetic and [medical device solutions](https://www.mmt.ae/products/) for healthcare field. Also enters the field of medical cobots by designing and developing the [i LASER](https://www.mmt.ae/i-laser/). Hiring ROS engineers ([Robotics Software Engineer](https://discourse.ros.org/t/job-robotics-software-engineer/19718)). | 2020 | \\n| [marinom GmbH](https://www.marinom.de/) | Provide maritime technology solutions. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2021 | \\n| [Marvelmind Robotics](https://marvelmind.com/) | Is an autonomous robotics company. They design, manufacture and sell autonomous robots and robotic systems for logistics, factory automation and research. ROS drivers for Marvelmind Robotics (see [`MarvelmindRobotics`](https://github.com/MarvelmindRobotics)). | 2005 |\\n| [MathWorks](https://www.mathworks.com/) | Develop mathematical computing  software. ROS Toolbox provides an interface connecting MATLAB (used for mathematical calculations)\\u202fand Simulink (modeling and simulating complex systems)\\u202fwith the ROS and ROS 2, enabling to create a network of ROS nodes. This project relies on ROS Toolbox functionality (see [`Message-De-Serializer-for-ROS`](https://github.com/mathworks/Message-De-Serializer-for-ROS))[^89]. | 1984 |\\n| [Matician](http://www.matician.com) | Build autonomous home machines. Using sensors and algorithms they design the devices with Level-5 autonomy and mobility. A ROS package tool to analyze the IMU performance (see [`MaticianInc/imu_utils`](https://github.com/MaticianInc/imu_utils)). | 2017 | \\n| [MeBotX](https://www.mebotx.com/) | Produces robotic exoskeletons. Based on ROS-BC Interface Platform (ROS-BCI) to create a [ROS](https://en.mebotx.com/?content/86)-based brain interface ecosystem. | 2018 | \\n| [Mech-Mind Robotics](https://www.mech-mind.com/) | Is dedicated to giving intelligence to industrial robots. ROS interface for Mech-Eye cameras (see [`mecheye_ros_interface`](https://github.com/MechMindRobotics/mecheye_ros_interface)). | 2016 |\\n| [Microchip](https://www.microchip.com) | Silicon vendor. Embedded control solutions. Well known for microcontrollers and FPGA solutions. PolarFire SoC family. | 1989 |\\n| [Microsoft](https://www.microsoft.com/) | Software corporation that develops, manufactures, licenses, supports, and sells a range of software products and services. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^147]. | 1975 |\\n| [MicroStrain](https://www.microstrain.com/) | Produce micro-displacement sensors for strain measurement in biomechanics research applications. ROS drivers for MicroStrain (see [`LORD-MicroStrain`](https://github.com/LORD-MicroStrain)). | 1987 | \\n| [Milvus Robotics](https://milvusrobotics.com) | Offer Autonomous Mobile Robots (AMRs). SEIT[^34] robots move materials with no human intervention required. ROS Drivers for communicating with Milvus Robotics products (see [`milvusrobotics`](https://github.com/milvusrobotics)). | 2011 | \\n| [MindHome](http://www.mindhome.co) | Transform home experience with robots designed to cook, clean and fold laundry. ROS drivers for MindHome robots (see [`MindHome-Inc`](https://github.com/MindHome-Inc)). | 2018 | \\n| [Miso Robotics](https://misorobotics.com) | Robots-as-a-Service and intelligent automation solutions for the food industry, specially restaurants and fast-food production. ROS drivers for Miso Robotics (see [`MisoRobotics`](https://github.com/MisoRobotics)). | 2016 |\\n| [Mitra Informatika](https://mit.id) | They help customer and app developer to build an application more powerful with one integrated platform. Hiring ROS engineers ([ADAS and AD Engineer](https://mit.id/jobs/adas)). | 2013 | \\n| [Mitsubishi Electric](http://www.mitsubishielectric.com/) | Manufacture and sell electric and electronic equipment used in various systems and appliances. Mitsubishi supports ROS functions [^172]. | 1921 |\\n| [Mobile Industrial Robots](https://www.mobile-industrial-robots.com/) | Produce and develop mobile autonomous robots for industry and manufacturing companies. MiR developing a cheap mobile robot with [ROS](https://www.dti.dk/specialists/mir-developing-a-cheap-mobile-robot-with-ros/33795). | 2013 |\\n| [Mojin Robotics GmbH](http://www.mojin-robotics.de) | Develop smart assistant robots. Also offers service robot platform and online and offline integration services. Provides nodes to assemble point clouds from either LaserScan or PointCloud messages for Mojin Robotics (see [`mojin-robotics/laser_assembler`](https://github.com/mojin-robotics/laser_assembler)). | 2015 | \\n| [Momentum Robotics](https://www.momentumrobotics.in/home) | Offer a range of products and services related to robotics, including consulting, design, development, and integration. Hiring ROS engineers ([Robotics Software Developer](https://www.f6s.com/jobs/51106/momentumrobotics/robotics-software-developer-intern)). | 2019 |\\n| [MORAI](https://www.morai.ai/) | Develop a virtual simulation environment for testing autonomous driving software. ROS drivers for MORAI (see [`MORAI-Autonomous`](https://github.com/MORAI-Autonomous)). | 2018 | \\n| [Motius](https://motius.de/) | Provide consulting, software development, and research and development services. ROS drivers for Motius (see [`motius`](https://github.com/motius)). | 2013 | \\n| [Motiv Space Systems](http://www.motivss.com) | Provider of advanced robotic systems for research, industrial applications, disaster relief, defense, and extreme environments. Installation and user instructions  for all Motiv [ROS Software](https://buildmedia.readthedocs.org/media/pdf/motiv-ros-documentation/industrial_arm/motiv-ros-documentation.pdf). | 2014 |\\n| [MoviĜo Robotics](http://www.movigorobotics.com) | Specialize in developing, delivering and implementing AGV industry 4.0 solutions. They offer ROS[^80] Development and complete data integration services with existing back-office and database systems. | 2018 |\\n| [MOV.AI](https://www.mov.ai/) | A Robotics Engine platform based on ROS and packaged in intuitive web based interface. It contains everything needed to build, deploy and operate intelligent robots. The IDE that brings visualization and structure to ROS (see [`movai-flow`](https://github.com/MOV-AI/movai-flow))[^88]. | 2016 |\\n| [mu Space Corp](http://www.muspacecorp.com) | Focus on developing and launching satellite and space technologies and services for a variety of applications, including telecommunications, earth observation, and space exploration. Hiring ROS engineers ([Robotics software engineer](https://muspacecorp.com/robotics-software-engineer/)). | 2017 | \\n| [Naïo Technologies](https://www.naio-technologies.com/en/home/) | Develop autonomous robot for agriculture in close collaboration with farmers. [Ted](https://www.naio-technologies.com/en/ted/), the first robot dedicated to vineyards. CanOpen-to-ROS bridge (see [`kacanopen`](https://github.com/NaioTechnologies/kacanopen)). | 2011 |\\n| [NakAI Robotics](https://nakairobotics.com) | Develop cutting-edge vessels\\' Grooming and Inspection solutions. ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for NakAI Robotics (see [`nakai-robotics/depthimage_to_laserscan`](https://github.com/nakai-robotics/depthimage_to_laserscan)). | 2021 | \\n| [Nala Robotics](https://nalarobotics.com/) | Design custom kitchen robots that work in a fully automated way. (Nala)[https://nalarobotics.com/nala-chef-one-point-one-product.html) is the first AI and ML-powered multi-cuisine Chef. Being AI-powered, Nala Chef, a customizable robot that uses machine learning to cook infinite recipes. Hiring ROS engineers ([ROS Engineer](https://www.localwalkins.com/job/ros-engineer)). | 2017 | \\n| [Nature Robots](https://naturerobots.com/) | Nature Robots promotes regenerative and ecological agriculture through AI and robotics by supporting perennial and diverse farming systems through innovative software and hardware solutions. Maintaining the software stack for navigation on meshes (see [`mesh_navigation`](https://github.com/naturerobots/mesh_navigation) and [`mesh_tools`](https://github.com/naturerobots/mesh_tools)).| 2022 |\\n| [Nauticus Robotics](https://nauticusrobotics.com/) | Developer of ocean robots, autonomy software and services delivered to the ocean industries. Hiring ROS engineers ([Software Project Manager](https://discourse.ros.org/t/software-project-manager-at-nauticus-robotics/27388)). | 2014 |\\n| [NavVis](https://www.navvis.com) | SLAM-based mobile mapping solutions to generate high-quality data and digital twins. Hiring engineers with experience in ROS ([Advanced Software Engineer Visual SLAM](https://www.glassdoor.com.hk/job-listing/advanced-software-engineer-visual-slam-fmd-navvis-JV_IC4990924_KO0,42_KE43,49.htm?jl=1008576029184&pos=126&ao=1136043&s=58&guid=000001877acc9e5b98ae3c30146d4898&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_9f8a7cb8&cb=1681392443993&jobListingId=1008576029184&jrtk=3-0-1gttcp7kak63v801-1gttcp7l4g2dh800-d6b6e4317c0d981a-&ctt=1681392478936)). | 2013 |\\n| [NCS Group](https://www.ncs.co/en-sg/) | Provide services and solutions in consulting, digital, technology and cybersecurity. [Robotmanager](https://www.robotmanager.com/) is a product developed by NCS Robotics, provides a highly extensible approach that allows robot vendors and developers to easily integrate 3rd-party business apps and support more A.I. capabilities.Sponsor of the [ROScon](https://roscon.ros.org/2022/). | 1981 | \\n| [Nearthlab](http://nearthlab.com) | Provide autonomous drone solutions powered by proprietary deep-learning algorithms for safety inspection in the wind and renewable energy sectors. ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Nearthlab (see [`nearthlab/vision_opencv`](https://github.com/nearthlab/vision_opencv)). | 2015 | \\n|[Neo Cybernetica](https://www.neocybernetica.com/) | Develop cybernetics technology to improve the capability of artificially intelligent systems. Hiring ROS engineers ([Embedded Systems Engineer](https://discourse.ros.org/t/embedded-systems-engineer-robotics-neo-cybernetica/27582)). | 2021 |\\n| [Neobotix GmbH](https://www.neobotix-robots.com/homepage) | Design, develop and manufacture mobile robot, robot arms and omnidirectional robots, with full ROS support can support industrial requirements. ROS and ROS-2 packages (see [`neobotix`](https://github.com/neobotix))[^87]. | 2010 |\\n| [Nerian Vision](https://nerian.com) | Manufacturer of 3D depth sensors for robotics, automation, surveillance and other industries. ROS driver for Nerian Vision sensors (see [`nerian-vision`](https://github.com/nerian-vision)). | 2015 |\\n| [NEURA Robotics](https://neura-robotics.com/) | Develop robotics solutions for various applications. The company provides innovative robotics technology, such as autonomous robots and smart machines, for industries such as logistics, agriculture, and construction. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2019 | \\n| [NEUROMEKA](http://www.neuromeka.com) | Specializes in robot technology and creates a robot platform business for manufacturing companies. ROS drivers for NEUROMEKA robots (see [`neuromeka-robotics`](https://github.com/neuromeka-robotics)). | 2013 |\\n| [Nexuni Co. Ltd.](www.nexuni.com) | Provide automation solutions in dessert and beverage shops and parking lot management. Our robotic systems incorporate a human-like cognitive learning process to continuously improve its decision-making model based on actual management data. ROS drivers for Nexuni robots (see [`nexuni`](https://github.com/nexuni)). | 2019 | \\n| [Niryo](https://niryo.com) |Design industrial robotic solutions composed of robot arms, vision, artificial intelligence and cloud computing. The Ned2[^59], 6-axis collaborative robot designed for Education. Ned ros stack (see [`ned_ros`](https://github.com/NiryoRobotics/ned_ros)). | 2016 | \\n| [Nissan](https://www.linkedin.com/company/nissan-motor-corporation) | Global car manufacturer. Looking for ROS talent[^260] in their Alliance Innovation Lab – Silicon Valley (AIL-SV) | 1933 |\\n| [Nobleo Technology](https://nobleo-technology.nl/) | Develop advanced technologies and solutions for the automotive industry. They focus on creating advanced driver assistance systems (ADAS), autonomous driving, and connected vehicle technologies. They use [ROS](https://nobleo-technology.nl/news/whitepaper-mobile-robot-navigation-ros2/) to develop and implement advanced features such as perception, navigation, and control in their robots. | 2011 | \\n| [NODE Robotics](https://node-robotics.com/) | NODE\\xa0offers\\xa0plug and play\\xa0software\\xa0solutions\\xa0for\\xa0autonomous\\xa0intralogistics. Have been using ROS as middleware and toolkit since day one to build NODE.OS, a plug-and-play, industry-ready, and hardware-agnostic software stack for intralogistics applications[^315]. | 2020 |\\n| [Nokia Bell Labs](https://www.bell-labs.com/) | Is the industrial research arm of Nokia, having invented many of the foundational technologies that underpin information and communications networks and all digital devices and systems. Sponsor of the [ROScon](https://roscon.ros.org/2022/). | 1925 | \\n| [NOKOV Motion Capture](https://www.nokov.com/) | Company focused on optical 3D motion capture system in researching, developing, manufacturing and relative technical services. ROS nodes for working with the Nokov motion capture system (see [`mocap_nokov`](https://github.com/NOKOV-MOCAP/mocap_nokov)). | 2015 |\\n| [Noosware BV](http://noosware.com/) | Offer business and cloud intelligence solutions through open collaborative online environments. A few ROS-based tutorials using the NOOS Cloud Robotics platform (see [`NoosWare/noos_ros_tutorials`](https://github.com/NoosWare/noos_ros_tutorials)). | 2018 | \\n| [Novium](https://www.noviumdesigns.com/) | Robotics engineering firm serving the space and automation industries. Hiring engineers with experience in ROS ([Robotics Software Engineer](https://www.linkedin.com/jobs/view/robotics-software-engineer-at-novium-ltd-3556755267/)). | 2021 |\\n| [NTT Disruption](https://disruption.global.ntt) | NTT Disruption is an information technology company dedicated to technical support and enterprise software design. Using [ROS](https://www.linkedin.com/in/jorgegd/?locale=en_US) in their robotics engineering activities. | 2019 |\\n| [Numurus](https://numurus.com/) | Help companies reduce the cost, time, and risks of bringing Edge-AI and robotic solutions to market. Numurus partners with PickNik to deliver web user interfaces for [ROS](https://numurus.com/press/numurus-partners-with-picknik-for-ros-ui-development/)-based systems. | 2017 |\\n| [Nuro](https://www.nuro.ai/) | Custom electric autonomous vehicles for home deliveries. Looking for ROS talent in their vehicle infrastructure team[^257]| 2016 |\\n| [NVIDIA](https://www.nvidia.com/es-es/autonomous-machines/robotics/) | Silicon vendor. High-performance GPU-based computing including CPU and GPU solutions. Jetson family of products.| 1993 |\\n| [NXP Semiconductors](http://www.nxp.com) | Provide technology solutions targeting the automotive, industrial & IoT, mobile, and communication infrastructure markets. Produce secure connectivity solutions for embedded applications. Installing [ROS](https://community.nxp.com/t5/i-MX-Processors-Knowledge-Base/Installing-ROS-Indigo-on-NXP-i-MX-boards/ta-p/1126471) on NXP i.MX boards  | 2006 | \\n| [NXROBO](http://www.nxrobo.com/) | Build China\\'s largest ROS community \"Spark Plan\", dedicated to the research and development of ROS commercial-grade product technology and empowering education. Its core business is to provide AI & The overall solution for robotic labs and practical courses. The ROS wrapper of Sparks\\'s driver plus various ROS applications (see [`spark`](https://github.com/NXROBO/spark)). | 2015 | \\n| [NXTGEN Robotics](http://www.nxtgenindustries.com.au) | Robotics and Data Intelligence company. Offers different [robotic control solutions](https://nxtgenindustries.com.au/robotic-controls/) like Robotic Autonomous Navigation, Robotic Vision and Perception Systems, Motion Control, Obstacle Avoidance and 3D Mapping. ROS drivers for NXTGEN Robotics (see [`NXTGEN-Robotics`](https://github.com/NXTGEN-Robotics)). | 2019 |\\n| [Object Computing](http://objectcomputing.com) | Deliver software solutions that accelerate business outcomes. Sponsor of the [ROScon](https://roscon.ros.org/world/2020/) 2020. ROSCon is a developers conference [^167]. | 1993 | \\n| [](https://www.ocadogroup.com) | End-to-end eCommerce, fulfilment and logistics platform. Hiring engineers with experience in ROS ([Senior Simulation Software Engineer](https://work180.com/en-gb/for-women/employer/ocado-technology/job/262701/senior-simulation-software-engineer---advance)). | 2000 | \\n| [Oceaneering](https://www.oceaneering.com/) | Design logistic solutions based on autonomous mobile robot technology. Hiring engineers with experience in ROS ([Senior Application Software Engineer](https://careers.oceaneering.com/global/en/job/23391/Senior-Application-Software-Engineer)). | 1964 |\\n| [Octobotics Tech](https://octobotics.tech/) | Build marine and aero  robotic platforms with modular manipulators for atonomous inspection. They combine the principles of control and balance with mechanical designs, cutting-edge hardware and electronics. Hiring ROS engineers ([ROS Engineer (Robotics)](https://www.linkedin.com/jobs/view/ros-engineer-robotics-at-octobotics-tech-3316487598/?originalSubdomain=in)). | 2020 | \\n| [Odd.Bot](https://www.odd.bot/) | Produce autonomous, mobile weed removal robots. Hiring ROS engineers ([Robot Network Engineer](https://www.odd.bot/vacancy-robot-network-engineer)). | 2018 | \\n| [OffWorld](http://offworld.ai) | Develop AI-powered rugged robots for heavy industrial jobs in the mining, infrastructure, and space sectors. Provides the ROS over CAN protocol proxy (see [`Offworld-Robotics/ROC2`](https://github.com/Offworld-Robotics/ROC2)). | 2016 | \\n| [Ola Electric](https://olaelectric.com/) | Indian electric mobility company that provides electric vehicles and charging solutions. Hiring ROS engineers ([Embedded Developer](https://www.instahyre.com/job-211749-embedded-developer-at-ola-electric-mobility-bangalore/)). | 2017 | \\n| [Olive Robotics](https://www.olive-robotics.com/) | Reprogrammable plug and play ROS and ROS 2 native robot hardware components. Modular ROS 2 native [actuators](https://discourse.ros.org/t/olive-robotics-native-ros-speaking-components/27851) and [sensors](https://discourse.ros.org/t/olive-robotics-native-ros-speaking-components/27851). Empowering everyone to build robots intuitively. | 2022 |\\n| [OMRON Group](https://www.omron.com/) | Manufacture and sale automation components, equipment and systems. ROS Packages for Omron Mobile Robot (see [`Omron_LD_ROS_Package`](https://github.com/OmronAPAC/Omron_LD_ROS_Package)). | 1933 |\\n| [Open Robotics](https://www.openrobotics.org/) | Open software and hardware platforms for robotics. Maintainers of [ROS](https://www.openrobotics.org/), Gazebo and Open-RMF. | 2012 |\\n| [Optonic](https://www.optonic.com/en/) | Reliable and innovative partner for our customers for industrial solutions in the field of 2D and 3D camera systems, image processing, as well as machine and robot control. Using [ROS](https://discourse.ros.org/t/optonic-is-looking-for-a-software-engineer-robotics-and-vision-freiburg-germany/24978) in their robotics engineering activities. | 2020 |\\n| [Orangewood Labs](http://www.orangewood.co) | Develop robotic arms. Hiring ROS engineers ([ROS Engineer](https://angel.co/company/orangewood-labs/jobs/1916372-ros-engineer-full-time)). | 2016 |\\n| [Orbbec](http://www.orbbec3d.com) | Develop 3D motion sensor. ROS wrapper for Astra camera (see [`orbbec/ros_astra_camera`](https://github.com/orbbec/ros_astra_camera)). | 2013 | \\n| [Orbital Composites](https://orbitalcomposites.com/) | 3D printing robots for on-orbit manufacturing of advanced materials. Flexible and modular systems utilize ROS and ROS2 for the planning and control of collaborative multi-agent systems. Orbital is an official system partner of KUKA and is driving forward support for KUKA robots in ROS Industrial. Hiring engineers with experience in ROS ([SWE](https://discourse.ros.org/t/orbital-composites-robotic-3d-printing-company-hiring-a-swe/26499)). | 2015 |\\n| [Organifarms](http://www.organifarms.de) | Agriculture company that provides sustainable and efficient agriculture solutions. It uses technology such as vertical farming and hydroponics to grow crops in an indoor environment. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2020 | \\n| [Orthoplex Solutions](https://orthoplexsolutions.com) | Provide engineering, software, and web development custom solutions. Hiring engineers with experience in ROS ([ROS Developer](https://www.linkedin.com/jobs/view/3734230723)). As a ROS Developer, responsible for developing and maintaining software for autonomous driving systems. | 2015 | \\n| [OTSAW](http://otsaw.com/) | Offer security, delivery and disinfection robot services on a subscription base to help you reduce time to benefit and be more flexible. Hiring engineers with experience in ROS ([Robotics Software Engineer](https://meet.jobs/en/jobs/22497-robotics-software-engineer)). | 2015 | \\n| [OttonomyIO](https://ottonomy.io/) | Develop autonomous robot fleets to make contactless deliveries in both indoor and outdoor environments. Hiring ROS engineers ([Robotics Engineer](https://tarta.ai/j/SH_whH0B6wMe-sGqFdJs-robotics-engineer-in-new-york-ny-at-ottonomyio)). | 2020 | \\n| [OTTO Motors](http://www.ottomotors.com/) | OTTO Motors is Clearpath’s industrial division, providing autonomous mobile robots (AMRs) for material handling inside manufacturing facilities and warehouses. Sponsor of the [ROScon](https://roscon.ros.org/2023/) 2023. | 2015 | \\n| [Ouster](https://ouster.com/) | Build digital lidar sensors and perception tools for robots. ROS is used as the middleware, providing inter-process communication between the software components as well as robot-specific libraries and visualizers. This repository contains Ouster SDK source code to connect ouster sensors, reading and visualizing data, and interfacing with ROS. (see [`ouster_example`](https://github.com/ouster-lidar/ouster_example)). | 2015 |\\n| [Outrider](https://www.outrider.ai) | Autonomous yard operations with robotic systems. Seeking for ROS talent in their autonomy team[^265]  | 2017 |\\n| [Outsight](https://outsight.ai/) | Develop a kind of sensor, a 3D Semantic Camera that brings Full Situation Awareness to Smart Machines and Cities. Hiring ROS engineers ([Field Application Engineer](https://jobs.lever.co/outsight/54d85492-14e7-45d2-b3a8-bf72da0f1bd2)). | 2019 | \\n| [Oversonic](https://www.oversonicrobotics.com/) | Design and build cognitive computing systems, applying them, in particular, to the field of robotics. ROS driver for Oversonic (see [`OversonicRobotics`](https://github.com/OversonicRobotics)). | 2020 | \\n| [Owl Autonomous Imaging](http://www.owlai.us) | Deliver Monocular 3D Thermal Ranging solutions to industrial and automotive mobility markets. Hiring ROS engineers ([Senior Application Engineer](https://www.linkedin.com/company/owlai/about/)). | 2018 | \\n| [PAL Robotics](https://pal-robotics.com/) | Design, craft and customize humanoid and mobile robots, and modular robotic parts that adjust to people’s needs, enabled with ROS framework. Software package and ROS wrappers (see [`pal-robotics`](https://github.com/pal-robotics))[^86]. | 2004 |\\n| [Parker Microstrain](https://www.microstrain.com/) | Make tiny sensors and systems that are used in a wide range of applications. Use ROS internally and to enable customers. Provide ROS drivers for their sensors and devices[^308]. | 1924 |\\n| [Parrot](https://www.parrot.com/us) | Leading European group in the drones industry. Various aerial solutions for commercial and professional applications which offer various ROS connectors and integrations (e.g. see [`slamdunk_ros`](https://github.com/Parrot-Developers/slamdunk_ros))[^85]. | 1994 |\\n| [Peer Robotics](https://www.peerrobotics.ai) | Collaborative mobile robotics company building material handling solutions for manufacturing industries. Robots designed to work with humans and built with ROS at its core. | 2019 |\\n| [Peppermint Robots](https://getpeppermint.co/) | Design, make and deploy intelligent housekeeping robots for industries and commercial spaces. ROS packages (see [`Peppermint-Robots`](https://github.com/Peppermint-Robots)). | 2019 | \\n| [PerceptIn](https://www.perceptin.io) | Provide the all-in-one perception, insight, and intelligence solutions for robots and autonomous driving. This package lets you use the Ironsides visual inertial computing module with ROS. (see [`IRONSIDES`](https://github.com/PerceptIn/IRONSIDES)). | 2016 |\\n| [Percipio Robotics](http://www.percipio-robotics.com) | Develop micro-gripper and micro-assembly robotics solutions. It offers precision robotic micromanipulation, micromechanics, dimensional measurement, chronograph, interfaces, robotic control, and platform solutions. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2011 |\\n| [Petpooja](https://www.petpooja.com) | Provide restaurant management software, including billing, inventory management, online ordering and all other front and back-of-house management modules that any restaurant requires. Hiring engineers with experience in ROS ([ROS Developer](https://www.linkedin.com/jobs/view/3735045438)). | 2011 | \\n| [Phantom AI](https://phantom.ai/) | Provide a comprehensive autonomous driving platform featuring computer vision, sensor fusion and control capabilities. Hiring engineers with experience in ROS ([Software Developer (C++) for Testing Perception Software](https://boards.greenhouse.io/phantomai/jobs/4059603006)). | 2016 | \\n| [Phoenix Contact](https://phoe.co/PhoenixContact) | Provide electrical engineering and automation solutions. It offers a wide range of products including electrical components, automation systems, and software solutions for industrial and building automation. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 1923 | \\n| [Photoneo](https://www.photoneo.com/) | Provide robotic vision and intelligence. Based on a patented 3D technology, Photoneo develop highest-resolution and highest-accuracy 3D camera ([Phoxi](https://www.photoneo.com/phoxi-3d-scanner/)). ROS Package for PhoXi Scanner/Camera. (see [`phoxi_camera`](https://github.com/photoneo/phoxi_camera)). | 2013 |\\n| [PI (Physik Instrumente)](https://www.physikinstrumente.com/en/) | Provide hardware and software interfaces for the application environment. Develop and produce robots with combinations of different axes. Hexapods provide motion in six degrees of freedom. ROS driver for PI-Hexapods (see [`PI_ROS_Driver`](https://github.com/PI-PhysikInstrumente/PI_ROS_Driver)). | 1970 | \\n| [Piaggio Fast Forward](https://www.piaggiofastforward.com/) | Build semi-autonomous self driving mobility platforms [^50]. ROS driver for the Roboclaw[^51] motor controllers (see [`roboclaw_ros`](https://github.com/piaggiofastforward/roboclaw_ros)). | 2015 |\\n| [PickNik Robotics](https://picknik.ai/) | Create, integrate, patch, or provide training for robotic applications. Particulary in ROS (see [`PickNikRobotics`](https://github.com/PickNikRobotics)), using a open robotics software platform to help companies to reduce risks, development time and costsassociated with robotic applications. | 2015 |\\n| [Pilz](https://www.pilz.com/en-US) | Develop and sell products, systems and services for safe automation including sensors[^46], safety relays[^47], control[^48] systems and drives[^49]. The pilz_robots packages provide ROS (see [`PilzDE`](https://github.com/PilzDE))  support for controlling the Pilz manipulator module PRBT (see [`pilz_robots`](https://github.com/PilzDE/pilz_robots)) and include robot description and launch files. | 1948 |\\n| [Pixelink](https://www.pixelink.com) | Pixelink is a trusted supplier to OEMs around the world offering cutting-edge camera customization and solutions for robotics, medical and life science instruments, research and industrial equipment. Their official ROS 2 package can be used to incorperate their cameras into  ROS2 application (see [`pixelink_ros2`](https://github.com/pixelink-support/pixelink_ros2/tree/main)). | 1992 |\\n| [PIX Moving](https://www.pixmoving.com/) | Offers one-stop solution with self-driving software and hardware stack, from drive-by-wire chassis, batch customization manufacturing of vehicles to self-driving software integration. ROS Drivers for PIX Moving robots[^45] (see [`pixmoving-moveit`](https://github.com/pixmoving-moveit)). | 2017 |\\n| [Pixel Robotics](https://www.pixel-robotics.eu/) | Pixel Robotics builds intelligent, perception-controlled robots tailored for logistics. With its unique AI vision infrastructure a digital twin of the operating area is created. Using this real-time twin, Pixel Robotics’s robots work together with their human colleagues - autonomous, safe and with an unmatched level of flexibility. Hiring engineers with experience in ROS ([Robotics Intern](https://discourse.ros.org/t/robotics-intern-pixel-robotics/29811)). | 2020 |\\n| [Plus](https://www.plus.ai/) | Level 4 Autonomous Trucking Technology. Powered by ROS. Actively seeking for ROS experts[^277]. | 2016 |\\n| [Plus One Robotics](https://plusonerobotics.com/) | Builds robot perception software and solutions. They give robots the eye-hand coordination to pick and place objects in the warehouses and distribution centers using 3D and AI-powered perception. ROS communications-related packages, core client libraries (roscpp, rospy, roslisp) and graph introspection tools (rostopic, rosnode, rosservice, rosparam) (see [`ros_comm`](https://github.com/plusone-robotics/ros_comm))[^44]. | 2016 |\\n| [Point One Navigation](https://pointonenav.com) | Provide pecise location as a service, is tailored for autonomous systems including [self driving vehicles](https://pointonenav.com/verticals), commercial drones and other robotic applications where localization is required. ROS drivers for GNSS receiver (see [`septentrio_gnss_driver`](https://github.com/PointOneNav/septentrio_gnss_driver)). | 2016 |\\n| [Polymath Robotics](https://polymathrobotics.com) | Develop autonomous vehicle software for industrial vehicles. Safety-critical navigation for industrial vehicles. | 2021 | \\n| [PPM Robotics AS](https://www.ppm.no/) | Develop solutions within the field of advanced, highly-flexible industrial robot systems. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^148]. | 2000 |\\n| [Process Champ](https://processchamp.com/) | Develop AI software solutions for positional alignment, machinery guidance, autonomous inspection and quality reporting, predictive failure analysis, and digital twin process optimization. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^149]. | 2016 |\\n| [PROPHESEE](https://www.prophesee.ai) | Is the inventor of the most advanced neuromorphic vision systems [^129]. ROS driver for Prophesee [event-based sensors](https://www.prophesee.ai/event-based-sensor-packaged/) (see [`prophesee_ros_wrapper`](https://github.com/prophesee-ai/prophesee_ros_wrapper)). | 2014 \\n| [PushCorp](http://pushcorp.com) | Manufacture robotic material removal end-of-arm tooling. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^150]. | 1993 |\\n| [qbrobotics](http://www.qbrobotics.com) | Produce actuators, devices and systems for soft robotics as robotic hands, handles, delta robots and VSA. ROS package for [SoftHand](https://qbrobotics.com/product/qb-softhand-industry/) device (see [`ROS-SoftHand`](https://github.com/NMMI/ROS-SoftHand))[^174]. | 2011 |\\n| [QuadSat](https://quadsat.com/) | Supply airborne antenna testing solutions. QuadSAT system combines advanced drone technology with a custom RF pointing payload. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^152]. | 2014 |\\n| [Qualcomm](https://www.qualcomm.com/products/application/industrial-commercial/robotics) | Silicon vendor. Their robotics platform offer compact connectivity-oriented (Wi-Fi, 4G LTE, 5G) high-performance (CPU, GPU, DSP) solutions. Seeking ROS expertise for ADAS software engineering[^278]. | 1985 |\\n| [Quanergy](http://www.quanergy.com) | Develop solid state sensors used to offer smart sensing services for [self-driving cars](https://quanergy.com/applications/transportation/). ROS driver wrapping the QuanergyClient library to produce ROS cloud messages from Quanergy sensors. (see [`quanergy_client_ros`](https://github.com/QuanergySystems/quanergy_client_ros)). | 2012 |\\n| [Quantillion Technologies](http://www.quantillion.io/) | Develop software for autonomous mobile robots (AMR). The company focus on industry 4.0, automating and optimizing processes in plants, from order to execution. Hiring engineers with experience in ROS ([Robotics engineer - mobile equipment (ROS/C++)](https://www.linkedin.com/jobs/view/3730269196)). | 2016 | \\n| [Quasi Robotics](https://quasi.ai) | Offer a range of products and services, including industrial robots, collaborative robots, mobile robots, and custom robotic solutions. ROS2 drivers for Quasi Robotics (see [`quasi-robotics`](https://github.com/quasi-robotics)). | 2017 | \\n| [RangeAero](http://www.range.aero) | Provide unmanned aircraft systems (UAS) and related services for a variety of applications. Offer a range of products and services, including UAS design, development, and manufacturing, as well as UAS operations and support. Hiring ROS engineers ([Control System Engineer](https://angel.co/company/rangeaero/jobs/701760-control-system-engineer)). | 2020 | \\n| [Rapyuta Robotics](https://www.rapyuta-robotics.com/) | Builds cloud [^42] robotics solutions. Rapyuta Robotics’ platform makes it easier for businesses to deploy robotics solutions. By integrating robot hardware, software, sensor data, and applications in the cloud. ROS Drivers for cloud and different robotics solutions[^43] (see [`rapyuta-robotics`](https://github.com/rapyuta-robotics)).  | 2014 |\\n| [RealMan Intelligent Technology (Beijing)Co., Ltd.](http://www.realman-robotics.com/) | Focuses on the research, development, manufacture, and marketing of ultra-lightweight humanoid robotic arms. Open API function library, supporting C/C++/C#/Python programming language, and supporting Windows/Linux/[ROS robot operating systems](http://www.realman-robotics.com/RM65xilie.html) and various communication protocols. | 2018 | \\n| [Realtime Robotics](https://www.rtr.ai) | Invent a specialized [processor](https://rtr.ai/products) for generating safe robot motion plans in micro-seconds, enabling robots to function in unstructured, collaborative work-spaces, reacting to other motions as soon as they are perceived. ROS drivers (see [`RealtimeRobotics`](https://github.com/RealtimeRobotics)). | 2016 |\\n| [Redwire Space](https://redwirespace.com/) | Provide space hardware and technology solutions. The company designs and manufactures advanced components and systems for the commercial, civil, and military space industries, including payloads, structures, and advanced robotics. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2020 | \\n| [Relativity Space](http://relativityspace.com) | Provide fully automated rocket production and launch services. The company uses advanced robotic technology to manufacture rockets. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2016 | \\n| [Relay Robotics](https://www.relayrobotics.com/) | Supplier of autonomous service robots that work with humans. ROS communications-related packages, including core client libraries and graph introspection tools (see [`ros_comm`](https://github.com/savioke/ros_comm)). Their job offers also hint the use of ROS[^213].| 2013 |\\n| [REMY Robotics](https://remyrobotics.com/) | Develop autonomous robotic kitchens to enhance sustainability for people, the planet and food service operators. Hiring engineers with experience in ROS ([Robot Control Engineer](https://discourse.ros.org/t/robot-control-engineer-remy-robotics-barcelona-spain/30267)). | 2018 |\\n| [Renesas Electronics](http://www.renesas.com) | Provide semiconductor solutions, including microcontrollers, SoC solutions, and analog and power devices. Sponsor of the [ROScon](https://roscon.ros.org/jp/2019/) JP 2019. ROSCon is a developers conference [^166]. | 2002 | \\n| [Renu Robotics](https://renurobotics.com) | Automating operations and maintenance for the solar industry. Develop and produce robots powered by [ROS](https://renurobotics.com/technology/) that   mow, spray, clean, and inspect solar panels for utility-scale solar. Hiring engineers with experience in ROS ([Software Test Engineer](https://www.wayup.com/i-j-Renu-Robotics-758133283012643/)). | 2018 | \\n| [RGo Robotics](https://www.rgorobotics.ai) | Develop artificial perception technology that enables mobile robots to understand complex surroundings and operate autonomously just like humans. Hiring ROS engineers ([Solution Architect](https://www.rgorobotics.ai/solutionarchitect)). | 2018 | \\n| [RIF Robotics](https://www.rifrobotics.com) | Develop robots for hospital logistics. ROS2 drivers for RIF Robotics (see [`RIF-Robotics`](https://github.com/RIF-Robotics)). | 2020 | \\n| [RIOS Intelligent Machines](http://www.rios.ai) | Create automated robotic workcells powered by AI for factories. Robotics and AI\\xa0can be used to transform labor-intensive workplaces into smart factories. Hiring engineers with experience in ROS ([Machine Learning and Robotics Software Engineer](https://boards.greenhouse.io/riosintelligentmachines/jobs/4019999005)). | 2018 |\\n| [Rivelin Robotics](http://www.rivelinrobotics.com) | Creators of autonomous metal [finishing robots](https://rivelinrobotics.com/meet-the-robots) called [NetShape®](https://rivelinrobotics.com/learn-the-tech). Unlike manual labour & casting automation, Rivelin NetShape® is repeatable AND flexible. ROS-I and Noetic drivers (see [`RivelinRobotics`](https://github.com/RivelinRobotics)). | 2018 |\\n| [Robertshaw](http://www.robertshaw.com/) | They offer expertise in integrating electronics with our electro-mechanical and mechanical components to create more original product designs.production more efficient and cost-competitive. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 1899 | \\n| [Roboception GmbH](https://roboception.com/en/) | Develop software and hardware products for real-time perception and localisation of robotic systems[^81]. ROS interface for the Roboception [rc_visard](https://roboception.com/en/rc_visard-en/) 3D sensor (see [`rc_visard_ros`](https://github.com/roboception/rc_visard_ros)). | 2015 |\\n| [RoboDeck](https://www.robo-deck.com/) | Outdoor manteinance robots powered by ROS and developed/controlled by ROS-ecosystem tools and extensions. Hiring engineers with experience in ROS ([Robotics Navigation and Computer Vision Engineer Internship](https://www.masaisrael.org/job/robotics-navigation-and-computer-vision-engineer/)). | 2022 |\\n| [RoboK](http://robok.ai) | Build cost-effective 3D sensing algorithms optimised for low-power computing platforms. ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for RoboK (see [`RoboK2017/vision_opencv`](https://github.com/RoboK2017/vision_opencv)). | 2017 | \\n| [Robolaunch](https://www.robolaunch.io/) | Provide Cloud-Native Robotics Platform and mobile robots based on [ROS/2](https://robolaunch.io/) to bring scalable and GPU accelerated robotics solutions to life. ROS drivers for Robolaunch (see [`robolaunch`](https://github.com/robolaunch)). | 2020 | \\n| [RoboSense](https://www.robosense.ai) | Is an environment perception solutions provider of autonomous driving LiDAR. RoboSense LiDAR SDK for ROS & ROS2 (see [`rslidar_sdk`](https://github.com/RoboSense-LiDAR/rslidar_sdk)). | 2014 |\\n| [Robotec.AI](https://robotec.ai/) | Develops high-tech solutions for automated and connected vehicles. Support in applying ROS and ROS2 middleware to develop robotic applications. Make LIDARs-based modules for localization, perception and motion planning. A ROS/ROS2 Multi-robot Simulator for Autonomous Vehicles (see [`simulator`](https://github.com/RobotecAI/simulator)), more ROS Drivers (see [`RobotecAI`](https://github.com/RobotecAI)). | 2019 |\\n| [RoboTech Vision](https://robotechvision.com/) | Develop advanced vision systems for robots. The company\\'s primary focus is on developing and integrating cutting-edge computer vision technology into robots. ROS2 drivers for RoboTech Vision (see [`robotechvision`](https://github.com/robotechvision)). | 2013 | \\n| [Robotic Solutions, Inc.](http://www.roboticsolutionsinc.com) | A robotic systems integrator that specializes in Milling applications. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2004 | \\n| [Robotican](https://robotican.net/) | Develop cutting-edge robotics technology systems. Offer modular robotics systems for research applications, solutions building robotics and mechatronics systems. ROS Drivers for communicating with Robotican products (see [`robotican`](https://github.com/robotican)). | 2011 |\\n| [Robotiq](http://robotiq.com/) | Manufacture flexible, plug & play robotic grippers and sensors. There exists ROS community packages for Robotiq\\'s technology (see [`robotiq`](https://github.com/ros-industrial/robotiq)). Also, Robotiq\\'s team seems to be providing ROS support for their technology [^314]. | 2008 |\\n| [ROBOTIS](https://robotis.us/) | Developer of smart servos, industrial actuators, manipulators, open-source humanoid platforms, and educational robotic kits, like the [Turtlebot3](https://robotis.us/turtlebot-3/) (see [`turtlebot3`](https://github.com/ROBOTIS-GIT/turtlebot3)). The ROS packages for the different robots (see [`ROBOTIS-GIT`](https://github.com/ROBOTIS-GIT)). | 1999 |\\n| [Roboto AI](https://www.roboto.ai/) | Technology startup that accelerates the search, transformation, and analysis of robotics data. The company is building a first-of-its-kind copilot for robotics engineers who have to pour through petabytes of data to find edge cases and debug system failures. Sponsor of the [ROScon](https://roscon.ros.org/2023/) 2023. | 2022 | \\n| [Rockwell Automation](http://www.rockwellautomation.com/) | Provider of industrial automation and digital transformation technologies. Rockwell Automation [signs agreement to acquire](https://www.rockwellautomation.com/en-us/company/news/press-releases/Rockwell-Automation-signs-agreement-to-acquire-autonomous-robotics-leader-Clearpath-Robotics.html) autonomous robotics leader Clearpath Robotics | 1903 | \\n| [Rope Robotics](http://www.roperobotics.com) | Develop robotic solutions for inspection, maintenance, and repair of offshore energy installations such as wind turbines, oil rigs, and subsea pipelines. ROS drivers for Rope Robotics (see [`Rope-Robotics`](https://github.com/Rope-Robotics)). | 2016 | \\n| [ROSEN](https://www.rosen-group.com/global.html) | Public safety cutting-edge solutions in all areas of the integrity process chain. Using ROS and ROS 2 for developing robotic systems. Looking for ROS talent [^283] | 1981 |\\n| [Rover Robotics](https://roverrobotics.com/) | Make robotics hardware ready for research and development, compatible with ROS[^21] and cutting edge computers from NVIDIA and ADLINK. ROS Drivers for communicating with Rover Robotics products(see [`RoverRobotics`](https://github.com/RoverRobotics)). | 2018 |\\n| [RT Corporation](https://rt-net.jp/) | Is a robotics research company which has developed products such as robot humanoid, robot arm and a basic robot kit for learning and education. The company also indulges in developing custom service robots, PCB developing machines and AI for robots. ROS drivers for RT products[^61] (see [`rt-net`](https://github.com/rt-net)). | 2005 | \\n| [RTI (Real-Time Innovations)](https://www.rti.com/en/) | Provides the real-time communications platform for the IoT. Resources for [ROS 2](https://community.rti.com/ros) + DDS Interoperation | 1991 |\\n| [Rucha Yantra LLP](https://www.yantrallp.com/) | Manufacture mobile robotic systems for industrial and commercial applications. They provide automated material handling equipment in series called [RAGHAV](https://www.yantrallp.com/raghav.php), [SAEVK](https://www.yantrallp.com/saevk.php) and [VAMEN](https://www.yantrallp.com/vamen.php), each having different specifications & capacity as per industrial requirements. We also provide automated sansitization robots an autonomous delivery robots for healthcare. Hiring ROS engineers ([Robotics Engineer](https://www.yantrallp.com/job_description.php?jid=4)). | 2019 | \\n| [RUVU](https://ruvu.nl/) | Helps robot OEMs and integrators develop useful robot applications by providing [software](https://ruvu.nl/#software) and integration services. Offers software for localization, [navigation](https://ruvu.nl/#navigation), and environment perception. ROS Navigation stack (see [`navigation`](https://github.com/ruvu/navigation)). | 2017 |\\n| [Ryberg](https://www.ryberg.nl/) | Autonomous disinfection robots built with ROS. Hiring engineers with experience in ROS ([Lead Software Engineer](https://discourse.ros.org/t/lead-software-engineer-ryberg-robotics-delft-the-netherlands/27460)). | 2020 |\\n| [SafeAI](https://www.safeai.ai/) | Retrofit existing construction and mining vehicles with autonomous driving technology to enable safer, more productive and connected worksites. Hiring ROS engineers ([Software Engineer](https://www.instahyre.com/job-148020-software-engineer-behavior-planning-at-safeai-work-from-home/)). | 2018 | \\n| [SAGA ROBOTICS](https://sagarobotics.com/) | Develop autonomous robots capable of performing a wide variety of agricultural operations. [Thorvald platform](https://sagarobotics.com/thorvald-platform/) is a multi-functional robot,iIt can be used for autonomous tasks around the farm or vineyard. ROS drivers for SAGA ROBOTICS(see [`SAGARobotics`](https://github.com/SAGARobotics)). | 2016 |\\n| [Saha Robotik](http://saharobotik.com/) | Offer autonomous mobile service and delivery robots. ROS2 drivers for Saha Robotik (see [`SahaRobotik`](https://github.com/SahaRobotik)). | 2020 | \\n| [SARCOS](https://www.sarcos.com) | Industrial robotic systems that augment human performance (mostly exoeskeletons). Hiring engineers with experience in ROS ([Internship Robotic Computing Hardware](https://www.salary.com/job/sarcos-technology-and-robotics-corporation/internship-robotic-computing-hardware/j202210080225154789095)). | 1983 |\\n| [Sastra Robotics](http://www.sastrarobotics.com) | Build Robotic solutions for human-like automated functional testing of real physical devices. Since 2013, our products are being used by OEM’s/TIER-1’s and Service Providers to expedite test cycles and reduce the time-to-market for their products. ROS packages of SR-SCARA-HX Manipulator (see [`sr_scara_hx_ros`](https://github.com/sastrarobotics/sr_scara_hx_ros)). | 2013 |\\n| [SBG Systems](https://www.sbg-systems.com/) | Provide inertial sensors[^19] that use ROS package. ROS 2 driver for SBG Systems IMU/AHRS/INS units such as ELLIPSE or QUANTA (see [`sbg_ros2_driver`](https://github.com/SBG-Systems/sbg_ros2_driver))[^18]. | 2007 |\\n| [Schaeffler](https://www.schaeffler.com/fork/) | Automotive and industrial supplier. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^154]. | 1975 |\\n| [Schindler Group](https://group.schindler.com/) | Involved in the integration of robotics and automation into its products and services, particularly in elevators and escalators. The company has developed technology that allows elevators to operate more efficiently and with greater intelligence. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 1874 | \\n| [SCHUNK](https://www.schunk.com) | Develop clamping technology[^63] and gripping systems[^62]. Control via [ROS](https://schunk.com/gb/en/gripping-systems/special-gripper/svh/c/PGR_3161) driver for the [SVH](https://schunk.com/gb/en/gripping-systems/special-gripper/svh/c/PGR_3161) (5-finger servo-electric gripping hand) | 1945 | \\n| [Scythe Robotics](https://www.scytherobotics.com/) | Developer of an autonomous, fully electric commercial lawnmower helping to overcome the industry\\'s labor crisis while simultaneously becoming the greenest option possible. Using [ROS](https://www.builtincolorado.com/company/scythe-robotics) in their robotics engineering activities. ROS drivers for Scythe Robotics (see [`scythe-robotics`](https://github.com/scythe-robotics)). | 2018 |\\n| [SDLE](https://sdle.es/) | Provides expertise in logistics, maintenance and R+D in military, defence, aeronautic and robotic fields. Company worker works as a [ROS developer](https://www.linkedin.com/in/luz-maria-hidalgo-garcia-659053b2/?originalSubdomain=es).  | 2009 | \\n| [SEAOS Inc.](https://www.seaos.co.jp/) | They work on product license Application software and robot development. ROS drivers for SEAOS (see [`SeaosRobotics`](https://github.com/SeaosRobotics)). | 2000 | \\n| [Seasony](https://www.seasony.io/) | Fully autonomous vertical farming robots built with ROS. Hiring engineers with experience in ROS ([Robotics Simulation Intern](https://thehub.io/jobs/6422f263f0e2ce7c97694d02)). | 2018 | \\n| [SEC Co.](https://www.sec.co.jp/ja/index.html) | Provide real-time software and solutions in the social and public fields and cutting-edge fields. Sponsor of the [ROScon](https://roscon.ros.org/2018/) 2018. ROSCon is a developers conference [^169]. | 1970 | \\n| [Sedenius Engineering GmbH](http://www.sedenius.com/) | Automotive company that provides artificial intelligence, autonomous driving, and test drive support services.. Hiring ROS engineers ([Software developer (ROS)](https://www.linkedin.com/jobs/view/3674951608)). | 2012 | \\n| [Seed Robotics](http://www.seedrobotics.com) | Develop humanoid robots and assorted technologies such as robotic hands and machine learning. ROS Package for Seed Robotics\\' [FTS and SINGLEX tactile sensors](https://www.seedrobotics.com/fts-tactile-pressure-sensors) (see [`ros_fts`](https://github.com/seedrobotics/ros_fts)). | 2015 |\\n| [Segway Robotics](https://robotics.segway.com/) | Develope first Robotic Mobile Platform (RMP) product line. Company has been continuously developing, and marketing robotic products. Its wide product lineup including the self-balancing robot Loomo, restaurant service robot, indoor delivery robot, outdoor delivery robot. ROS package for interfacing with Segway\\'s RMP{50,100,[200](https://robotics.segway.com/product/rmp-lite-220/),400} series robotic platforms (see [`segway_rmp`](https://github.com/segwayrmp/segway_rmp)). | 2001 |\\n| [SENSYN ROBOTICS](https://www.sensyn-robotics.com) | Develop business solutions that combine robotics technology such as drones with advanced technology. In particular, by promoting automation and generalization. ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for SENSYN ROBOTICS (see [`sensyn-robotics/vision_opencv-pub`](https://github.com/sensyn-robotics/vision_opencv-pub)). | 2015 | \\n| [Seoul Robotics](https://seoulrobotics.org) | Build deep learning based Lidar[^126] perception module for self-driving cars and robots. ROS drivers for Seoul Robotics(see [`seoulrobotics`](https://github.com/seoulrobotics)). | 2017 |\\n| [Septentrio](http://www.septentrio.com) | Design and manufacture high-precision OEM [GNSS receivers](https://www.septentrio.com/en/products/gnss-receivers) and surveying/GIS equipment. Used by prominent dredging, [UAV](https://www.septentrio.com/en/applications/uavandrobotics) and [agricultural](https://www.septentrio.com/en/applications/agriculture) companies. ROS 1 & 2 driver for Septentrio GNSS & INS receivers (see [`septentrio_gnss_driver`](https://github.com/septentrio-gnss/septentrio_gnss_driver)). | 2000 |\\n| [SEQSENSE](https://www.seqsense.com/) | Autonomous mobile [robot](https://www.seqsense.com/product/) and solution provider in Japan. Applying an original laser sensor technology, manufacturing and business development of new service robots. Sponsor of the [ROScon](https://roscon.ros.org/jp/2021/) JP 2021. ROSCon is a developers conference [^165]. Using ROS 1 internally in their systems. Thinking of moving to ROS 2. | 2016 | \\n| [SESTO Robotics](https://www.sestorobotics.com) | Develop autonomous mobile robots (AMRs) for industrial automation and logistics. Hiring ROS engineers ([Automation & Controls Engineer](https://www.sestorobotics.com/careers/)).| 2017 | \\n| [Sevensense Robotics](https://www.sevensense.ai/) | Accelerate robotics industry by enabling robots to safely and autonomously navigate. Alphasense Position[^112] is a multi-camera, industrial grade, Visual-SLAM-in-a-box solution for mobile robots. Source code of the ACP-ROS bridge for Alphasense Position (see [`alphasense_acp_bridge`](https://github.com/sevensense-robotics/alphasense_acp_bridge)). | 2018 |\\n| [Shadow Robot](https://www.shadowrobot.com/) | Desing and manufacture anthropomorphic robot hands[^17]. Shadow Robot’s humanoid hands are ROS programmable off the shelf. Drivers and controllers for Shadow Robot\\'s EtherCAT Hand (see [`shadow-robot`](https://github.com/shadow-robot)). | 1987 |\\n| [Shenzhen EAI Technology](http://www.ydlidar.com) | Supply LiDAR sensors as well as intelligent robot mobile solution provider. Together with optimized robot mobile solution for autonomous mapping, real-time positioning, planning navigation, and automatic obstacle avoidance, EAI products has been widely used on service robots, robot vacuums, AGV, warehouse robots for commercial application, research and education. Ydlidar driver package under ros (see [`ydlidar_ros_driver`](https://github.com/YDLIDAR/ydlidar_ros_driver)). | 2015 |\\n| [Shield AI](https://shield.ai/) | Produce AI and autonomy stack for aircraft. ROS2 drivers for Shield AI (see [`shield-ai`](https://github.com/shield-ai)). | 2015 | \\n| [Shunya Ekai Technologies](https://shunyaekai.tech) | Build new age IoT devices and autonomous mobility bots to automate operations, solve challenges across various industries and improve human efficiency and lifestyle. Hiring ROS engineers ([Robotics Engineer/Trainee - Visual SLAM/ROS](https://www.linkedin.com/jobs/view/shunya-ekai-technologies-robotics-engineer-trainee-visual-slam-ros-at-shunya-ekai-technologies-3435996676/?originalSubdomain=in)). | 2020 | \\n| [SICK Sensor Intelligence](http://www.sick.com) | Provides sensor intelligence and application solutions that create the basis for controlling processes securely. Use ROS2 Driver to read the raw data from the SICK Scanners. Sick_scan is an open-source project to support the laser scanner of the company SICK using the ROS-framework (see [`sick_scan`](https://github.com/SICKAG/sick_scan))[^16]. | 1946 |\\n| [Siemens](https://www.siemens.com/global/en.html) | Is an engineering and electronics company that specializes in the fields of industry, energy, transportation, and healthcare. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^155]. | 1847 |\\n| [Simbe Robotics](https://www.simberobotics.com/) | Builds automation solutions for the retail industry. Simbe’s first product, [Tally](https://www.simberobotics.com/platform/tally/), is the world’s first fully autonomous shelf auditing and analytics solution. Hiring ROS engineers ([Robotics Software Engineer](https://discourse.ros.org/t/robotics-software-engineer-simbe/25079)). | 2014 |\\n| [Simelabs](http://www.simelabs.com/) |  Offer a software solution in business mobility, omnichannel, IoT, cloud, and blockchain technology. Also, offer solutions for robots. Hiring ROS engineers ([Robotics Engineer](https://www.simelabs.com/careers/robotics-engineer/)). | 2014 | \\n| [Skarv Technologies](http://www.skarvtech.com) | Developadvanced underwater robotic systems. The company leverages the latest advancements in robotics, artificial intelligence, and underwater technology to develop innovative solutions for various applications in the marine and offshore industries. Gazebo/ROS packages for underwater robotics simulation (see [`skarvtech/uuv_simulator`](https://github.com/skarvtech/uuv_simulator)). | 2019 | \\n| [Skyline Robotics](https://www.skylinerobotics.com/) | Provide building maintenance services using drones and robotic systems. They develop and operate a range of drones and robots that can perform tasks such as window cleaning, inspection, and maintenance on tall buildings, bridges and structures. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2017 | \\n| [SLAMcore](http://www.slamcore.com) | Provide location, mapping and perception software for robots and other autonomous machines to become spatially intelligent. ROS dockers for SLAMcore (see [`slamcore`](https://github.com/slamcore)). | 2016 |\\n| [Slip Robotics](https://sliprobotics.com/) | Produces autonomous mobile robots used for unloading trucks. Hiring engineers with experience in ROS ([Robotics Software Engineer](https://tarta.ai/j/3bdEiX8BUtwXGc8feysB-robotics-software-engineer-perception-computer-vision-ml-ai-at-slip-robotics)). | 2019 | \\n| [sliQue Robotics](https://slique.us/) | Produces mobile autonomous robots for delivery and cleaning applications. Hiring engineers with experience in ROS ([Senior ROS Developer](https://www.linkedin.com/jobs/view/senior-ros-developer-at-slique-robotics-3637036813/?originalSubdomain=in)). | 2022 | \\n| [Small Robot Company](http://www.smallrobotcompany.com/) | An agricultural start-up developing autonomous scanning and weeding robotics. Full field scans at a per-plant level are then visualised on a web interface which dictates job-planning and data analysis. Utilising ROS1 for communication, localization and state-control. Company worker works as a [ROS developer](https://www.smallrobotcompany.com/team).   | 2017 |\\n| [smartmicro](https://www.smartmicro.com/) | Develop sensor solutions for traffic management and automotive industries. ROS2 drivers for smartmicro (see [`smartmicro radars`](https://discourse.ros.org/t/ros-2-driver-for-smartmicro-radars/23153)). | 1997 | \\n| [Smart Machine](http://www.oxin.nz) | Machinery manufacturing. Oxin, their flagship product a fully autonomous viticultural vehicle. PCL (Point Cloud Library) ROS interface stack for Smart Machine (see [`oxin-ros/perception_pcl`](https://github.com/oxin-ros/perception_pcl)). | 2018 | \\n| [Smart Robotics](https://smart-robotics.io) | Developer of cutting-edge robot solutions in the logistics space. Building [pick and place](https://smart-robotics.io/en/pick-and-place-robot/) robots using deep learning for vision and self-developed motion planning for robust and fast robotic solutions. Using ROS as the backbone for communication within the application. ROS drivers for Smart Robotics (see [`smart-robotics`](https://github.com/smart-robotics)). | 2015 | \\n| [Smile Robotics, Inc.](smilerobotics.com) | Develop automatic serving for restaurants. The company develops integrated type shelf transfer robot to prepare multiple shelves and possible to load items onto the shelves without waiting for the arrival of the robot. ROS drivers for Smile Robotics (see [`smilerobotics`](https://github.com/smilerobotics)). | 2019 | \\n| [SNCF](http://www.sncf.com) | Is a travel and logistic service provider company. SNCF runs and manages SNCF voyage. Sponsor of the [ROScon](https://roscon.ros.org/fr/2019/)  2019. ROSCon is a developers conference [^168]. | 1938 | \\n| [SoftBank Robotics](https://www.softbankrobotics.com/emea/en) | Create robots and explores and commercializes the robotic solutions. Pepper[^35] is social humanoid robot able to recognize faces and basic human emotions. ROS drivers for SoftBank Robotics (see [`softbankrobotics-research`](https://github.com/softbankrobotics-research)). | 2005 | \\n| [solectrix GmbH](http://www.solectrix.de) | Provide electronics and software solutions for a variety of applications. Offers a range of products and services, including electronics design, software development, and system integration. The company\\'s products and services are used in a variety of industries, including automation, aerospace, and medical technology. The use of [proFRAME](https://solectrix.de/en/products/video-grabber-and-playback-systems/) in different SW platforms or working environments ([ROS](https://solectrix.de/en/products/video-grabber-and-playback-systems/)). | 2005 |\\n| [Solid State of Mind](https://solidstateofmind.com/) | Develop an artificial intelligence capable of adapting to real-time changes in the environment. A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data for Solid State of Mind (see [`Solid-State-of-Mind-Inc/image_transport_plugins`](https://github.com/Solid-State-of-Mind-Inc/image_transport_plugins)). | 2020 | \\n| [Soltrex](https://www.soltrex.io/) | Design and manufacture of solar-tracking systems for large-scale solar power projects. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2021 | \\n| [SOMATIC](http://getsomatic.com) | Make bathroom cleaning robots for commercial spaces like office buildings. A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data for SOMATIC (see [`getsomatic/image_transport_plugins`](https://github.com/getsomatic/image_transport_plugins)). | 2018 | \\n| [Sony](https://www.sony.com/en/) | Develop and manufacture audio, video, communications, and information technology products for the consumer and professional markets. Known to use ROS and ROS 2 in their latest robotics products (Aibo[^203] and Airpeak S1[^202]). Sponsor of the [ROScon](https://roscon.ros.org/) across multiple years. | 1946 | \\n| [Southwest Research Institute](https://www.swri.org/industries/industrial-robotics-automation) | Develop automation and robotics solutions. Southwest Research Institute (SwRI) has used the ROS to develop complex intelligent systems. SwRI has leveraged ROS applications in the areas of: Industrial Robotics & Automation[^70], Robotics Research & Development[^71], ROS-Industrial[^72] and Automated Driving Systems & UGVs[^73]. (see [`swri-robotics`](https://github.com/swri-robotics/))[^74]. ROS drivers | 1947 |\\n| [SpaceTime Labs](https://www.spacetimelabs.ai/) | Artificial intelligence firm that develops and operates automated platforms. Hiring ROS engineers ([Senior Robotics Engineer](https://static1.squarespace.com/static/60b6393782659e2d1e1634c3/t/60b6848b5685206ff41de365/1622574219913/02+Robotics_Eng_vJan21-final.pdf)). | 2014 | \\n| [spinbotics](http://spinbotics.com) | Develop actuators for automation, manipulation, and manufacturing. ROS drivers for spinbotics (see [`Spinbotics-s-r-o`](https://github.com/Spinbotics-s-r-o)). | 2020 | \\n| [Spirit Aerosystems](https://www.spiritaero.com/) | Manufacture component parts and assemblies for commercial aircraft. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^156]. | 2005 |\\n| [Square Robot Inc.](http://www.squarerobots.com) | Build robotic systems for submerged oil and gas inspections. An image processing pipeline for ROS for Square Robot Inc. (see [`squarerobot/image_pipeline`](https://github.com/squarerobot/image_pipeline)). | 2016 | \\n| [ST Robotics](http://strobotics.com) | Manufacture bench top robots. Their most popular products are the robotic arms[^66],ROS package providing moveit support for the ST Robotics arms, including controller configuration (see [`ST-ROBOTICS`](https://github.com/ST-ROBOTICS)). | 1986 |\\n| [Starship Technologies](http://www.starship.xyz) | Is a robotics company building fleets of self-driving delivery robots designed to deliver goods. C++ ROS bag reader (see [`bag_rdr`](https://github.com/starship-technologies/bag_rdr)). | 2014 |\\n| [Steatite Limited](http://www.steatite.co.uk) | Design and manufacture of rugged electronics and embedded systems. Steatite robotics controllers are optimised for use with [ROS2](https://www.steatite-embedded.co.uk/product_categories/robotics/robotic-solutions/) to simplify product development and reduce time to market. | 1938 | \\n| [Stellantis](https://www.stellantis.com) | World leading automakers and mobility provider. Seeking for ROS talent in their Cockpit AI team[^267]. Acquired aiMotive which uses ROS 2. | 2021 |\\n| [Stereolabs](https://www.stereolabs.com/) | Is the leading provider of 3D depth and motion sensing solutions based on stereo vision and artificial intelligence. From robots to drones and cars, Stereolabs empowers machines with the ability to see and understand the world in 3D. Stereo cameras for robotics: [ZED-X](https://www.stereolabs.com/zed-x/) - [ZED2i](https://www.stereolabs.com/zed-2i/). ROS[^310] and ROS2[^311] drivers, with examples and tutorials[^312][^313]. | 2010 | \\n| [STMicroelectronics](https://www.st.com/) | Semiconductor seller. [Micro-ROS module](https://discourse.ros.org/t/micro-ros-module-for-stm32cubemx/19487/1) for [STM32CubeMX](https://www.st.com/en/development-tools/stm32cubemx.html#overview). | 1987 | \\n| [Stogl Robotics](https://www.stoglrobotics.de/) | Is the consulting and engineering services company specialized on Robot Control, software and hardware integration, and use of ROS and ROS2. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^153]. | 2021 |\\n| [Stratom](http://www.stratom.com) | Develop autonomous systems, including drones and robotics. The company use artificial intelligence, machine learning, and autonomous technology to develop innovative solutions for various industries, such as defense, logistics, and agriculture. ROS2 drivers for Stratom (see [`StratomInc`](https://github.com/StratomInc)). | 2001 | \\n| [Sundance Multiprocessor Technology](http://www.sundance.com) | Provide embedded signal processing solutions. Sponsor of the [ROScon](https://roscon.ros.org/world/2020/) 2020. ROSCon is a developers conference [^167]. | 1989 | \\n| [Svenzva Robotics](https://www.svenzva.com/) | Specializes in design the hardware and software to power high-performance robotics.  This broader accessibility facilitates rapid development towards robotic manipulation and automation. the premier product, Revel[^52], is a robotic manipulator. ROS Drivers for the svenzva arm product line (see [`svenzva_ros`](https://github.com/SvenzvaRobotics/svenzva_ros)). | 2017 | \\n| [Swift Navigation](https://www.swiftnav.com) | Offer hardware and software that makes GPS positioning technology available for [autonomous vehicle](https://www.swiftnav.com/automotive) and device guidance. ROS drivers for Swift Navigation (see [`swift-nav`](https://github.com/swift-nav)). | 2012 |\\n| [SyncBotic](https://syncbotic.com/) | Provides software-defined synchronization robot components and makes rugged robot controllers and research & education robot platforms that run ROS and ROS 2. | 2021 |\\n| [Synersight](https://www.synersight.es/) | Provide companies the automation of workflows with automated guided vehicles (AGV). Hiring ROS engineers ([ROS SOFTWARE Programmer](https://www.linkedin.com/jobs/view/3432959263/?eBP=NotAvailableFromMidTier&recommendedFlavor=ACTIVELY_HIRING_COMPANY&refId=u6O4P8%2Fg%2BO%2Fjt43vIHs14A%3D%3D&trackingId=HLhcsuutYvbFzIvxXUwzYg%3D%3D&trk=flagship3_search_srp_jobs)). | 2017 |\\n| [Synkar Autonomous](http://www.synkar.com) | Develop autonomous systems for various industries, such as transportation, logistics, and agriculture. ROS2 drivers for Synkar Autonomous (see [`Synkar`](https://github.com/Synkar)). | 2019 | \\n| [Systems Engineering Consultants Co., LTD.](http://www.sec.co.jp/english/index.html) | Specialist in real-time technology company that contribute to the safety and development of the networked society and strategic focus on network-based real-time services.. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^152]. | 1970 |\\n| [Systemtrio](https://systemtrio.com/) | Provide software and hardware solutions for the transportation and logistics industries. ROS drivers for SystemTrio Robotics (see [`SystemTrio-Robotics`](https://github.com/SystemTrio-Robotics)). | 2014 | \\n| [TAILOS](https://tailos.com/) | Provide safe and cost-efficient automated solutions to the hospitality industry. Tailos decreases the time to clean a room. ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for TAILOS (see [`tailosinc/depthimage_to_laserscan`](https://github.com/tailosinc/depthimage_to_laserscan)). | 2015 | \\n| [Tangram Vision](https://www.tangramvision.com/) | Helps perception teams accelerate development of critical foundations like calibration, fusion, and sensor multiplexing. It can be used with service robots, industrial robots, drones, industrial automation, products with embedded vision. Hiring engineers with experience in ROS ([Perception Sensor Specialist](https://www.salary.com/job/tangram-vision/perception-sensor-specialist/j202204262228276837502)). | 2020 |\\n| [Tata Elxsi](https://www.tataelxsi.com) | Provider of design and technology services across industries including Automotive, Broadcast, Communications, and Healthcare. Hiring ROS engineers ([Automotive Application SW Developer](https://www.tataelxsi.com/careers-experience/tbu-019-automotive-application-sw-developer)). | 1989 | \\n| [TDK InvenSense](http://www.invensense.com) | Develop MEMS sensor platforms found in mobile, wearables, smart home, industrial, and automotive products. [TDK RoboKit1](https://invensense.tdk.com/news-media/tdk-shakes-up-robotics-market-with-next-generation-smartrobotics-platform-tdk-robokit1/) is a robotic platform enables quick prototyping and development for robotic developers, providing a robust hardware platform accompanied by full ROS1 and ROS2 compliant drivers and software algorithms. | 2003 | \\n| [TDS Technology](https://www.tdstech.com/) | Is an industrial automation company for the factory, marine, pharmaceutical, oil, and gas industries. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^157]. | 1996 |\\n| [TechMagic](https://techmagic.co.jp/) | Integrates technologies such as machine learning of artificial intelligence with hardware to make robots intelligent that solve problems in the food industry. Repositories that provides ROS support (see [`TechMagicKK`](https://github.com/TechMagicKK)). | 2018 |\\n| [TECHMAN ROBOT](http://tm-robot.com/) | Is a collaborative robot and vision tech company helping businesses and people through robotic technology applications. Sponsor of the [ROScon](https://roscon.ros.org/2023/) 2023. | 2016 | \\n| [TelemeThing](https://telemething.com/) | Create components for an autonomous drone robotics platform for applications focusing on autonomous navigation, searching, tracking, and visualization. The onboard computer is carried on the UAV, running various AI and CV applications on [ROS](https://telemething.com/). | 2018 |\\n| [TerraClear](https://www.terraclear.com/) | Manufacturing of automation machinery[^14], an automated agricultural implement that clears rocks out of fields. Integrate aerial sensing, machine vision, high-accuracy GPS, and advanced robotics solution. URDF model for Gazebo integrated with ROS (see [`rosbot_description`](https://github.com/TerraClear/rosbot_description)). | 2017 |\\n| [teTra aviation corp](https://www.tetra-aviation.com) | Research, development, manufacture and sales of new aircraft. Hiring ROS engineers ([ROS Engineer](https://www.linkedin.com/jobs/view/3478665844/?eBP=JOB_SEARCH_ORGANIC&recommendedFlavor=ACTIVELY_HIRING_COMPANY&refId=TYJ6wUAy5prj5WNQ6Q4ETw%3D%3D&trackingId=1MZS1Q9EJ47xjXHk9a0TKA%3D%3D&trk=flagship3_search_srp_jobs)). | 2018 | \\n| [Tettix](https://www.tettix.info) | Designs and manufactures industrial automation systems mostly through AMRs. Acting mainly as a robot integrator using ROS and ROS 2. Hiring ROS engineers ([Robotics Software Engineer](https://www.tettix.info/robotics-software-engineer/)). | 2009 |\\n| [Texas Instruments](https://www.ti.com/applications/industrial/robotics.html) | Silicon vendor. Analog and embedded silicon technologies to build robots (microcontrollers, servo drive controllers, power management). | 1930 |\\n| [Textron](http://www.textron.com) | Multi-industry company focused on aircraft, defense, industrial and finance businesses. Using ROS in their robotics activities. Actitively seeking for ROS expertise[^244]. | 1923 |\\n| [The Construct](https://www.theconstructsim.com/) | Provider of both a platform and online robotics training courses around [ROS and ROS 2](https://www.theconstructsim.com/robotigniteacademy_learnros/ros-courses-library/) to grow your robotics skills. | 2015 |\\n| [The ePlane Company](http://www.eplane.ai) | Manufacturing of aviation and aerospace components. Hiring ROS engineers ([Navigation Engineer: Motion Planning](https://in.indeed.com/viewjob?jk=6cc6c5ce186dd93e&tk=1gppq1pd4k998800&from=serp&vjs=3)). | 2017 | \\n| [The Hi-Tech Robotic Systemz Ltd](http://www.thrsl.xyz) | Develop an [autonomous driver assistive systems](https://thrsl.xyz/technology_platform.html) for commercial and industrial vehicles. Hiring ROS engineers ([Software Deployment Engineer](https://www.naukri.com/job-listings-software-deployment-engineer-the-hi-tech-robotic-systemz-limited-ankleshwar-0-to-1-years-041122008297)). | 2014 | \\n| [TIER IV](https://tier4.jp/en/) | Building autonomous-driving cars with ROS and Autoware[^13]. Provides solutions for the commercialization of autonomous vehicles based on the Autoware software. Extension commands for rosbag in ROS 2 (see [`ros2bag_extensions`](https://github.com/tier4/ros2bag_extensions)). | 2015 |\\n| [TinyMobileRobots](https://tinymobilerobots.com/) | Specializes in high-precision outdoor robots that perform marking and stake-out. Combine advanced robotics software with artificial intelligence and high-precision technologies from the land surveying industry to make robots. Code for testing a mobile robot using ROS (see [`Frobit-Simple-Code-Snippets`](https://github.com/tinymobilerobots/Frobit-Simple-Code-Snippets)). | 2015 |\\n| [TIS inc.](https://www.tis.com/) | Offers solutions to improve urban management, help by robots and AI. Sponsor of the [ROScon](https://roscon.ros.org/jp/2018/) JP 2018. ROSCon is a developers conference [^170]. | 1971 | \\n| [TMC](https://tmc-employeneurship.com) | Business and tech consulting and services. ROS is used and seeked in their robotics engineering team[^263] | 2000 | \\n| [TokyoRobotics](https://robotics.tokyo/) | Create humanoid robots and robotic applications. Torobo is a robot developed to accelerate research into industrial applications of full-body humanoid robots[^11]. The robots software is based on ROS (see [`toroboeye_ros`](https://github.com/TokyoRobotics/toroboeye_ros))[^12]. | 2015 |\\n| [Tomahawk Robotics](https://tomahawkrobotics.com/) | Creates safe robotic solutions for unmanned systems in stressful and harsh environments. Tomahawk Robotics\\' Kinesis common control software integrates easily with unmanned systems built on [ROS/ROS2](https://twitter.com/TomahawkRobots/status/1491177615834730499). | 2018 | \\n| [Toposens](http://www.toposens.com) | Build robust and low-cost near-field 3D ultrasonic vision technology for robotics and autonomous vehicles. Custom ROS packages for prototyping with Toposens 3D ultrasound sensors. (see [`ros-packages`](https://gitlab.com/toposens/public/ros-packages))[^179]. | 2015 |\\n| [Torc Robotics](http://torc.ai/) | Develops automated Level 4, Class 8 trucks with Daimler. Provides end-to-end self-driving[^124] software for mobility, trucking, mining, and defense markets.  Hiring engineers with experience in ROS ([Staff Automotive Software Engineer](https://wellfound.com/company/torc-robotics/jobs/2608551-staff-automotive-software-engineer-diagnostics-flashing)). | 2005 |\\n| [Tormach](https://www.tormach.com/) | Manufacture engineering products including CNC mills, routers, grinders, lathes and CNC accessories. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^158]. | 2001 |\\n| [Toyota Research Institute](https://www.tri.global/) | Use artificial intelligence to make automobiles safer. By using ROS, to design the software of the robots and Gazebo for simulation tests. Hiring ROS engineers ([Software Engineer](https://discourse.ros.org/t/ros2-jobs-at-toyota-research-institute-cambridge-ma/5008)). | 2016 |\\n| [Toyota Woven Planet](https://www.woven-planet.global/en) | Group formed to expand and improve operations of Toyota Research Institute for the purpose of developing innovative products that will enable its vision, \"Mobility to Love, Safety to Live”. Uses ROS 2 forks to develop autonomous platforms[^205][^206][^207] | 2021 |\\n| [TRACLabs](http://traclabs.com) | Develop control software, human-robot interfaces, electronic procedure systems, on-board satellite autonomous planning and execution solutions, and other solutions in the field of robotics and automation. Sponsor of the [ROScon](https://roscon.ros.org/world/2020/) 2020. ROSCon is a developers conference [^167]. ROS drivers for TRACLabs (see [`traclabs`](https://github.com/traclabs)) | 1994 | \\n| [Transforma Robotics](http://www.transformarobotics.com) | Develop modular collaborative robotic platforms with data analytics and artificial intelligence to enable safe, cost-effective, and efficient construction. They offer robots and robotic services to the construction industry: Quality Inspectionand Assessment Robot ([QuicaBot](https://www.transformarobotics.com/quicabot)) for construction quality assessment and Spray Painting Robot ([PictoBot](https://www.transformarobotics.com/pictobot)) for indoor wall painting. Hiring ROS engineers ([Software/Robotic Positions at TransformaRobotics](https://discourse.ros.org/t/software-robotic-positions-at-transformarobotics/2778/1)). | 2017 |  \\n| [Trend Micro](www.trendmicro.com) | Create a secure environment for companies and individuals to exchange digital information with Internet content security and threat management solutions. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^159]. | 1988 |\\n| [Trimble](http://www.trimble.com) | Develop positioning technology solutions for surveying, construction, agriculture, public safety and mapping purposes. Hiring engineers with experience in ROS ([Systems Engineer](https://dayton-oh.geebo.com/jobs-online/view/id/1037006150-systems-engineer-at-trimble-/)). | 1978 |\\n| [Triton Medical Robotics](https://tritonrobotics.com) | Medical robotics devices built with ROS that enables doctors to reach deep into human anatomy. Their robots aim to disrupt flexible endoscopy and set a new standard in outcomes for decades to come. Looking for ROS talent[^298] | 2016 |\\n| [Trossen Robotics](http://www.trossenrobotics.com/) | Focus on research and educational robotics who specializes in robotic manipulators / arms[^64]. ROS Packages for Trossen robotics products (see [`interbotix`](https://github.com/interbotix)). | 2005 |\\n| [Tryo Labs](https://tryolabs.com) | Machine learning consulting shop. Use ROS 2 in robotics projects[^234]. | 2009 |\\n| [Tsuk Arm Robotics](https://tsukarm.co.jp/) | Develop technologies such as robot arms ([xArm](https://tsukarm.co.jp/xarm-2)), robot vision, and IoT (Edge Computing), starting from the technology of \"grabbing\" objects with a robot arm. xARm users can extend their functions by providing SDKs for ROS [^173]. | 2021 |\\n| [TuSimple](http://www.tusimple.com) | Is a self-driving truck company developing technology that allows them to drive from depot-to-depot without human intervention. ROS drivers for TuSimple [product](https://www.tusimple.com/product/) (see [`TuSimple`](https://github.com/TuSimple)). | 2015 |\\n| [T-Systems International GmbH](https://www.t-systems.com) | Provide system security to manage the data in a big data analysis method. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^160]. | 2000 |\\n| [UBC AgroBot](https://ubcagrobot.com/) | The company hopes to help accelerate the implementation of automation and robotics in farming. Design a autonomous robot capable of traversing crop rows and performing targeted weed extermination, fertilization and collecting crop data. Incorporate ROS[^122] for communication between subsystems. | 2018 |\\n| [Ubica Robotics GmbH](https://www.ubica-robotics.eu) | Develop autonomous scanning robots for stationery retailers to create digital twins of branches. A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data for Ubica Robotics (see [`ubica-robotics/image_transport_plugins`](https://github.com/ubica-robotics/image_transport_plugins)). | 2020 | \\n| [Ubiquity Robotics](https://www.ubiquityrobotics.com/) | Build platforms with mobility, navigation, power and compute working. The most popular robot is Magni[^40], it is compatible with ROS (see [`magni_robot`](https://github.com/UbiquityRobotics/magni_robot)). | 2016 | \\n| [Udacity](http://www.udacity.com) | Develop an online learning platform offering programs in [artificial intelligence](https://www.udacity.com/enterprise/artificial-intelligence), machine learning, and robotics sector. ROS package for Udacity (see [`udacity`](https://github.com/udacity)). | 2011 |\\n| [Udelv](http://www.udelv.com/) | Focus on autonomous vehicles, paired with uPod delivery technology, enable long-range and high-capacity deliveries that are eco, business and customer-friendly. Hiring engineers with experience in ROS ([Robotics Software Engineer](https://boards.greenhouse.io/udelv/jobs/4185013003)). | 2017 | \\n| [UFACTORY](http://www.ufactory.cc) | Develop and manufacture robotics systems. Focus on creating robotic arms. ROS Drivers for communicating with UFACTORY robotics arms (see [`uArm-Developer`](https://github.com/uArm-Developer)). | 2013 |\\n| [Uhnder](http://www.uhnder.com/) | Develop a digital automotive radar-on-chip designed to automate systems for safety and better feedback response. Hiring ROS engineers ([Senior/Software Engineer](https://app.trinethire.com/companies/32235-uhnder-inc/jobs/64347-senior-software-engineer-system-integration?ref=www.uncrewedengineeringjobs.com)). | 2015 | \\n| [Unbox Robotics](https://unboxrobotics.com/) | Builds software-defined robotics systems to enable logistics players to automate and radically improve their operations on-demand in a limited footprint and capital. Hiring ROS engineers ([Robotics Software Engineer](https://www.spottabl.com/unboxrobotics/robotics-software-engineer-213974)). | 2019 | \\n| [Unibap AB](https://unibap.com) | Provide industrial automation and robotics solutions to a variety of industries. Focus on developing intelligent robotic systems that can be used in manufacturing, logistics, and other industrial applications. ROS drivers for Unibap AB (see [`Unibap`](https://github.com/Unibap)). | 2013 | \\n| [United Robotics Group](https://unitedrobotics.group) | Young service robotics companies into a unique ecosystem by bundling hardware and software expertise under one roof. Using ROS across companies in the group. Acquired Robotnik who\\'s a very active user of ROS[^309] | 2019 | \\n| [United Robots](https://www.unitedrobots.co/) | Mobile robotic solutions for safer, cleaner and healthier spaces  Uses ROS and Navigation stack to build their robots. Hiring engineers with experience in ROS ([Senior C++ Engineer](https://jobs.unitedrobots.co/jobs/1451848-senior-c-engineer)). | 2016 | \\n| [Unitree](https://www.unitree.com/) | Focus on the development, production and sales of high-performance quadruped robots[^83]. The company develop robot core components, motion control, robot perception, etc. ROS simulation packages for Unitree robots (see [`unitree_ros`](https://github.com/unitreerobotics/unitree_ros)). | 2016 |\\n| [Unity](https://unity.com/solutions/automotive-transportation-manufacturing/robotics) | Experimentation platform that  create and model highly customizable real-world situations for robot design and simulations. This is a central repository for tools, tutorials, resources, and documentation about ROS in Unity (see [`Unity-Robotics-Hub`](https://github.com/Unity-Technologies/Unity-Robotics-Hub))[^8].| 2004 |\\n| [Universal Field Robots](http://universalfieldrobots.com.au/) | Is an engineering company that offers machine learning, artificial intelligence, research, and development services. ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Universal Field Robots (see [`universal-field-robots/vision_opencv`](https://github.com/universal-field-robots/vision_opencv)). | 2015 | \\n| [Universal Robots](https://www.universal-robots.com/) | Develop and sell industrial robots that automate industrial processes. The ROS driver works with all UR cobots that come with a CB3 or UR series. Hosts drivers for usage with the ROS (see [`UniversalRobots`](https://github.com/UniversalRobots))[^9] for CB3 and e-Series where RTDE is available.   | 2005 |\\n| [Unmanned Life](http://unmanned.life) | Software platform for seamless orchestration of autonomous robotics. Unmanned Life software platform is capable of integrating different technologies, suchas AI, 5G and Edge computing with multiple robots such as drones and autonomous mobile robots (AMRs). ROS2 drivers for Unmanned Life (see [`umdlife`](https://github.com/umdlife)). | 2015 | \\n| [Urban Machine](http://www.urbanmachine.build) | Construction company that manufactures reclaims and co-creates locally sourced premium lumber products. Open3D analog to perception_pcl, containing conversion functions from Open3D to/from ROS types for Urban Machine (see [`UrbanMachine/perception_open3d`](https://github.com/UrbanMachine/perception_open3d)). | 2021 | \\n| [UVD Robots](https://uvd.blue-ocean-robotics.com/) | Autonomous disinfection robots using ultraviolet (UV) light. Hiring engineers with experience in ROS ([Robotics Software Developer](https://discourse.ros.org/t/robotics-software-developer-to-develop-uvd-robots-blue-ocean-robotics/24170)). | 2016 |\\n| [UVify](https://www.uvify.com/) | Is a developer and manufacturer of high-performance drones, autonomous technologies, and related hardware and software. ROS drivers for UVify (see [`uvify`](https://github.com/uvify)). | 2014 |\\n| [U POWER](https://upower.com/) | An automotive company that empowers clients and brings Car-as-a-Service (CaaS) capabilities to their projects. Hiring ROS engineers ([Sr. Embedded and System Software Engineer](https://www.linkedin.com/jobs/view/sr-embedded-and-system-software-engineer-adas-ad-middleware-ros2-dds-rmw-at-u-power-3618258703/)). | 2021 | \\n| [Vaarst](https://vaarst.com/) | Develop robotic analytic solutions designed for ocean applications. Vaarst uses computer vision technology to capture, and for storing, managing, and analyzing data, it features live streaming and geo-referencing capabilities. PCL (Point Cloud Library) ROS interface stack for Vaarst (see [`rovco/perception_pcl`](https://github.com/rovco/perception_pcl)). | 2015 | \\n| [Valeo](https://www.valeo.com/) | Company innovating in automotive electrification & micromobility. Partner to all automakers worldwide. Using ROS in their development and engineering services. Actively seeking for ROS talent[^248]. | 1923 |\\n| [Vayu Robotics](http://www.vayurobotics.com) | Develop automotive sensing, autonomous vehicles, and robotics technology. The company builds robotics platforms using bio-inspired sensing, scalable machine learning, and purposeful robotic design. ROS2 drivers for Vayu Robotics (see [`Vayu-Robotics`](https://github.com/Vayu-Robotics)). | 2022 | \\n| [Vecna Robotics](http://vecnarobotics.com) | Create and commercialize health care solutions in the areas of robotics, patient safety, infection control, and patient self-service. Hiring engineers with experience in ROS ([Senior Robotics Software Engineer](https://discourse.ros.org/t/senior-robotics-software-engineer/22466/1)). | 1998 |\\n| [VECROS](http://www.vecros.com) | Offer a range of products and services, including robotics consulting, design and development, and integration and deployment. Hiring ROS engineers ([Robotics Software Development](https://www.freshersworld.com/jobs/robotics-software-development-jobs-opening-in-vecros-technologies-private-limited-at-delhi-1531291)). | 2018 | \\n| [Vention](https://vention.io/) |  Platform to Design, Automate, Order, and Deploy automated equipment. Looking for ROS talent for their automation equipment[^285].  | 2016 |\\n| [Viam](http://www.viam.com/) | Software platform that simplifies turning great ideas into smart machines in production. Viam lets users configure & build, code, manage & scale, and do more with their smart machine fleets in the cloud, all from a single platform. Sponsor of the [ROScon](https://roscon.ros.org/2023/) 2023. ROSCon is a developers conference [^379]. | 2020 | \\n| [Vicarious](http://vicarious.com) | Is a firm that develops general intelligence for robots using artificial intelligence and the computational principles of the brain[^10]. Wrappers, tools and additional API\\'s for using ROS with the Gazebo simulator (see [`gazebo_ros_pkgs`](https://github.com/vicariousinc/gazebo_ros_pkgs)). | 2010 |\\n| [Visteon Corporation](http://www.visteon.com) | Design and manufactures vehicle cockpit electronics products, connected car & electrification solutions. Also, advanced driver assistance systems (ADAS). Hiring ROS engineers ([ADAS Systems Integration Engineer](https://www.disabledperson.com/jobs/34862126-adas-systems-integration-engineer)). | 2000 | \\n| [Vistion](https://vistion.si) | Hardware and software system integration. Machine vision systems. Use ROS across their offering[^236] | 2017 |\\n| [Volador FlyTech](http://www.voladorft.com/) | Provide drone solutions for various industries and applications. Their offerings include multi-rotor drones, software and hardware solutions, as well as services such as aerial photography and mapping. Hiring ROS engineers ([Robotics/UAS Control Engineer](https://www.linkedin.com/jobs/view/robotics-uas-control-engineer-at-volador-flytech-3440929186/?originalSubdomain=uk)). | 2018 | \\n| [Volvo Group](https://www.volvogroup.com/) | Manufacture trucks, buses, construction equipment, and marine and industrial engines. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^161]. | 1927 |\\n| [Vortex Robotics](http://www.vortex-co.com) | Provide marine services like tank inspection, underwater filming, pipeline inspection and visual sonar inspection. ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Vortex Robotics (see [`VorteX-co/vision_opencv`](https://github.com/VorteX-co/vision_opencv)). | 2016 | \\n| [Wandelbots](http://www.wandelbots.com) | Develop software for industrial robots. Their flagship product is Wandelbot, a collaborative robot (cobot) that can be trained by non-experts to perform a wide range of tasks using a simple, gesture-based interface. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 2017 | \\n| [WeGo-Robotics](https://wego-robotics.com) | Company building solutions using ROS and doing system integration with it for labs, as well as Proof of Concepts. System integration using [`MoveIt`](https://github.com/ros-planning/moveit) for controlling Manipulator or [`Navigation Stack`](https://github.com/ros-planning/navigation) for controlling Mobile Robot or both for Mobile Manipulator. Mainly based on `ROS`, but started to support `ROS2`. (2022) (see [`WeGo-Robotics`](https://github.com/WeGo-Robotics)). | 2016 |\\n| [Weston Robot](https://www.westonrobot.com/) | Develop integrated robotics solutions. The company\\'s products include [exoskeletons](https://www.westonrobot.com/industrial-exoskeleton), [outdoor](https://www.westonrobot.com/ground-UGV) robots, robotic [arms](https://www.westonrobot.com/robot-arm) and hands, warehousing and logistics robots. ROS drivers (see [`westonrobot`](https://github.com/westonrobot)). | 2019 |\\n| [WHILL](https://whill.inc/jp/) | Design and create personal mobility products. The robots\\' software is based on ROS [^2]. A ROS package is available for R&D purposes (see [`ros_whill`](https://github.com/WHILL/ros_whill))[^3]. | 2012 |\\n| [Wind River](http://www.windriver.com) | Provide software and services for embedded systems and the Internet of Things (IoT). Their products include operating systems, development tools, and middleware for embedded devices, as well as software for edge computing, industrial automation, and autonomous systems. ROS used for industrial use cases. Participation in ROS-Industrial Conference 2022. | 1981 |  \\n| [Woodside](www.woodside.com.au) | Is an exploration and production company. Woodside is the largest operator of oil and gas production in Australia and also it\\'s largest independent dedicated oil and gas company. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^162]. | 1954 |\\n| [Wyca Robotics](https://www.wyca-robotics.fr/) | Indoor autonomous mobile robot platform for system integrators that leverages ROS 2 subprojects[^212] for their Elodie robot. | 2015 |\\n| [Xaxxon Technologies](http://www.xaxxon.com/) | Develop a surveillance robot called the Oculus Prime[^60] which can be used for automated surveillance of private property. ROS packages for Oculus Prime Robot (see [`oculusprime_ros`](https://github.com/xaxxontech/oculusprime_ros)). | 2008 | \\n| [Xsens](http://www.xsens.com) | Is a company specializing in the field of 3D motion tracking technologies. ROS node driver for Xsens devices. (see [`xsens_mti_ros_node`](https://github.com/xsens/xsens_mti_ros_node)). | 2000 |\\n| [X - ENDER](https://www.x-ender.com/) | Develope decentralized control systems to enable full and functional autonomy over groups of heavy autonomous drones for agriculture and firefighting, autonomous tractors, smartcities management and much more. Hiring engineers with experience in ROS ([ROS developer](https://www.linkedin.com/jobs/view/3739750233)). | 2020 | \\n| [Yaak](http://www.yaak.ai) | Develop an autonomous driving platform. ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Yaak (see [`yaak-ai/vision_opencv`](https://github.com/yaak-ai/vision_opencv)). | 2020 | \\n| [Yaskawa Motoman](https://www.motoman.com) | Provided automation products and solutions for industry and robotic application. A wide range of robotic arms[^37]. [ROS 2](https://www.motoman.com/en-us/about/blog/ros-2-and-what-it-means-for-your-yaskawa-robotic-a) and what it means for your yaskawa robotic application development | 1989 | \\n| [YoGoKo](http://www.yogoko.com) | Is a communication solutions provider for the connected, cooperative & autonomous vehicles evolving in intelligent environments. Can be integrated into a diversity of hardware and software platforms designed by third parties. ,also includes autonomous vehicle development software ([ROS](https://www.yogoko.com/solutions/y-smart-technology-description/)). | 2014 |\\n| [Yokogawa](https://www.yokogawa.com/sg/) | Is a electrical engineering and software company, with businesses based on its measurement, control, and information technologies. The company is [currently member](https://rosindustrial.org/current-members) of ROS-Industrial, is an open-source project that extends the advanced capabilities of ROS to manufacturing automation and robotics (see [`ros-industrial`](https://github.com/ros-industrial))[^163]. | 1957 |\\n| [Yujin Robot](https://yujinrobot.com/) | Offer products and services such as factory automation, autonomous mobile robots, mobile platform demo kits for research purposes, LiDAR sensors, SLAM technology and navigation software. Tools and utilities for development with ROS build environments (see [`yujin_tools`](https://github.com/yujinrobot/yujin_tools)). | 1988 |\\n| [Yuman](https://yuman-robots.com/) | Develop autonomous mobile robots that automate the transport of small equipment in hospital wards that nurses need when caring for their patients. Hiring ROS engineers ([Robotics Engineer](https://thehub.io/jobs/6332b59560ad5faa531a1078)). | 2022 | \\n| [YZ Robot](http://www.yzrobot.cn/en/) | Specializes in the research and development of AI products. \"ROSYZ Robot kits\" are [ROS](http://www.yzrobot.cn/en/about-48-1.html) robot platforms which are prepared for students and robot fans who studying ROS and want to own a low cost high performance ROS open source platform.  | 2014 |\\n| [Zebra Technologies](https://www.zebra.com/es/es.html) | Global leader in barcode printing and RTLS technology including printers, RFID, software and supplies. Sponsor of the [ROScon](https://roscon.ros.org/2022/). | 1969 | \\n| [Zendar](https://www.zendar.io/) | Develop high-definition [radar](https://www.zendar.io/technology) for autonomous vehicles. They offer [satellite radar systems](https://www.zendar.io/products) for cars, agriculture, robots and trucks. ROS drivers for Zendar radars (see [`ZendarInc`](https://github.com/ZendarInc)). | 2017 |\\n| [Zeropoint Robotics](https://www.zeropointrobotics.com/) | Design and develop Autonomous Mobile Robots that collaborate with humans. Hiring ROS engineers ([Robotics Software Engineer](https://www.freshersworld.com/jobs/robotics-software-engineer-jobs-in-bangalore-zeropoint-robotics-pvt-ltd-940633)). | 2019 | \\n| [ZettaScale Technology](https://www.zettascale.tech) | The company develops open source communication middleware that underpins next-generation robotics, transportation and mission critical applications. Sponsor of the [ROScon](https://roscon.ros.org/2022/). | 2022 | \\n| [Zhen Robotics](http://www.zhenrobot.com/) | Develop package for delivery robots. Hiring ROS engineers ([ROS Development Engineer](http://www.zhenrobot.com/career_en.html)). | 2016 | \\n| [ZF](https://www.zf.com/mobile/en/homepage/homepage.html) | Company supplies systems for passenger cars, commercial vehicles and industrial technology in four technology domains: Vehicle Motion Control, Integrated Safety, Automated Driving, and Electric Mobility. They are known to be using ROS 2 forks[^210] to develop software. | 1915 | \\n| [Zipline](https://www.flyzipline.com/) | Design, manufacture and operate drones to deliver vital medical products. Hiring engineers with experience in ROS ([Junior Embedded Systems Software Engineer](https://www.wayup.com/i-j-ZipLine-307782695030606/)). | 2014 | \\n| [Zivid](https://www.zivid.com) | Provide of industrial 3D machine vision cameras and vision software for autonomous industrial robot cells, collaborative robot (cobot) cells and other industrial automation systems. ROS driver for Zivid 3D cameras (see [`zivid/zivid-ros`](https://github.com/zivid/zivid-ros)). | 2015 | \\n| [ZMP](https://www.zmp.co.jp/en) | Provide robot infrastructure,  autonomous vehicles[^53], automotive technology and sensing technology[^54]. ROS Nodes for RoboCar[^55] (see [`robocar110_ros`](https://github.com/zmp/robocar110_ros)). | 2001 | \\n| [ZVISION](http://www.zvision.xyz) | Provide [automotive-grade](http://www.zvision.xyz/en/Solution/index.aspx) solid-state LiDAR solution for autonomous driving applications. ROS driver for ZVISION Lidar (see [`zvision_ros_driver`](https://github.com/ZVISION-lidar/zvision_ros_driver)). | 2017 |\\n| [4am Robotics](https://www.4am-robotics.com/en/) | Develop mobile robot assistants designed to assist humans in their daily lives. Hiring engineers with experience in ROS ([Softwareentwickler ROS Mobile Robotik (m/w/d)](https://www.linkedin.com/jobs/view/3724898600)). | 2022 | \\n<!-- !end-companies! -->\\n\\n### Companies acquired, closed or inactive\\n<!-- !acquired! -->\\n| Company | Description | Year Founded | Reason |\\n|---------|-------------|--------------|--------|\\n| [Acutronic Robotics](https://web.archive.org/web/20190630193757/https://acutronicrobotics.com/) | DARPA and Sony backed company offering modularity for industrial robots. ROS 2-native  hardware components for robots. System integration. H-ROS (Hardware Robot Operating System). | 2016 | <ins>Closed</ins>, lack of funding[^188] (2019) |\\n| [aiMotive](https://aimotive.com/) | Deliver software, tools and hardware products complemented by proprietary [data management tools](https://aimotive.com/solutions) to use in [automated driving](https://aimotive.com/aidata). [aiSim](https://aimotive.com/aisim) is a ASIL-D certified simulator tool, has integrated ROS2[^127]. | 2015 | **Acquired** (2022, Stellantis) [^286] [^287]|\\n| [Aldebaran Robotics](https://web.archive.org/web/20160101095830/https://www.aldebaran.com/en) |  Aldebaran Robotics designs, manufactures, and sells autonomous humanoid robots for entertainment purposes.| 2005 | **Acquired** (2012, Softbank Robotics, 100M USD) |\\n| [Argo AI](http://www.argo.ai) | Ford and VW-backed company that offered autonomy products and services. Argo designs its Autonomy Platform and Solutions to support autonomous [ridesharing](https://www.argo.ai/services/#built-to-drive) and goods [delivery](https://www.argo.ai/services/#built-to-deliver). Hiring ROS engineers ([Hardware, Radar Integration Engineer](https://boards.greenhouse.io/argo/jobs/4320653)). | 2016 | <ins>Closed</ins>, investors shift resources to developing advanced driver assistance systems (Level 2 and 3 autonomy), and not autonomous vehicle technology (Level 4 autonomy)[^272][^273] (2022) |\\n| [AutonomousStuff](https://autonomoustuff.com/) | Autonomy-enabling technologies and world class services. Using ROS across products and services. Involved in various projects with architectures built with ROS. Authors of various ROS drivers. | 2010 | **Acquired** (2018, Hexagon)\\n| [Clearpath Robotics](https://clearpathrobotics.com/) | Manufacturer of robot development platforms, each with ROS-support. Focused on unmanned ground vehicles, unmanned surface vehicles (waterborne), and other industrial vehicles. | 2009 | **Acquired** (2023, Rockwell Automation) [^378] |\\n| [Cruise](https://www.getcruise.com/) | Build self-driving vehicles using ROS. Various community contributions, hiring actively for ROS expertise.  | 2013 | **Acquired**[^306] (2016, General Motors) |\\n| [Drag&bot](http://www.dragandbot.com) | No-code robot programming software for flexible use of industrial robots with an easy-to-use UI. drag&bot uses an abstracted interface called [`robot-movemvent-interface (RMI)`](https://github.com/dragandbot/dnb_robot_movement_interface) to command any industrial robot and kinematic in a unified way. ROS Noetic is currently the used distribution. The `tf` library aswell as the ROSBridge are core components for the software. Moreover drag&bot can be tested in the cloud for free using this link for [`registration`](https://www.dragandbot.com/get-started/robot-simulation/). | 2017 | **Acquired**[^266] (2022, KEBA) |\\n| [Erle Robotics](https://web.archive.org/web/20161124120233/http://erlerobotics.com/) | Linux and ROS-based autopilots for drones. DIY robotic kits | 2014 | **Acquired** (2016, Acutronic Robotics) |\\n| [Fetch Robotics](https://fetchrobotics.com/) | Autonomous Mobile Robots (AMRs) for the warehousing. Designed with the ROS framework (see [`fetch_ros`](https://github.com/fetchrobotics/fetch_ros))[^104]. | 2014 | **Acquired**[^189] (2021, Zebra Technologies, $290M[^305]) |\\n| [iRobot](https://www.irobot.com/) | Design and builds consumer robots, include mapping and navigation systems. Launched educational robot platform that support for ROS 2 [^94] | 1990 |  **Acquired**[^302] (2021, Amazon, 1.7B USD) |\\n| [Luxoft](https://www.luxoft.com/) | Luxoft is the design, data and development arm of DXC Technology, providing bespoke, end-to-end technology solutions for mission critical systems, products and services. Hiring ROS engineers ([Senior C++ Automotive Software Developer](https://career.luxoft.com/job/senior-c-automotive-software-developer/337285/)). | 2000 | **Acquired** (2019, DXC Technology[^299]) |\\n| [Modbot](https://www.modbot.com) | ROS-enabled[^184][^185] innovative modular robotics platforms | 2014 | *Inactive*  |\\n| [Open Robotics](https://www.openrobotics.org/) | ROS and ROS 2 maintainers. Engineering services in robotics for creating both hardware and software solutions | 2012 | **Acquired** (2022, Intrinsic[^301]) |\\n| [Planck Aerosystems](https://www.planckaero.com/) | Designs and builds autonomy and navigation solutions for unmanned systems using various open open source robotics technologies, including ROS and Gazebo. Job offers requiring ROS and Gazebo *knowhow* [^195].  | 2014 | **Acquired** (2022, AeroVironment[^196]) |\\n| [Rethink Robotics](http://www.rethinkrobotics.com) | Created ROS-based collaborative compliant robotic arms for use in manufacturing facilities[^41] (see [`RethinkRobotics`](https://github.com/RethinkRobotics)). | 2008 | <ins>Closed</ins> (2018), short on cash as its sales failed to meet expectations, later integrated in HAHN Group |\\n| [Robotnik](https://robotnik.eu/) | Manufacturer of service robots built with ROS. They design mobile robots, UGVs, and other mobile robots for industrial and logistics applications. ROS Drivers for [collaborative robots](https://robotnik.eu/products/) (see [`RobotnikAutomation`](https://github.com/RobotnikAutomation)).  | 2002 | **Acquired** (2023, United Robotics Group[^309]) |\\n| [Rocos](https://web.archive.org/web/20200723041448/https://www.rocos.io/) | Cloud platform to build and manage your robot operations. Offered ROS 2 connectors. | 2017 | **Acquired** (2021, DroneDeploy) |\\n| [Rovenso](https://www.rovenso.com/) | Autonomous Robots for Security and Safety Monitoring of Industrial Sites. Using ROS to build their autonomy stack. | 2016 | <ins>Closed</ins>, out of cash[^259] (2022) |\\n| [TechnoYantra](https://www.technoyantra.com/) | Developing robotic technologies using ROS for various applications like mapping. navigation, SLAM, image processing, etc... TortoiseBot is an ROS-based open-sourced mobile robot applications (see [`tortoisebot`](https://github.com/TechnoYantra/tortoisebot)). | 2020 | **Acquired** (2022, Acceleration Robotics[^300]) |\\n| [Unbounded Robotics](https://web.archive.org/web/20131030012058/http://unboundedrobotics.com/) | Building the next generation of advanced, affordable, mobile manipulation platforms with ROS | 2013 | <ins>Closed</ins> (2014), issues with the Willow Garage spin-off agreement which prevented them from raising an A round |\\n| [Verb Surgical](https://www.linkedin.com/company/verb-surgical/about/) | Building the next generation of advanced, affordable, mobile manipulation platforms with ROS | 2015 | **Acquired**[^189] (2019, Johnson & Johnson) |\\n| [Waypoint Robotics](http://waypointrobotics.com) | Build autonomous mobile robots. In addition to designing the robots, they also offer accessories. ROSBridge to use interfaces on Waypoint Robotics robots (see [`waypoint-rosbridge-ros-api`](https://github.com/waypointrobotics/waypoint-rosbridge-ros-api)). | 2016 | **Acquired** (2021, Locus Robotics) |\\n| [Wind River](https://www.windriver.com/) |  A global leader in delivering software for mission-critical intelligent systems. Behind VxWorks RTOS. Contributor to the ROS community and member of the TSC | 1981 | **Acquired** (2022, Aptiv, $3.5 billion[^303][^304]) |\\n| [Xilinx](https://www.xilinx.com) | Adaptive computing leader. Creator of the FPGA. Various robotics silicon solutions featuring CPUs and FPGAs. Kria SOMs robotics strategy was built around ROS 2[^218] | 1984 | **Acquired** (2021, AMD, $35 billion[^219]) |\\n| [5D Robotics](https://web.archive.org/web/20180319195556/https://5drobotics.com/) | 5D Robotics is a software company that accelerates human productivity and safety in an evolving, dynamic world. | 2009 | **Acquired** (2018, Humatics) |\\n| [6 River Systems](https://6river.com/) | Manufacturer of autonomous mobile robots (AMRs) built with ROS, artificial intelligence and operational experience. Through the use of robotics[^4], they make warehouses more efficient[^5].| 2015 | **Acquired** (2019, Shopify, 450M USD) |\\n<!-- !end-acquired! -->\\n\\n\\n### Contribute\\n\\nSend a Pull Request with additions, modifications or removals. For new contributions, **please indicate how you\\'re using ROS** (which distro you\\'re using, which packages, etc.). Make sure to hint how you\\'re related to the organization if suggesting a relevant change.\\n\\n### Criteria\\n\\nThe criteria to be included in the list is as follows:\\n- The company must be known to use ROS or ROS 2 for development, to create products, to offer services or who ships ROS with or as part of their product(s).\\n- Ideally, there should be a public reference to the company using ROS or ROS 2. This can be a blog post, a press release, a video, a tweet, a GitHub repository, a LinkedIn job offer highlighting their ROS focus, etc.\\n\\n**NOTE**: *Third party ROS drivers (e.g. community) or technology connectors (e.g. bridges) for a particular company\\'s product or technology should not considered a reference to the company using ROS or ROS 2*.\\n\\n### `ROS` stacks\\n\\nLists companies known to use popular ROS stacks.\\n\\n#### Navigation\\nLists companies known to use the ROS Navigation stack and ROS 2\\'s Nav2 framework.\\n\\n<!-- !navigation! -->\\n| Company | Description | Year Founded| \\n|---------|-------------|-------------|\\n| [ADLATUS Robotics GmbH](http://www.adlatus-robotics.com) | Uses the Nav2 stack for autonomous mobile robots to use in industrial environments such as manufacturing, logistics, and warehousing (see [`adlatusrobotics/navigation2`](https://github.com/adlatusrobotics/navigation2)). | 2015 | \\n| [ADLINK Technology](https://www.adlinktech.com/en/index) | ADLINK is using Navigation stack in their products like the [ROScube-X series](https://www.adlinktech.com/Products/Download.ashx?type=MDownload&isDatasheet=yes&file=1783%5CROScube-X_series_DS.pdf) of embedded systems for robots. ADLINK offers a [AMR visual SLAM navigation solution](https://www.adlinktech.com/en/kudan-amr-visual-slam). Empowering tracking in Autonomous Mobile Robots (AMRs). ROS2 Navigation (see [`Adlink-ROS/navigation2`](https://github.com/Adlink-ROS/navigation2)). | 1995 |\\n| [Angsa Robotics](https://angsa-robotics.com) | Uses ROS and Navigation stack to build their robots (see [`angsa-robotics/navigation2`](https://github.com/angsa-robotics/navigation2)). | 2019 | \\n| [ANYbotics](https://www.anybotics.com/) | The company uses the ROS Navigation stack to enable their robots to navigate autonomously in complex environments. ROS Navigation stack (see [`ANYbotics/navigation_ros`](https://github.com/ANYbotics/navigation_ros)). | 2016 |\\n| [A&K Robotics](http://www.AandKrobotics.com) | Uses the ROS Navigation stack to enable their robots to navigate autonomously in indoor environments. ROS Navigation stack (see [`akrobotics/navigation`](https://github.com/akrobotics/navigation)). | 2015 |\\n| [Badger Technologies](http://www.badger-technologies.com/) | Badger Technologies uses this stack to enable their robots to navigate around the store and avoid obstacles, while also localizing themselves in the store\\'s map. ROS Navigation stack (see [`BadgerTechnologies/navigation`](https://github.com/BadgerTechnologies/navigation)). | 2017 | \\n| [Beta Robots](https://beta-robots.com/) | Use the ROS Navigation stack to provide autonomous navigation capabilities to their mobile robots. ROS Navigation stack (see [`beta-robots/navigation`](https://github.com/beta-robots/navigation)). | 2016 |\\n| [Birds Eye Robotics](https://www.birdseyerobotics.com) | A list of robots using ROS Navigation stack and ROS 2\\'s Nav2 framework (see [`Robots`](https://navigation.ros.org/about/robots.html)). | 2021 |\\n| [BlueSpace.ai](http://www.bluespace.ai) | Uses the Nav2 Stack to test and validate their autonomous navigation systems in simulated and real-world environments (see [`njtech-robomaster/navigation2`](https://github.com/njtech-robomaster/navigation2)). | 2019 |\\n| [Bluewhale Robot](http://www.bwbot.org) | The company uses the ROS Navigation stack to provide advanced navigation capabilities to its robots. ROS Navigation stack (see [`BluewhaleRobot/navigation`](https://github.com/BluewhaleRobot/navigation)). | 2015 | \\n| [Bosch](https://www.bosch.com/) | Uses the Nav2 stack, an open-source robotic navigation stack, in their autonomous systems, such as AMRs and self-driving cars (see [`boschresearch/navigation2`](https://github.com/boschresearch/navigation2)).   | 1886 | \\n| [BotsAndUs](https://www.botsandus.com/) | They use the Nav2 stack to help their robots navigate autonomously in various environments. (see [`botsandus/navigation2`](https://github.com/botsandus/navigation2)). | 2015 |\\n| [Brisa Robótica](https://www.brisa.tech/) | Automate existing vehicles or develop new ones. Uses ROS and Navigation stack to build their robots (see [`brisa-robotics/navigation2`](https://github.com/brisa-robotics/navigation2)). | 2018 |\\n| [Coalescent Mobile Robotics](https://cm-robotics.com/) | Uses the Nav2 stack to help their robots navigate through various environments (see [`cmrobotics/navigation2`](https://github.com/cmrobotics/navigation2)). | 2018 |\\n| [Dexory](http://dexory.com) | A list of robots using ROS Navigation stack and ROS 2\\'s Nav2 framework (see [`Robots`](https://navigation.ros.org/about/robots.html)). | 2015 |\\n| [Dorabot](https://www.dorabot.com/) | The company uses the ROS Navigation stack to enable its robots to navigate through indoor environments and perform tasks such as transporting goods, picking and placing items, and inventory management. ROS Navigation stack (see [`dorabot/navigation`](https://github.com/dorabot/navigation)). | 2015 |\\n| [Dyno Robotics](http://www.dynorobotics.se) | Uses ROS and Navigation stack to build their robots (see [`DynoRobotics/navigation2`](https://github.com/DynoRobotics/navigation2)). | 2018 | \\n| [Elroy Air](http://elroyair.com) | Uses ROS and Navigation stack to build their robots (see [`Robots`](https://navigation.ros.org/about/robots.html)). | 2016 | \\n| [FastSense](http://www.fastsense.tech) | Uses the Nav2 Stack to develop and implement navigation capabilities in their products (see [`FastSense/navigation2`](https://github.com/FastSense/navigation2)). | 2017 | \\n| [FireFly Automatix](https://fireflyautomatix.com) | Uses Nav2 Stack to develop and implement autonomous navigation capabilities in their products (see [`fireflyautomatix/navigation2`](https://github.com/fireflyautomatix/navigation2)). | 2010 | \\n| [FloMobility](https://flomobility.com) | Build autonomous lawnmowers, for the communication between electronics they are using ROS and [Navigation stack](https://www.linkedin.com/posts/mohansivam_we-at-flo-mobility-are-looking-for-ros-interns-activity-7022084995691290624-RoFV/?originalSubdomain=in).  | 2019|\\n| [GITAI](http://gitai.tech/) | Uses ROS and Navigation stack to build their robots. ROS Navigation stack (see [`GITAI/navigation`](https://github.com/GITAI/navigation)). | 2016 | \\n| [Helgen Technologies](https://www.helgen.tech) | They use the Nav2 Stack to create autonomous navigation solutions for unmanned aerial vehicles (UAVs), autonomous underwater vehicles (AUVs), and ground vehicles (see [`Helgen-Tech/navigation2`](https://github.com/Helgen-Tech/navigation2)). | 2021 |\\n| [Hyundai](https://www.hyundai.com/eu.html) | Uses the Nav2 Stack to develop and implement autonomous navigation capabilities in their vehicles. This includes using the stack to process sensor data, plan and execute safe and efficient routes, and make decisions in real-time to navigate the vehicle through its environment (see [`HYUNDAI-Robotics-Autonomous-Engineering/navigation2`](https://github.com/HYUNDAI-Robotics-Autonomous-Engineering/navigation2)). | 2000 |\\n| [InDro Robotics](https://indrorobotics.ca/) | Uses ROS and Navigation stack to build their robots (see [`indro-robotics/navigation2_velocity_smoother`](https://github.com/indro-robotics/navigation2_velocity_smoother)) | 2014 |\\n| [Intermodalics](http://www.intermodalics.eu) | Use the ROS Navigation stack to develop autonomous navigation capabilities for mobile robots. ROS Navigation stack (see [`Intermodalics/navigation`](https://github.com/Intermodalics/navigation)). | 2010 |\\n| [Kiwibot](https://www.kiwibot.com/) | Uses Nav2 in their delivery robots to enable them to navigate and move around in the environment safely and efficiently (see [`kiwicampus/navigation2`](https://github.com/kiwicampus/navigation2)). | 2017 |\\n| [Locus Robotics](https://locusrobotics.com/industry_solutions/industrial/) | Uses  Nav2 in their autonomous mobile robots, which are designed for warehouse automation. These robots use the Nav2 stack to localize themselves in the warehouse environment, map the warehouse, and plan and execute safe and efficient paths to move products from one location to another. (see [`locusrobotics/robot_navigation`](https://github.com/locusrobotics/robot_navigation)). | 2014 |\\n| [Magazino GmbH](https://www.magazino.eu/?lang=en) | Magazino GmbH incorporates the ROS Navigation stack into their robot systems to achieve autonomous navigation and obstacle avoidance capabilities. ROS Navigation stack (see [`magazino/navigation`](https://github.com/magazino/navigation)). | 2014 |\\n| [Motius](https://motius.de/) | Uses Nav2 stack, a collection of open-source software tools and libraries, to develop and implement autonomous navigation capabilities for their clients. (see [`motius/navigation2`](https://github.com/motius/navigation2)). | 2013 | \\n| [Neobotix GmbH](https://www.neobotix-robots.com/homepage) | Uses the Nav2 Stack to integrate with other systems, such as mapping and localization tools, to further enhance the robot\\'s navigation capabilities (see [`neobotix/navigation2`](https://github.com/neobotix/navigation2)). | 2010 |\\n| [Nexuni Co. Ltd.](www.nexuni.com) | Uses ROS and Navigation stack to build their robots (see [`nexuni/navigation2`](https://github.com/nexuni/navigation2)). | 2019 | \\n| [Nobleo Technology](https://nobleo-technology.nl/) | Uses the Nav2 Stackto develop and implement navigation capabilities in their sensors (see [`nobleo/navigation2`](https://github.com/nobleo/navigation2)). | 2011 | \\n| [PAL Robotics](https://pal-robotics.com/) | Uses the Nav2 stack as a part of their navigation software system for autonomous robots (see [`pal-robotics-forks/navigation2`](https://github.com/pal-robotics-forks/navigation2)). | 2004 |\\n| [Peppermint Robots](https://getpeppermint.co/) | Uses the Nav2 stack for its robot navigation and control system. Peppermint Robots leverages the Nav2 stack to provide accurate and reliable navigation for its robots (see [`Peppermint-Robots/navigation2`](https://github.com/Peppermint-Robots/navigation2)). | 2019 | \\n| [Pixel Robotics](https://www.pixel-robotics.eu/) | The Nav2 Stack is integrated into Pixel Robotics\\' software platform and is used to ensure that its robots are able to navigate and interact with the environment in a safe and efficient manner (see [`pixel-robotics/navigation2`](https://github.com/pixel-robotics/navigation2)). | 2020 |\\n| [Polymath Robotics](https://polymathrobotics.com) | A list of robots using ROS Navigation stack and ROS 2\\'s Nav2 framework (see [`Robots`](https://navigation.ros.org/about/robots.html)). | 2021 | \\n| [Quasi Robotics](https://quasi.ai) | Uses the Nav2 Stack as a navigation and control platform for its autonomous robots (see [`quasi-robotics/navigation2`](https://github.com/quasi-robotics/navigation2)).| 2017 | \\n| [Relay Robotics](https://www.relayrobotics.com/) | Uses the ROS Navigation stack to enable their robots to navigate autonomously. ROS Navigation stack (see [`savioke/navigation`](https://github.com/savioke/navigation)). | 2013 |\\n| [RIF Robotics](https://www.rifrobotics.com) | The Nav2 Stack is an essential tool for RIF Robotics, helping them to create effective, efficient, and reliable autonomous systems (see [`RIF-Robotics/navigation2`](https://github.com/RIF-Robotics/navigation2)). | 2020 | \\n| [Robolaunch](https://www.robolaunch.io/) | Uses [Navigation](https://www.linkedin.com/posts/ahmet-tuna-%C3%A7etin-83b0a61b6_robotics-cloud-opensource-ugcPost-7024121373060976640-uvMu/?utm_source=share&utm_medium=member_ios) stack to control [Cloudy](https://www.robolaunch.io/robots), is a fully open-source and autonomous robotics learning platform based on ROS framework. | 2020 | \\n| [RoboTech Vision](https://robotechvision.com/) | Nav2 is a key component of RoboTech Vision\\'s autonomous navigation capabilities, as it provides a robust and flexible solution for robot navigation, motion planning, and environment monitoring (see [`robotechvision/navigation2`](https://github.com/robotechvision/navigation2)). | 2013 | \\n| [ROBOTIS](https://robotis.us/) | Uses the Nav2 stack as the main navigation platform for their robots (see [`ROBOTIS-SYS/navigation2`](https://github.com/ROBOTIS-SYS/navigation2)). | 1999 |\\n| [Rover Robotics](https://roverrobotics.com/) | Packages for running an OpenRover robot on ROS2 (see [`RoverRobotics-archive/roverrobotics_ros2`](https://github.com/RoverRobotics-archive/roverrobotics_ros2)). | 2018 |\\n| [RUVU](https://ruvu.nl/) | ROS Navigation stack (see [`ruvu/navigation`](https://github.com/ruvu/navigation)). | 2017 |\\n| [Seasony](https://www.seasony.io/) | Uses ROS and Navigation stack to build their robots (see [`Robots`](https://navigation.ros.org/about/robots.html)). | 2018 | \\n| [Skarv Technologies](http://www.skarvtech.com) | Uses the Nav2 Stack to provide navigation solutions for their customers\\' robots (see [`skarvtech/navigation2`](https://github.com/skarvtech/navigation2)). | 2019 | \\n| [SLAMcore](http://www.slamcore.com) | SLAMcore uses the Nav2 Stack to provide real-time 6 DOF simultaneous localization and mapping (SLAM) solutions for robotics and autonomous systems (see [`slamcore/navigation2`](https://github.com/slamcore/navigation2)). | 2016 |\\n| [Smile Robotics, Inc.](smilerobotics.com) | Uses the ROS Navigation stack to enable their robots to navigate autonomously. ROS Navigation stack (see [`smilerobotics/navigation`](https://github.com/smilerobotics/navigation)). | 2019 | \\n| [Stogl Robotics](https://www.stoglrobotics.de/) | The Nav2 stack provides a platform for developing autonomous systems, enabling Stogl Robotics to rapidly prototype and test new autonomous capabilities in their robots (see [`StoglRobotics-forks/navigation2`](https://github.com/StoglRobotics-forks/navigation2)). | 2021 |\\n| [Stratom](http://www.stratom.com) | Utilizes the Nav2 Stack for a variety of navigation tasks, including mapping and localization (see [`StratomInc/navigation2`](https://github.com/StratomInc/navigation2)). | 2001 | \\n| [Synkar Autonomous](http://www.synkar.com) | Uses ROS and Navigation stack to build their robots (see [`Synkar/navigation2`](https://github.com/Synkar/navigation2)). | 2019 |\\n| [TAILOS](https://tailos.com/) | ROS Navigation stack (see [`tailosinc/navigation`](https://github.com/tailosinc/navigation)). | 2015 | \\n| [TIER IV](https://tier4.jp/en/) | Uses ROS and Navigation stack to build their robots (see [`tier4/navigation2`](https://github.com/tier4/navigation2)). | 2015 |\\n| [Toyota Research Institute](https://www.tri.global/) | Uses ROS and Navigation stack to build their robots (see [`Robots`](https://navigation.ros.org/about/robots.html)). | 2016 |\\n| [United Robots](https://www.unitedrobots.co/) | Mobile robotic solutions for safer, cleaner and healthier spaces  uses ROS and Navigation stack to build their robots. Hiring engineers with experience in navigation stack ([AUTONOMOUS NAVIGATION ENGINEER](https://www.linkedin.com/jobs/view/3567565845/)). | 2016 | \\n| [Unmanned Life](http://unmanned.life) | Uses ROS and Navigation stack to build their robots (see [`umdlife/navigation2`](https://github.com/umdlife/navigation2)). | 2015 | \\n| [Vayu Robotics](http://www.vayurobotics.com) | Uses the Nav2 Stack for better integration with other systems, such as control and monitoring software, and provides a platform for further development and innovation (see [`Vayu-Robotics/navigation2`](https://github.com/Vayu-Robotics/navigation2)). | 2022 | \\n| [Vecna Robotics](http://vecnarobotics.com) | Uses the ROS Navigation stack to enable their robots to navigate autonomously. ROS Navigation stack (see [`vecnatechnologies/navigation`](https://github.com/vecnatechnologies/navigation)). | 1998 |\\n| [Wyca Robotics](https://www.wyca-robotics.fr/) | A list of robots using ROS Navigation stack and ROS 2\\'s Nav2 framework (see [`Robots`](https://navigation.ros.org/about/robots.html)). | 2015 |\\n| [Yujin Robot](https://yujinrobot.com/) | Uses the ROS Navigation stack to enable their robots to navigate autonomously. ROS Navigation stack (see [`yujinrobot/navigation`](https://github.com/yujinrobot/navigation)). | 1988 |\\n<!-- !end-navigation! -->\\n\\n#### Manipulation\\nLists companies known to use the ROS Manipulation stack (MoveIt).\\n<!-- !manipulation! -->\\n| Company | Description | Year Founded| \\n|---------|-------------|-------------|\\n| [Active8 Robots](http://www.active8robots.com) | The company uses the ROS Manipulation stack (MoveIt) in the [AR10 Robotic Hand](https://www.active8robots.com/ar10-robotic-hand/). | 2013 | \\n| [Aivot](https://www.aivot.com/) | Develop humanoid robots and use the manipulation stack to control its arms and hands for manipulation tasks (see [`AivotRobotics/moveit`](https://github.com/AivotRobotics/moveit)). | 2017 | \\n| [ASIMOV Robotics](http://www.asimovrobotics.com) | The company uses the manipulation stack in some of its robots to perform manipulation tasks (see [`asimov-robust/moveit`](https://github.com/asimov-robust/moveit)). | 2012 |\\n| [AUBO Robotics](https://www.aubo-cobot.com/public/index3) | The company uses the ROS Manipulation stack (MoveIt) in the i3/i5/i7/i10 (see [`AuboRobot/aubo_robot`](https://github.com/AuboRobot/aubo_robot)). | 2013 |\\n| [Bastian Solutions](http://www.bastiansolutions.com) | The company uses the manipulation stack in a variety of projects aimed at creating automated material handling systems for its customers (see [`BastianSolutionsRandD/moveit`](https://github.com/BastianSolutionsRandD/moveit)). | 1952 |\\n| [Bowery Farming](http://boweryfarming.com) | The company employs the manipulation stack for governing its self-directed mobile robots that carry out a range of activities within the farming facility, including sowing seeds, supervising crop growth, and gathering crops at harvest time (see [`BoweryFarming/moveit`](https://github.com/BoweryFarming/moveit)). | 2015 | \\n| [Canvas](https://www.canvas.build/) | Uses ROS and Manipulation stack to build their robots (see [`Canvas-Construction/moveit`](https://github.com/Canvas-Construction/moveit)). | 2017 | \\n| [Comau](http://www.comau.com) | The company uses the ROS Manipulation stack (MoveIt) in the e.Do (see [`Comau/eDO_moveit`](https://github.com/Comau/eDO_moveit)). | 1973 | \\n| [DENSO](https://www.denso.com/us-ca/en/) | A guide on how to navigate the [MOVEIT Software (RVIZ)](https://support.densorobotics.com/support/solutions/articles/60000702891-guide-on-using-the-moveit-software-rviz-) to get the [COBOTTA](https://www.denso-wave.com/en/robot/product/collabo/cobotta.html) to move positions. | 1947 |\\n| [Doosan](https://www.doosan.com/en) | The company uses the ROS Manipulation stack (MoveIt) in the M0609/M0617/M1013/M1509 (see [`doosan-robotics/doosan-robot`](https://github.com/doosan-robotics/doosan-robot)). | 2012 | \\n| [eBots](http://www.ebots.com) | Use the MoveIt2 stack as part of their software to plan and execute motion for their robotic systems (see [`ebots-inc/moveit2`](https://github.com/ebots-inc/moveit2)). | 2017 |\\n| [Elephant Robotics](elephantrobotics.com/en/) | The company uses the ROS Manipulation stack (MoveIt) in the MyCobot (see [`elephantrobotics/mycobot_moveit`](https://github.com/elephantrobotics/mycobot_moveit)). | 2016 |\\n| [Forssea Robotics](http://www.forssea-robotics.fr) | Uses ROS and Manipulation stack to build their robots (see [`forssea-robotics/moveit2`](https://github.com/forssea-robotics/moveit2)). | 2016 | \\n| [Franka Emika](http://www.franka.de) | The company uses the ROS Manipulation stack (MoveIt). Support for [ROS Control and MoveIt](https://frankaemika.github.io/docs/) (see [`frankaemika/franka_ros`](https://github.com/frankaemika/franka_ros)). | 2016 |\\n| [GITAI](http://gitai.tech/) | Utilizes the manipulation stack to execute different operations including object recognition, grasping, manipulation, and motion planning.  (see [`GITAI/moveit`](https://github.com/GITAI/moveit)). | 2016 | \\n| [Griffin](http://griffin.ethz.ch) | Uses ROS and Manipulation stack to build their robots (see [`Griffin-Focus-Project/moveit`](https://github.com/Griffin-Focus-Project/moveit)). | 2020 |\\n| [Han\\'s Robot](https://www.hansrobot.net/index) | The company uses the ROS Manipulation stack (MoveIt) in the Elfin3/Elfin5/Elfin5I/Elfin10/Elfin15 (see [`hans-robot/elfin_robot`](https://github.com/hans-robot/elfin_robot)). | 2017 |\\n| [Hyundai](https://www.hyundai.com/eu.html) | Hyundai uses the Manipulation stack for its industrial robots to perform tasks such as welding, painting, and assembly in automotive manufacturing (see [`HYUNDAI-Robotics-Autonomous-Engineering/moveit`](https://github.com/HYUNDAI-Robotics-Autonomous-Engineering/moveit)). | 2000 |\\n| [IKNOWHOW SA](http://www.Iknowhow.com) | Uses ROS and Manipulation stack to build their robots (see [`ikh-innovation/moveit`](https://github.com/ikh-innovation/moveit)). | 2004 | \\n| [Intermodalics](http://www.intermodalics.eu) | Intermodalics uses the Manipulation stack to enable their clients robots to perform complex motions efficiently and safely (see [`Intermodalics/moveit`](https://github.com/Intermodalics/moveit)). | 2010 |\\n| [IR4 PTY LTD](http://www.ir4.com.au) | The manipulation stack allows them to develop motion planning and control solutions for their robotic systems (see [`sssmanufacturing/moveit-1`](https://github.com/sssmanufacturing/moveit-1)). | 2016 | \\n| [Iron Ox](https://ironox.com/) | Uses the ROS Manipulation stack to control the movement and positioning of their robotic arms (see [`iron-ox/moveit`](https://github.com/iron-ox/moveit)). | 2015 |\\n| [Kawasaki](https://global.kawasaki.com) | The company uses the ROS Manipulation stack (MoveIt) in the Duaro (see [`Kawasaki-Robotics/khi_robot`](https://github.com/Kawasaki-Robotics/khi_robot)). | 1896 |\\n| [Kinova Robotics](https://assistive.kinovarobotics.com/) | The company uses the ROS Manipulation stack (MoveIt) in the Jaco/Jaco2/MICO/Movo (see [`Kinovarobotics/kinova-ros/tree/master/kinova_moveit`](https://github.com/Kinovarobotics/kinova-ros/tree/master/kinova_moveit)). | 2006 | \\n| [KiQ Robotics](https://kiq-robotics.co.jp/) | Uses ROS and Manipulation stack to build their robots (see [`KiQ-Robotics/moveit2`](https://github.com/KiQ-Robotics/moveit2)). | 2019 | \\n| [MindHome](http://www.mindhome.co) | Uses the ROS Manipulation stack to enable their robotic arm to pick up and manipulate objects in a home environment (see [`MindHome-Inc/moveit`](https://github.com/MindHome-Inc/moveit)). | 2018 | \\n| [Miso Robotics](https://misorobotics.com) | Use the MoveIt2 stack as part of their software infrastructure to control the motion of their robotic systems and to perform complex tasks such as preparing food items in a commercial kitchen (see [`MisoRobotics/moveit2`](https://github.com/MisoRobotics/moveit2)). | 2016 |\\n| [NEUROMEKA](http://www.neuromeka.com) | The company uses the ROS Manipulation stack (MoveIt) in the Indy 5/Indy 7/Indy RP/Indy RP2 (see [`neuromeka-robotics/ros_indy`](https://github.com/neuromeka-robotics/ros_indy)). | 2013 |\\n| [Niryo](https://niryo.com) | The company uses the ROS Manipulation stack (MoveIt) in the Niryo One (see [`NiryoRobotics/niryo_one_ros`](https://github.com/NiryoRobotics/niryo_one_ros)). | 2016 | \\n| [NXTGEN Robotics](http://www.nxtgenindustries.com.au) | Uses the ROS Manipulation stack to control and plan the motion of their robotic systems (see [`NXTGEN-Robotics/moveit`](https://github.com/NXTGEN-Robotics/moveit)). | 2019 |\\n| [OMRON Group](https://www.omron.com/) | OMRON Group uses the Manipulation stack for the development of their collaborative robots, the TM series. They have integrated MoveIt into the robot programming interface to enable users to easily program and simulate complex movements and tasks (see [`omron-sinicx/moveit`](https://github.com/omron-sinicx/moveit)). | 1933 |\\n| [Optonic](https://www.optonic.com/en/) | They use the Manipulation stack to plan and execute precise and accurate movements of their robotics solutions for the agricultural industry (see [`isys-vision/moveit`](https://github.com/isys-vision/moveit)). | 2020 |\\n| [Oversonic](https://www.oversonicrobotics.com/) | Oversonic uses the Manipulation stack to control the movements of their robotic arms. They integrate MoveIt into their software to plan, execute, and monitor the motion of the robotic arms in real-time (see [`OversonicRobotics/moveit`](https://github.com/OversonicRobotics/moveit)). | 2020 |\\n| [PAL Robotics](https://pal-robotics.com/) | The company uses the ROS Manipulation stack (MoveIt) in the ARI (see [`pal-robotics/ari_moveit_config`](https://github.com/pal-robotics/ari_moveit_config)). | 2004 |\\n| [PickNik Robotics](https://picknik.ai/) | Use the MoveIt2 stack as part of their software to plan and execute motion for their robotic systems (see [`PickNikRobotics/moveit2`](https://github.com/PickNikRobotics/moveit2)). | 2015 |\\n| [Pilz](https://www.pilz.com/en-US) | The company uses the ROS Manipulation stack (MoveIt) (see [`PilzDE/moveit2`](https://github.com/PilzDE/moveit2)). | 1948 |\\n| [Quasi Robotics](https://quasi.ai) | Use the MoveIt2 stack as part of their software to plan and execute motion for their robotic systems (see [`quasi-robotics/moveit2`](https://github.com/quasi-robotics/moveit2)). | 2017 | \\n| [RIF Robotics](https://www.rifrobotics.com) | Uses ROS and Manipulation stack to build their robots (see [`RIF-Robotics/moveit2`](https://github.com/RIF-Robotics/moveit2)). | 2020 | \\n| [Rivelin Robotics](http://www.rivelinrobotics.com) | Rivelin Robotics uses the ROS Manipulation stack to plan and control the motion of their robotic arms (see [`rivelinrobotics/rivelin_move_group_sequence`](https://github.com/rivelinrobotics/rivelin_move_group_sequence)). | 2018 |\\n| [ROBOTIS](https://robotis.us/) | The company uses the ROS Manipulation stack (MoveIt) in the Open Manipulator (see [`ROBOTIS-GIT/open_manipulator`](https://github.com/ROBOTIS-GIT/open_manipulator)). | 1999 |\\n| [Rope Robotics](http://www.roperobotics.com) | Uses the Manipulation stack for motion planning and control of their industrial robots (see [`Rope-Robotics/moveit`](https://github.com/Rope-Robotics/moveit)). | 2016 | \\n| [RT Corporation](https://rt-net.jp/) | The company uses the ROS Manipulation stack (MoveIt) in the Crane-X7 (see [`rt-net/crane_x7_ros`](https://github.com/rt-net/crane_x7_ros)). | 2005 | \\n| [RUVU](https://ruvu.nl/) | Uses the Manipulation stack for motion planning and control of their autonomous mobile robots (see [`ruvu/moveit`](https://github.com/ruvu/moveit)). | 2017 |\\n| [SESTO Robotics](https://www.sestorobotics.com) | SESTO Robotics leverages MoveIt for its Autonomous Mobile Robot (AMR) platform, called SESTO Magnus. The robot uses the ROS Manipulation stack to perform autonomous navigation, obstacle avoidance, and manipulation tasks (see [`hopetechnik/moveit`](https://github.com/hopetechnik/moveit)). | 2017 | \\n| [Shadow Robot](https://www.shadowrobot.com/) | The company uses the ROS Manipulation stack (MoveIt) (see [`shadow-robot/moveit`](https://github.com/shadow-robot/moveit)). | 1987 | \\n| [Spinbotics](http://spinbotics.com) | Use this software to develop and implement robotic applications that require motion planning and control (see [`Spinbotics-s-r-o/moveit2`](https://github.com/Spinbotics-s-r-o/moveit2)). | 2020 | \\n| [ST Robotics](http://strobotics.com) | The company uses the ROS Manipulation stack (MoveIt) in the R12 (see [`ST-ROBOTICS/r12_moveit_config`](https://github.com/ST-ROBOTICS/r12_moveit_config)). | 1986 |\\n| [Stogl Robotics](https://www.stoglrobotics.de/) | Use the MoveIt2 stack as part of their software to plan and execute motion for their robotic systems (see [`StoglRobotics-forks/moveit2`](https://github.com/StoglRobotics-forks/moveit2)). | 2021 |\\n| [TRACLabs](http://traclabs.com) | Uses the Manipulation stack  to control robotic manipulators, plan motion trajectories, and optimize grasping and manipulation tasks (see [`traclabs/moveit`](https://github.com/traclabs/moveit)). | 1994 | \\n| [Trossen Robotics](http://www.trossenrobotics.com/) | The company uses the ROS Manipulation stack (MoveIt) (see [`Interbotix/interbotix_ros_manipulators`](https://github.com/Interbotix/interbotix_ros_manipulators)). | 2005 |\\n| [UFACTORY](http://www.ufactory.cc) | The company uses the ROS Manipulation stack (MoveIt) in the xArm 5/ xArm 6/xArm 7 (see [`xArm-Developer/xarm_ros`](https://github.com/xArm-Developer/xarm_ros)). | 2013 |\\n| [Unibap AB](https://unibap.com) | The Manipulation stack is utilized by Unibap AB to perform the motion planning and control of industrial robots (see [`Unibap/moveit`](https://github.com/Unibap/moveit)). | 2013 |\\n| [Universal Robots](https://www.universal-robots.com/) | The company uses the ROS Manipulation stack (MoveIt) in the UR3/UR5/UR10 (see [`ros-industrial/universal_robot`](https://github.com/ros-industrial/universal_robot)). | 2005 |\\n<!-- !end-manipulation! -->\\n\\n\\n#### Perception\\nLists companies known to use the [ROS Perception stack](https://github.com/ros-perception).\\n<!-- !perception! -->\\n| Company | Description | Year Founded|\\n|---------|-------------|-------------|\\n| [Acceleration Robotics](https://accelerationrobotics.com) | Hardware Acceleration solutions for robots using ROS 2. Use the ROS 2 perception stack actively in customer projects and serve [`ROBOTCORE®` Perception](https://accelerationrobotics.com/robotcore-perception.php), an optimized robotic perception stack that leverages hardware acceleration to provide a speedup in perception computations (while remaining API-compatible with the default ROS 2 perception stack). | 2021 |\\n| [ADLINK Technology](https://www.adlinktech.com/en/index) | An image processing pipeline for ROS for ADLINK Technology (see [`Adlink-ROS/image_pipeline`](https://github.com/Adlink-ROS/image_pipeline)). | 1995 |\\n| [Aeva](http://www.aeva.com) | Aeva introduces a [Aeries II](https://iot-automotive.news/aeva-introduces-aeries-ii-the-worlds-first-4d-lidar-with-camera-level-resolution/), the world\\'s first 4D LiDAR with camera-level resolution [^330]. Hiring perception engineers ([Perception Validation Engineer](https://www.aeva.com/career/?lv_jid=f16593e0-9605-4927-a12a-c30bab868b22)). | 2017 | \\n| [AEye](https://www.aeye.ai/) | Develop a sensor data type called Dynamic Vixels™, which combines pixels from digital 2D cameras with voxels from AEye’s Agile 3D LiDAR sensor into a single super-resolution sensor data type, allowing vehicles to see and perceive more like humans to better evaluate potential driving hazards and adapt to changing conditions [^331]. | 2013 |\\n| [Analog Devices](https://www.analog.com/en/index.html) | Specializes in high-performance signal processing and offers a range of LIDAR technology products to enable high-performance LIDAR systems [^332].  | 1965 |\\n| [ANYbotics](https://www.anybotics.com/) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for ANYbotics (see [`ANYbotics/vision_opencv`](https://github.com/ANYbotics/vision_opencv)).| 2016 |\\n| [Apex.AI](https://www.apex.ai/) | Provides the LaserProjection class for turning laser scan data into point clouds for Apex.AI (see [`ApexAI/laser_geometry`](https://github.com/ApexAI/laser_geometry)). | 2017 |\\n| [ARAV](https://www.arav.jp/) | Converts a 3D Point Cloud into a 2D laser scan for ARAV (see [`arav-jp/pointcloud_to_laserscan`](https://github.com/arav-jp/pointcloud_to_laserscan)). | 2020 | \\n| [Arbe](http://www.arberobotics.com) | Through an AI-based analysis of the vehicle’s surroundings, Arbe’s 360° Perception is the first radar technology detailed enough to enhance perception algorithms, elevating L2+ and higher applications from nice-to-have comfort solutions to must-have safety features [^333]. | 2015 | \\n| [ASIMOV Robotics](http://www.asimovrobotics.com) | slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities for ASIMOV Robotics (see [`asimov-robust/slam_gmapping`](https://github.com/asimov-robust/slam_gmapping)). | 2012 |\\n| [A&K Robotics](http://www.AandKrobotics.com) | An image processing pipeline for ROS for A&K Robotics (see [`akrobotics/image_pipeline`](https://github.com/akrobotics/image_pipeline)). | 2015 | \\n| [Badger Technologies](http://www.badger-technologies.com/) | ROS Perception drivers (laser_filters) for Badger Technologies (see [`BadgerTechnologies/laser_filters`](https://github.com/BadgerTechnologies/laser_filters)).| 2017 | \\n| [Beagle Systems](https://www.beaglesystems.com/) | Common code for working with images in ROS for Beagle Systems (see [`BeagleSystems/image_common`](https://github.com/BeagleSystems/image_common)). | 2019 | \\n| [Beta Robots](https://beta-robots.com/) | slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities for Beta Robots (see [`beta-robots/slam_gmapping`](https://github.com/beta-robots/slam_gmapping)). | 2016 |\\n| [Blickfeld](https://www.blickfeld.com/) | [Blickfeld Percept](https://www.blickfeld.com/lidar-sensor-products/percept/) is a perception software that empowers everyone to translate data from Blickfeld’s LiDAR sensors into actionable insight for real-world applications [^334]. | 2017 |\\n| [Bluewhale Robot](http://www.bwbot.org) | ROS Perception drivers (laser_filters) for Bluewhale Robot (see [`BluewhaleRobot/laser_filters`](https://github.com/BluewhaleRobot/laser_filters)), slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities (see [`BluewhaleRobot/slam_gmapping`](https://github.com/BluewhaleRobot/slam_gmapping)), ros2 vision_opencv contains packages to interface ROS 2 with OpenCV (see [`BluewhaleRobot/vision_opencv`](https://github.com/BluewhaleRobot/vision_opencv)) and ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization (see [`BluewhaleRobot/depthimage_to_laserscan`](https://github.com/BluewhaleRobot/depthimage_to_laserscan)) for Bluewhale Robot. | 2015 | \\n| [Bosch](https://www.bosch.com/) | Provides the LaserProjection class for turning laser scan data into point clouds (see [`boschresearch/laser_geometry`](https://github.com/boschresearch/laser_geometry)) an image processing pipeline for ROS (see [`boschresearch/image_pipeline`](https://github.com/boschresearch/image_pipeline)) for Bosch. | 1886 | \\n| [BrainGarden](https://www.braingarden.ai) | ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for BrainGarden (see [`BrainGardenAI/depthimage_to_laserscan`](https://github.com/BrainGardenAI/depthimage_to_laserscan)) and provides the LaserProjection class for turning laser scan data into point clouds (see [`BrainGardenAI/laser_geometry`](https://github.com/BrainGardenAI/laser_geometry)) for BrainGarden. | 2017 | \\n| [Brain Corp](http://braincorp.com/) | ROS Perception drivers (laser_filters)  (see [`braincorp/laser_filters`](https://github.com/braincorp/laser_filters)) and an image processing pipeline for ROS (see [`braincorp/backup-image_pipeline`](https://github.com/braincorp/backup-image_pipeline)) for Brain Corp. | 2009 | \\n| [Carnegie Robotics](http://carnegierobotics.com) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Carnegie Robotics (see [`carnegieroboticsllc/vision_opencv`](https://github.com/carnegieroboticsllc/vision_opencv)). | 2010 | \\n| [Cepton](http://cepton.com/) | [The Helius Smart Lidar System](https://www.cepton.com/products/helius) combines Cepton\\'s state-of-the-art, patented, MMT® lidar technology with edge computing and ground-breaking perception software, to provide intelligent, anonymized 3D perception [^336]. | 2016 |\\n| [Clearpath Robotics](https://clearpathrobotics.com/) | ROS Perception drivers (laser_filters) (see [`clearpathrobotics/laser_filters`](https://github.com/clearpathrobotics/laser_filters)), PCL (Point Cloud Library) ROS interface stack (see [`clearpathrobotics/perception_pcl`](https://github.com/clearpathrobotics/perception_pcl)), an image processing pipeline for ROS (see [`clearpathrobotics/image_pipeline`](https://github.com/clearpathrobotics/image_pipeline)),  slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities (see [`clearpathrobotics/slam_gmapping`](https://github.com/clearpathrobotics/slam_gmapping)), provides the LaserProjection class for turning laser scan data into point clouds (see [`clearpathrobotics/laser_geometry`](https://github.com/clearpathrobotics/laser_geometry)) and a set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data (see [`clearpathrobotics/image_transport_plugins`](https://github.com/clearpathrobotics/image_transport_plugins)) for Clearpath Robotics. | 2009 |\\n| [Coalescent Mobile Robotics](https://cm-robotics.com/) | PCL (Point Cloud Library) ROS interface stack for Coalescent Mobile Robotics (see [`cmrobotics/perception_pcl`](https://github.com/cmrobotics/perception_pcl)). | 2018 |\\n| [Constructive Realities](http://constructiverealities.io) | PCL (Point Cloud Library) ROS interface stack for Constructive Realities (see [`constructiverealities/perception_pcl`](https://github.com/constructiverealities/perception_pcl)). | 2022 |\\n| [Continental](https://www.continental.com/en/) | For automated driving, 360° sensor coverage, and central data fusion is a necessity. CES offers a modular prototype solution for your development activities in the field of autonomy. A variety of different hardware components and software modules are available off-the-shelf for quick onboarding [^337]. | 1871 |\\n| [Demine Robotics](https://deminerobotics.com/) | An image processing pipeline for ROS for Demine Robotics (see [`DemineRobotics/image_pipeline`](https://github.com/DemineRobotics/image_pipeline)). | 2016 |\\n| [DENSO](https://www.denso.com/us-ca/en/) | Announced a partnership with U.S. LiDAR and perception systems company, Aeva, to develop next-generation sensing and perception systems [^338]. | 1947 |\\n| [Dexai Robotic](https://www.dexai.com) | An image processing pipeline for ROS for Dexai Robotics (see [`DexaiRobotics/image_pipeline`](https://github.com/DexaiRobotics/image_pipeline)). | 2018 | \\n| [DreamVu](http://www.dreamvu.com) | [ALIA](https://dreamvu.com/alia/) is an omnidirectional vision system that provides long-range and high-resolution 3D imaging and perception capabilites in a single video stream with intelligence at the edge [^339]. | 2017 |\\n| [EikonTech](http://www.eikontech.it) | A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data (see [`eikontech/image_transport_plugins`](https://github.com/eikontech/image_transport_plugins)), an image processing pipeline for ROS (see [`eikontech/image_pipeline`](https://github.com/eikontech/image_pipeline)), ros2 vision_opencv contains packages to interface ROS 2 with OpenCV (see [`eikontech/vision_opencv`](https://github.com/eikontech/vision_opencv)) and common code for working with images in ROS (see [`eikontech/image_common`](https://github.com/eikontech/image_common)) for EikonTech. | 2009 |\\n| [ENWAY](http://www.enway.ai) | opencv_apps provides various nodes that run internally OpenCV\\'s functionalities and publish the result as ROS topics for ENWAY (see [`enwaytech/opencv_apps`](https://github.com/enwaytech/opencv_apps)). | 2017 | \\n| [Eurogroep](http://www.eurogroep.com) |  ROS Perception drivers (laser_filters) for Eurogroep (see [`eurogroep/laser_filters`](https://github.com/eurogroep/laser_filters)).| 2005 | \\n| [EVAR](https://www.evar.co.kr/) | Algorithm-agnostic computer vision message types for ROS for EVAR (see [`EvarClab/vision_msgs`](https://github.com/EvarClab/vision_msgs)). | 2016 | \\n| [e-con Systems](https://www.e-consystems.com) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for e-con Systems (see [`econsystems/vision_opencv`](https://github.com/econsystems/vision_opencv)). | 2003 |\\n| [FarmWise](http://farmwiselabs.com) | Code for working with images in ROS (see [`FarmWise/image_common`](https://github.com/FarmWise/image_common)). | 2016 |\\n| [FastSense](http://www.fastsense.tech) | An image processing pipeline for ROS for FastSense (see [`FastSense/image_pipeline`](https://github.com/FastSense/image_pipeline)). | 2017 | \\n| [Filics](http://www.filics.eu) | ROS Perception drivers (laser_filters) for Filics (see [`FutureInLogistics/laser_filters`](https://github.com/FutureInLogistics/laser_filters)). | 2016 | \\n| [FireFly Automatix](https://fireflyautomatix.com) | ROS Perception drivers (perception_pcl) for FireFly Automatix (see [`fireflyautomatix/perception_pcl`](https://github.com/fireflyautomatix/perception_pcl)). | 2010 |\\n| [Fizyr](http://www.fizyr.com) | A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data (see [`fizyr-forks/image_transport_plugins`](https://github.com/fizyr-forks/image_transport_plugins)), an image processing pipeline for ROS (see [`fizyr-forks/image_pipeline`](https://github.com/fizyr-forks/image_pipeline)), ros2 vision_opencv contains packages to interface ROS 2 with OpenCV (see [`fizyr-forks/vision_opencv`](https://github.com/fizyr-forks/vision_opencv)) and common code for working with images in ROS (see [`fizyr-forks/image_common`](https://github.com/fizyr-forks/image_common)) for Fizyr. | 2014 |\\n| [Forssea Robotics](http://www.forssea-robotics.fr) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Forssea Robotics (see [`forssea-robotics/vision_opencv`](https://github.com/forssea-robotics/vision_opencv)). | 2016 |\\n| [GITAI](http://gitai.tech/) | Common code for working with images in ROS (see [`GITAI/image_common`](https://github.com/GITAI/image_common)) and an image processing pipeline for ROS (see [`GITAI/image_pipeline`](https://github.com/GITAI/image_pipeline)) for GITAI. | 2016 | \\n| [Hatchbed](https://hatchbed.com/) | An image processing pipeline for ROS for Hatchbed (see [`hatchbed/image_pipeline`](https://github.com/hatchbed/image_pipeline)). | 2019 | \\n| [Hesai Technology](http://www.hesaitech.com/en) | Hesai Technology announces new Lidar design win with SAIC\\'s Rising Auto [^340]. | 2014 |\\n| [Hokuyo Automatic](http://www.hokuyo-aut.jp) | Hokuyo, SiLC Technologies collaborate to bring 4D LiDAR technology to industrial automation and robotics applications [^341]. | 1946 |\\n| [Honeywell](https://www.honeywell.com/) | Honeywell introduces new robotic technology to help warehouses boost productivity, reduce injuries. Driven by sophisticated machine learning and advances in perception and gripping technologies [^342]. | 1906 | \\n| [iFollow](https://www.ifollow.fr/) | ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for iFollow (see [`ifollow-robotics/depthimage_to_laserscan`](https://github.com/ifollow-robotics/depthimage_to_laserscan)). | 2017 |\\n| [inaho](https://en.inaho.co/) | Algorithm-agnostic computer vision message types for ROS for inaho (see [`teaminaho/vision_msgs`](https://github.com/teaminaho/vision_msgs)). | 2021 | \\n| [InDro Robotics](https://indrorobotics.ca/) | Converts a 3D Point Cloud into a 2D laser scan for InDro Robotics (see [`indro-robotics/pointcloud_to_laserscan`](https://github.com/indro-robotics/pointcloud_to_laserscan)).| 2014 |\\n| [Inertial Sense](https://inertialsense.com) | Develop autonomous navigation software and precision sensors for commercial mobile robotics. Hiring Perception engineers ([Senior Robotics Perception Engineer](https://www.linkedin.com/jobs/view/1682602369/))[^343]. | 2013 |\\n| [Infineon](https://www.infineon.com/cms/en/) | Infineon presents the world\\'s first ISO26262-compliant high-resolution 3D image sensor for automotive. The imager might be used in environmental perception scenarios as a Flash-LiDAR in the automotive space and – based on the safety conformity – it is also an ideal candidate for adjacent applications in mobile robotics, drones and other autonomous use cases [^344]. | 1999 |\\n| [Innoviz Technologies](http://www.innoviz.tech) | Innoviz’s advanced perception software, a tool for extracting additional data from the point cloud, offers and provides vehicles with a deep understanding of any 3D driving scene [^346]. | 2016 |\\n| [Intel](https://www.intel.com/content/www/us/en/homepage.html) | They offers tutorials with solutions for sensors and computer vision in ROS 2-based Docker containers [^347]. | 1968 |\\n| [Intermodalics](http://www.intermodalics.eu) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV (see [`Intermodalics/vision_opencv`](https://github.com/Intermodalics/vision_opencv)) and an image processing pipeline for ROS (see [`Intermodalics/image_pipeline-1`](https://github.com/Intermodalics/image_pipeline-1)) for Intermodalics. | 2010 |\\n| [Iron Ox](https://ironox.com/) | ROS Perception drivers (laser_filters) for Iron Ox (see [`iron-ox/laser_filters`](https://github.com/iron-ox/laser_filters)). | 2015 |\\n| [IVEX](http://www.ivex.ai) | AR tag tracking library for ROS for IVEX (see [`IVEX-AI/ar_track_alvar`](https://github.com/IVEX-AI/ar_track_alvar)). | 2018 |\\n| [Kapernikov](http://www.kapernikov.com) | They apply data analytics and computer vision techniques to turn data streams into valuable information which in turn helps people or robots make the right decisions. A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data (see [`Kapernikov/image_transport_plugins`](https://github.com/Kapernikov/image_transport_plugins)) and common code for working with images in ROS (see [`Kapernikov/image_common`](https://github.com/Kapernikov/image_common)) for Kapernikov. | 2011 | \\n| [Kiwibot](https://www.kiwibot.com/) | Algorithm-agnostic computer vision message types for ROS (see [`kiwicampus/vision_msgs`](https://github.com/kiwicampus/vision_msgs)) and for an image processing pipeline for ROS (see [`kiwicampus/image_pipeline`](https://github.com/kiwicampus/image_pipeline)) Kiwibot. | 2017 |\\n| [Kudan](https://www.kudan.io/) | Kudan\\'s Artificial Perception technology fills a critical gap to harness the power of Artificial Intelligence. Kudan provides sensory functions to the brain of machines [^348]. | 2010 |\\n| [LeddarTech](http://www.leddartech.com) | LeddarTech is an automotive ADAS and AD software company that offers comprehensive end-to-end raw data fusion and perception solutions enabling OEMs and Tier-1-2 suppliers to solve critical sensing, fusion and perception challenges [^349]. | 2007 | \\n| [LEJU ROBOTICS](http://www.lejurobot.com) | An image processing pipeline for ROS for LEJU ROBOTICS (see [`LejuRobotics/ros_image_pipeline`](https://github.com/LejuRobotics/ros_image_pipeline)). | 2016 | \\n| [Leo Drive](http://www.leodrive.ai) | slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities (see [`leo-drive/slam_gmapping`](https://github.com/leo-drive/slam_gmapping)) and ros2 vision_opencv contains packages to interface ROS 2 with OpenCV (see [`leo-drive/vision_opencv`](https://github.com/leo-drive/vision_opencv)) for Leo Drive.  | 2015 |\\n| [LG (SVL Simulator)](https://www.svlsimulator.com/) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for LG (SVL Simulator) (see [`lgsvl/vision_opencv`](https://github.com/lgsvl/vision_opencv)). | 2018 |\\n| [Livox LiDAR](https://www.livoxtech.com/) | [Mid-360](https://www.livoxtech.com/mid-360) is the latest generation of Livox LiDAR for low speed robotics. This product inherits the cost-effectiveness of the Livox Mid series and delivers 3D perception in 360 degrees [^350]. | 2016 |\\n| [Locus Robotics](https://locusrobotics.com/industry_solutions/industrial/) | PCL (Point Cloud Library) ROS interface stack (see [`locusrobotics/perception_pcl`](https://github.com/locusrobotics/perception_pcl)) and an image processing pipeline for ROS (see [`locusrobotics/image_pipeline`](https://github.com/locusrobotics/image_pipeline)) for Locus Robotics. | 2014 |\\n| [LUCID Vision Labs](https://thinklucid.com) | LUCID presents new Helios2+ time-of-flight camera with HDR and high-speed modes for precise 3D object detection and measurement at control [^345]. | 2017 | \\n| [Luminar Technologies](https://www.luminartech.com) | Luminar introduced the industry’s most advanced LiDAR perception technology that enables safe driver-out-of-the-loop autonomy [^351]. | 2012 |\\n| [Luxonis](https://www.luxonis.com/) | DepthAI platform supports different ways of perceiving depth: passive stereo depth perception, active stereo depth perception and time-of-flight depth perception [^352]. | 2018 |\\n| [Magazino GmbH](https://www.magazino.eu/?lang=en) | An image processing pipeline for ROS for Magazino (see [`magazino/image_pipeline`](https://github.com/magazino/image_pipeline)). | 2014 |\\n| [Magna International](https://www.magna.com/) | ROS Perception drivers (laser_filters) for Magna International (see [`MagnaRobotics/laser_filters`](https://github.com/MagnaRobotics/laser_filters)). | 1957 |\\n| [MAP IV](https://www.map4.jp) | slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities for MAP IV (see [`MapIV/slam_gmapping`](https://github.com/MapIV/slam_gmapping)). | 2016 | \\n| [Mech-Mind Robotics](https://www.mech-mind.com/) | The company is developing software solutions for industrial robots. Its software solutions include robotic vision (2D/3D), advanced programming models, and fast environment perception [^354]. | 2016 |\\n| [Milvus Robotics](https://milvusrobotics.com) | ROS Perception drivers (laser_filters) for Milvus Robotics (see [`milvusrobotics/laser_filters`](https://github.com/milvusrobotics/laser_filters)). | 2011 |\\n| [Miso Robotics](https://misorobotics.com) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV  (see [`MisoRobotics/vision_opencv`](https://github.com/MisoRobotics/vision_opencv)) and an image processing pipeline for ROS (see [`MisoRobotics/image_pipeline`](https://github.com/MisoRobotics/image_pipeline)) for Miso Robotics. | 2016 |\\n| [Mojin Robotics GmbH](http://www.mojin-robotics.de) | Provides nodes to assemble point clouds from either LaserScan or PointCloud messages for Mojin Robotics (see [`mojin-robotics/laser_assembler`](https://github.com/mojin-robotics/laser_assembler)). | 2015 | \\n| [Motius](https://motius.de/) | ROS Perception drivers (laser_filters) for Motius (see [`motius/laser_filters`](https://github.com/motius/laser_filters)). | 2013 | \\n| [NakAI Robotics](https://nakairobotics.com) | ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for NakAI Robotics (see [`nakai-robotics/depthimage_to_laserscan`](https://github.com/nakai-robotics/depthimage_to_laserscan)). | 2021 | \\n| [Nearthlab](http://nearthlab.com) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Nearthlab (see [`nearthlab/vision_opencv`](https://github.com/nearthlab/vision_opencv)). | 2015 | \\n| [Neobotix GmbH](https://www.neobotix-robots.com/homepage) | slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities for Neobotix (see [`neobotix/slam_gmapping`](https://github.com/neobotix/slam_gmapping)). | 2010 |\\n| [Nexuni Co. Ltd.](www.nexuni.com) | ROS Perception drivers (laser_filters) for Nexuni (see [`nexuni/laser_filters`](https://github.com/nexuni/laser_filters)), slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities (see [`nexuni/slam_gmapping`](https://github.com/nexuni/slam_gmapping)) and ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization (see [`nexuni/depthimage_to_laserscan`](https://github.com/nexuni/depthimage_to_laserscan)) for Nexuni. | 2019 |\\n| [NODE Robotics](http://www.node-robotics.com) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for NODE Robotics (see [`node-robotics/vision_opencv`](https://github.com/node-robotics/vision_opencv)). | 2020 | \\n| [NVIDIA](https://www.nvidia.com/es-es/autonomous-machines/robotics/) | NVIDIA DRIVE® Perception enables robust perception of obstacles, paths, and wait conditions (such as stop signs and traffic lights) right out of the box with an extensive set of pre-processing, post-processing, and fusion processing modules [^357]. | 1993 |\\n| [Orbbec](http://www.orbbec3d.com) | The Astra + is Orbbec’s latest 3D depth perception solution [^358]. | 2013 | \\n| [Ouster](https://ouster.com/) | Ouster launches digital Lidar perception platform Ouster Gemini [^359]. | 2015 |\\n| [Outsight](https://outsight.ai/) | Outsight develops a edge computing device that can pre-processes 3D LiDAR data from sensors built by different manufacturers [^360]. | 2019 | \\n| [Owl Autonomous Imaging](http://www.owlai.us) | Owl autonomous imaging launches monocular 3D thermal rangerTM computer vision for ADAS & autonomous vehicles [^353]. | 2018 | \\n| [PAL Robotics](https://pal-robotics.com/) | PCL (Point Cloud Library) ROS interface stack for PAL Robotics (see [`pal-robotics-forks/perception_pcl`](https://github.com/pal-robotics-forks/perception_pcl)), an image processing pipeline for ROS (see [`pal-robotics-forks/image_pipeline`](https://github.com/pal-robotics-forks/image_pipeline)) and ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for PAL Robotics (see [`pal-robotics-forks/depthimage_to_laserscan`](https://github.com/pal-robotics-forks/depthimage_to_laserscan)). | 2004 |\\n| [Photoneo](https://www.photoneo.com/) | Photoneo unveils new robotic possibilities with new color 3D camera [^355]. | 2013 |\\n| [Plus One Robotics](https://plusonerobotics.com/) | An image processing pipeline for ROS for Plus One Robotics (see [`plusone-robotics/image_pipeline`](https://github.com/plusone-robotics/image_pipeline)). | 2016 |\\n| [PROPHESEE](https://www.prophesee.ai) | PROPHESEE exhibited its bio-inspired machine vision for the automotive industry at AutoSens – The Automotive Sensor and Perception Conference [^356]. | 2014 |\\n| [Quanergy](http://www.quanergy.com) | Quanergy offers a comprehensive product portfolio, including hardware sensors and perception software [^361]. | 2012 |\\n| [Quasi Robotics](https://quasi.ai) | An image processing pipeline for ROS for Quasi Robotics (see [`quasi-robotics/image_pipeline`](https://github.com/quasi-robotics/image_pipeline)). | 2017 | \\n| [Rapyuta Robotics](https://www.rapyuta-robotics.com/) | PCL (Point Cloud Library) ROS interface stack for Rapyuta Robotics (see [`rapyuta-robotics/perception_pcl`](https://github.com/rapyuta-robotics/perception_pcl)). | 2014 | \\n| [Relay Robotics](https://www.relayrobotics.com/) | Catkinized ROS Package of the OpenKarto Library (LGPL3) for Relay Robotics (see [`savioke/open_karto`](https://github.com/savioke/open_karto)). | 2013 |\\n| [RoboK](http://robok.ai) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for RoboK (see [`RoboK2017/vision_opencv`](https://github.com/RoboK2017/vision_opencv)). | 2017 | \\n| [RoboSense](https://www.robosense.ai) | They offer RS-LiDAR-Perception, the AI Perception Software based on 3D LiDAR point cloud, specially developed for autonomous driving environment perception [^362]. | 2014 |\\n| [RIOS Intelligent Machines](http://www.rios.ai) | AR tag tracking library for ROS for RIOS Intelligent Machines (see [`rios-ai/ar_track_alvar`](https://github.com/rios-ai/ar_track_alvar)). | 2018 |\\n| [RoboTech Vision](https://robotechvision.com/) | An image processing pipeline for ROS for RoboTech Vision (see [`robotechvision/image_pipeline`](https://github.com/robotechvision/image_pipeline)). | 2013 | \\n| [Rover Robotics](https://roverrobotics.com/) | Colconized ROS Package of the OpenKarto Library (LGPL3) for Rover Robotics (see [`RoverRobotics-forks/open_karto_ros2`](https://github.com/RoverRobotics-forks/open_karto_ros2)). | 2018 |\\n| [RUVU](https://ruvu.nl/) | Common code for working with images in ROS for RUVU (see [`ruvu/image_common`](https://github.com/ruvu/image_common)). | 2017 |\\n| [SAGA ROBOTICS](https://sagarobotics.com/) | slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities for SAGA ROBOTICS (see [`SAGARobotics/slam_gmapping`](https://github.com/SAGARobotics/slam_gmapping)). | 2016 |\\n| [SEAOS Inc.](https://www.seaos.co.jp/) | AR tag tracking library for ROS for Rover Robotics (see [`SeaosRobotics/ar_track_alvar`](https://github.com/SeaosRobotics/ar_track_alvar)). | 2000 | \\n| [Seasony](https://www.seasony.io/) | ROS Perception drivers (laser_filters) (see [`seasony-org/laser_filters`](https://github.com/seasony-org/laser_filters)) and provides the LaserProjection class for turning laser scan data into point clouds (see [`seasony-org/laser_geometry`](https://github.com/seasony-org/laser_geometry)) for Seasony. | 2018 | \\n| [SENSYN ROBOTICS](https://www.sensyn-robotics.com) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for SENSYN ROBOTICS (see [`sensyn-robotics/vision_opencv-pub`](https://github.com/sensyn-robotics/vision_opencv-pub)). | 2015 | \\n| [SEQSENSE](https://www.seqsense.com/) | An image processing pipeline for ROS for SEQSENSE (see [`seqsense/image_pipeline`](https://github.com/seqsense/image_pipeline)). | 2016 |\\n| [Shield AI](https://shield.ai/) | Provides the LaserProjection class for turning laser scan data into point clouds for Shield AI (see [`shield-ai/laser_geometry`](https://github.com/shield-ai/laser_geometry)). | 2015 | \\n| [SICK Sensor Intelligence](http://www.sick.com) | SICK’s portfolio of safety solutions enables unimpaired and safe human intervention into the robot system and reduces downtime in production. This can be achieved with an adaptive perception of the environment with the aid of intelligent, rugged, and reliable sensors and safe systems [^363]. | 1946 |\\n| [SLAMcore](http://www.slamcore.com) | SLAMcore released the SpatialAI SDK in 2021 to enable high quality perception for autonomous mobile robots [^364]. | 2016 |\\n| [Smart Machine](http://www.oxin.nz) | PCL (Point Cloud Library) ROS interface stack (see [`oxin-ros/perception_pcl`](https://github.com/oxin-ros/perception_pcl)) and ros2 vision_opencv contains packages to interface ROS 2 with OpenCV (see [`oxin-ros/vision_opencv`](https://github.com/oxin-ros/vision_opencv)) for Smart Machine. | 2018 | \\n| [Smile Robotics, Inc.](smilerobotics.com) | ROS Perception drivers (laser_filters) for Smile Robotics (see [`smilerobotics/laser_filters`](https://github.com/smilerobotics/laser_filters)). | 2019 | \\n| [SoftBank Robotics](https://www.softbankrobotics.com/emea/en) | ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for SoftBank Robotics (see [`softbankrobotics-research/depthimage_to_laserscan`](https://github.com/softbankrobotics-research/depthimage_to_laserscan)). | 2005 | \\n| [Solid State of Mind](https://solidstateofmind.com/) | Develop an artificial intelligence capable of adapting to real-time changes in the environment. A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data for Solid State of Mind (see [`Solid-State-of-Mind-Inc/image_transport_plugins`](https://github.com/Solid-State-of-Mind-Inc/image_transport_plugins)). | 2020 |\\n| [SOMATIC](http://getsomatic.com) | Make bathroom cleaning robots for commercial spaces like office buildings. A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data for SOMATIC (see [`getsomatic/image_transport_plugins`](https://github.com/getsomatic/image_transport_plugins)). | 2018 |\\n| [Square Robot Inc.](http://www.squarerobots.com) | An image processing pipeline for ROS for Square Robot Inc. (see [`squarerobot/image_pipeline`](https://github.com/squarerobot/image_pipeline)). | 2016 | \\n| [Stereolabs](https://www.stereolabs.com/) | They announced the release of the latest ZED SDK with Stereolabs’ new Neural Depth perception module based on deep neural networks for advanced robotics and spatial analytics applications [^367]. | 2010 | \\n| [STMicroelectronics](https://www.st.com/) | AdaSky and STMicroelectronics cooperate to bring day/night high-resolution vision and perception to cars [^366]. | 1987 | \\n| [Stratom](http://www.stratom.com) | PCL (Point Cloud Library) ROS interface stack (see [`StratomInc/perception_pcl`](https://github.com/StratomInc/perception_pcl)) and common code for working with images in ROS (see [`StratomInc/image_common`](https://github.com/StratomInc/image_common)) for Stratom. | 2001 | \\n| [Synkar Autonomous](http://www.synkar.com) | A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data (see [`Synkar/image_transport_plugins`](https://github.com/Synkar/image_transport_plugins)), an image processing pipeline for ROS (see [`Synkar/image_pipeline`](https://github.com/Synkar/image_pipeline)), ros2 vision_opencv contains packages to interface ROS 2 with OpenCV (see [`Synkar/vision_opencv`](https://github.com/Synkar/vision_opencv)) and common code for working with images in ROS (see [`Synkar/image_common`](https://github.com/Synkar/image_common)) for Synkar Autonomous. | 2019 | \\n| [TAILOS](https://tailos.com/) | ROS Perception package (depthimage_to_laserscan) that converts a depth image to a laser scan for use with navigation and localization for TAILOS (see [`tailosinc/depthimage_to_laserscan`](https://github.com/tailosinc/depthimage_to_laserscan)). | 2015 | \\n| [Tangram Vision](https://www.tangramvision.com/) | Tangram Vision’s team of expert perception engineers helps robotics and autonomous vehicle companies solve complex perception challenges like sensor fusion, streaming, multi-sensor calibration, diagnostics, and data management to develop and deploy autonomy at scale [^368]. | 2020 |\\n| [TDK InvenSense](http://www.invensense.com) | TDK announced Coursa Drive, the world’s first high-precision inertial-aided positioning software for autonomous vehicles [^369]. | 2003 | \\n| [Texas Instruments](https://www.ti.com/applications/industrial/robotics.html) | The Texas Instruments Perception Toolkit (PTk) is a software package for accelerating sensing and perception capabilities, particularly for prototyping automotive and robotic applications [^365]. | 1930 |\\n| [TIER IV](https://tier4.jp/en/) | PCL (Point Cloud Library) ROS interface stack (see [`tier4/perception_pcl`](https://github.com/tier4/perception_pcl)), an image processing pipeline for ROS (see [`tier4/image_pipeline`](https://github.com/tier4/image_pipeline)) and a set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data (see [`tier4/image_transport_plugins`](https://github.com/tier4/image_transport_plugins)) for TIER IV. | 2015 |\\n| [TinyMobileRobots](https://tinymobilerobots.com/) | Converts a 3D Point Cloud into a 2D laser scan for TinyMobileRobots (see [`tinymobilerobots/pointcloud_to_laserscan`](https://github.com/tinymobilerobots/pointcloud_to_laserscan)). | 2015 |\\n| [Toposens](http://www.toposens.com) | They make you mobile robot system safer and most efficient by adding another layer of sensory perception: accustic sensor technology for next-level robotic safety [^370]. | 2015 |\\n| [Toyota Research Institute](https://www.tri.global/) | Converts a 3D Point Cloud into a 2D laser scan for Toyota (see [`ToyotaResearchInstitute/pointcloud_to_laserscan`](https://github.com/ToyotaResearchInstitute/pointcloud_to_laserscan)). | 2016 |\\n| [TuSimple](http://www.tusimple.com) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for TuSimple (see [`TuSimple/vision-opencv`](https://github.com/TuSimple/vision-opencv)). | 2015 |\\n| [Ubica Robotics GmbH](https://www.ubica-robotics.eu) | A set of plugins for publishing and subscribing to sensor_msgs/Image topics in representations other than raw pixel data (see [`ubica-robotics/image_transport_plugins`](https://github.com/ubica-robotics/image_transport_plugins)) and an image processing pipeline for ROS (see [`ubica-robotics/image_pipeline`](https://github.com/ubica-robotics/image_pipeline)) for Ubica Robotics. | 2020 | \\n| [Uhnder](http://www.uhnder.com/) | Uhnder become the first company to mass produce a fully automotive qualified, 4D digital imaging radar-on-chip that will transform our roadways, making possible next-generation ADAS, autonomous vehicles and automated mobility applications [^371]. | 2015 | \\n| [Universal Field Robots](http://universalfieldrobots.com.au/) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Universal Field Robots (see [`universal-field-robots/vision_opencv`](https://github.com/universal-field-robots/vision_opencv)). | 2015 | \\n| [Unmanned Life](http://unmanned.life) | An image processing pipeline for ROS for Unmanned Life (see [`umdlife/image_pipeline`](https://github.com/umdlife/image_pipeline)). | 2015 | \\n| [Vaarst](https://vaarst.com/) | PCL (Point Cloud Library) ROS interface stack for Vaarst (see [`rovco/perception_pcl`](https://github.com/rovco/perception_pcl)). | 2015 |\\n| [Vortex Robotics](http://www.vortex-co.com) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Vortex Robotics (see [`VorteX-co/vision_opencv`](https://github.com/VorteX-co/vision_opencv)). | 2016 | \\n| [WINGCOPTER](https://wingcopter.com/) | Manufacturer of unmanned, eVTOL, fixed-wing aircrafts for commercial and humanitarian applications. Hiring engineers with experience in ROS ([(Senior) Data Engineer (m/f/d)](https://careers.wingcopter.com/en/p/en/jobs/10067/senior-data-engineer-mfd)). | 2017 | \\n| [Wyca Robotics](https://www.wyca-robotics.fr/) | ROS Perception drivers (laser_filters) for Wyca Robotics (see [`wyca-robotics/laser_filters`](https://github.com/wyca-robotics/laser_filters)). | 2015 |\\n| [Yaak](http://www.yaak.ai) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Yaak (see [`yaak-ai/vision_opencv`](https://github.com/yaak-ai/vision_opencv)). | 2020 | \\n| [Yujin Robot](https://yujinrobot.com/) | ros2 vision_opencv contains packages to interface ROS 2 with OpenCV for Yujin Robot (see [`yujinrobot/vision_opencv`](https://github.com/yujinrobot/vision_opencv)). | 1988 |\\n| [Zendar](https://www.zendar.io/) | Develop high-definition radar for autonomous vehicles Hiring Perception engineers ([Senior / Lead Software Engineer - Perception](https://zendar.breezy.hr/p/d1d6882cbd7c-senior-lead-software-engineer-perception?source=www.google.com&popup=true)) [^375]. | 2017 |\\n| [Zivid](https://www.zivid.com) | The Ascent Pick system uses a perception engine for sensing and understanding its environment [^376]. | 2015 | \\n\\n\\n<!-- !end-perception! -->\\n\\n<!-- !references! -->\\n[^1]: Robot Immune System https://aliasrobotics.com/ris.php\\n[^2]: https://whill.inc/jp/\\n[^3]: https://whill.inc/jp/news/25181\\n[^4]: https://6river.com/\\n[^5]: Shopify acquires 6 River Systems for $450 million to expand its AI-powered fulfillment network https://venturebeat.com/commerce/shopify-acquires-6-river-systems-for-450-million-to-expand-its-ai-powered-fulfillment-network/\\n[^6]: http://lidar.yujinrobot.com/?p=3481&ckattempt=1\\n[^7]: http://lidar.yujinrobot.com/?p=3481\\n[^8]: https://assetstore.unity.com/packages/tools/physics/ros-107085#description\\n[^9]: https://www.universal-robots.com/articles/ur/application-installation/universal-robots-ros-driver/\\n[^10]: http://www.vicarious.com/solutions/\\n[^11]: https://robotics.tokyo/products/torobo/\\n[^12]: https://robotics.tokyo/products/torobo_eye/\\n[^13]: https://tier4.jp/en/autoware/\\n[^14]: https://www.terraclear.com/products/rock-picker\\n[^16]: http://wiki.ros.org/sick_scan\\n[^17]: https://www.shadowrobot.com/dexterous-hand-series/\\n[^18]: https://www.sbg-systems.com/support/technology/ros-driver-for-sbg-imu-ahrs-ins/\\n[^19]: https://www.sbg-systems.com/products/\\n[^21]: https://roverrobotics.com/blogs/guides/rover-zero-ros-topic-list\\n[^23]: https://www.aubo-cobot.com/public/iproduct3\\n[^24]: https://www.dataspeedinc.com/adas-by-wire-system/\\n[^26]: https://coex.tech/education\\n[^27]: https://coex.tech/pelicanairdelivery\\n[^28]: https://www.botsandus.com/platform\\n[^29]: https://www.bitcraze.io/products/crazyflie-2-1/\\n[^31]: https://www.innok-robotics.de/en/products/\\n[^32]: https://www.cogniteam.com/nimbus\\n[^33]: https://assistive.kinovarobotics.com/product/jaco-robotic-arm\\n[^34]: https://milvusrobotics.com/products/seit\\n[^35]: https://www.softbankrobotics.com/emea/en/pepper\\n[^37]: https://www.motoman.com/en-us/products/robots/industrial\\n[^40]: https://www.ubiquityrobotics.com/products-magni/\\n[^41]: https://www.rethinkrobotics.com/sawyer\\n[^42]: https://www.rapyuta-robotics.com/rapyuta-io/\\n[^43]: https://www.rapyuta-robotics.com/solutions-pa-amr/\\n[^44]: https://github.com/plusone-robotics\\n[^45]: https://www.pixmoving.com/robobus\\n[^46]: https://www.pilz.com/en-INT/products/sensor-technology\\n[^47]: https://www.pilz.com/en-INT/products/relay-modules\\n[^48]: https://www.pilz.com/en-INT/products/controllers\\n[^49]: https://www.pilz.com/en-INT/products/drive-technology\\n[^50]: https://mygita.com/how-it-works\\n[^51]: https://www.basicmicro.com/motor-controller\\n[^52]: https://svenzva.com/revel/\\n[^53]: https://www.zmp.co.jp/products/lrb\\n[^54]: https://www.zmp.co.jp/products/sensor\\n[^55]: https://www.zmp.co.jp/products/robocar-innovation\\n[^56]: https://luxai.com/humanoid-social-robot-for-research-and-teaching/\\n[^57]: https://crosswing.com/nav2/\\n[^59]: https://niryo.com/robotic-solution-education-research/ned2-robotics-arm/\\n[^60]: http://www.xaxxon.com/oculusprime/slamnavigator\\n[^61]: https://rt-net.jp/works_category/allproducts/\\n[^62]: https://schunk.com/us_en/gripping-systems/category/gripping-systems/\\n[^63]: https://schunk.com/us_en/clamping-technology/category/clamping-technology/\\n[^64]: https://www.trossenrobotics.com/robotic-arms.aspx\\n[^65]: https://www.botsync.co/mag.html\\n[^66]: https://strobotics.com/products.htm\\n[^69]: https://www.brisa.tech/#windrose\\n[^70]: https://www.swri.org/industries/industrial-robotics-automation\\n[^71]: https://www.swri.org/robotics-research-development\\n[^72]: https://www.swri.org/ros-industrial\\n[^73]: https://www.swri.org/industry/sensing-perception-automotive-software-unmanned-systems-automotive-software-electronics\\n[^74]: https://www.swri.org/robot-operating-system-ros\\n[^77]: https://www.dfautomation.com/autonomous-mobile-robot-amr-series\\n[^79]: https://accerion.tech/solutions/triton/\\n[^80]: https://movigorobotics.borealtech.com/en/services/\\n[^81]: https://github.com/DLu/ros_map/tree/master/data\\n[^82]: https://www.incubedit.com/product/robot-localization-and-navigation-software/\\n[^83]: https://www.unitree.com/products/go1\\n[^84]: https://www.roboticsbusinessreview.com/rbr50-company/formant-puts-data-collection-analysis-and-robot-management-in-the-cloud/\\n[^85]: https://developer.parrot.com/\\n[^86]: http://wiki.ros.org/Robots/TIAGo\\n[^87]: https://www.neobotix-robots.com/products/ros\\n[^88]: https://www.mov.ai/technology/\\n[^89]: https://www.mathworks.com/products/ros.html\\n[^90]: https://rosindustrial.org/news/2015/5/26/company-spotlight-magazino-gmbh\\n[^91]: https://www.svlsimulator.com/product/simulation/\\n[^92]: https://youtu.be/KhtJoBp16T0\\n[^93]: https://discourse.ros.org/t/iron-ox-two-robotics-software-positions-for-automating-farming/9898\\n[^94]: https://edu.irobot.com/what-we-offer/create3\\n[^95]: http://wiki.ros.org/IntelROSProject\\n[^96]: https://husarnet.com/docs/tutorial-ros2\\n[^97]: https://husarion.com/tutorials/ros-tutorials/1-ros-introduction/\\n[^98]: https://discourse.ros.org/t/honeybee-robotics-software-engineer-brooklyn-new-york-usa/1769\\n[^99]: https://docs.hello-robot.com/#ros-interface\\n[^100]: https://elfincollaborativerobot.eu/index.php?option=com_content&view=article&id=129&Itemid=878&lang=en\\n[^102]: https://www.greenzie.com/product\\n[^103]: http://edu.gaitech.hk/\\n[^104]: https://robots.ros.org/fetch/\\n[^105]: https://www.eprosima.com/index.php/company-all/news/67-fast-rtps-is-adopted-by-ros\\n[^106]: https://www.energid.com/blog/is-actin-for-you\\n[^107]: https://www.dronedeploy.com/blog/connecting-robots-at-scale\\n[^108]: https://developer.dji.com/onboard-sdk/\\n[^109]: https://www.roboticsbusinessreview.com/rbr50-company/diligent-robotics-introduces-moxi-mobile-manipulator-in-hospitals/\\n[^110]: https://concurrent-rt.com/support/resources/white-papers/using-ros-with-redhawk-linux-on-the-nvidia-jetson-tx2/\\n[^111]: http://wiki.ros.org/aceinna_openimu\\n[^112]: https://www.sevensense.ai/product/alphasense-position\\n[^113]: https://static1.squarespace.com/static/51df34b1e4b08840dcfd2841/t/62b6223162567f5d658db7f0/1656103480255/RICA+2022+Event+Template_Aerobotix.pdf\\n[^114]: https://static1.squarespace.com/static/51df34b1e4b08840dcfd2841/t/62b6219f793dbb33d003decd/1656103332379/The+ROS-Industrial+Consortium+Americas_An+An+analysis+of+how+the+ARM+projects+have+used+and+benefited+from+using+ROS-I+during+their+development_Arnie+Kravitz_uploaded.pdf\\n[^115]: https://roscon.ros.org/2015/presentations/ROSCon-Automated-Driving.pdf\\n[^116]: https://www.imandra.ai/core\\n[^120]: https://apptronik.com/our-work/\\n[^122]: https://ubcagrobot.com/agrobot/\\n\\n[^124]: https://torc.ai/technology/\\n[^126]: https://www.seoulrobotics.org/lidar-processing-units\\n[^127]: https://aimotive.com/-/aisim-integrates-ros\\n[^128]: https://blackberry.qnx.com/en/campaigns/2021/robotics-software-solutions\\n[^129]: https://www.prophesee.ai/event-based-sensor-packaged/\\n[^130]: https://innoviz.tech/wp-content/uploads/InnovizPro-datasheet_Jul_19.pdf\\n[^131]: https://rosindustrial.org/ric/current-members/#arc-specialties\\n[^132]: https://rosindustrial.org/ric/current-members/#amsted-rail\\n[^133]: https://rosindustrial.org/ric/current-members/#bastian-solutions\\n[^134]: https://rosindustrial.org/ric/current-members/#boeing\\n[^135]: https://rosindustrial.org/ric/current-members/#bosch\\n[^136]: https://rosindustrial.org/ric/current-members/#caterpillar\\n[^137]: https://rosindustrial.org/ric/current-members/#delta-electronics\\n[^138]: https://rosindustrial.org/ric/current-members/#glidewell-laboratories\\n[^139]: https://rosindustrial.org/ric/current-members/#harting\\n[^140]: https://rosindustrial.org/ric/current-members/#iav\\n[^141]: https://rosindustrial.org/ric/current-members/#infineon\\n[^142]: https://rosindustrial.org/ric/current-members/#john-deere\\n[^143]: https://rosindustrial.org/ric/current-members/#johnson-johnson\\n[^144]: https://rosindustrial.org/ric/current-members/#kyocera\\n[^145]: https://rosindustrial.org/ric/current-members/#lely\\n[^146]: https://rosindustrial.org/ric/current-members/#magna\\n[^147]: https://rosindustrial.org/ric/current-members/#microsoft\\n[^148]: https://rosindustrial.org/ric/current-members/#ppm-a-s\\n[^149]: https://rosindustrial.org/ric/current-members/#process-champ\\n[^150]: https://rosindustrial.org/ric/current-members/#pushcorp-inc-\\n[^151]: https://rosindustrial.org/ric/current-members/#quadsat\\n[^152]: https://rosindustrial.org/ric/current-members/#systems-engineering-consultants-co-ltd-\\n[^153]: https://rosindustrial.org/ric/current-members/#stogl-robotics\\n[^154]: https://rosindustrial.org/ric/current-members/#schaeffler\\n[^155]: https://rosindustrial.org/ric/current-members/#siemens\\n[^156]: https://rosindustrial.org/ric/current-members/#spirit-aerosystems\\n[^157]: https://rosindustrial.org/ric/current-members/#tds-technology\\n[^158]: https://rosindustrial.org/ric/current-members/#tormach\\n[^159]: https://rosindustrial.org/ric/current-members/#trend-micro\\n[^160]: https://rosindustrial.org/ric/current-members/#t-systems-international-gmbh\\n[^161]: https://rosindustrial.org/ric/current-members/#volvo-group\\n[^162]: https://rosindustrial.org/ric/current-members/#woodside\\n[^163]: https://rosindustrial.org/ric/current-members/#yokogawa\\n[^164]: https://roscon.ros.org/2022/\\n[^165]: https://roscon.ros.org/jp/2021/\\n[^166]: https://roscon.ros.org/jp/2019/\\n[^167]: https://roscon.ros.org/world/2020/\\n[^168]: https://roscon.ros.org/fr/2019/\\n[^169]: https://roscon.ros.org/2018/\\n[^170]: https://roscon.ros.org/jp/2018/\\n[^171]: https://youtu.be/Zj7Qupb6hU8\\n[^172]: https://www.robotics247.com/article/mitsubishi_electric_announces_new_robot_control_system_designed_to_cut_production_times\\n[^173]: https://tsukarm.co.jp/xarm-2\\n[^174]: http://wiki.ros.org/Robots/qbhand\\n[^175]: https://www.artisense.ai/technology\\n[^176]: http://wiki.ros.org/applanix\\n[^177]: https://resources.inertiallabs.com/en-us/knowledge-base/inertial-labs-ros-driver-package\\n[^179]: http://wiki.ros.org/toposens\\nros2-embarks-on-a-mission-to-the-bottom-of-lake-tahoe/17139/1\\n[^184]: Modbot at Hannover Messe 2016, ROS-Industrial blog https://rosindustrial.org/news/tag/ModBot\\n[^185]: Apply for Positions at Modbot Inc (SF based Modular Robotics Startup) https://www.ros.org/news/2015/08/apply-for-positions-at-modbot-inc-sf-based-modular-robotics-startup.html\\n[^186]: HEBI Developer APIs https://www.hebirobotics.com/apis\\n[^187]: HEBI Robots examples https://wiki.ros.org/hebi_cpp_api_examples\\n[^188]: Acutronic Robotics fails to find funding for H-ROS for robot hardware https://www.therobotreport.com/acutronic-robotics-h-ros-robot-hardware-fails/\\n[^189]: https://www.therobotreport.com/fetch-robotics-acquired-by-zebra-technologies-for-290m/\\n[^190]: Improving the security of Data Distribution Service (DDS) for ROS 2 robotic systems https://news.aliasrobotics.com/improving-security-dds-ros2/\\n[^191]: SROS2: Usable Cyber Security Tools for ROS 2 https://aliasrobotics.com/files/SROS2.pdf\\n[^192]: Cybersecurity in the ROS 2 communication middleware, targeting the top 6 DDS implementations https://discourse.ros.org/t/cybersecurity-in-the-ros-2-communication-middleware-targeting-the-top-6-dds-implementations/23254\\n[^193]: DroneDeploy acquires robotics software startup Rocos https://www.therobotreport.com/dronedeploy-acquires-robotics-software-startu-rocos\\n[^195]: Drone Solutions Engineer Planck Aerosystems  https://www.suasnews.com/2020/07/drone-solutions-engineer-planck-aerosystems/\\n[^196]: AeroVironment Acquires Planck Aerosystems, a Leading Provider of Advanced Unmanned Aircraft Navigation Solutions  https://www.businesswire.com/news/home/20220815005622/en/AeroVironment-Acquires-Planck-Aerosystems-a-Leading-Provider-of-Advanced-Unmanned-Aircraft-Navigation-Solutions\\n[^197]: telemax EVO RECCE https://www.avinc.com/images/uploads/product_docs/telemax_EVO_Recce_Datasheet_v10_220418.pdf\\n[^198]: AEROVIRONMENT, INC. FORM 10-K (2010) https://investor.avinc.com/static-files/be0e6367-75b2-4d03-819b-a7253d751d40\\n[^199]: GreyOrange Expands in U.S. Warehouse Automation Market https://www.roboticsbusinessreview.com/news/greyorange-expands-u-s-warehouse-automation/\\n[^200]: Discovery UAV https://www.airvolute.com/product/discovery-uav/\\n[^201]: DroneCore.Suite https://www.airvolute.com/product/dronecore^\\n[^202]: First Sony drone uses Fast DDS\\n https://www.eprosima.com/index.php/company-all/news/286-first-sony-drone-uses-fast-dds\\n[^203]: ROSCon 2018 Madrid: aibo development using ROS https://vimeo.com/293292255\\n[^205]: Toyota partners with Apex.AI to develop autonomous platform https://electrek.co/2021/04/14/toyota-partners-with-apex-ai-to-develop-autonomous-platform/\\n[^206]: Customer Success Story Toyota’s Woven Planet https://www.apex.ai/toyota-woven-planet\\n[^207]: Toyota taps Apex.AI for its autonomous vehicle operating system https://techcrunch.com/2021/04/14/toyota-taps-apex-ai-for-its-autonomous-vehicle-operating-system/\\n[^210]: ZF Acquires a Stake in Apex.AI https://www.just-auto.com/news/zf-acquires-a-stake-in-apex-ai/\\n[^212]: Wyca relies on micro-ROS for autonomous indoor robot “Elodie” https://www.eprosima.com/index.php/company-all/news/206-wyca-relies-on-microros-for-robot-elodie\\n[^213]: Robot Software Engineer at Relay Robotics https://discourse.ros.org/t/robot-software-engineer-at-relay-robotics/27244\\n[^214]: MOV.AI and Lanner Electronics Announce Fully Integrated Platform Powered by NVIDIA Isaac ROS to Accelerate Robotics Development and Improve Operational Efficiency in Industrial Environments https://www.lannerinc.com/news-and-events/latest-news/mov-ai-and-lanner-electronics-announce-fully-integrated-platform-powered-by-nvidia-isaac-ros-to-accelerate-robotics-development-and-improve-operational-efficiency-in-industrial-environments\\n[^218]: Introducing the Kria Robotics Stack for Hardware Acceleration in Robotics\\n https://www.xilinx.com/about/blogs/adaptable-advantage-blog/2021/introducing-the-kria-robotics-stack-for-hardware-acceleration-in.html\\n[^219]: AMD to Acquire Xilinx, Creating the Industry’s High Performance Computing Leader https://ir.amd.com/news-events/press-releases/detail/977/amd-to-acquire-xilinx-creating-the-industrys-high\\n[^220]: Webots open-source robot simulator https://github.com/cyberbotics/webots\\n[^221]: Webots ROS 1 interface https://github.com/cyberbotics/webots_ros\\n[^222]: Webots ROS 2 interface https://github.com/cyberbotics/webots_ros2\\n[^223]: Robot simulations on the web https://webots.cloud\\n[^224]: Robot benchmarks on the web https://robotbenchmark.net\\n[^225]: Pesticide spraying robot https://youtu.be/B8s5MSlwCGw\\n[^226]: https://www.doosanrobotics.com/en/Index\\n[^227]: https://onrobot.com/en\\n[^234]: ROS: the framework to accelerate your next robotics project https://tryolabs.com/blog/2022/09/15/ros-the-framework-to-accelerate-your-next-robotics-project\\n[^236]: https://vistion.si/en/ros-2/\\n[^237]: https://discourse.ros.org/t/senior-slam-engineer-labrador-systems/27502\\n[^239]: https://www.linkedin.com/jobs/view/3289018523\\n[^242]: https://www.linkedin.com/jobs/view/3264971272\\n[^244]: https://www.linkedin.com/jobs/view/3291491344\\n[^248]: https://www.linkedin.com/jobs/view/3291382311\\n[^250]: https://www.linkedin.com/jobs/view/3295097708\\n[^252]: Unbounded Robotics Closes Down https://www.therobotreport.com/unbounded-robotics-closes-down/\\n[^255]: https://www.linkedin.com/jobs/view/3291923198/\\n[^257]: https://www.linkedin.com/jobs/view/3219200169\\n[^259]: https://www.linkedin.com/feed/update/urn:li:activity:6983427857892933633/\\n[^260]: https://www.linkedin.com/jobs/view/3303184619\\n[^262]: https://www.linkedin.com/jobs/view/3293827403/\\n[^263]: https://www.linkedin.com/jobs/view/3302556445/\\n[^264]: https://hexagondownloads.blob.core.windows.net/public/AutonomouStuff/wp-content/uploads/2018/09/Welcome_AutonomouStuff_Final.pdf\\n[^265]: https://www.linkedin.com/jobs/view/3306515734\\n[^267]: https://www.linkedin.com/jobs/view/3300413498\\n[^268]: https://discourse.ros.org/t/roboticist-sf-bay-area/27657\\n[^269]: Johnson & Johnson Announces Agreement to Acquire Remaining Stake in Verb Surgical Inc. https://www.jnj.com/johnson-johnson-announces-agreement-to-acquire-remaining-stake-in-verb-surgical-inc\\n[^271]: https://www.prnewswire.com/news-releases/numurus-secures-2-million-to-grow-its-open-source-robotic-applications-software-business-301658096.html\\n[^272]: https://techcrunch.com/2022/10/26/ford-vw-backed-argo-ai-is-shutting-down/\\n[^273]: https://www.therobotreport.com/ford-ceo-gives-insight-into-argo-ais-shutdown/\\n[^274]: https://www.linkedin.com/jobs/view/3328013334\\n[^276]: https://www.linkedin.com/jobs/view/3178546296\\n[^277]: https://www.linkedin.com/jobs/view/3347981895\\n[^278]: https://www.linkedin.com/jobs/view/3348691229\\n[^280]: https://www.flexiv.com/en/newslist?id=159\\n[^283]: https://jobs.rosen-group.com/Job/3765\\n[^285]: https://www.linkedin.com/jobs/view/3354974779\\n[^286]: https://www.stellantis.com/en/news/press-releases/2022/november/stellantis-accelerates-autonomous-driving-journey-with-acquisition-of-aimotive-a-leading-artificial-intelligence-and-autonomous-driving-start-up?adobe_mc_ref=\\n[^287]: https://aimotive.com/w/stellantis-accelerates-autonomous-driving-journey-with-acquisition-of-aimotive-a-leading-artificial-intelligence-and-autonomous-driving-start-up\\n[^290]: https://www.linkedin.com/jobs/view/3026369126\\n[^292]: https://www.linkedin.com/jobs/view/3286634248\\n[^298]: https://www.linkedin.com/jobs/view/3378140574\\n[^299]: https://www.luxoft.com/pr/dxc-technology-completes-acquisition-of-leading-digital-innovator-luxoft/\\n[^300]: https://news.accelerationrobotics.com/acceleration-robotics-expands-to-india-and-takes-over-technoyantra-to-grow-in-asia/\\n[^301]: https://spectrum.ieee.org/alphabet-intrinsic-open-robotics-acquisition\\n[^302]: https://techcrunch.com/2022/08/05/amazon-is-buying-irobot-for-1-7b/\\n[^303]: https://www.therobotreport.com/aptiv-acquiring-wind-river-for-43b/\\n[^305]: https://fetchrobotics.com/fetch-robotics-blog/zebra-technologies-to-acquire-fetch-robotics/\\n[^306]: https://news.gm.com/newsroom.detail.html/Pages/news/us/en/2016/mar/0311-cruise.html\\n[^308]: https://www.linkedin.com/feed/update/urn:li:activity:7020419329082966016?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7020419329082966016%2C7020576945654419456%29\\n[^309]: https://cobiotx.unitedrobotics.group/uploads/PR_Robotnik_ENG.pdf\\n[^310]: ZED ROS Wrapper - https://github.com/stereolabs/zed-ros-wrapper\\n[^311]: ZED ROS2 Wrapper - https://github.com/stereolabs/zed-ros2-wrapper\\n[^312]: ZED ROS Examples - https://github.com/stereolabs/zed-ros-examples\\n[^313]: ZED ROS2 Examples - https://github.com/stereolabs/zed-ros2-examples\\n[^314]: Robotiq offering ROS support for their technology https://dof.robotiq.com/discussion/2634/how-to-communicate-to-the-robotiq-2f-85-gripper-via-ros-melodic-and-ur10e\\n[^315]: NODE\\'s view on ROSification https://node-robotics.com/nodes-view-on-rosification/\\n[^316]: https://blueatlasrobotics.com/\\n[^330]: https://iot-automotive.news/aeva-introduces-aeries-ii-the-worlds-first-4d-lidar-with-camera-level-resolution/\\n[^331]: https://www.aeye.ai/press-releases/dynamic-vixels/\\n[^332]: https://www.analog.com/en/applications/technology/lidar.html\\n[^333]: https://arberobotics.com/perception/\\n[^334]: https://www.blickfeld.com/lidar-sensor-products/percept/\\n[^335]: https://www.bosch.com/research/know-how/success-stories/superhuman-perception/\\n[^336]: https://www.cepton.com/products/helius\\n[^337]: https://conti-engineering.com/perception-development-kit-pdk/\\n[^338]: https://www.denso.com/global/en/news/newsroom/2021/20210119-g01/\\n[^339]: https://dreamvu.com/alia/\\n[^340]: https://www.hesaitech.com/hesai-technology-announces-new-lidar-design-win-with-saics-rising-auto/\\n[^341]: https://www.silc.com/hokuyo-silc-technologies-collaborate-to-bring-4d-lidar-technology-to-industrial-automation-and-robotics-applications/\\n[^342]: https://www.honeywell.com/us/en/press/2021/09/honeywell-introduces-new-robotic-technology-to-help-warehouses-boost-productivity-reduce-injuries\\n[^343]: https://www.linkedin.com/jobs/view/1682602369/\\n[^344]: https://www.infineon.com/cms/en/about-infineon/press/market-news/2022/INFPSS202206-092.html\\n[^345]: https://thinklucid.com/lucid-presents-new-helios2-time-of-flight-camera-with-hdr-and-high-speed-modes-for-precise-3d-object-detection-and-measurement-at-control-2022/\\n[^346]: https://innoviz.tech/perception-software\\n[^347]: https://www.intel.com/content/www/us/en/docs/ei-for-amr/developer-guide/2022-3-1/perception.html\\n[^348]: https://www.kudan.io/\\n[^349]: https://leddartech.com/\\n[^350]: https://www.livoxtech.com/mid-360\\n[^351]: https://www.luminartech.com/updates/luminar-launches-perception-engine-with-subscription-service\\n[^352]: https://docs.luxonis.com/en/latest/pages/depth/\\n[^353]: https://www.yolegroup.com/industry-news/owl-autonomous-imaging-launches-monocular-3d-thermal-rangertm-computer-vision-for-adas-autonomous-vehicles/\\n[^354]: https://www.thoughtsmag.com/mech-mind-robotics-and-the-ubiquity-of-robots/\\n[^355]: https://www.robotics247.com/article/photoneo_unveils_new_robotic_possibilities_with_new_color_3d_camera/artificial_intelligence\\n[^356]: https://www.prophesee.ai/2017/09/19/chronocam-exhibiting-at-autosens-2017/\\n[^357]: https://developer.nvidia.com/drive/perception\\n[^358]: https://orbbec3d.com/index/Product/info.html?cate=38&id=9\\n[^359]: https://investors.ouster.com/news/news-details/2023/Ouster-Launches-Digital-Lidar-Perception-Platform-Ouster-Gemini/default.aspx\\n[^360]: https://www.futurecar.com/4599/Outsight-Develops-a-Edge-Computing-Device-That-Can-Pre-processes-3D-Lidar-Data-From-Sensors-Built-by-Different-Manufacturers\\n[^361]: https://quanergy.com/products/\\n[^362]: https://www.robosense.ai/en/rslidar/RS-LiDAR-Perception\\n[^363]: https://s.sick.com/il-en-customer-event\\n[^364]: https://www.roboticsbusinessreview.com/rbr50-company-2021/slamcore/\\n[^365]: https://software-dl.ti.com/jacinto7/esd/processor-sdk-rtos-jacinto7/08_00_00_12/exports/docs/perception/ptk_release_notes.html\\n[^366]: https://www.marketscreener.com/quote/stock/STMICROELECTRONICS-N-V-70121/news/AdaSky-and-STMicroelectronics-Cooperate-to-Bring-Day-Night-High-Resolution-Vision-and-Perception-to-26029461/\\n[^367]: https://www.stereolabs.com/blog/neural-depth-sensing/\\n[^368]: https://www.linkedin.com/company/tangram-vision/\\n[^369]: https://invensense.tdk.com/news-media/tdk-announces-coursa-drive-the-worlds-first-high-precision-inertial-aided-positioning-software-for-autonomous-vehicles/\\n[^370]: https://toposens.com/\\n[^371]: https://www.uhnder.com/news/uhnder-launches-industrys-first-4d-digital-imaging-radar\\n[^375]: https://zendar.breezy.hr/p/d1d6882cbd7c-senior-lead-software-engineer-perception?source=www.google.com&popup=true\\n[^376]: https://www.zivid.com/application-stories/ascent-intelligent-on-arm-piece-picking-application\\n[^377]: https://global.agilex.ai/blogs/news/the-world-s-first-ros2-mobile-robot-navigation-open-source-education-kit-released\\n[^378]: https://www.therobotreport.com/rockwell-automation-acquiring-amr-developer-clearpath-robotics/\\n[^379]: https://roscon.ros.org/2023/\\n'},\n",
       " {'repo': 'wuhaoran996/openRobotics',\n",
       "  'language': 'MATLAB',\n",
       "  'readme_contents': '# OpenRobotics\\n这里是银河帝国暗黑卿的一个开源项目，展示了我最近的工作。\\n\\n苟利国家生死以，岂因祸福避趋之，代码献给真正的粉丝。+1S\\n\\n暗黑卿的任何项目都是开源的（特殊情况除外）\\n\\n★欢迎大家使用我的代码，转载请注明原作者，请勿将代码用于商业用途！\\n\\n\\nnew.m:\\n利用puma560机器人写字，献出自己的1s\\n\\njixieshoubixinxinxin.m:\\n机器人的运动学逆解，工作空间，示教等\\n\\nMATLAB机器人仿真+ PID控制（的Simscape + SIMULINK）的.zip\\t:\\n利用SW和MATLAB的SIMULINK联合仿真，加入PID控制\\n\\nsixuamnyi.slx\\t:\\n四旋翼无人机的控制\\n\\njixiebinew.slx:\\nsimscape2G\\n\\nmusic.zip:matlab音乐 only my railgun\\n\\nSPK  -  SERVO.zip:matlab的GUI界面控制机械臂运动学正解和逆解\\n\\n\\n\\nSimulink Model:\\nMATLAB对于电机简历模型并加入PID控制\\n\\nTrajectory planning.zip机器人基于关节空间和位姿空间的轨迹规划问题\\n\\n7DOF-Trajectory planning.zip 7dof机器人轨迹规划——robotics system toolbox\\n\\n3dof-inverse.zip\\t3DOF机器人运动学逆解，平面上写字仿真。\\n\\nPRM_pathplanning.m 基于PRM算法的移动机器人路径规划问题\\n\\nPlan and Execute Collision-Free Trajectories.zip 7DOF机器人蔽障+轨迹规划\\n\\ndrawingrobot.m 精湛细腻的工笔画\\n\\ndc_motor.slx 直流电机PWM级联速度调节，具体参数请见\\n'},\n",
       " {'repo': 'GT-RIPL/Awesome-LLM-Robotics',\n",
       "  'language': None,\n",
       "  'readme_contents': '# Awesome-LLM-Robotics [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\\r\\n\\r\\nThis repo contains a curative list of **papers using Large Language/Multi-Modal Models for Robotics/RL**. Template from [awesome-Implicit-NeRF-Robotics](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics) <br>\\r\\n\\r\\n#### Please feel free to send me [pull requests](https://github.com/GT-RIPL/Awesome-LLM-Robotics/blob/main/how-to-PR.md) or [email](mailto:zkira-changetoat-gatech--changetodot-changetoedu) to add papers! <br>\\r\\n\\r\\nIf you find this repository useful, please consider [citing](#citation) and STARing this list. Feel free to share this list with others!\\r\\n\\r\\n---\\r\\n## Overview\\r\\n\\r\\n  - [Reasoning](#reasoning)\\r\\n  - [Planning](#planning)\\r\\n  - [Manipulation](#manipulation)\\r\\n  - [Instructions and Navigation](#instructions-and-navigation)\\r\\n  - [Simulation Frameworks](#simulation-frameworks)\\r\\n  - [Citation](#citation)\\r\\n\\r\\n---\\r\\n## Reasoning\\r\\n\\r\\n* **[RT-X]** \"Open X-Embodiment: Robotic Learning Datasets and RT-X Models\", *arXiv, July 2023*.\\r\\n[[Paper](https://robotics-transformer-x.github.io/paper.pdf)] [[Website](https://robotics-transformer-x.github.io/)]\\r\\n* **[RT-2]** \"RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control\", *arXiv, July 2023*.\\r\\n[[Paper](https://arxiv.org/abs/2307.15818)] [[Website](https://robotics-transformer2.github.io/)]\\r\\n * **Instruct2Act**: \"Mapping Multi-modality Instructions to Robotic Actions with Large Language Model\", *arXiv, May 2023*. [[Paper](https://arxiv.org/abs/2305.11176)]  [[Pytorch Code](https://github.com/OpenGVLab/Instruct2Act)]\\r\\n * **TidyBot**: \"Personalized Robot Assistance with Large Language Models\",  *arXiv, May 2023*. [[Paper](https://arxiv.org/abs/2305.05658)] [[Pytorch Code](https://github.com/jimmyyhwu/tidybot/tree/main/robot)] [[Website](https://tidybot.cs.princeton.edu/)]\\r\\n * **PaLM-E**: \"PaLM-E: An Embodied Multimodal Language Model\", *arXiv, Mar 2023*, [[Paper](https://arxiv.org/abs/2303.03378)] [[Webpage](https://palm-e.github.io/)]\\r\\n * **RT-1**: \"RT-1: Robotics Transformer for Real-World Control at Scale\", *arXiv, Dec 2022*. [[Paper](https://arxiv.org/abs/2212.06817)]  [[GitHub](https://github.com/google-research/robotics_transformer)] [[Website](https://robotics-transformer.github.io/)]\\r\\n * **ProgPrompt**: \"Generating Situated Robot Task Plans using Large Language Models\", *arXiv, Sept 2022*. [[Paper](https://arxiv.org/abs/2209.11302)]  [[Github](https://github.com/progprompt/progprompt)] [[Website](https://progprompt.github.io/)]\\r\\n * **Code-As-Policies**: \"Code as Policies: Language Model Programs for Embodied Control\", *arXiv, Sept 2022*. [[Paper](https://arxiv.org/abs/2209.07753)]  [[Colab](https://github.com/google-research/google-research/tree/master/code_as_policies)] [[Website](https://code-as-policies.github.io/)]\\r\\n * **Say-Can**: \"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances\", *arXiv, Apr 2021*. [[Paper](https://arxiv.org/abs/2204.01691)]  [[Colab](https://say-can.github.io/#open-source)] [[Website](https://say-can.github.io/)]\\r\\n * **Socratic**: \"Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language\", *arXiv, Apr 2021*. [[Paper](https://arxiv.org/abs/2204.00598)] [[Pytorch Code](https://socraticmodels.github.io/#code)] [[Website](https://socraticmodels.github.io/)]\\r\\n * **PIGLeT**: \"PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D World\", *ACL, Jun 2021*. [[Paper](https://arxiv.org/abs/2201.07207)] [[Pytorch Code](http://github.com/rowanz/piglet)] [[Website](https://rowanzellers.com/piglet/)]\\r\\n* **Matcha**: \"Chat with the Environment: Interactive Multimodal Perception using\\r\\n  Large Language Models\", *IROS, 2023*. [[Paper](https://arxiv.org/abs/2303.08268)] [[Github](https://github.com/xf-zhao/Matcha)] [[Website](https://matcha-model.github.io/)]\\r\\n* **Generative Agents**: \"Generative Agents: Interactive Simulacra of Human Behavior\", *arXiv, Apr 2023*. [[Paper](https://arxiv.org/abs/2304.03442v1) [Code](https://github.com/joonspk-research/generative_agents)] \\r\\n* \"Large Language Models as Zero-Shot Human Models for Human-Robot Interaction\", *arXiv, Mar 2023*. [[Paper](https://arxiv.org/abs/2303.03548v1)] \\r\\n* \"Translating Natural Language to Planning Goals with Large-Language Models\", *arXiv, Feb 2023*. [[Paper](https://arxiv.org/abs/2302.05128)] \\r\\n* \"PDDL Planning with Pretrained Large Language Models\", *NeurlPS, 2022*. [[Paper](https://openreview.net/forum?id=1QMMUB4zfl)] [[Github](https://tinyurl.com/llm4pddl)]\\r\\n* **CortexBench** \"Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence?\" *arXiv, Mar 2023*. [[Paper](https://arxiv.org/abs/2303.18240)]\\r\\n\\r\\n---\\r\\n## Planning\\r\\n\\r\\n * **LLM+P**:\"LLM+P: Empowering Large Language Models with Optimal Planning Proficiency\", *arXiv, Apr 2023*, [[Paper](https://arxiv.org/abs/2304.11477)] [[Code](https://github.com/Cranial-XIX/llm-pddl)]\\r\\n * \"Foundation Models for Decision Making: Problems, Methods, and Opportunities\", *arXiv, Mar 2023*, [[Paper](https://arxiv.org/abs/2303.04129)]\\r\\n * **PromptCraft**: \"ChatGPT for Robotics: Design Principles and Model Abilities\", *Blog, Feb 2023*, [[Paper](https://arxiv.org/abs/2306.17582)] [[Website](https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/)]\\r\\n * **Text2Motion**: \"Text2Motion: From Natural Language Instructions to Feasible Plans\", *arXiV, Mar 2023*, [[Paper](https://arxiv.org/abs/2303.12153)] [[Website](https://sites.google.com/stanford.edu/text2motion)]\\r\\n * **ChatGPT-Prompts**: \"ChatGPT Empowered Long-Step Robot Control in Various Environments: A Case Application\", *arXiv, Apr 2023*, [[Paper](https://arxiv.org/abs/2304.03893?s=03)] [[Code/Prompts](https://github.com/microsoft/ChatGPT-Robot-Manipulation-Prompts)]\\r\\n * **LM-Nav**: \"Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action\", *arXiv, July 2022*. [[Paper](https://arxiv.org/abs/2207.04429)] [[Pytorch Code](https://github.com/blazejosinski/lm_nav)] [[Website](https://sites.google.com/view/lmnav)]\\r\\n * **InnerMonlogue**: \"Inner Monologue: Embodied Reasoning through Planning with Language Models\", *arXiv, July 2022*. [[Paper](https://arxiv.org/abs/2207.05608)] [[Website](https://innermonologue.github.io/)]\\r\\n * **Housekeep**: \"Housekeep: Tidying Virtual Households using Commonsense Reasoning\", *arXiv, May 2022*. [[Paper](https://arxiv.org/abs/2205.10712)] [[Pytorch Code](https://github.com/yashkant/housekeep)] [[Website](https://yashkant.github.io/housekeep/)]\\r\\n * **LID**: \"Pre-Trained Language Models for Interactive Decision-Making\", *arXiv, Feb 2022*. [[Paper](https://arxiv.org/abs/2202.01771)] [[Pytorch Code](https://github.com/ShuangLI59/Language-Model-Pre-training-Improves-Generalization-in-Policy-Learning)] [[Website](https://shuangli-project.github.io/Pre-Trained-Language-Models-for-Interactive-Decision-Making/)]\\r\\n * **ZSP**: \"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents\", *ICML, Jan 2022*. [[Paper](https://arxiv.org/abs/2201.07207)] [[Pytorch Code](https://github.com/huangwl18/language-planner)] [[Website](https://wenlong.page/language-planner/)]\\r\\n* **FILM**: \"FILM: Following Instructions in Language with Modular Methods\", *ICLR, 2022*. [[Paper](https://arxiv.org/abs/2110.07342)] [[Code](https://github.com/soyeonm/FILM)] [[Website](https://soyeonm.github.io/FILM_webpage/)]\\r\\n* **Don\\'t Copy the Teacher**: \"Don’t Copy the Teacher: Data and Model Challenges in Embodied Dialogue\", *EMNLP, 2022*. [[Paper](Don\\'t Copy the Teacher: Data and Model Challenges in Embodied Dialogue)] [[Website](https://www.youtube.com/watch?v=qGPC65BDJw4&t=2s)]\\r\\n* **ReAct**: \"ReAct: Synergizing Reasoning and Acting in Language Models\", *ICLR, 2023*. [[Paper](https://arxiv.org/abs/2210.03629)] [[Github](https://github.com/ysymyth/ReAct)] [[Website](https://react-lm.github.io/)]\\r\\n* **LLM-BRAIn**: \"LLM-BRAIn: AI-driven Fast Generation of Robot Behaviour Tree based on Large Language Model\", *arXiv, May 2023*. [[Paper](https://arxiv.org/abs/2305.19352)]\\r\\n* **MOO**: \"Open-World Object Manipulation using Pre-Trained Vision-Language Models\", *arXiv, Mar 2022*. [[Paper](https://arxiv.org/abs/2303.00905)] [[Website](https://robot-moo.github.io/)]\\r\\n* **CALM**: \"Keep CALM and Explore: Language Models for Action Generation in Text-based Games\", *arXiv, Oct 2020*. [[Paper](https://arxiv.org/abs/2010.02903)] [[Pytorch Code](https://github.com/princeton-nlp/calm-textgame)] \\r\\n* \"Planning with Large Language Models via Corrective Re-prompting\", *arXiv, Nov 2022*. [[Paper](https://arxiv.org/abs/2311.09935)]\\r\\n* \"Visually-Grounded Planning without Vision: Language Models Infer Detailed Plans from High-level Instructions\", *arXiV, Oct 2020*, [[Paper](https://arxiv.org/abs/2009.14259)] \\r\\n* **LLM-planner**: \"LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models\", *arXiv, Mar 2023*. [[Paper](https://arxiv.org/abs/2212.04088)] [[Pytorch Code](https://github.com/OSU-NLP-Group/LLM-Planner/)] [[Website](https://dki-lab.github.io/LLM-Planner/)]\\r\\n* **GD**: \"Grounded Decoding: Guiding Text Generation with Grounded Models for Robot Control\", *arXiv, Mar 2023*. [[Paper](https://arxiv.org/abs/2303.00855)] [[Website](https://grounded-decoding.github.io/)]\\r\\n* **COWP**: \"Robot Task Planning and Situation Handling in Open Worlds\", *arXiv, Oct 2022*. [[Paper](https://arxiv.org/abs/2210.01287)] [[Pytorch Code](https://github.com/yding25/GPT-Planner)] [[Website](https://cowplanning.github.io/)]\\r\\n* **GLAM**: \"Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning\", *arXiv, May 2023*. [[Paper](https://arxiv.org/abs/2302.02662)] [[Pytorch Code](https://github.com/flowersteam/Grounding_LLMs_with_online_RL)] \\r\\n* \"Reward Design with Language Models\", *ICML, Feb 2023*. [[Paper](https://arxiv.org/abs/2303.00001v1)] [[Pytorch Code](https://github.com/minaek/reward_design_with_llms)] \\r\\n* **LLM-MCTS**: \"Large Language Models as Commonsense Knowledge for Large-Scale Task Planning\", *arXiv, May 2023*. [[Paper](https://arxiv.org/abs/2305.14078v1)] \\r\\n* \"Collaborating with language models for embodied reasoning\", *NeurIPS, Feb 2022*. [[Paper](https://arxiv.org/abs/2302.00763v1)]\\r\\n* **LLM-Brain**: \"LLM as A Robotic Brain: Unifying Egocentric Memory and Control\", arXiv, Apr 2023. [[Paper](https://arxiv.org/abs/2304.09349v1)] \\r\\n* **Co-LLM-Agents**: \"Building Cooperative Embodied Agents Modularly with Large Language Models\", *arXiv, Jul 2023*. [[Paper](https://arxiv.org/abs/2307.02485)] [[Code](https://github.com/UMass-Foundation-Model/Co-LLM-Agents)] [[Website](https://vis-www.cs.umass.edu/Co-LLM-Agents/)]\\r\\n* **LLM-Reward**: \"Language to Rewards for Robotic Skill Synthesis\", *arXiv, Jun 2023*. [[Paper](https://arxiv.org/abs/2306.08647)] [[Website](https://language-to-reward.github.io/)]\\r\\n\\r\\n\\r\\n---\\r\\n## Manipulation\\r\\n\\r\\n* **[Text2Reward]** \"Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning\", *arXiv, Sep 2023*\\r\\n  [[Paper](https://arxiv.org/abs/2309.11489)] [[Website](https://text-to-reward.github.io/)]\\r\\n* **[VoxPoser]** \"VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models\", *arXiv, July 2023*\\r\\n[[Paper](https://arxiv.org/abs/2307.05973)] [[Website](https://voxposer.github.io/)]\\r\\n * **ProgramPort**:\"Programmatically Grounded, Compositionally Generalizable Robotic Manipulation\", *ICLR, Apr 2023*, [[Paper](https://arxiv.org/abs/2304.13826)] [[Website] (https://progport.github.io/)]\\r\\n * **CoTPC**:\"Chain-of-Thought Predictive Control\", *arXiv, Apr 2023*, [[Paper](https://arxiv.org/abs/2304.00776)] [[Code](https://github.com/SeanJia/CoTPC)]\\r\\n * **DIAL**:\"Robotic Skill Acquistion via Instruction Augmentation with Vision-Language Models\", *arXiv, Nov 2022*, [[Paper](https://arxiv.org/abs/2211.11736)] [[Website](https://instructionaugmentation.github.io/)]\\r\\n * **CLIP-Fields**:\"CLIP-Fields: Weakly Supervised Semantic Fields for Robotic Memory\", *arXiv, Oct 2022*, [[Paper](https://arxiv.org/abs/2210.05663)] [[PyTorch Code](https://github.com/notmahi/clip-fields)] [[Website](https://mahis.life/clip-fields/)]\\r\\n * **VIMA**:\"VIMA: General Robot Manipulation with Multimodal Prompts\", *arXiv, Oct 2022*, [[Paper](https://arxiv.org/abs/2210.03094)] [[Pytorch Code](https://github.com/vimalabs/VIMA)] [[Website](https://vimalabs.github.io/)]\\r\\n * **Perceiver-Actor**:\"A Multi-Task Transformer for Robotic Manipulation\", *CoRL, Sep 2022*. [[Paper](https://arxiv.org/abs/2209.05451)] [[Pytorch Code](https://github.com/peract/peract)] [[Website](https://peract.github.io/)]\\r\\n * **LaTTe**: \"LaTTe: Language Trajectory TransformEr\", *arXiv, Aug 2022*. [[Paper](https://arxiv.org/abs/2208.02918)] [[TensorFlow Code](https://github.com/arthurfenderbucker/NL_trajectory_reshaper)] [[Website](https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/robot-language/)]\\r\\n * **Robots Enact Malignant Stereotypes**: \"Robots Enact Malignant Stereotypes\", *FAccT, Jun 2022*. [[Paper](https://arxiv.org/abs/2207.11569)] [[Pytorch Code](https://github.com/ahundt/RobotsEnactMalignantStereotypes)] [[Website](https://sites.google.com/view/robots-enact-stereotypes/home)] [[Washington Post](https://www.washingtonpost.com/technology/2022/07/16/racist-robots-ai/)] [[Wired](https://www.wired.com/story/how-to-stop-robots-becoming-racist/)] (code access on request)\\r\\n * **ATLA**: \"Leveraging Language for Accelerated Learning of Tool Manipulation\", *CoRL, Jun 2022*. [[Paper](https://arxiv.org/abs/2206.13074)]\\r\\n * **ZeST**: \"Can Foundation Models Perform Zero-Shot Task Specification For Robot Manipulation?\", *L4DC, Apr 2022*. [[Paper](https://arxiv.org/abs/2204.11134)]\\r\\n * **LSE-NGU**: \"Semantic Exploration from Language Abstractions and Pretrained Representations\", *arXiv, Apr 2022*. [[Paper](https://arxiv.org/abs/2204.05080)]\\r\\n * **Embodied-CLIP**: \"Simple but Effective: CLIP Embeddings for Embodied AI\", *CVPR, Nov 2021*. [[Paper](https://arxiv.org/abs/2111.09888)] [[Pytorch Code](https://github.com/allenai/embodied-clip)]\\r\\n * **CLIPort**: \"CLIPort: What and Where Pathways for Robotic Manipulation\", *CoRL, Sept 2021*. [[Paper](https://arxiv.org/abs/2109.12098)] [[Pytorch Code](https://github.com/cliport/cliport)] [[Website](https://cliport.github.io/)]\\r\\n * **TIP**: \"Multimodal Procedural Planning via Dual Text-Image Prompting\", *arXiV, May 2023*, [[Paper](https://arxiv.org/abs/2305.01795)] \\r\\n * **VLaMP**: \"Pretrained Language Models as Visual Planners for Human Assistance\", *arXiV, Apr 2023*, [[Paper](https://arxiv.org/abs/2304.09179)]\\r\\n * **R3M**:\"R3M: A Universal Visual Representation for Robot Manipulation\", *arXiv, Nov 2022*, [[Paper](https://arxiv.org/abs/2203.12601)] [[Pytorch Code](https://github.com/facebookresearch/r3m)] [[Website](https://tinyurl.com/robotr3m)]\\r\\n * **LIV**:\"LIV: Language-Image Representations and Rewards for Robotic Control\", *arXiv, Jun 2023*, [[Paper](https://arxiv.org/abs/2306.00958)] [[Pytorch Code](https://github.com/penn-pal-lab/LIV)] [[Website](https://penn-pal-lab.github.io/LIV/)]\\r\\n * **LILAC**:\"No, to the Right – Online Language Corrections for Robotic Manipulation via Shared Autonomy\", *arXiv, Jan 2023*, [[Paper](https://arxiv.org/abs/2301.02555)] [[Pytorch Code](https://github.com/Stanford-ILIAD/lilac)]\\r\\n * **NLMap**:\"Open-vocabulary Queryable Scene Representations for Real World Planning\", *arXiv, Oct 2023*, [[Paper](https://arxiv.org/abs/2209.09874)] [[Website](https://nlmap-saycan.github.io/)]\\r\\n * **LLM-GROP**:\"Task and Motion Planning with Large Language Models for Object Rearrangement\", *arXiv, May 2023*. [[Paper](https://arxiv.org/pdf/2303.06247)] [[Website](https://sites.google.com/view/llm-grop)]\\r\\n * \"Towards a Unified Agent with Foundation Models\", *ICLR, 2023*. [[Paper](https://www.semanticscholar.org/paper/TOWARDS-A-UNIFIED-AGENT-WITH-FOUNDATION-MODELS-Palo-Byravan/67188a50e1d8a601896f1217451b99f646af4ac8)] \\r\\n * **ELLM**:\"Guiding Pretraining in Reinforcement Learning with Large Language Models\", *arXiv, Feb 2023*. [[Paper](https://arxiv.org/abs/2302.06692)] \\r\\n * \"Language Instructed Reinforcement Learning for Human-AI Coordination\", *arXiv, Jun 2023*. [[Paper](https://arxiv.org/pdf/2304.07297)] \\r\\n * **VoxPoser**:\"VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models\", *arXiv, Jul 2023*. [[Paper](https://arxiv.org/abs/2307.05973)] [[Website](https://voxposer.github.io/)]\\r\\n * **DEPS**:\"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents\", *arXiv, Feb 2023*. [[Paper](https://arxiv.org/abs/2302.01560)] [[Pytorch Code](https://github.com/CraftJarvis/MC-Planner)]\\r\\n * **Plan4MC**:\"Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks\", *arXiv, Mar 2023*. [[Paper](https://arxiv.org/abs/2303.16563)] [[Pytorch Code](https://github.com/PKU-RL/Plan4MC)] [[Website](https://sites.google.com/view/plan4mc)]\\r\\n * **VOYAGER**:\"VOYAGER: An Open-Ended Embodied Agent with Large Language Models\", *arXiv, May 2023*. [[Paper](https://arxiv.org/abs/2305.16291)] [[Pytorch Code](https://github.com/MineDojo/Voyager)] [[Website](https://voyager.minedojo.org/)]\\r\\n* **Scalingup**: \"Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition\", *arXiv, July 2023*. [[Paper](https://arxiv.org/abs/2307.14535)] [[Code](https://github.com/columbia-ai-robotics/scalingup)] [[Website](https://www.cs.columbia.edu/~huy/scalingup/)]\\r\\n* **Gato**: \"A Generalist Agent\", *TMLR, Nov 2022*. [[Paper/PDF](https://openreview.net/pdf?id=1ikK0kHjvj)]  [[Website](https://www.deepmind.com/publications/a-generalist-agent)]\\r\\n* **RoboCat**: \"RoboCat: A self-improving robotic agent\", *arxiv, Jun 2023*. [[Paper/PDF](https://arxiv.org/abs/2306.11706)]  [[Website](https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent)]\\r\\n* **PhysObjects**: \"Physically Grounded Vision-Language Models for Robotic Manipulation\", *arxiv, Sept 2023*. [[Paper](https://arxiv.org/abs/2309.02561)]\\r\\n* **MetaMorph**: \"METAMORPH: LEARNING UNIVERSAL CONTROLLERS WITH TRANSFORMERS\", *arxiv, Mar 2022*. [[Paper](https://arxiv.org/abs/2203.11931)]\\r\\n* **SPRINT**: \"SPRINT: Semantic Policy Pre-training via Language Instruction Relabeling\", *arxiv, June 2023*. [[Paper](https://arxiv.org/abs/2306.11886)] [[Website](https://clvrai.github.io/sprint/)]\\r\\n* **BOSS**: \"Bootstrap Your Own Skills: Learning to Solve New Tasks with LLM Guidance\", *CoRL, Nov 2023*. [[Paper](https://openreview.net/forum?id=a0mFRgadGO)] [[Website](https://clvrai.github.io/boss/)]\\r\\n\\r\\n\\r\\n---\\r\\n## Instructions and Navigation\\r\\n\\r\\n * **ADAPT**: \"ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts\", *CVPR, May 2022*. [[Paper](https://arxiv.org/abs/2205.15509)]\\r\\n * \"The Unsurprising Effectiveness of Pre-Trained Vision Models for Control\", *ICML, Mar 2022*. [[Paper](https://arxiv.org/abs/2203.03580)] [[Pytorch Code](https://github.com/sparisi/pvr_habitat)] [[Website](https://sites.google.com/view/pvr-control)]\\r\\n * **CoW**: \"CLIP on Wheels: Zero-Shot Object Navigation as Object Localization and Exploration\", *arXiv, Mar 2022*. [[Paper](https://arxiv.org/abs/2203.10421)]\\r\\n * **Recurrent VLN-BERT**: \"A Recurrent Vision-and-Language BERT for Navigation\", *CVPR, Jun 2021* [[Paper](https://arxiv.org/abs/2011.13922)] [[Pytorch Code](https://github.com/YicongHong/Recurrent-VLN-BERT)]\\r\\n * **VLN-BERT**: \"Improving Vision-and-Language Navigation with Image-Text Pairs from the Web\", *ECCV, Apr 2020* [[Paper](https://arxiv.org/abs/2004.14973)] [[Pytorch Code](https://github.com/arjunmajum/vln-bert)]\\r\\n* \"Interactive Language: Talking to Robots in Real Time\", *arXiv, Oct 2022* [[Paper](https://arxiv.org/abs/2210.06407)] [[Website](https://interactive-language.github.io/)]\\r\\n* **VLMaps**: \"Visual Language Maps for Robot Navigation\", *arXiv, Mar 2023*. [[Paper](https://arxiv.org/abs/2210.05714)] [[Pytorch Code](https://github.com/vlmaps/vlmaps)] [[Website](https://vlmaps.github.io/)]\\r\\n\\r\\n---\\r\\n## Simulation Frameworks\\r\\n\\r\\n * **MineDojo**: \"MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge\", *arXiv, Jun 2022*. [[Paper](https://arxiv.org/abs/2206.08853)] [[Code](https://github.com/MineDojo/MineDojo)] [[Website](https://minedojo.org/)] [[Open Database](https://minedojo.org/knowledge_base.html)]\\r\\n * **Habitat 2.0**: \"Habitat 2.0: Training Home Assistants to Rearrange their Habitat\", *NeurIPS, Dec 2021*. [[Paper](https://arxiv.org/abs/2106.14405)] [[Code](https://github.com/facebookresearch/habitat-sim)] [[Website](https://aihabitat.org/)]\\r\\n * **BEHAVIOR**: \"BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments\", *CoRL, Nov 2021*. [[Paper](https://arxiv.org/abs/2108.03332)] [[Code](https://github.com/StanfordVL/behavior)] [[Website](https://behavior.stanford.edu/)]\\r\\n * **iGibson 1.0**: \"iGibson 1.0: a Simulation Environment for Interactive Tasks in Large Realistic Scenes\", *IROS, Sep 2021*. [[Paper](https://arxiv.org/abs/2012.02924)] [[Code](https://github.com/StanfordVL/iGibson)] [[Website](https://svl.stanford.edu/igibson/)]\\r\\n * **ALFRED**: \"ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks\", *CVPR, Jun 2020*. [[Paper](https://arxiv.org/abs/1912.01734)] [[Code](https://github.com/askforalfred/alfred)] [[Website](https://askforalfred.com/)]\\r\\n  * **BabyAI**: \"BabyAI: A Platform to Study the Sample Efficiency of Grounded Language Learning\", *ICLR, May 2019*. [[Paper](https://openreview.net/pdf?id=rJeXCo0cYX)] [[Code](https://github.com/mila-iqia/babyai/tree/iclr19)]\\r\\n\\r\\n\\r\\n----\\r\\n## Citation\\r\\nIf you find this repository useful, please consider citing this list:\\r\\n```\\r\\n@misc{kira2022llmroboticspaperslist,\\r\\n    title = {Awesome-LLM-Robotics},\\r\\n    author = {Zsolt Kira},\\r\\n    journal = {GitHub repository},\\r\\n    url = {https://github.com/GT-RIPL/Awesome-LLM-Robotics},\\r\\n    year = {2022},\\r\\n}\\r\\n```\\r\\n'},\n",
       " {'repo': 'yvonshong/Probabilistic-Robotics',\n",
       "  'language': None,\n",
       "  'readme_contents': '# Probabilistic-Robotics\\n《概率机器人》中文版，书和课后习题\\n'},\n",
       " {'repo': 'hubotio/hubot',\n",
       "  'language': 'JavaScript',\n",
       "  'readme_contents': \"![Pipeline Status](https://github.com/hubotio/hubot/actions/workflows/pipeline.yml/badge.svg)\\n\\n![Build Status: MacOS](https://github.com/hubotio/hubot/actions/workflows/nodejs-macos.yml/badge.svg)\\n![Build Status: Ubuntu](https://github.com/hubotio/hubot/actions/workflows/nodejs-ubuntu.yml/badge.svg)\\n![Build Status: Window](https://github.com/hubotio/hubot/actions/workflows/nodejs-windows.yml/badge.svg)\\n\\n# Hubot\\n\\nHubot is a framework to build chat bots, modeled after GitHub's Campfire bot of the same name, hubot.\\nHe's pretty cool. He's [extendable with scripts](https://hubotio.github.io/hubot/docs#scripts) and can work\\non [many different chat services](https://hubotio.github.io/hubot/adapters.html).\\n\\nThis repository provides a library that's distributed by `npm` that you\\nuse for building your own bots.  See the [documentation](https://hubotio.github.io/hubot/docs.html)\\nfor details on getting up and running with your very own robot friend.\\n\\nIn most cases, you'll probably never have to hack on this repo directly if you\\nare building your own bot. But if you do, check out [CONTRIBUTING.md](CONTRIBUTING.md)\\n\\n# Create your own Hubot instance\\n\\nThis will create a directory called `myhubot` in the current working directory.\\n\\n```sh\\nnpx hubot --create myhubot --adapter @hubot-friends/hubot-slack\\n```\\n\\nReview `scripts/example.mjs`. Create more scripts in the `scripts` folder.\\n\\n## License\\n\\nSee the [LICENSE](LICENSE.md) file for license rights and limitations (MIT).\\n\"},\n",
       " {'repo': 'Le0nX/ModernRoboticsCpp',\n",
       "  'language': 'C++',\n",
       "  'readme_contents': '# Modern Robotics:  Mechanics, Planning, and Control\\n# C++ Library\\n\\nThis repository contains the code library accompanying [_Modern Robotics:\\nMechanics, Planning, and Control_](http://modernrobotics.org) (Kevin Lynch\\nand Frank Park, Cambridge University Press 2017). The\\n[user manual](https://github.com/NxRLab/ModernRobotics/blob/master/doc/MRlib.pdf) is in the doc directory of [main repository](https://github.com/NxRLab/ModernRobotics/).\\n\\nThe functions are available in:\\n\\n* C++\\n* [Python](https://github.com/NxRLab/ModernRobotics/tree/master/packages/Python)\\n* [MATLAB](https://github.com/NxRLab/ModernRobotics/tree/master/packages/Matlab)\\n* [Mathematica](https://github.com/NxRLab/ModernRobotics/tree/master/packages/Mathematica)\\n\\nEach function has a commented section above it explaining the inputs required for its use as well as an example of how it can be used and what the output will be. This repository also contains a pdf document that provides an overview of the available functions using MATLAB syntax. Functions are organized according to the chapter in which they are introduced in the book. Basic functions, such as functions to calculate the magnitude of a vector, normalize a vector, test if the value is near zero, and perform matrix operations such as multiplication and inverses, are not documented here.\\n\\nThe primary purpose of the provided software is to be easy to read and educational, reinforcing the concepts in the book. The code is optimized neither for efficiency nor robustness.\\n\\n## Installation\\n\\n### 1. Install Eigen library.\\n* On Mac\\n```console\\nfoo@bar:~$ brew install eigen\\n```\\n* On Linux\\n```console\\nfoo@bar:~$ sudo apt-get install libeigen3-dev\\n```\\n\\n### 2. Prepare build\\n```console\\nfoo@bar:~$ mkdir build && cd build\\n```\\n\\nBy default cmake will install our build into the system directories.\\nTo define a custom install directory we simply pass it to cmake:\\n```console\\nfoo@bar:build $ cmake .. -DCMAKE_INSTALL_PREFIX=../_install\\n```\\nOr just configure with defaults\\n```console\\nfoo@bar:build $ cmake ..\\n```\\nBuilding and installing library\\n```console\\nfoo@bar:build $ make all && make install\\n```\\n\\n## Testing the library\\n```console\\nfoo@bar:build $ ./lib_test\\n```\\n'},\n",
       " {'repo': 'ros/ros_comm',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': 'FailToLoadReadME'},\n",
       " {'repo': 'PetoiCamp/OpenCat',\n",
       "  'language': 'C++',\n",
       "  'readme_contents': '# OpenCat\\n\\nOpenCat is the open-source Arduino and Raspberry Pi-based quadruped robotic pet framework developed by Petoi, the maker of futuristic programmable robotic pets.\\n\\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/walk.gif?raw=true)\\n\\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/run.gif?raw=true)\\n\\nInspired by Boston Dynamics\\' Big Dog and Spot Mini, Dr. Rongzhong Li started the project in his dorm in 2016. After one year of R&D, he founded Petoi LLC and devoted all his resources to the startup. \\n\\nThe goal is to foster collaboration in quadruped(four-legged) robotic research, education, and engineering development of agile and affordable quadruped robot pets, bring STEM concepts to the mass and inspire newcomers (including many kids and adults) to join the robotic AI revolution to create more applications.\\n\\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/slope.gif?raw=true)\\n\\nThe project is still [a complex quadruped robot system](https://www.petoi.com/pages/petoi-programmable-quadruped-robot-system) only for skilled makers. Yet we want to share our design and work with the community by mass production and bring down the hardware and software costs. OpenCat has been deployed on Petoi\\'s bionic palm-sized, realistic lifelike [cute robot cat Nybble](https://www.petoi.com/collections/robots/products/petoi-nybble-robot-cat?utm_source=github&utm_medium=code&utm_campaign=nybble) and\\n[high-performance robot dog Bittle](https://www.petoi.com/collections/robots/products/petoi-bittle-robot-dog?utm_source=github&utm_medium=code&utm_campaign=bittle). We now have established a production line and can ship these [affordable robotic kits and accessories](https://www.petoi.com/store?utm_source=github&utm_medium=code&utm_campaign=store) worldwide.\\n\\nThis project provides a base open-source platform to create amazing programmable gaits, locomotion, and deployment of inverse kinematics quadruped robots and bring simulations to the real world via C/C++/Python programming languages.  \\nOur users have deployed [NVIDIA Issac simulations and reinforcement learning on our robots](https://www.youtube.com/playlist?list=PLHMFXft_rV6MWNGyofDzRhpatxZuUZMdg), [developed visual and lidar-based SLAM with ROS using Bittle and Raspberry Pi](https://www.youtube.com/watch?v=uXpQUIF_Jyk&list=PLHMFXft_rV6MWNGyofDzRhpatxZuUZMdg&index=6) and [imitation learning using Tiny Machine Learning Models with Petoi Bittle and Raspberry Pi](https://www.learnwitharobot.com/p/imitation-learning-with-petoi-bittle).  \\nOur users have also successfully deployed OpenCat on their [DIY 3D-print robot pets](https://www.petoi.com/pages/3d-printed-robot-dog-robot-cat) and developed many robotics projects & applications, such as using [IoT automation of a robot fleet with AWS to improve worker safety](https://www.petoi.com/blogs/blog/aws-iot-robot-fleet-demo-with-petoi-bittle).\\n\\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/stand.gif?raw=true)\\n\\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/NybbleBalance.gif?raw=true)\\n\\nWe\\'ve successfully crowdfunded these two mini robot kits and shipped thousands of units worldwide. \\n\\nWith our customized Arduino board and servos coordinating all instinctive and sophisticated movements(walking, running, jumping, backflipping), one can clip on [various sensors](https://www.petoi.com/products/petoi-sensor-pack) and [camera](https://www.petoi.com/products/intelligent-camera-module) to bring in perception and inject artificial intelligence capabilities by mounting a Raspberry Pi or other AI chips(such as Nvidia Jetson Nano) through wired/wireless connections. \\n \\nPlease see [Petoi FAQs](https://www.petoi.com/pages/faq?utm_source=github&utm_medium=code&utm_campaign=faq) for more info.\\n\\nAlso, Check out [all of the OpenCat and Petoi robot user showcases](https://www.petoi.camp/forum/showcase).\\n\\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/ball.gif?raw=true)\\n\\n## Setup  Process:\\n\\nOpenCat software works on both Nybble and Bittle, controlled by NyBoard based on ATmega328P. More detailed documentation can be found at the [Petoi Doc Center](https://docs.petoi.com).\\n\\nTo configure the board:\\n\\n1. Download the repo and unfold. Remove the **-main** (or any branch name) suffix of the folder.\\n\\n2. Open the file OpenCat.ino, select your robot and board version.\\n```cpp\\n#define BITTLE    //Petoi 9 DOF robot dog: 1x on head + 8x on leg\\n//#define NYBBLE  //Petoi 11 DOF robot cat: 2x on head + 1x on tail + 8x on leg\\n\\n//#define NyBoard_V0_1\\n//#define NyBoard_V0_2\\n#define NyBoard_V1_0\\n//#define NyBoard_V1_1\\n```\\n\\n3. Comment out ```#define MAIN_SKETCH``` so that it will turn the code to the board configuration mode. Upload and follow the serial prompts to proceed.\\n```cpp\\n// #define MAIN_SKETCH\\n```\\n\\n4. If you activate ```#define AUTO_INIT```, the program will automatically set up without prompts. It will not reset joint offsets but calibrate the IMU. It\\'s just a convenient option for our production line.\\n\\n5. Plug the USB uploader to the NyBoard and install the driver if no USB port is found under Arduino -> Tools -> Port.\\n\\n6. Press the upload button (->) at the top-left corner in Arduino IDE.\\n\\n7. Open the serial monitor of Arduino IDE. You can find the button either under Tools, or at the top-right corner of the IDE.\\n\\nSet the serial monitor as **no line ending** and **115200** baud rate.\\nThe serial prompts:\\n```\\nReset joint offsets? (Y/n)\\nY\\n```\\n\\nInput ‘Y’ and hit enter, if you want to reset all the joint offsets to 0.\\n\\nThe program will do the reset, then update the constants and instinctive skills in the static memory.\\n\\n8. IMU (Inertial Measurement Unit) calibration.\\n\\nThe serial prompts:\\n```\\nCalibrate the IMU? (Y/n):\\nY\\n```\\nInput ‘Y’ and hit enter, if you have never calibrated the IMU or want to redo calibration.\\n\\nPut the robot flat on the table and don\\'t touch it. The robot will long beep six times to give you enough time. Then it will read hundreds of sensor data and save the offsets. It will beep when the calibration finishes.\\n\\nWhen the serial monitor prints \"Ready!\", you can close the serial monitor to do the next step.\\n\\n9. Uncomment ```#define MAIN_SKETCH``` to make it active. This time the code becomes the normal program for the major functionalities. Upload the code.\\n```cpp\\n#define MAIN_SKETCH\\n```\\nWhen the serial monitor prints \"Ready!\", the robot is ready to take your next instructions.\\n\\n10. If you have never calibrated the joints’ offsets or reset the offsets in Step2, you need to calibrate them. If you boot up the robot with one side up, it will enter the calibration state automatically for you to install the legs. Otherwise, it will enter the normal rest state\\n\\n11. You can use the serial monitor to calibrate it directly. Or you may plug in the Bluetooth dongle, and use the Petoi app (on Android/iOS) for a more user-friendly interface. The mobile app is available on:\\n\\n* IOS: [App Store](https://apps.apple.com/us/app/petoi/id1581548095)\\n* Android: [Google Play](https://play.google.com/store/apps/details?id=com.petoi.petoiapp)\\n\\nYou can refer to the calibration section in the user manual (https://bittle.petoi.com/6-calibration) and Guide for the Petoi App(https://docs.petoi.com/app-guide).\\n\\n12. you can use the infrared remote or other applications (such as the Petoi App, Python, serial monitor ... etc.) to play with the robot (https://bittle.petoi.com/7-play-with-bittle).\\n\\nFor updates:\\n* star this repository to receive timely notifications on changes.\\n* visit www.petoi.com and subscribe to our official newsletters for project announcements. We also host a forum at [petoi.camp](https://www.petoi.com/forum).\\n* follow us on [Twitter](https://twitter.com/petoicamp), [Instagram](https://www.instagram.com/petoicamp/), and [YouTube channel](https://www.youtube.com/c/rongzhongli) for fun videos and community activities.\\n\\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/backflip.gif?raw=true)\\n\\n## Resources:\\n* [STEM Curriculum & Educational Robots for Teaching Coding Robotics](https://www.petoi.com/pages/resources-curriculum-stem-coding-robot)\\n* [Advanced tutorials made by users](https://www.youtube.com/playlist?list=PLHMFXft_rV6MWNGyofDzRhpatxZuUZMdg)\\n* [Review, open-box, and demos by users](https://www.youtube.com/playlist?list=PLHMFXft_rV6PSS3Qu5yQ-0iPW-ohu1sM3)\\n* [OpenCat robot showcase by users](https://www.petoi.com/pages/petoi-open-source-extensions-user-demos-and-hacks)\\n* [OpenCat robot gallery](https://www.petoi.com/pages/robot-pet-gallery)\\n\\nThe [old repository for OpenCat](https://github.com/PetoiCamp/OpenCat-Old) is too redundant with large image logs and is obsolete without further updates.\\n'},\n",
       " {'repo': 'cyberbotics/webots',\n",
       "  'language': 'C++',\n",
       "  'readme_contents': '# Webots: open-source robot simulator\\n\\n[![Webots](https://img.shields.io/github/v/release/cyberbotics/webots)](https://github.com/cyberbotics/webots/releases/latest)\\n[![Software License](https://img.shields.io/badge/license-Apache%202.0-blue)](LICENSE)\\n[![User Guide](https://img.shields.io/badge/doc-guide-blue)](https://cyberbotics.com/doc/reference/index)\\n[![Reference Manual](https://img.shields.io/badge/doc-reference-blue.svg)](https://cyberbotics.com/doc/reference/index)<br>\\n[![Stars](https://img.shields.io/github/stars/cyberbotics/webots)](https://github.com/cyberbotics/webots/stargazers)\\n[![Downloads](https://img.shields.io/github/downloads/cyberbotics/webots/total?color=blue)](https://hanadigital.github.io/grev/?user=cyberbotics&repo=webots)\\n[![Contributions](https://img.shields.io/github/commit-activity/m/cyberbotics/webots.svg)](https://github.com/cyberbotics/webots/graphs/commit-activity)\\n[![Contributors](https://img.shields.io/github/contributors/cyberbotics/webots?color=blue)](https://github.com/cyberbotics/webots/graphs/contributors)\\n[![GitHub Discussions](https://img.shields.io/github/discussions/cyberbotics/webots)](https://github.com/cyberbotics/webots/discussions)\\n[![Chat](https://img.shields.io/discord/565154702715518986?color=blue)](https://discordapp.com/invite/nTWbN9m)\\n\\n\\n![Webots Screenshot](docs/guide/images/main_window.png?raw=true \"Webots Screenshot\")\\n\\nWebots provides a complete development environment to model, program and simulate robots, vehicles and mechanical systems.\\n\\n- See the [Webots introduction video](https://www.youtube.com/watch?v=O7U3sX_ubGc).\\n- View online Webots simulations at [webots.cloud](https://webots.cloud).\\n- Participate in the [IROS 2023 Simulated Humanoid Robot Wrestling Competition](https://webots.cloud/run?version=R2023a&url=https%3A%2F%2Fgithub.com%2Fcyberbotics%2Fwrestling%2Fblob%2Fmain%2Fworlds%2Fwrestling.wbt&type=competition) and win 1 Ethereum.\\n\\n### Download\\n\\nGet pre-compiled binaries for the [latest release](https://github.com/cyberbotics/webots/releases/latest), as well as [older releases and nightly builds](https://github.com/cyberbotics/webots/releases).\\n\\nCheck out installation instructions:\\n\\n[![Linux](https://img.shields.io/badge/Linux-0f80c0?logo=linux&logoColor=white)](https://cyberbotics.com/doc/guide/installation-procedure#installation-on-linux)\\n[![Windows](https://img.shields.io/badge/Windows-0f80c0?logo=windows&logoColor=white)](https://cyberbotics.com/doc/guide/installation-procedure#installation-on-windows)\\n[![macOS](https://img.shields.io/badge/macOS-0f80c0?logo=apple&logoColor=white)](https://cyberbotics.com/doc/guide/installation-procedure#installation-on-macos)\\n\\n### Build from Source\\n\\nIf you prefer to [compile Webots from source](https://github.com/cyberbotics/webots/wiki), read the [contributing guidelines](CONTRIBUTING.md).\\n\\n### Continuous Integration Nightly Tests\\n\\n[![master branch](https://img.shields.io/badge/branch-master-blue)](https://github.com/cyberbotics/webots/tree/master)\\n[![Linux build (master)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_linux.yml/badge.svg?event=schedule)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_linux.yml?query=event%3Aschedule)\\n[![Windows build (master)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_windows.yml/badge.svg?event=schedule)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_windows.yml?query=event%3Aschedule)\\n[![macOS build (master)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_mac.yml/badge.svg?event=schedule&label=macOS)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_mac.yml?query=event%3Aschedule)<br>\\n[![develop branch](https://img.shields.io/badge/branch-develop-blue)](https://github.com/cyberbotics/webots/tree/develop)\\n[![Linux build (develop)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_linux_develop.yml/badge.svg?event=schedule)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_linux_develop.yml?query=event%3Aschedule)\\n[![Windows build (develop)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_windows_develop.yml/badge.svg?event=schedule)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_windows_develop.yml?query=event%3Aschedule)\\n[![macOS build (develop)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_mac_develop.yml/badge.svg?event=schedule)](https://github.com/cyberbotics/webots/actions/workflows/test_suite_mac_develop.yml?query=event%3Aschedule)\\n\\n### About us\\n\\nWebots was originally designed at [EPFL](https://epfl.ch) in 1996 and then further developed and commercialized by [Cyberbotics](https://cyberbotics.com) since 1998. In December 2018, Webots was open sourced. Since then, [Cyberbotics](https://cyberbotics.com) continues to develop Webots thanks to paid customer support, training, consulting for industry and academic research projects.\\n\\n[Contact us](mailto:info@cyberbotics.com) to discuss your custom robot simulation projects.\\n'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5edf8cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf765c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AtsushiSakai/PythonRobotics</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;img src=\"https://github.com/AtsushiSakai/Pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kiloreux/awesome-robotics</td>\n",
       "      <td>None</td>\n",
       "      <td>Awesome Robotics\\n================\\n\\n[![Aweso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NxRLab/ModernRobotics</td>\n",
       "      <td>Python</td>\n",
       "      <td># Modern Robotics:  Mechanics, Planning, and C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mithi/robotics-coursework</td>\n",
       "      <td>None</td>\n",
       "      <td># [🐳](https://mithi.github.io/deep-blueberry) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>onlytailei/CppRobotics</td>\n",
       "      <td>C++</td>\n",
       "      <td># CppRobotics\\n\\nThis is the cpp implementatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JdeRobot/RoboticsAcademy</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>&lt;a href=\"https://jderobot.github.io/\"&gt;&lt;img src...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pptacher/probabilistic_robotics</td>\n",
       "      <td>C++</td>\n",
       "      <td># probabilistic_robotics\\nI am working on deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jslee02/awesome-robotics-libraries</td>\n",
       "      <td>None</td>\n",
       "      <td># Awesome Robotics Libraries\\n\\nA curated list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>petercorke/robotics-toolbox-python</td>\n",
       "      <td>Python</td>\n",
       "      <td># Robotics Toolbox for Python\\n\\n[![A Python R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unity-Technologies/Unity-Robotics-Hub</td>\n",
       "      <td>C#</td>\n",
       "      <td>&lt;p align=\"center\"&gt;&lt;img src=\"images/warehouse.g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    repo    language  \\\n",
       "0            AtsushiSakai/PythonRobotics      Python   \n",
       "1              kiloreux/awesome-robotics        None   \n",
       "2                  NxRLab/ModernRobotics      Python   \n",
       "3              mithi/robotics-coursework        None   \n",
       "4                 onlytailei/CppRobotics         C++   \n",
       "5               JdeRobot/RoboticsAcademy  JavaScript   \n",
       "6        pptacher/probabilistic_robotics         C++   \n",
       "7     jslee02/awesome-robotics-libraries        None   \n",
       "8     petercorke/robotics-toolbox-python      Python   \n",
       "9  Unity-Technologies/Unity-Robotics-Hub          C#   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  <img src=\"https://github.com/AtsushiSakai/Pyth...  \n",
       "1  Awesome Robotics\\n================\\n\\n[![Aweso...  \n",
       "2  # Modern Robotics:  Mechanics, Planning, and C...  \n",
       "3  # [🐳](https://mithi.github.io/deep-blueberry) ...  \n",
       "4  # CppRobotics\\n\\nThis is the cpp implementatio...  \n",
       "5  <a href=\"https://jderobot.github.io/\"><img src...  \n",
       "6  # probabilistic_robotics\\nI am working on deta...  \n",
       "7  # Awesome Robotics Libraries\\n\\nA curated list...  \n",
       "8  # Robotics Toolbox for Python\\n\\n[![A Python R...  \n",
       "9  <p align=\"center\"><img src=\"images/warehouse.g...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_df = pd.DataFrame(repos)\n",
    "repos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a23707f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AtsushiSakai/PythonRobotics</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;img src=\"https://github.com/AtsushiSakai/Pyth...</td>\n",
       "      <td>img srchttpsgithubcomatsushisakaipythonrobotic...</td>\n",
       "      <td>&lt;img src=\"https://github.com/AtsushiSakai/Pyth...</td>\n",
       "      <td>img srchttpsgithubcomatsushisakaipythonrobotic...</td>\n",
       "      <td>img srchttpsgithubcomatsushisakaipythonrobotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kiloreux/awesome-robotics</td>\n",
       "      <td>None</td>\n",
       "      <td>Awesome Robotics\\n================\\n\\n[![Aweso...</td>\n",
       "      <td>awesome robotics awesomehttpscdnrawgitcomsindr...</td>\n",
       "      <td>Awesome Robotics ================ [![Awesome](...</td>\n",
       "      <td>awesom robot awesomehttpscdnrawgitcomsindresor...</td>\n",
       "      <td>awesome robotics awesomehttpscdnrawgitcomsindr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NxRLab/ModernRobotics</td>\n",
       "      <td>Python</td>\n",
       "      <td># Modern Robotics:  Mechanics, Planning, and C...</td>\n",
       "      <td>modern robotics mechanics planning control cod...</td>\n",
       "      <td># Modern Robotics: Mechanics, Planning, Contro...</td>\n",
       "      <td>modern robot mechan plan control code librari ...</td>\n",
       "      <td>modern robotics mechanic planning control code...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mithi/robotics-coursework</td>\n",
       "      <td>None</td>\n",
       "      <td># [🐳](https://mithi.github.io/deep-blueberry) ...</td>\n",
       "      <td>httpsmithigithubiodeepblueberry httpskoficommi...</td>\n",
       "      <td># [🐳](https://mithi.github.io/deep-blueberry) ...</td>\n",
       "      <td>httpsmithigithubiodeepblueberri httpskoficommi...</td>\n",
       "      <td>httpsmithigithubiodeepblueberry httpskoficommi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>onlytailei/CppRobotics</td>\n",
       "      <td>C++</td>\n",
       "      <td># CppRobotics\\n\\nThis is the cpp implementatio...</td>\n",
       "      <td>cpprobotics cpp implementation pythonroboticsh...</td>\n",
       "      <td># CppRobotics This cpp implementation [PythonR...</td>\n",
       "      <td>cpprobot cpp implement pythonroboticshttpsgith...</td>\n",
       "      <td>cpprobotics cpp implementation pythonroboticsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JdeRobot/RoboticsAcademy</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>&lt;a href=\"https://jderobot.github.io/\"&gt;&lt;img src...</td>\n",
       "      <td>hrefhttpsjderobotgithubioimg srcimglogogif wid...</td>\n",
       "      <td>&lt;a href=\"https://jderobot.github.io/\"&gt;&lt;img src...</td>\n",
       "      <td>hrefhttpsjderobotgithubioimg srcimglogogif wid...</td>\n",
       "      <td>hrefhttpsjderobotgithubioimg srcimglogogif wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pptacher/probabilistic_robotics</td>\n",
       "      <td>C++</td>\n",
       "      <td># probabilistic_robotics\\nI am working on deta...</td>\n",
       "      <td>probabilisticrobotics working detailed solutio...</td>\n",
       "      <td># probabilistic_robotics I working detailed so...</td>\n",
       "      <td>probabilisticrobot work detail solut exercis b...</td>\n",
       "      <td>probabilisticrobotics working detailed solutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jslee02/awesome-robotics-libraries</td>\n",
       "      <td>None</td>\n",
       "      <td># Awesome Robotics Libraries\\n\\nA curated list...</td>\n",
       "      <td>awesome robotics libraries curated list roboti...</td>\n",
       "      <td># Awesome Robotics Libraries A curated list ro...</td>\n",
       "      <td>awesom robot librari curat list robot simul li...</td>\n",
       "      <td>awesome robotics library curated list robotics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>petercorke/robotics-toolbox-python</td>\n",
       "      <td>Python</td>\n",
       "      <td># Robotics Toolbox for Python\\n\\n[![A Python R...</td>\n",
       "      <td>robotics toolbox python python robotics packag...</td>\n",
       "      <td># Robotics Toolbox Python [![A Python Robotics...</td>\n",
       "      <td>robot toolbox python python robot packagehttps...</td>\n",
       "      <td>robotics toolbox python python robotics packag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unity-Technologies/Unity-Robotics-Hub</td>\n",
       "      <td>C#</td>\n",
       "      <td>&lt;p align=\"center\"&gt;&lt;img src=\"images/warehouse.g...</td>\n",
       "      <td>p aligncenterimg srcimageswarehousegifp unity ...</td>\n",
       "      <td>&lt;p align=\"center\"&gt;&lt;img src=\"images/warehouse.g...</td>\n",
       "      <td>p aligncenterimg srcimageswarehousegifp uniti ...</td>\n",
       "      <td>p aligncenterimg srcimageswarehousegifp unity ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    repo    language  \\\n",
       "0            AtsushiSakai/PythonRobotics      Python   \n",
       "1              kiloreux/awesome-robotics        None   \n",
       "2                  NxRLab/ModernRobotics      Python   \n",
       "3              mithi/robotics-coursework        None   \n",
       "4                 onlytailei/CppRobotics         C++   \n",
       "5               JdeRobot/RoboticsAcademy  JavaScript   \n",
       "6        pptacher/probabilistic_robotics         C++   \n",
       "7     jslee02/awesome-robotics-libraries        None   \n",
       "8     petercorke/robotics-toolbox-python      Python   \n",
       "9  Unity-Technologies/Unity-Robotics-Hub          C#   \n",
       "\n",
       "                                            original  \\\n",
       "0  <img src=\"https://github.com/AtsushiSakai/Pyth...   \n",
       "1  Awesome Robotics\\n================\\n\\n[![Aweso...   \n",
       "2  # Modern Robotics:  Mechanics, Planning, and C...   \n",
       "3  # [🐳](https://mithi.github.io/deep-blueberry) ...   \n",
       "4  # CppRobotics\\n\\nThis is the cpp implementatio...   \n",
       "5  <a href=\"https://jderobot.github.io/\"><img src...   \n",
       "6  # probabilistic_robotics\\nI am working on deta...   \n",
       "7  # Awesome Robotics Libraries\\n\\nA curated list...   \n",
       "8  # Robotics Toolbox for Python\\n\\n[![A Python R...   \n",
       "9  <p align=\"center\"><img src=\"images/warehouse.g...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  img srchttpsgithubcomatsushisakaipythonrobotic...   \n",
       "1  awesome robotics awesomehttpscdnrawgitcomsindr...   \n",
       "2  modern robotics mechanics planning control cod...   \n",
       "3  httpsmithigithubiodeepblueberry httpskoficommi...   \n",
       "4  cpprobotics cpp implementation pythonroboticsh...   \n",
       "5  hrefhttpsjderobotgithubioimg srcimglogogif wid...   \n",
       "6  probabilisticrobotics working detailed solutio...   \n",
       "7  awesome robotics libraries curated list roboti...   \n",
       "8  robotics toolbox python python robotics packag...   \n",
       "9  p aligncenterimg srcimageswarehousegifp unity ...   \n",
       "\n",
       "                                    remove_stopwords  \\\n",
       "0  <img src=\"https://github.com/AtsushiSakai/Pyth...   \n",
       "1  Awesome Robotics ================ [![Awesome](...   \n",
       "2  # Modern Robotics: Mechanics, Planning, Contro...   \n",
       "3  # [🐳](https://mithi.github.io/deep-blueberry) ...   \n",
       "4  # CppRobotics This cpp implementation [PythonR...   \n",
       "5  <a href=\"https://jderobot.github.io/\"><img src...   \n",
       "6  # probabilistic_robotics I working detailed so...   \n",
       "7  # Awesome Robotics Libraries A curated list ro...   \n",
       "8  # Robotics Toolbox Python [![A Python Robotics...   \n",
       "9  <p align=\"center\"><img src=\"images/warehouse.g...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  img srchttpsgithubcomatsushisakaipythonrobotic...   \n",
       "1  awesom robot awesomehttpscdnrawgitcomsindresor...   \n",
       "2  modern robot mechan plan control code librari ...   \n",
       "3  httpsmithigithubiodeepblueberri httpskoficommi...   \n",
       "4  cpprobot cpp implement pythonroboticshttpsgith...   \n",
       "5  hrefhttpsjderobotgithubioimg srcimglogogif wid...   \n",
       "6  probabilisticrobot work detail solut exercis b...   \n",
       "7  awesom robot librari curat list robot simul li...   \n",
       "8  robot toolbox python python robot packagehttps...   \n",
       "9  p aligncenterimg srcimageswarehousegifp uniti ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  img srchttpsgithubcomatsushisakaipythonrobotic...  \n",
       "1  awesome robotics awesomehttpscdnrawgitcomsindr...  \n",
       "2  modern robotics mechanic planning control code...  \n",
       "3  httpsmithigithubiodeepblueberry httpskoficommi...  \n",
       "4  cpprobotics cpp implementation pythonroboticsh...  \n",
       "5  hrefhttpsjderobotgithubioimg srcimglogogif wid...  \n",
       "6  probabilisticrobotics working detailed solutio...  \n",
       "7  awesome robotics library curated list robotics...  \n",
       "8  robotics toolbox python python robotics packag...  \n",
       "9  p aligncenterimg srcimageswarehousegifp unity ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_words = []\n",
    "exclude_words = []\n",
    "repos_df = prep.process_dataframe(repos_df, extra_words, exclude_words)\n",
    "repos_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
