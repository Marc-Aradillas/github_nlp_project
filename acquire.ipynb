{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e801830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from env import github_token, github_username\n",
    "import acquire as aqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0d2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = aqr.scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edf8cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'repo': 'AtsushiSakai/PythonRobotics',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': '<img src=\"https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true\" align=\"right\" width=\"300\" alt=\"header pic\"/>\\n\\n# PythonRobotics\\n![GitHub_Action_Linux_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/Linux_CI/badge.svg)\\n![GitHub_Action_MacOS_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/MacOS_CI/badge.svg)\\n![GitHub_Action_Windows_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/Windows_CI/badge.svg)\\n[![Build status](https://ci.appveyor.com/api/projects/status/sb279kxuv1be391g?svg=true)](https://ci.appveyor.com/project/AtsushiSakai/pythonrobotics)\\n[![codecov](https://codecov.io/gh/AtsushiSakai/PythonRobotics/branch/master/graph/badge.svg)](https://codecov.io/gh/AtsushiSakai/PythonRobotics)\\n\\nPython codes for robotics algorithm.\\n\\n\\n# Table of Contents\\n   * [What is this?](#what-is-this)\\n   * [Requirements](#requirements)\\n   * [Documentation](#documentation)\\n   * [How to use](#how-to-use)\\n   * [Localization](#localization)\\n      * [Extended Kalman Filter localization](#extended-kalman-filter-localization)\\n      * [Particle filter localization](#particle-filter-localization)\\n      * [Histogram filter localization](#histogram-filter-localization)\\n   * [Mapping](#mapping)\\n      * [Gaussian grid map](#gaussian-grid-map)\\n      * [Ray casting grid map](#ray-casting-grid-map)\\n      * [Lidar to grid map](#lidar-to-grid-map)\\n      * [k-means object clustering](#k-means-object-clustering)\\n      * [Rectangle fitting](#rectangle-fitting)\\n   * [SLAM](#slam)\\n      * [Iterative Closest Point (ICP) Matching](#iterative-closest-point-icp-matching)\\n      * [FastSLAM 1.0](#fastslam-10)\\n   * [Path Planning](#path-planning)\\n      * [Dynamic Window Approach](#dynamic-window-approach)\\n      * [Grid based search](#grid-based-search)\\n         * [Dijkstra algorithm](#dijkstra-algorithm)\\n         * [A* algorithm](#a-algorithm)\\n         * [D* algorithm](#d-algorithm)\\n         * [D* Lite algorithm](#d-lite-algorithm)\\n         * [Potential Field algorithm](#potential-field-algorithm)\\n         * [Grid based coverage path planning](#grid-based-coverage-path-planning)\\n      * [State Lattice Planning](#state-lattice-planning)\\n         * [Biased polar sampling](#biased-polar-sampling)\\n         * [Lane sampling](#lane-sampling)\\n      * [Probabilistic Road-Map (PRM) planning](#probabilistic-road-map-prm-planning)\\n      * [Rapidly-Exploring Random Trees (RRT)](#rapidly-exploring-random-trees-rrt)\\n         * [RRT*](#rrt)\\n         * [RRT* with reeds-shepp path](#rrt-with-reeds-shepp-path)\\n         * [LQR-RRT*](#lqr-rrt)\\n      * [Quintic polynomials planning](#quintic-polynomials-planning)\\n      * [Reeds Shepp planning](#reeds-shepp-planning)\\n      * [LQR based path planning](#lqr-based-path-planning)\\n      * [Optimal Trajectory in a Frenet Frame](#optimal-trajectory-in-a-frenet-frame)\\n   * [Path Tracking](#path-tracking)\\n      * [move to a pose control](#move-to-a-pose-control)\\n      * [Stanley control](#stanley-control)\\n      * [Rear wheel feedback control](#rear-wheel-feedback-control)\\n      * [Linear–quadratic regulator (LQR) speed and steering control](#linearquadratic-regulator-lqr-speed-and-steering-control)\\n      * [Model predictive speed and steering control](#model-predictive-speed-and-steering-control)\\n      * [Nonlinear Model predictive control with C-GMRES](#nonlinear-model-predictive-control-with-c-gmres)\\n   * [Arm Navigation](#arm-navigation)\\n      * [N joint arm to point control](#n-joint-arm-to-point-control)\\n      * [Arm navigation with obstacle avoidance](#arm-navigation-with-obstacle-avoidance)\\n   * [Aerial Navigation](#aerial-navigation)\\n      * [drone 3d trajectory following](#drone-3d-trajectory-following)\\n      * [rocket powered landing](#rocket-powered-landing)\\n   * [Bipedal](#bipedal)\\n      * [bipedal planner with inverted pendulum](#bipedal-planner-with-inverted-pendulum)\\n   * [License](#license)\\n   * [Use-case](#use-case)\\n   * [Contribution](#contribution)\\n   * [Citing](#citing)\\n   * [Support](#support)\\n   * [Sponsors](#sponsors)\\n      * [JetBrains](#JetBrains)\\n      * [1Password](#1password)\\n   * [Authors](#authors)\\n\\n# What is this?\\n\\nThis is a Python code collection of robotics algorithms.\\n\\nFeatures:\\n\\n1. Easy to read for understanding each algorithm\\'s basic idea.\\n\\n2. Widely used and practical algorithms are selected.\\n\\n3. Minimum dependency.\\n\\nSee this paper for more details:\\n\\n- [\\\\[1808\\\\.10703\\\\] PythonRobotics: a Python code collection of robotics algorithms](https://arxiv.org/abs/1808.10703) ([BibTeX](https://github.com/AtsushiSakai/PythonRoboticsPaper/blob/master/python_robotics.bib))\\n\\n\\n# Requirements\\n\\nFor running each sample code:\\n\\n- [Python 3.11.x](https://www.python.org/)\\n \\n- [NumPy](https://numpy.org/)\\n \\n- [SciPy](https://scipy.org/)\\n \\n- [Matplotlib](https://matplotlib.org/)\\n \\n- [cvxpy](https://www.cvxpy.org/) \\n\\nFor development:\\n  \\n- [pytest](https://pytest.org/) (for unit tests)\\n  \\n- [pytest-xdist](https://pypi.org/project/pytest-xdist/) (for parallel unit tests)\\n  \\n- [mypy](http://mypy-lang.org/) (for type check)\\n  \\n- [sphinx](https://www.sphinx-doc.org/) (for document generation)\\n  \\n- [pycodestyle](https://pypi.org/project/pycodestyle/) (for code style check)\\n\\n# Documentation\\n\\nThis README only shows some examples of this project. \\n\\nIf you are interested in other examples or mathematical backgrounds of each algorithm, \\n\\nYou can check the full documentation online: [Welcome to PythonRobotics’s documentation\\\\! — PythonRobotics documentation](https://atsushisakai.github.io/PythonRobotics/index.html)\\n\\nAll animation gifs are stored here: [AtsushiSakai/PythonRoboticsGifs: Animation gifs of PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs)\\n\\n# How to use\\n\\n1. Clone this repo.\\n\\n   ```terminal\\n   git clone https://github.com/AtsushiSakai/PythonRobotics.git\\n   ```\\n\\n\\n2. Install the required libraries.\\n\\n- using conda :\\n\\n  ```terminal\\n  conda env create -f requirements/environment.yml\\n  ```\\n \\n- using pip :\\n\\n  ```terminal\\n  pip install -r requirements/requirements.txt\\n  ```\\n\\n\\n3. Execute python script in each directory.\\n\\n4. Add star to this repo if you like it :smiley:. \\n\\n# Localization\\n\\n## Extended Kalman Filter localization\\n\\n<img src=\"https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif\" width=\"640\" alt=\"EKF pic\">\\n\\nRef:\\n\\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/localization/extended_kalman_filter_localization_files/extended_kalman_filter_localization.html)\\n\\n## Particle filter localization\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif)\\n\\nThis is a sensor fusion localization with Particle Filter(PF).\\n\\nThe blue line is true trajectory, the black line is dead reckoning trajectory,\\n\\nand the red line is an estimated trajectory with PF.\\n\\nIt is assumed that the robot can measure a distance from landmarks (RFID).\\n\\nThese measurements are used for PF localization.\\n\\nRef:\\n\\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\\n\\n\\n## Histogram filter localization\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif)\\n\\nThis is a 2D localization example with Histogram filter.\\n\\nThe red cross is true position, black points are RFID positions.\\n\\nThe blue grid shows a position probability of histogram filter.  \\n\\nIn this simulation, x,y are unknown, yaw is known.\\n\\nThe filter integrates speed input and range observations from RFID for localization.\\n\\nInitial position is not needed.\\n\\nRef:\\n\\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\\n\\n# Mapping\\n\\n## Gaussian grid map\\n\\nThis is a 2D Gaussian grid mapping example.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif)\\n\\n## Ray casting grid map\\n\\nThis is a 2D ray casting grid mapping example.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif)\\n\\n## Lidar to grid map\\n\\nThis example shows how to convert a 2D range measurement to a grid map.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/lidar_to_grid_map/animation.gif)\\n\\n## k-means object clustering\\n\\nThis is a 2D object clustering with k-means algorithm.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif)\\n\\n## Rectangle fitting\\n\\nThis is a 2D rectangle fitting for vehicle detection.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif)\\n\\n\\n# SLAM\\n\\nSimultaneous Localization and Mapping(SLAM) examples\\n\\n## Iterative Closest Point (ICP) Matching\\n\\nThis is a 2D ICP matching example with singular value decomposition.\\n\\nIt can calculate a rotation matrix, and a translation vector between points and points.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif)\\n\\nRef:\\n\\n- [Introduction to Mobile Robotics: Iterative Closest Point Algorithm](https://cs.gmu.edu/~kosecka/cs685/cs685-icp.pdf)\\n\\n\\n## FastSLAM 1.0\\n\\nThis is a feature based SLAM example using FastSLAM 1.0.\\n\\nThe blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.\\n\\nThe red points are particles of FastSLAM.\\n\\nBlack points are landmarks, blue crosses are estimated landmark positions by FastSLAM.\\n\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif)\\n\\n\\nRef:\\n\\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\\n\\n- [SLAM simulations by Tim Bailey](http://www-personal.acfr.usyd.edu.au/tbailey/software/slam_simulations.htm)\\n\\n\\n# Path Planning\\n\\n## Dynamic Window Approach\\n\\nThis is a 2D navigation sample code with Dynamic Window Approach.\\n\\n- [The Dynamic Window Approach to Collision Avoidance](https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf)\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif)\\n\\n\\n## Grid based search\\n\\n### Dijkstra algorithm\\n\\nThis is a 2D grid based the shortest path planning with Dijkstra\\'s algorithm.\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif)\\n\\nIn the animation, cyan points are searched nodes.\\n\\n### A\\\\* algorithm\\n\\nThis is a 2D grid based the shortest path planning with A star algorithm.\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif)\\n\\nIn the animation, cyan points are searched nodes.\\n\\nIts heuristic is 2D Euclid distance.\\n\\n### D\\\\* algorithm\\n\\nThis is a 2D grid based the shortest path planning with D star algorithm.\\n\\n![figure at master · nirnayroy/intelligentrobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStar/animation.gif)\\n\\nThe animation shows a robot finding its path avoiding an obstacle using the D* search algorithm.\\n\\nRef:\\n\\n- [D* Algorithm Wikipedia](https://en.wikipedia.org/wiki/D*)\\n\\n### D\\\\* Lite algorithm\\n\\nThis algorithm finds the shortest path between two points while rerouting when obstacles are discovered. It has been implemented here for a 2D grid.\\n\\n![D* Lite](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStarLite/animation.gif)\\n\\nThe animation shows a robot finding its path and rerouting to avoid obstacles as they are discovered using the D* Lite search algorithm.\\n\\nRefs:\\n\\n- [D* Lite](http://idm-lab.org/bib/abstracts/papers/aaai02b.pd)\\n- [Improved Fast Replanning for Robot Navigation in Unknown Terrain](http://www.cs.cmu.edu/~maxim/files/dlite_icra02.pdf)\\n\\n### Potential Field algorithm\\n\\nThis is a 2D grid based path planning with Potential Field algorithm.\\n\\n![PotentialField](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif)\\n\\nIn the animation, the blue heat map shows potential value on each grid.\\n\\nRef:\\n\\n- [Robotic Motion Planning:Potential Functions](https://www.cs.cmu.edu/~motionplanning/lecture/Chap4-Potential-Field_howie.pdf)\\n\\n### Grid based coverage path planning\\n\\nThis is a 2D grid based coverage path planning simulation.\\n\\n![PotentialField](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif)\\n\\n## State Lattice Planning\\n\\nThis script is a path planning code with state lattice planning.\\n\\nThis code uses the model predictive trajectory generator to solve boundary problem.\\n\\nRef: \\n\\n- [Optimal rough terrain trajectory generation for wheeled mobile robots](http://journals.sagepub.com/doi/pdf/10.1177/0278364906075328)\\n\\n- [State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments](http://www.frc.ri.cmu.edu/~alonzo/pubs/papers/JFR_08_SS_Sampling.pdf)\\n\\n\\n### Biased polar sampling\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif)\\n\\n\\n### Lane sampling\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif)\\n\\n## Probabilistic Road-Map (PRM) planning \\n\\n![PRM](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif)\\n\\nThis PRM planner uses Dijkstra method for graph search.\\n\\nIn the animation, blue points are sampled points,\\n\\nCyan crosses means searched points with Dijkstra method,\\n\\nThe red line is the final path of PRM.\\n\\nRef:\\n\\n- [Probabilistic roadmap \\\\- Wikipedia](https://en.wikipedia.org/wiki/Probabilistic_roadmap)\\n\\n\\u3000\\u3000\\n\\n## Rapidly-Exploring Random Trees (RRT)\\n\\n### RRT\\\\*\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif)\\n\\nThis is a path planning code with RRT\\\\*\\n\\nBlack circles are obstacles, green line is a searched tree, red crosses are start and goal positions.\\n\\nRef:\\n\\n- [Incremental Sampling-based Algorithms for Optimal Motion Planning](https://arxiv.org/abs/1005.0416)\\n\\n- [Sampling-based Algorithms for Optimal Motion Planning](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.5503&rep=rep1&type=pdf)\\n\\n### RRT\\\\* with reeds-shepp path\\n\\n![Robotics/animation.gif at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif))\\n\\nPath planning for a car robot with RRT\\\\* and reeds shepp path planner.\\n\\n### LQR-RRT\\\\*\\n\\nThis is a path planning simulation with LQR-RRT\\\\*.\\n\\nA double integrator motion model is used for LQR local planner.\\n\\n![LQR_RRT](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif)\\n\\nRef:\\n\\n- [LQR\\\\-RRT\\\\*: Optimal Sampling\\\\-Based Motion Planning with Automatically Derived Extension Heuristics](http://lis.csail.mit.edu/pubs/perez-icra12.pdf)\\n\\n- [MahanFathi/LQR\\\\-RRTstar: LQR\\\\-RRT\\\\* method is used for random motion planning of a simple pendulum in its phase plot](https://github.com/MahanFathi/LQR-RRTstar)\\n\\n\\n## Quintic polynomials planning\\n\\nMotion planning with quintic polynomials.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif)\\n\\nIt can calculate a 2D path, velocity, and acceleration profile based on quintic polynomials.\\n\\nRef:\\n\\n- [Local Path Planning And Motion Control For Agv In Positioning](http://ieeexplore.ieee.org/document/637936/)\\n\\n## Reeds Shepp planning\\n\\nA sample code with Reeds Shepp path planning.\\n\\n![RSPlanning](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true)\\n\\nRef:\\n\\n- [15.3.2 Reeds\\\\-Shepp Curves](http://planning.cs.uiuc.edu/node822.html) \\n\\n- [optimal paths for a car that goes both forwards and backwards](https://pdfs.semanticscholar.org/932e/c495b1d0018fd59dee12a0bf74434fac7af4.pdf)\\n\\n- [ghliu/pyReedsShepp: Implementation of Reeds Shepp curve\\\\.](https://github.com/ghliu/pyReedsShepp)\\n\\n\\n## LQR based path planning\\n\\nA sample code using LQR based path planning for double integrator model.\\n\\n![RSPlanning](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true)\\n\\n\\n## Optimal Trajectory in a Frenet Frame \\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif)\\n\\nThis is optimal trajectory generation in a Frenet Frame.\\n\\nThe cyan line is the target course and black crosses are obstacles.\\n\\nThe red line is the predicted path.\\n\\nRef:\\n\\n- [Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame](https://www.researchgate.net/profile/Moritz_Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af.pdf)\\n\\n- [Optimal trajectory generation for dynamic street scenarios in a Frenet Frame](https://www.youtube.com/watch?v=Cj6tAQe7UCY)\\n\\n\\n# Path Tracking\\n\\n## move to a pose control\\n\\nThis is a simulation of moving to a pose control\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif)\\n\\nRef:\\n\\n- [P. I. Corke, \"Robotics, Vision and Control\" \\\\| SpringerLink p102](https://link.springer.com/book/10.1007/978-3-642-20144-8)\\n\\n\\n## Stanley control\\n\\nPath tracking simulation with Stanley steering control and PID speed control.\\n\\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif)\\n\\nRef:\\n\\n- [Stanley: The robot that won the DARPA grand challenge](http://robots.stanford.edu/papers/thrun.stanley05.pdf)\\n\\n- [Automatic Steering Methods for Autonomous Automobile Path Tracking](https://www.ri.cmu.edu/pub_files/2009/2/Automatic_Steering_Methods_for_Autonomous_Automobile_Path_Tracking.pdf)\\n\\n\\n\\n## Rear wheel feedback control\\n\\nPath tracking simulation with rear wheel feedback steering control and PID speed control.\\n\\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif)\\n\\nRef:\\n\\n- [A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles](https://arxiv.org/abs/1604.07446)\\n\\n\\n## Linear–quadratic regulator (LQR) speed and steering control\\n\\nPath tracking simulation with LQR speed and steering control.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif)\\n\\nRef:\\n\\n- [Towards fully autonomous driving: Systems and algorithms \\\\- IEEE Conference Publication](http://ieeexplore.ieee.org/document/5940562/)\\n\\n\\n## Model predictive speed and steering control\\n\\nPath tracking simulation with iterative linear model predictive speed and steering control.\\n\\n<img src=\"https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif\" width=\"640\" alt=\"MPC pic\">\\n\\nRef:\\n\\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/path_tracking/model_predictive_speed_and_steering_control/model_predictive_speed_and_steering_control.html)\\n\\n- [Real\\\\-time Model Predictive Control \\\\(MPC\\\\), ACADO, Python \\\\| Work\\\\-is\\\\-Playing](http://grauonline.de/wordpress/?page_id=3244)\\n\\n## Nonlinear Model predictive control with C-GMRES\\n\\nA motion planning and path tracking simulation with NMPC of C-GMRES \\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif)\\n\\nRef:\\n\\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/path_tracking/cgmres_nmpc/cgmres_nmpc.html)\\n\\n\\n# Arm Navigation\\n\\n## N joint arm to point control\\n\\nN joint arm to a point control simulation.\\n\\nThis is an interactive simulation.\\n\\nYou can set the goal position of the end effector with left-click on the plotting area. \\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif)\\n\\nIn this simulation N = 10, however, you can change it.\\n\\n## Arm navigation with obstacle avoidance \\n\\nArm navigation with obstacle avoidance simulation.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif)\\n\\n\\n# Aerial Navigation\\n\\n## drone 3d trajectory following \\n\\nThis is a 3d trajectory following simulation for a quadrotor.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif)\\n\\n## rocket powered landing\\n\\nThis is a 3d trajectory generation simulation for a rocket powered landing.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif)\\n\\nRef:\\n\\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/aerial_navigation/rocket_powered_landing/rocket_powered_landing.html)\\n\\n# Bipedal\\n\\n## bipedal planner with inverted pendulum\\n\\nThis is a bipedal planner for modifying footsteps for an inverted pendulum.\\n\\nYou can set the footsteps, and the planner will modify those automatically.\\n\\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif)\\n\\n# License \\n\\nMIT\\n\\n# Use-case\\n\\nIf this project helps your robotics project, please let me know with creating an issue.\\n\\nYour robot\\'s video, which is using PythonRobotics, is very welcome!!\\n\\nThis is a list of user\\'s comment and references:[users\\\\_comments](https://github.com/AtsushiSakai/PythonRobotics/blob/master/users_comments.md)\\n\\n# Contribution\\n\\nAny contribution is welcome!! \\n\\nPlease check this document:[How To Contribute — PythonRobotics documentation](https://atsushisakai.github.io/PythonRobotics/how_to_contribute.html)\\n\\n# Citing\\n\\nIf you use this project\\'s code for your academic work, we encourage you to cite [our papers](https://arxiv.org/abs/1808.10703) \\n\\nIf you use this project\\'s code in industry, we\\'d love to hear from you as well; feel free to reach out to the developers directly.\\n\\n# <a id=\"support\"></a>Supporting this project\\n\\nIf you or your company would like to support this project, please consider:\\n\\n- [Sponsor @AtsushiSakai on GitHub Sponsors](https://github.com/sponsors/AtsushiSakai)\\n\\n- [Become a backer or sponsor on Patreon](https://www.patreon.com/myenigma)\\n\\n- [One-time donation via PayPal](https://www.paypal.me/myenigmapay/)\\n\\nIf you would like to support us in some other way, please contact with creating an issue.\\n\\n## <a id=\"sponsors\"></a>Sponsors\\n\\n### <a id=\"JetBrains\"></a>[JetBrains](https://www.jetbrains.com/)\\n\\nThey are providing a free license of their IDEs for this OSS development.   \\n\\n### [1Password](https://github.com/1Password/1password-teams-open-source)\\n\\nThey are providing a free license of their 1Password team license for this OSS project.   \\n\\n\\n# Authors\\n\\n- [Contributors to AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics/graphs/contributors)\\n\\n'},\n",
       " {'repo': 'kiloreux/awesome-robotics',\n",
       "  'language': None,\n",
       "  'readme_contents': \"Awesome Robotics\\n================\\n\\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\\n\\nThis is a list of various books, courses and other resources for robotics. It's an attempt to gather useful material in one place for everybody who wants to learn more about the field.\\n\\n\\n### Courses ###\\n* [Artificial Intelligence for Robotics](https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373) **Udacity**\\n* [Robotics Nanodegree](https://www.udacity.com/course/robotics-software-engineer--nd209) **Udacity** :dollar:\\n* [Autonomous Mobile Robots](https://courses.edx.org/courses/course-v1:ETHx+AMRx+2T2019/5b151c51e8bf47c29d97f8a12369df17/) **edX**\\n* [Underactuated Robotics](http://underactuated.csail.mit.edu/underactuated.html) **MIT CSAIL**\\n* [Autonomous Mobile Robots](https://courses.edx.org/courses/ETHx/AMRx/1T2014/info) **edX**\\n* [Robot Mechanics and Control, Part I](https://www.edx.org/course/robot-mechanics-control-part-i-snux-snu446-345-1x) **edX**\\n* [Robot Mechanics and Control, Part II](https://www.edx.org/course/robot-mechanics-control-part-ii-snux-snu446-345-2x) **edX**\\n* [Autonomous Navigation for Flying Robots](https://www.edx.org/course/autonomous-navigation-flying-robots-tumx-autonavx-0) **edX**\\n* [Robotics Specialization by GRASP Lab](https://www.coursera.org/specializations/robotics) **Coursera** :dollar:\\n* [Control of Mobile Robots](https://www.coursera.org/course/conrob) **Coursera**\\n* [QUT Robot Academy](https://robotacademy.net.au/) **QUT**\\n* [Robotic vision](https://www.qut.edu.au/study/short-courses-and-professional-development/short-courses/robotic-vision) **QUT**\\n* [Introduction to robotics](http://ocw.mit.edu/courses/mechanical-engineering/2-12-introduction-to-robotics-fall-2005/) **MIT**\\n* [Robotics: Vision Intelligence and Machine Learning](https://www.edx.org/course/robotics-vision-intelligence-machine-pennx-robo2x) **edX**\\n* [Applied robot design](https://www.youtube.com/user/StanfordCS235/videos) **Stanford University**\\n* [Introduction to Robotics](https://see.stanford.edu/Course/CS223A) **Stanford University**\\n* [Introduction to Mobile Robotics](http://ais.informatik.uni-freiburg.de/teaching/ss16/robotics/index_en.php) **University of Freiburg**\\n* [Robotics](https://www.edx.org/micromasters/pennx-robotics) **edx** :dollar:\\n* [Columbia Robotics](https://www.edx.org/course/robotics-columbiax-csmm-103x-2) **edx** \\n* [Modern Robotics: Mechanics, Planning, and Control](https://www.coursera.org/specializations/modernrobotics?) **Coursera**\\n* [Hello (Real) World with ROS – Robot Operating System](https://www.edx.org/course/hello-real-world-with-ros-robot-operating-system-2) **edx**\\n* [Advanced Robotics](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/) **UCBerkeley**\\n* [Building Arduino robots and devices](https://www.coursera.org/learn/arduino) **Coursera**\\n* [Introduction to The Robot Operating System (ROS2)](https://www.coursera.org/projects/ros2-intro) **Coursera**\\n* [Modern Robotics: Mechanics, Planning, and Control Specialization](https://www.coursera.org/specializations/modernrobotics) **Coursera**\\n* [Become a Robotics Software Enginee](https://www.udacity.com/course/robotics-software-engineer--nd209) **Udacity**\\n* [Advanced Robotics](http://www.cs.berkeley.edu/~pabbeel/cs287-fa13/) **UC Berkeley**\\n\\n### Books ###\\n* [Probabilistic Robotics (Intelligent Robotics and Autonomous Agents series)](http://www.amazon.com/Probabilistic-Robotics-Intelligent-Autonomous-Agents/dp/0262201623/)  :dollar:\\n* [Introduction to Autonomous Mobile Robots (Intelligent Robotics and Autonomous Agents series)](http://www.amazon.com/Introduction-Autonomous-Mobile-Intelligent-Robotics/dp/0262015358/)  :dollar:\\n* [Springer Handbook of Robotics](https://www.amazon.com/Springer-Handbook-Robotics-Handbooks/dp/3319325507/)  :dollar:\\n* [Planning Algorithms](http://planning.cs.uiuc.edu/)\\n* [A gentle introduction to ROS](https://cse.sc.edu/~jokane/agitr/agitr-letter.pdf)\\n* [A Mathematical Introduction to Robotic Manipulation](http://www.cds.caltech.edu/~murray/mlswiki/?title=First_edition)\\n* [Learning Computing With Robots](http://wiki.roboteducation.org/Introduction_to_Computer_Science_via_Robots)\\n* [Robotics, Vision and Control: Fundamental Algorithms in MATLAB (Springer Tracts in Advanced Robotics)](http://www.amazon.com/Robotics-Vision-Control-Fundamental-Algorithms/dp/3642201431)  :dollar:\\n* [INTECH Books](http://www.intechopen.com/subjects/robotics)\\n* [Introduction to Autonomous Robots](https://github.com/correll/Introduction-to-Autonomous-Robots/releases)\\n* [Principles of Robot Motion: Theory, Algorithms, and Implementations ](https://www.amazon.com/Principles-Robot-Motion-Implementations-Intelligent/dp/0262033275):dollar:\\n* [Introduction to Modern Robotics: Mechanics, Planning, and Control](http://hades.mech.northwestern.edu/index.php/LynchAndPark) [[pdf](http://hades.mech.northwestern.edu/images/7/7f/MR.pdf)]\\n* [Programming Robots with ROS: A Practical Introduction to the Robot Operating System](https://www.amazon.com/Programming-Robots-ROS-Practical-Introduction/dp/1449323898/) :dollar:\\n* [Learning ROS for Robotics Programming](https://www.amazon.com/Learning-ROS-Robotics-Programming-Second/dp/1783987588) :dollar:\\n* [Mastering ROS for Robotics Programming](https://www.amazon.com/Mastering-Robotics-Programming-Lentin-Joseph/dp/1783551798) :dollar:\\n* [Behavior Trees in Robotics and AI: An Introduction](https://btirai.github.io/) [[pdf](https://arxiv.org/pdf/1709.00084)]\\n* [Automated Planning and Acting](http://projects.laas.fr/planning/) [[pdf](http://projects.laas.fr/planning/book.pdf)]\\n* [Robotics for Software Engineers](https://www.manning.com/books/robotics-for-software-engineers) :dollar:\\n\\n\\n### Software and Libraries ###\\n[**Gazebo**](http://gazebosim.org/)\\nRobot Simulator\\n\\n[**ROS**](http://www.ros.org/)\\nThe Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.\\n\\n[**ROS2**](https://index.ros.org/doc/ros2/)\\nROS2 is a new version of ROS with radical design changes and improvement over older ROS version.\\n\\n[**RobWork**](http://www.robwork.dk/apidoc/nightly/rw/)\\nRobWork is a collection of C++ libraries for simulation and control of robot systems. RobWork is used for research and education as well as for practical robot applications.\\n\\n[**MRPT**](http://www.mrpt.org/)\\nMobile Robot Programming Toolkit provides developers with portable and well-tested applications and libraries covering data structures and algorithms employed in common robotics research areas.\\n\\n[**Robotics Library**](http://www.roboticslibrary.org/)\\nThe Robotics Library (RL) is a self-contained C++ library for robot kinematics, motion planning and control. It covers mathematics, kinematics and dynamics, hardware abstraction, motion planning, collision detection, and visualization.\\n\\n[**Simbad**](http://simbad.sourceforge.net/)\\n2D/3D simulator in Java and Jython.\\n\\n[**Morse**](https://www.openrobots.org/wiki/morse/)\\nGeneral purpose indoor/outdoor 3D simulator.\\n\\n[**Carmen**](http://carmen.sourceforge.net/)\\nCARMEN is an open-source collection of software for mobile robot control. CARMEN is modular software designed to provide basic navigation primitives including: base and sensor control, logging, obstacle avoidance, localization, path planning, and mapping.\\n\\n[**Peekabot**](http://www.peekabot.org/)\\nPeekabot is a real-time, networked 3D visualization tool for robotics, written in C++. Its purpose is to simplify the visualization needs faced by a roboticist daily.\\n\\n[**YARP**](http://www.yarp.it/)\\nYet Another Robot Platform.\\n\\n[**V-REP**](http://www.coppeliarobotics.com/)\\nRobot simulator, 3D, source available, Lua scripting, APIs for C/C++, Python, Java, Matlab, URBI, 2 physics engines, full kinematic solver.\\n\\n[**Webots**](https://www.cyberbotics.com/overview)\\nWebots is a development environment used to model, program and simulate mobile robots.\\n\\n[**Drake**](http://drake.mit.edu/)\\nA planning, control and analysis toolbox for nonlinear dynamical systems.\\n\\n[**Neurorobotics Platform (NRP)**](https://neurorobotics.net/)\\nAn Internet-accessible simulation system that allows the simulation of robots controlled by spiking neural networks.\\n\\n[**The Player Project**](http://playerstage.sourceforge.net/)\\nFree Software tools for robot and sensor applications\\n\\n[**Open AI's Roboschool**](https://github.com/openai/roboschool)\\nOpen-source software for robot simulation, integrated with OpenAI Gym.\\n\\n[**ViSP**](http://visp.inria.fr/)\\nOpen-source visual servoing platform library, is able to compute control laws that can be applied to robotic systems.\\n\\n[**ROS Behavior Trees**](https://github.com/miccol/ROS-Behavior-Tree)\\nOpen-source library to create robot's behaviors in form of Behavior Trees running in ROS (Robot Operating System).\\n\\n[**g2core**](https://github.com/synthetos/g2)\\nOpen-source motion control software for CNC and Robotics, designed to run on Arduino Due class microcontrollers.\\n\\n[**ur5controller**](https://github.com/roboticsleeds/ur5controller)\\nOpen-source OpenRAVE controller for UR5 robot integrated with ROS.\\n\\n[**RBDL**](https://github.com/rbdl/rbdl)\\nOpen-source (zlib) C++ libray for both forward and inverse dynamics and kinematics. Also supports contacts and loops.\\n\\n[**Unity Robotics Hub**](https://github.com/Unity-Technologies/Unity-Robotics-Hub)\\nCentral repository for open-source Unity packages, tutorials, and other resources demonstrating how to use Unity for robotics simulations. Includes new support for ROS integration.\\n\\n### Papers ###\\n* [Optimization Based Controller Design and Implementation for the\\nAtlas Robot in the DARPA Robotics Challenge Finals](https://www.cs.cmu.edu/~cga/drc/ICHR15_0025_MS.pdf)\\n\\n\\n### Conferences ###\\n* [ACM/IEEE International Conference on Human Robot Interaction (HRI)](http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1040036)\\n* [CISM IFToMM Symposium on Robot Design, Dynamics and Control (RoManSy)](http://www.romansy2016.org/)\\n* [IEEE Conference on Decision and Controls (CDC)](http://ieeexplore.ieee.org/servlet/opac?punumber=1000188)\\n* [IEEE International Conference on Rehabilitation Robotics (ICORR)](http://www.rehabrobotics.org/)\\n* [IEEE International Conference on Robotics and Automation (ICRA)](http://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra)\\n* [IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)](http://www.iros.org/)\\n* [IEEE-RAS International Conference on Humanoid Robots (Humanoids)](http://ieeexplore.ieee.org/servlet/opac?punumber=1002042)\\n* [International Symposium of Robotic Research (ISRR)](http://ifrr.org/isrr.php)\\n* [International Symposium of Experimental Robotics (ISER)](http://ifrr.org/iser.php)\\n* [Robotica](http://www.ieee-ras.org/conferences-workshops/technically-co-sponsored/robotica)\\n* [Robotics: Science and Systems Conference (RSS)](http://www.roboticsconference.org/)\\n* [The International Workshop on the Algorithmic Foundations of Robotics (WAFR)](http://www.wafr.org/)\\n\\n\\n### Journals ###\\n* [Autonomous Robots](http://www.springer.com/engineering/robotics/journal/10514)\\n* [Bioinspiration & Biomimetics](http://iopscience.iop.org/journal/1748-3190)\\n* [Frontiers in Robotics and AI](http://journal.frontiersin.org/journal/robotics-and-ai)\\n* [IEEE Robotics & Automation Magazine](http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=100)\\n* [IEEE Transactions on Haptics](http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4543165)\\n* [IEEE Transactions on Robotics](http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8860)\\n* [IEEE/ASME Transactions on Mechatronics](http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=3516)\\n* [International Journal of Social Robotics](http://www.springer.com/engineering/robotics/journal/12369)\\n* [Journal of Field Robotics](http://www.journalfieldrobotics.org/Home.html)\\n* [Journal of Intelligent & Robotic Systems](http://www.springer.com/engineering/robotics/journal/10846)\\n* [Mechatronics](http://www.journals.elsevier.com/mechatronics)\\n* [Robotics and Computer-Integrated Manufacturing](http://www.journals.elsevier.com/robotics-and-computer-integrated-manufacturing)\\n* [Robotics and Autonomous Systems](http://www.journals.elsevier.com/robotics-and-autonomous-systems)\\n* [The International Journal of Robotics Research](http://www.ijrr.org/)\\n\\n\\n### Competitions ###\\n* [ICRA Robot Challenges](http://www.icra2017.org/conference/robot-challenges)\\n* [RobotChallenge](http://www.robotchallenge.org/)\\n* [DARPA Robotics Challenge](http://www.theroboticschallenge.org/)\\n* [European Robotics Challenges](http://www.euroc-project.eu/)\\n* [First Robotics Competition](http://www.firstinspires.org/robotics/frc)\\n* [VEX Robotics Competition](https://www.vexrobotics.com/)\\n* [RoboCup](http://www.robocup.org/)\\n* [RoboCupJunior](https://junior.robocup.org/)\\n* [Eurobot](http://www.eurobot.org/) International Students Robotics Contest\\n* [RoboMasters](https://www.robomaster.com/en-US)\\n* [RoboSoft, Grand Challenge](http://www.robosoftca.eu/)\\n* [Intelligent Ground Vehicle Competition](http://www.igvc.org/)\\n* [Robotex](https://robotex.ee/en/) The biggest robotics festival in Europe\\n* [First Lego League](https://www.firstlegoleague.org/)\\n\\n### Companies ###\\n* [Boston Dynamics](http://www.bostondynamics.com/) robotics R&D company, creator of the state of the art [Atlas](https://www.youtube.com/watch?v=rVlhMGQgDkY) and [Spot](https://www.youtube.com/watch?v=M8YjvHYbZ9w) robots\\n* [iRobot](http://www.irobot.com/) manufacturer of the famous [Roomba](https://en.wikipedia.org/wiki/Roomba) robotic vacuum cleaner\\n* [PAL Robotics](http://pal-robotics.com)\\n* [Aldebaran Robotics](https://www.aldebaran.com/en) creator of the [NAO robot](https://www.youtube.com/watch?v=nNbj2G3GmAo)\\n* [ABB Robotics](http://new.abb.com/products/robotics) the largest manufacturer of industrial robots\\n* [KUKA Robotics](http://www.kuka-robotics.com/en/) major manufacturer of industrial robots targeted at factory automation\\n* [FANUC](http://www.fanucamerica.com/) industrial robots manufacturer with the biggest install base\\n* [Rethink Robotics](http://www.rethinkrobotics.com/) creator of the collaborative robot [Baxter](https://www.youtube.com/watch?v=fCML42boO8c)\\n* [DJI](http://www.dji.com/) industry leader in drones for both commerical and industrial needs.\\n* [The construct sim](http://www.theconstructsim.com/)  A cloud based tool for building modern, future-proof robot simulations.\\n* [Fetch Robotics](http://www.fetchrobotics.com/) A robotics startup in San Jose, CA building the future of e-commerce fulfillment and R&D robots.\\n* [Festo Robotics](https://www.festo.com/) Festo is known for making moving robots that move like animals such as the sea gull like SmartBird, jellyfish, butterflies and kangaroos.\\n* [Neobotix](https://www.neobotix-robots.com/homepage) manufacturer of industrial, research and as well as custom mobile robots. \\n\\n### Misc ###\\n* [IEEE Spectrum Robotics](http://spectrum.ieee.org/robotics) robotics section of the IEEE Spectrum magazine\\n* [MIT Technology Review Robotics](https://www.technologyreview.com/c/robotics/) robotics section of the MIT Technology Review magazine\\n* [reddit robotics subreddit](https://www.reddit.com/r/robotics/)\\n* [RosCON conference (video talks included)](http://roscon.ros.org/2015/)\\n* [Carnegie Mellon Robotics Academy](http://education.rec.ri.cmu.edu/)\\n* [Let's Make Robots](http://letsmakerobots.com/)\\n* [How do I learn Robotics?](https://www.quora.com/How-do-I-learn-robotics)\\n* [Free NXT Lego MindStorms NXT-G code tutorials](http://www.drgraeme.net/DrGraeme-free-NXT-G-tutorials/ChV4.htm)\\n* [StackExachange Robotics community](https://robotics.stackexchange.com)\\n* [47 Programmable robotic kits](http://www.intorobotics.com/47-programmable-robotic-kits/)\\n* [Linorobot](https://linorobot.org/) A suite of DIY ROS compatible robots\\n* [Hexapod Robot Simulator](https://github.com/mithi/hexapod) - Solve and visualize hexapod robot inverse kinematics and gaits in the web\\n* [PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics) - Implementations of various robotics algorithms in python\\n\\n### Related awesome lists ###\\n* [Awesome Artificial Intelligence](https://github.com/owainlewis/awesome-artificial-intelligence)\\n* [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)\\n* [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning)\\n* [Awesome Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning)\\n* [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision)\\n* [Awesome Gazebo](https://github.com/fkromer/awesome-gazebo)\\n* [Awesome Reinforcement Learning](https://github.com/aikorea/awesome-rl/)\\n* [Awesome Robotics](https://github.com/ahundt/awesome-robotics)\\n* [Awesome Robotics Libraries](https://github.com/jslee02/awesome-robotics-libraries)\\n* [Awesome ROS2](https://github.com/fkromer/awesome-ros2)\\n* [Awesome RoboCupJunior Soccer](https://github.com/RoboCupJuniorTC/awesome-rcj-soccer)\\n\"},\n",
       " {'repo': 'NxRLab/ModernRobotics',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': \"# Modern Robotics:  Mechanics, Planning, and Control\\n# Code Library\\n\\nThis repository contains the code library accompanying [_Modern Robotics: \\nMechanics, Planning, and Control_](http://modernrobotics.org) (Kevin Lynch \\nand Frank Park, Cambridge University Press 2017). The \\n[user manual](/doc/MRlib.pdf) is in the doc directory.\\n\\nThe functions are available in:\\n\\n* Python\\n* MATLAB\\n* Mathematica\\n\\nEach function has a commented section above it explaining the inputs required for its use as well as an example of how it can be used and what the output will be. This repository also contains a pdf document that provides an overview of the available functions using MATLAB syntax. Functions are organized according to the chapter in which they are introduced in the book. Basic functions, such as functions to calculate the magnitude of a vector, normalize a vector, test if the value is near zero, and perform matrix operations such as multiplication and inverses, are not documented here.\\n\\nThe primary purpose of the provided software is to be easy to read and educational, reinforcing the concepts in the book. The code is optimized neither for efficiency nor robustness.\\n\\nSome unofficial versions in other languages are being developed:\\n* [C++ version](https://github.com/Le0nX/ModernRoboticsCpp)\\n* [Julia version](https://github.com/ferrolho/ModernRoboticsBook.jl)\\n* [Nim version](https://github.com/Nimbotics/ModernRoboticsNim)\\n\\nSome libraries built on ours:\\n* [KinematicsFromDescriptionTool](https://github.com/Interbotix/kinematics_from_description), which calculates the kinematics input parameters from a robot's URDF or robot_description parameter using ROS and Python3.\\n* [mr_urdf_loader](https://github.com/tjdalsckd/mr_urdf_loader), which generates `M`, `Slist`, `Blist`, `Mlist` and `Glist` parameters for kinematics and dynamics. It also provides UR5 simulation using `PyBullet`.\\n* [tf_rbdl](https://github.com/junhyeokahn/tf_rbdl#tf_rbdl), which refactors the Python version using the package `tensorflow`.\\n\\nAny contribution is welcomed but the maintenance team for this library here doesn't vouch for the reliability of those projects.\\n\"},\n",
       " {'repo': 'mithi/robotics-coursework',\n",
       "  'language': None,\n",
       "  'readme_contents': \"# [🐳](https://mithi.github.io/deep-blueberry) [☕️](https://ko-fi.com/minimithi) \\n\\n- If you want to use Arduino or Raspberry Pi to make robots, [this](./PROTOTYPING.md) short list might be helpful.\\n- Check [this](./BOOKS.MD) short list if you like reading textbooks.\\n- Here are [some pending links](https://github.com/mithi/robotics-coursework/issues/6) that might be someday be transfered in this document.\\n- If there's anything you think should be included here, you can submit an issue and I'll check it out.\\n\\n# Series of Courses\\n\\n- [♥️ Robot Academy][series1], Peter Corke, Queensland University of Technology\\n- [MIT Open Courseware: Robotics][series9] \\n- Coursera: [Robotics Specialization][series3], University of Pennsylvania\\n- Coursera: [Modern Robotics Specialization][series4] | [book][series11a] + [📺 channel][series11b], Northwestern University\\n- Coursera: [Self-Driving Cars][series10], University of Toronto\\n- :dollar: Udacity: [Robotics Nanodegree][series5]\\n- :dollar: Udacity: [Intro to Self-Driving Cars Nanodegree][series6b]\\n- :dollar: Udacity: [Self-Driving Car Nanodegree][series6]\\n- :dollar: Udacity: [Flying Car Nanodegree][series7]\\n- :dollar: Udacity: [Sensor Fusion Nanodegree][series12]\\n- :dollar: [The Construct: Robotics Developers Course Library][series8], Robot Ignite Academy\\n- :dollar: [Master's Certification Program in Autonomous Vehicles][series13], Skill Lync\\n\\n[series1]: http://robotacademy.net.au\\n[series3]: https://www.coursera.org/specializations/robotics\\n[series4]: https://www.coursera.org/specializations/modernrobotics\\n[series5]: https://www.udacity.com/robotics\\n[series6]: https://www.udacity.com/drive\\n[series6b]: https://www.udacity.com/course/intro-to-self-driving-cars--nd113\\n[series7]: https://www.udacity.com/course/flying-car-nanodegree--nd787\\n[series8]: https://www.theconstructsim.com/robotigniteacademy_learnros/ros-courses-library/\\n[series9]: https://ocw.mit.edu/search/ocwsearch.htm?q=robotics\\n[series10]: https://www.coursera.org/specializations/self-driving-cars\\n[series11a]: http://modernrobotics.org \\n[series11b]: https://www.youtube.com/playlist?list=PLggLP4f-rq02vX0OQQ5vrCxbJrzamYDfx\\n[series12]: https://www.udacity.com/course/sensor-fusion-engineer-nanodegree--nd313\\n[series13]: https://skill-lync.com/courses/masters-certification-program-autonomous-driving\\n\\n# Single Courses\\n- Udacity: [Artificial Intelligence for Robotics][course21], Sebastian Thrun\\n- EdX: [Self-Driving Cars with Duckietown][course40], ETHzurich\\n- EdX: [Autonomous Mobile Robots][course1], ETHZurich\\n- EdX: [Autonomous Navigation for Flying Robots][course2], Technische Universitat Munchen\\n- EdX: [Underactuated Robotics][course3], Massachusetts Institute of Technology\\n- EdX: [Robotics][course4], Columbia University in the city of New York\\n- EdX: Robot Mechanics and Control [Part I][course5] and [Part II][course6], Seoul National University\\n- EdX: [Robotics Foundations I - Robot Modeling][course7], Università degli Studi di Napoli Federico II\\n- EdX: [Robotics Foundation II - Robot Control][course41], Bruno Siciliano, Università degli Studi di Napoli Federico II\\n- EdX: [Robot Development][course42], Angelo Cangelosi, Università degli Studi di Napoli Federico II\\n- EdX: [Hello (Real) World with ROS – Robot Operating System][course8], Delft University of Technology\\n- Udemy: [ROS for Beginners: Basics, Motion and OpenCV][course30], Anish Koubaa\\n- Udemy: [ROS for Beginners II: Localization, Navigation and SLAM][course31], Anish Koubaa\\n- [Self-Driving Cars with ROS and Autoware][course27], Apex.AI\\n- [Autonomous Intelligent Systems][course10], Wolfram Burgard et al, University of Freiburg\\n- [Introduction to Robotics][course11], Oussama Khatib, Stanford Engineering Everywhere\\n- [Introduction to Aerial Robotics][course13], Kostas Alexis, University of Nevada\\n- [Deep-learning for Self-Driving Cars][course14], Lex Fridman, Massachusetts Institute of Technology\\n- [Advanced Robotics (CS 287)][course19], Pieter Abbeel, University of California at Berkeley\\n- [♥️ Underactuated Robotics][course20c] | [book][course20a] + [📺 channel][course20b], Russ Tedrake, Massachusetts Institute of Technology\\n- [Robotics Manipulation: Perception, Planning, and Control][course29] + [📺 channel][course29b], Russ Tedrake, Massachusetts Institute of Technology\\n- [Visual Navigation for Flying Robot][course22], Jürgen Sturm, Technical University of Munich\\n- [📺 SLAM playlist][course15], Cyrill Stachniss, University of Freiburg\\n- [📺 Robotics I][course16], De Luca, Universita di Roma\\n- [📺 SLAM Lectures][course18], Clause Brenne, Leibniz University Hannover\\n- [📺 Applied Robot Design (CS235)][course23], Reuben Brewer, Standford University\\n- [Robogrok: Robotics][course17a] + [📺 channel][course17b], Angela Sodemann\\n- [Autonomous Robots Lab: Autonomous Mobile Robot Design (and more)][course24], University of Nevada\\n- [MEAM 620: Robotics][course25], University of Pennsylvania\\n- [Robotics: Advanced Concepts and Analysis][course26], Ashitava Ghosal, Indian Institute of Science\\n- [Introduction to Robotics][course28], Burton Ma, York University \\n- [NPTEL: Introduction to Robotics][course32], IIT Madras\\n- [CMSC828T Vision, Planning And Control In Aerial Robotics][course33], Yiannis Aloimonos, University of Maryland\\n- [HKUST ELEC5660 Introduction to Aerial Robots][course34], Shaojie SHEN, Hong Kong University of Science and Technology\\n- [ENAE 788M: Hands On Autonomous Aerial Robotics][course35], Nitin Sanket, University of Maryland\\n- [📺 Evolutionary robotics][course43], Josh Bongard, University of Vermont\\n- [Programming for Robotics - ROS][course44], Edo Jelavić, Tom Lankhorst, Marco Hutter, ETHZurich\\n\\n[course1]: https://www.edx.org/course/autonomous-mobile-robots-ethx-amrx-2\\n[course2]: https://www.edx.org/course/autonomous-navigation-flying-robots-tumx-autonavx-0\\n[course3]: https://www.edx.org/course/underactuated-robotics-mitx-6-832x-0\\n[course4]: https://www.edx.org/course/robotics-columbiax-csmm-103x#!\\n[course5]: https://www.edx.org/course/robot-mechanics-control-part-i-snux-snu446-345-1x\\n[course6]: https://www.edx.org/course/robot-mechanics-control-part-ii-snux-snu446-345-2x\\n[course7]: https://www.edx.org/course/robotics-foundations-i-robot-modeling\\n[course8]: https://www.edx.org/course/hello-real-world-with-ros-robot-operating-system\\n[course9]: https://www.coursera.org/learn/mobile-robot\\n[course10]: http://ais.informatik.uni-freiburg.de/teaching/ss16/robotics/index_en.php\\n[course11]: https://see.stanford.edu/Course/CS223A\\n[course13]: http://www.kostasalexis.com/introduction-to-aerial-robotics.html\\n[course14]: http://selfdrivingcars.mit.edu/\\n[course15]: https://www.youtube.com/watch?v=V9qQc5X7O0k&list=PLgnQpQtFTOGQECnBvZSV61oxTrkPut-nc\\n[course16]: https://www.youtube.com/watch?v=pitZv3PuVMw&list=PLAQopGWlIcyaqDBW1zSKx7lHfVcOmWSWt\\n[course17a]: http://robogrok.com/index.html\\n[course17b]: https://www.youtube.com/user/asodemann3/videos\\n[course18]: https://www.youtube.com/watch?v=B2qzYCeT9oQ&list=PLpUPoM7Rgzi_7YWn14Va2FODh7LzADBSm\\n[course19]: https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/\\n[course20a]: http://underactuated.csail.mit.edu/underactuated.html\\n[course20b]: https://www.youtube.com/channel/UChfUOAhz7ynELF-s_1LPpWg/playlists\\n[course20c]: http://underactuated.csail.mit.edu/Spring2020/\\n[course21]: https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373\\n[course22]: https://vision.in.tum.de/teaching/ss2013/visnav2013\\n[course23]: https://www.youtube.com/user/StanfordCS235/videos\\n[course24]: https://www.autonomousrobotslab.com/education.html\\n[course25]: https://alliance.seas.upenn.edu/~meam620/wiki/index.php?n=Main.Projects\\n[course26]: https://nptel.ac.in/courses/112/108/112108093/#\\n[course27]: https://www.apex.ai/autoware-course\\n[course28]: https://www.eecs.yorku.ca/course_archive/2017-18/W/4421/\\n[course29]: http://manipulation.mit.edu/\\n[course29b]: https://www.youtube.com/watch?v=PGY-4LOPs7U\\n[course30]: https://www.udemy.com/course/ros-essentials/learn/\\n[course31]: https://www.udemy.com/course/ros-navigation/\\n[course32]: https://nptel.ac.in/courses/107/106/107106090/\\n[course33]: https://cmsc828t.github.io/\\n[course34]: https://gaowenliang.github.io/HKUST-ELEC5660-Introduction-to-Aerial-Robots/index.html\\n[course35]: http://prg.cs.umd.edu/enae788m\\n[course40]: https://www.edx.org/course/self-driving-cars-with-duckietown\\n[course41]: https://www.edx.org/course/robotics-foundation-ii-robot-control\\n[course42]: https://www.edx.org/course/developmental-robotics\\n[course43]: https://www.youtube.com/watch?v=CmiJIKxtEOE&list=PLAuiGdPEdw0inlKisMbjDypCbvcb_GBN9\\n[course44]: https://rsl.ethz.ch/education-students/lectures/ros.html\\n\\n# Hands-on and Blogs\\n- ♥️ Mithi's Hexapod Robot Simulator [Live Demo][h29] | [Source Code][h30] | [In Real Life][h36]\\n- [♥️ Akiyuki Kawaguchi][h19]\\n- [📺 OpenDog][h14] + [Mini Robot Dog][h27], James Bruton\\n- [Building a DIY Arduino drone][h8] + [📺 channel][h13], Joop Brokking\\n- [DIY Walkers][h10], Ben Vagle\\n- [PythonRobotics][h25], Atsushi Sakai\\n- [Spot Mini Mini][h33] + [Open Quadruped][h34]\\n- [Duckie Town: Minimal Autonomy Platforms][h35]\\n- [F1/10 (Penn Engineering)][h5] | [AutoRally (GeorgiaTech)][h32]\\n- [Donkey Car][h1] | [DIY Robocars][h2] | [Formula Pi][h17]\\n- [MIT Race Car][h3] | [MIT RaceCar Team 5 Documentation][h4]\\n- [Jetson Hacks][h6] | [:dollar: Racecar RJ][h7]\\n- [Prof Daniela Rus][h26] | [Sarah Tang][h28] | [Beatty Robotics][h18]\\n- [Andrew Dahdouh][h11] | [Oscar Liang][h12] | [Maurice Rahme][h31]\\n\\n[h1]: http://www.donkeycar.com/\\n[h2]: http://diyrobocars.com/\\n[h3]: https://mit-racecar.github.io\\n[h4]: https://mit-racecar.github.io/6.141-spring-2016-team-5-documentation/\\n[h5]: http://f1tenth.org/lectures\\n[h6]: https://www.jetsonhacks.com/category/robotics/\\n[h7]:https://racecarj.com/\\n[h8]: http://www.brokking.net/ymfc-32_main.html\\n[h9]: https://dojofordrones.com/\\n[h10]: https://www.diywalkers.com/\\n[h11]: https://realitybytes.blog/\\n[h12]: https://oscarliang.com/\\n[h13]: https://www.youtube.com/user/MacPuffdog/playlists\\n[h14]: https://www.youtube.com/watch?v=0BoPoWF_FwY&list=PLpwJoq86vov_PkA0bla0eiUTsCAPi_mZf\\n[h15]: https://mithi.github.io/robotics-blog/\\n[h16]: https://github.com/mithi/hexapod-robot-simulator\\n[h17]: https://www.formulapi.com/\\n[h18]: https://beatty-robotics.com/\\n[h19]: https://akiyuki.jp/en/\\n[h25]: https://github.com/AtsushiSakai/PythonRobotics\\n[h26]: http://danielarus.csail.mit.edu/index.php/projects/\\n[h27]: https://www.youtube.com/watch?v=DfBF26DaT-M\\n[h28]: https://www.sarahtang.net/\\n[h29]: https://hexapod.netlify.app/\\n[h30]: https://github.com/mithi/hexapod\\n[h31]: https://moribots.github.io/\\n[h32]: https://autorally.github.io/\\n[h33]: https://github.com/OpenQuadruped/spot_mini_mini\\n[h34]: https://github.com/adham-elarabawy/open-quadruped\\n[h35]: https://www.duckietown.org/\\n[h36]: https://github.com/mithi/hexapod-irl\\n\\n# Useful Concepts and Tools\\n- CAD Tools: [Autodesk Fusion 360][tools10] | [OnShape][tools12]\\n- [♥️ 🐳 Deep Learning][tools1]\\n- [Hackertools: The Missing Semester of Your CS Education][tools15], MIT Open Learning\\n- Kalman Filters: [Roger R. Labbe][tools2] | [Balzer82][tools11]\\n- Control Systems: [📺 Steve Brunton][tools3] | [📺 Brian Douglas][tools4] | [Tyler Veness][tool5]\\n- Algorithms and Data Structures, C++, Python, Octave\\n- [♥️ More courses](https://github.com/mithi/robotics-coursework/issues/6#issuecomment-629713457)\\n\\n[tools1]: https://mithi.github.io/deep-blueberry/\\n[tools2]: https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/\\n[tools3]: https://youtu.be/Pi7l8mMjYVE?list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m\\n[tools4]: https://www.youtube.com/user/ControlLectures/featured\\n[tools10]: https://www.autodesk.com/products/fusion-360/students-teachers-educators\\n[tools11]: https://github.com/balzer82/Kalman\\n[tools12]: https://www.onshape.com/\\n[tool5]: https://github.com/calcmogul/controls-engineering-in-frc\\n[tools15]: https://missing.csail.mit.edu/\\n\\n# Archived Courses\\n- EdX: [Robotics: Locomotion Engineering][course36], Dan Koditschek, University of Pennsylvania\\n- EdX: [Robotics: Dynamics and Control][course37], Vijay Kumar, University of Pennsylvania\\n- EdX: [Robotics: Vision Intelligence and Machine Learning][course38], Jianbo Shi, University of Pennsylvania\\n- EdX: [Robotics: Kinematics and Mathematical Foundations][course39], Camillo Taylor, University of Pennsylvania\\n- Coursera: Control of Mobile Robots, Magnus Egerstedt, Georgia Institute of technology\\n\\n\\n[course36]: https://www.edx.org/course/robotics-locomotion-engineering\\n[course37]: https://www.edx.org/course/robotics-dynamics-and-control\\n[course38]: https://www.edx.org/course/robotics-vision-intelligence-and-machine-learning\\n[course39]: https://www.edx.org/course/robotics-kinematics-and-mathematical-foundations\\n\\n\\n# Related Lists\\n| [Ahundt](https://github.com/ahundt/awesome-robotics)\\n| [Jslee02](https://github.com/jslee02/awesome-robotics-libraries)\\n| [Kiloreux](https://github.com/Kiloreux/awesome-robotics)\\n| [Msadowki](https://github.com/msadowski/awesome-weekly-robotics)\\n| [Protontypes](https://github.com/protontypes/awesome-robotic-tooling)\\n| [Fkromer](https://github.com/fkromer/awesome-ros2)\\n| [HarshMaithani](https://medium.com/@harshmaithani09/a-fast-introduction-to-robotics-v-2-0-6d07516e053f)\\n| [Kanster](https://github.com/kanster/awesome-slam)\\n| [Papers Related to Quadrotors](https://github.com/prgumd/prg_QuadrotorPapers)\\n\\n# Misc\\n| [Adafruit](https://adafruit.com/)\\n| [Instructables][related1]\\n| [Hackster][related2]\\n| [Thingiverse][related3] \\n| [Hackaday](https://hackaday.com/)\\n| [Sparkfun](https://www.sparkfun.com/)\\n| [Robotshop][related4]\\n| [Robotics Today][related5]\\n| [Reddit](https://www.reddit.com/r/robotics/)\\n| [Youtube](https://github.com/mithi/robotics-coursework/issues/6#issue-608400679)\\n| [Planet GBC](http://www.planet-gbc.com/)\\n| [Euro Bricks](https://www.eurobricks.com/forum/index.php?/forums/topic/117305-gbc-the-akiyuki-project/)\\n\\n[related1]: https://www.instructables.com/howto/robot/\\n[related2]: https://www.hackster.io/search?i=projects&q=robot\\n[related3]: https://www.thingiverse.com/search?q=robot\\n[related4]: https://www.robotshop.com/community/robot\\n[related5]: https://roboticstoday.github.io/watch.html\\n\\n\\n# [🐳](https://mithi.github.io/deep-blueberry) [☕️](https://ko-fi.com/minimithi)\\n\"},\n",
       " {'repo': 'onlytailei/CppRobotics',\n",
       "  'language': 'C++',\n",
       "  'readme_contents': '# CppRobotics\\n\\nThis is the cpp implementation of the [PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics)\\n\\n## Requirment\\n- cmake\\n- opencv 3.3\\n- Eigen 3\\n- [CppAD](https://www.coin-or.org/CppAD/Doc/install.htm) / [IPOPT](https://www.coin-or.org/Ipopt/documentation/node14.html) (*for MPC convex optimization*) [install tips](https://github.com/udacity/CarND-MPC-Quizzes/blob/master/install_Ipopt_CppAD.md)\\n- ~~ROS~~ (*~~To make the repo lightweight :)~~. Yet, we may still need it for 3D visualization.*)\\n\\n## Build\\n     $ mkdir build\\n     $ cd build\\n     $ cmake ../\\n     $ make -j 8\\n\\nFind all the executable files in ***build/bin***.\\n\\n# Table of Contents\\n* [Localization](#localization)\\n    * [Extended kalmam filter](#extended-kalman-filter-localization)\\n    * [Particle filter](#particle-filter-localization)\\n    * Histogram filter\\n* [Mapping](#mapping)\\n    * Gaussian grid map\\n* [SLAM](#SLAM)\\n    * FastSLAM 1.0\\n* [Path Planning](#path-planning)\\n    * [Dijkstra](#dijkstra)\\n    * [A Star](#a-star)\\n    * [RRT](#rrt)\\n    * [Dynamic Window Approach](#dynamic-window-approach)\\n    * [Model Predictive Trajectory Generator](#model-predictive-trajectory-generator)\\n    * [Cubic Spline Planner](#cubic-spline-planner)\\n    * [State Lattice Planner](#state-lattice-planner)\\n    * [Frenet Frame Trajectory](#frenet-frame-trajectory)\\n* [Path Tracking Control](#path-tracking-control)\\n    * [LQR Sterring Control](#lqr-steering-control)\\n    * [LQR Speed and Steering Control](#lqr-speed-and-steering-control)\\n    * [Model Predictive Speed and Steering Control](#mpc-speed-and-steering-control)\\n* [Aerial Navigation](#aerial-navigation)\\n     * Drone 3D Trajectory Following\\n     * Rocket Powered Landing\\n\\n# Localization\\n## Extended Kalman Filter Localization\\n* green line: the groundtruth trajectory\\n* black line: dead reckoning\\n* red points: observations (e.g. GPS)\\n* blue line: estimated positions\\n\\n<!-- ![ekf_gif](./gif/ekf.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/ekf.gif\" alt=\"ekf\" width=\"400\"/>\\n\\n[Probabilistic Robotics](http://www.probabilistic-robotics.org/)\\n\\n## Particle Filter Localization\\n* green line: the groundtruth trajectory\\n* black line: dead reckoning\\n* red points: landmarks\\n* blue line: estimated positions\\n\\n<!-- ![pf_gif](./gif/pf.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/pf.gif\" alt=\"pf\" width=\"400\"/>\\n\\n[Probabilistic Robotics](http://www.probabilistic-robotics.org/)\\n\\n# Path Planning\\n\\n## Dijkstra\\n* blue point: the start point\\n* red point: the goal point\\n<img src=\"https://ram-lab.com/file/tailei/gif/dijkstra.gif\" alt=\"dijkstra\" width=\"400\"/>\\n\\n## A star\\n* blue point: the start point\\n* red point: the goal point\\n<img src=\"https://ram-lab.com/file/tailei/gif/a_star.gif\" alt=\"a_star\" width=\"400\"/>\\n\\n## RRT\\n* red circle: the start point\\n* blue circle: the goal point\\n* black circle: obstacles\\n<img src=\"https://ram-lab.com/file/tailei/gif/rrt.gif\" alt=\"rrt\" width=\"400\"/>\\n\\n## Dynamic Window Approach\\n* blue circle: the target point\\n* red circle: the robot\\n\\n<!-- ![dwa_gif](./gif/dwa.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/dwa.gif\" alt=\"dwa\" width=\"400\"/>\\n\\n[The dynamic window approach to collision avoidance](https://ieeexplore.ieee.org/document/580977)\\n\\n## Model Predictive Trajectory Generator\\nThis part is based on the bicycle motion model.\\n* blue circle: the target point\\n* red circle: the initial point\\n\\n<!-- ![mptg_gif](./gif/mptg.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/mptg.gif\" alt=\"mptg\" width=\"400\"/>\\n\\n## Cubic Spline Planner\\n\\n<!-- ![mptg_gif](./gif/csp.png =500x) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/csp.png\" alt=\"csp\" width=\"400\"/>\\n\\n## State Lattice Planner\\n* blue circle: the target point\\n* red circle: the initial point\\n\\n<!-- ![mptg_gif](./gif/slp.gif) -->\\n<img src=\"https://ram-lab.com/file/tailei/gif/slp.gif\" alt=\"slp\" width=\"400\"/>\\n\\n[State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments](https://www.ri.cmu.edu/pub_files/pub4/howard_thomas_2008_1/howard_thomas_2008_1.pdf)\\n\\n## Frenet Frame Trajectory\\n\\n* black line: the planned spline path\\n* red circle: the obstacle\\n* blue circle: the planned trajectory\\n* green circle: the real-time position of robot\\n\\n<img src=\"https://ram-lab.com/file/tailei/gif/frenet.gif\" alt=\"frenet\" width=\"400\"/>\\n\\n[Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame](https://www.researchgate.net/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame)\\n\\n\\n# Path Tracking Control\\n## LQR Steering Control\\n* black line: the planned spline path\\n* red circle: the position under lqr control\\n\\n<img src=\"https://ram-lab.com/file/tailei/gif/lqr_steering.gif\" alt=\"lqr_steering\" width=\"400\"/>\\n\\n\\n## LQR Speed and Steering Control\\n* black line: the planned spline path\\n* red circle: the position under lqr control\\n\\n<img src=\"https://ram-lab.com/file/tailei/gif/lqr_full.gif\" alt=\"lqr_full\" width=\"400\"/>\\n\\n\\n## MPC Speed and Steering Control\\n* black line: the planned spline path\\n* blue line: the passed path\\n* yellow cross: the reference trajectory for MPC    \\n(To compile this part, you need to uncomment the related lines in CMakeLists.txt and install [CppAD](https://www.coin-or.org/CppAD/Doc/install.htm) and [IPOPT](https://coin-or.github.io/Ipopt/).)\\n\\n<img src=\"https://ram-lab.com/file/tailei/gif/mpc.gif\" alt=\"mpc\" width=\"400\"/>\\n'},\n",
       " {'repo': 'JdeRobot/RoboticsAcademy',\n",
       "  'language': 'JavaScript',\n",
       "  'readme_contents': '<a href=\"https://jderobot.github.io/\"><img src=\"./img/logo.gif\" width=\"150\" align=\"right\" /></a>\\n\\n# RoboticsAcademy: Learn Robotics, Artificial Intelligence and Computer Vision\\n\\nJdeRobot Academy is an **open source**  platform that has a collection of exercises to learn robotics in a practical way. Gazebo simulator is the main tool required for testing with ROS. Its latest documentation (including installation recipes, current available exercises and illustrative videos) is on its <a href=\"https://jderobot.github.io/RoboticsAcademy\">webpage</a>.\\n\\nIf you are a contributor, please note that we use GitHub Pages and a Jekyll theme (MinimalMistakes) for Academy web page. Feel free to install Jekyll locally, so that, you can test your changes before submitting your pull-request.\\n\\n## How to contribute?\\n\\nTake a look at the [contributing](CONTRIBUTING.md) guide lines.\\n\\n\\n\\n## INDEX\\n- [Instructions for developers.][]\\n- [Client side.][] (Robotics Academy architecture)\\n- [Repository Architecture.][]\\n- [Generate a mini RADI.][]\\n- [Humble mini RADI structure.][]\\n- [Develop using volume binding.][]\\n\\n[Instructions for developers.]: ./docs/InstructionsForDevelopers.md\\n[Client side.]: ./docs/clientside.md\\n[Repository Architecture.]: ./docs/RepositoryArchitecture.md\\n[Generate a mini RADI.]: ./docs/generate_a_mini_radi.md\\n[Humble mini RADI structure.]: ./scripts/mini_RADI/README.md\\n[Develop using volume binding.]: ./docs/develop_binding_volumes.md\\n'},\n",
       " {'repo': 'pptacher/probabilistic_robotics',\n",
       "  'language': 'C++',\n",
       "  'readme_contents': '# probabilistic_robotics\\nI am working on detailed solutions of exercises of the book \"probabilistic robotics\". This is a work in progress, any helpful feedback is welcomed.\\n\\nI also deployed the fastslam nodejs/c++ app on google cloud [here](http://35.242.140.13:8080) (server running from 0000 to 0800 UTC).\\n\\n![alt text](https://github.com/pptacher/probabilistic_robotics/blob/master/ch12_the_sparse_extended_information_filter/seif.jpg)\\n***SEIF** algorithm running on Victoria Park dataset*\\n\\n\\n## references\\n\\n- *Probabilistic robotics*, *MIT press*, Sebastian Thrun, Wolfram Burgard and Dieter Fox, [Probabilistic Robotics](https://mitpress.mit.edu/books/probabilistic-robotics)\\n\\n- *Victoria Park dataset*, The University of Sidney, Eduardo Nebot, [Victoria Park dataset](http://www-personal.acfr.usyd.edu.au/nebot/victoria_park.htm)\\n'},\n",
       " {'repo': 'jslee02/awesome-robotics-libraries',\n",
       "  'language': None,\n",
       "  'readme_contents': '# Awesome Robotics Libraries\\n\\nA curated list of robotics simulators and libraries.\\n\\n#### Table of Contents\\n* [Simulators](#simulators)\\n* [Libraries](#libraries)\\n  * [Dynamics Simulation](#dynamics-simulation)\\n  * [Inverse Kinematics](#inverse-kinematics)\\n  * [Machine Learning](#machine-learning)\\n  * [Motion Planning and Control](#motion-planning-and-control)\\n  * [Optimization](#optimization)\\n  * [Robot Modeling](#robot-modeling)\\n  * [Robot Platform](#robot-platform)\\n  * [SLAM](#slam)\\n  * [Vision](#vision)\\n  * [Fluid](#fluid)\\n  * [Multiphysics](#multiphysics)\\n  * [Math](#math)\\n  * [ETC](#etc)\\n* [Other Awesome Lists](#other-awesome-lists)\\n* [Contributing](#contributing)\\n\\n## [Simulators](#awesome-robotics-libraries)\\n\\n###### Free or Open Source\\n\\n* [AI2-THOR](https://ai2thor.allenai.org/) - Python framework with a Unity backend, providing interaction, navigation, and manipulation support for household based robotic agents [[github](https://github.com/allenai/ai2thor) ![AI2-THOR](https://img.shields.io/github/stars/allenai/ai2thor.svg?style=flat&label=Star&maxAge=86400)]\\n* AirSim - Simulator based on Unreal Engine for autonomous vehicles [[github](https://github.com/Microsoft/AirSim) ![AirSim](https://img.shields.io/github/stars/Microsoft/AirSim.svg?style=flat&label=Star&maxAge=86400)]\\n* [ARGoS](https://www.argos-sim.info/) - Physics-based simulator designed to simulate large-scale robot swarms [[github](https://github.com/ilpincy/argos3) ![ilpincy/argos3](https://img.shields.io/github/stars/ilpincy/argos3.svg?style=flat&label=Star&maxAge=86400)]\\n* [ARTE](http://arvc.umh.es/arte/index_en.html) - Matlab toolbox focussed on robotic manipulators [[github](https://github.com/4rtur1t0/ARTE) ![4rtur1t0/ARTE](https://img.shields.io/github/stars/4rtur1t0/ARTE.svg?style=flat&label=Star&maxAge=86400)]\\n* [AVIS Engine](https://avisengine.com) - Autonomous Vehicles Intelligent simulation software, A Fast and robust simulator software for Autonomous vehicle development. [[github](https://github.com/AvisEngine/AVIS-Engine-Python-API) ![AvisEngine/AVIS-Engine-Python-API](https://img.shields.io/github/stars/AvisEngine/AVIS-Engine-Python-API.svg?style=flat&label=Star&maxAge=86400)]\\n* [CARLA](http://carla.org/) - Open-source simulator for autonomous driving research [[github](https://github.com/carla-simulator/carla) ![carla-simulator/carla](https://img.shields.io/github/stars/carla-simulator/carla.svg?style=flat&label=Star&maxAge=86400)]\\n* [CoppeliaSim](http://www.coppeliarobotics.com/) - Formaly V-REP. Virtual robot experimentation platform [[github](https://github.com/CoppeliaRobotics/CoppeliaSimLib) ![CoppeliaRobotics/CoppeliaSimLib](https://img.shields.io/github/stars/CoppeliaRobotics/CoppeliaSimLib.svg?style=flat&label=Star&maxAge=86400)]\\n* [Gazebo](http://gazebosim.org/) - Dynamic multi-robot simulator [[github](https://github.com/osrf/gazebo) ![osrf/gazebo](https://img.shields.io/github/stars/osrf/gazebo.svg?style=flat&label=Star&maxAge=86400)]\\n* [GraspIt!](http://graspit-simulator.github.io/) - Simulator for grasping research that can accommodate arbitrary hand and robot designs [[github](https://github.com/graspit-simulator/graspit) ![graspit](https://img.shields.io/github/stars/graspit-simulator/graspit.svg?style=flat&label=Star&maxAge=86400)]\\n* [Habitat-Sim](https://aihabitat.org/) - Simulation platform for research in embodied artificial intelligence [[github](https://github.com/facebookresearch/habitat-sim) ![facebookresearch/habitat-sim](https://img.shields.io/github/stars/facebookresearch/habitat-sim.svg?style=flat&label=Star&maxAge=86400)]\\n* [Hexapod Robot Simulator](https://hexapod.netlify.app/) - Open-source hexapod robot inverse kinematics and gaits visualizer [[github](https://github.com/mithi/hexapod) ![mithi/hexapod](https://img.shields.io/github/stars/mithi/hexapod.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ignition Gazebo](https://ignitionrobotics.org/home) - Open source robotics simulator [[github](https://github.com/ignitionrobotics/ign-gazebo) ![ignitionrobotics/ign-gazebo](https://img.shields.io/github/stars/ignitionrobotics/ign-gazebo.svg?style=flat&label=Star&maxAge=86400)]\\n* [Isaac](https://www.nvidia.com/en-us/deep-learning-ai/industries/robotics/) - Nvidia\\'s virtual simulator for robots\\n* [MORSE](http://morse-simulator.github.io/) - Modular open robots simulation engine [[github](https://github.com/morse-simulator/morse) ![morse](https://img.shields.io/github/stars/morse-simulator/morse.svg?style=flat&label=Star&maxAge=86400)]\\n* [Neurorobotics Platform](https://neurorobotics.net/) - Internet-accessible simulation of robots controlled by spiking neural networks [[bitbucket](https://bitbucket.org/hbpneurorobotics/neurorobotics-platform)]\\n* [PyBullet](https://docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA/edit#heading=h.2ye70wns7io3) - An easy to use simulator for robotics and deep reinforcement learning [[github](https://github.com/bulletphysics/bullet3) ![bullet3](https://img.shields.io/github/stars/bulletphysics/bullet3.svg?style=flat&label=Star&maxAge=86400)]\\n* [PyBullet_Industrial](https://pybullet-industrial.readthedocs.io/en/latest/) - A extension to PyBullet that allows for the simulation of various robotic manufacturing processes such as milling or 3D-printing. [[github](https://github.com/WBK-Robotics/pybullet_industrial) ![pybullet_industrial](https://img.shields.io/github/stars/WBK-Robotics/pybullet_industrial.svg?style=flat&label=Star&maxAge=86400)]\\n* [Robot Gui](http://robot.glumb.de/) - A three.js based 3D robot interface [[github](https://github.com/glumb/robot-gui) ![glumb/robot-gui](https://img.shields.io/github/stars/glumb/robot-gui.svg?style=flat&label=Star&maxAge=86400)]\\n* [Simbad](http://simbad.sourceforge.net/) - A Java 3D robot simulator, enables to write own robot controller with modifying environment using available sensors.\\n* [Unity](https://unity.com/solutions/automotive-transportation-manufacturing/robotics) - Popular game engine that now offers open-source tools, tutorials, and resources for robotics simulation [[github](https://github.com/Unity-Technologies/Unity-Robotics-Hub) ![Unity-Technologies/Unity-Robotics-Hub](https://img.shields.io/github/stars/Unity-Technologies/Unity-Robotics-Hub.svg?style=flat&label=Star&maxAge=86400)]\\n* [Webots](http://www.cyberbotics.com/) - Robot simulator that provides a complete development environment [[github](https://github.com/omichel/webots) ![omichel/webots](https://img.shields.io/github/stars/omichel/webots.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### Commercial\\n\\n* [Actin Simulation](http://www.energid.com/)\\n* [Artiminds](https://www.artiminds.com/) - Planning, programming, operation, analysis and optimization\\n* [Kineo](https://www.plm.automation.siemens.com/global/en/products/plm-components/kineo.html) - Path planning and trajectory optimization for industrial robotics and digital mock-up review applications\\n* [RobotDK](https://robodk.com/) - Simulation and OLP for robots\\n* [RobotStudio](http://new.abb.com/products/robotics/robotstudio)\\n* [Robot Virtual Worlds](http://www.robotvirtualworlds.com/)\\n* [Virtual Robotics Toolkit](https://www.virtualroboticstoolkit.com/)\\n* [Visual Components](https://www.visualcomponents.com/)\\n\\n###### Cloud\\n\\n* [AWS RoboMaker](https://aws.amazon.com/robomaker/) - Service that makes it easy to develop, test, and deploy intelligent robotics applications at scale\\n\\n## [Libraries](#awesome-robotics-libraries)\\n\\n### [Dynamics Simulation](#awesome-robotics-libraries)\\n\\n> :warning: The following table is not complete. Please feel free to report if you find something incorrect or missing.\\n\\n| Name | Models | Features | Languages | Licenses | Code | Popularity |\\n|:----:| ------ | -------- | --------- | -------- | ---- | ---------- |\\n| [ARCSim](http://graphics.berkeley.edu/resources/ARCSim/index.html) | soft |  | C++ | | |  |\\n| [Bullet](http://bulletphysics.org) | rigid, soft | ik, id, urdf, sdf | C++, Python | Zlib | [github](https://github.com/bulletphysics/bullet3) | ![bullet3](https://img.shields.io/github/stars/bulletphysics/bullet3.svg?style=flat&label=Star&maxAge=86400) |\\n| [CHRONO::ENGINE](http://chronoengine.info/) | rigid, soft, granular, fluid | ik, urdf | C++, Python | BSD-3-Clause | [github](https://github.com/projectchrono/chrono) | ![chrono](https://img.shields.io/github/stars/projectchrono/chrono.svg?style=flat&label=Star&maxAge=86400) |\\n| [DART](http://dartsim.github.io/) | rigid, soft | ik, id, plan, urdf, sdf | C++, Python | BSD-2-Clause | [github](https://github.com/dartsim/dart.git) | ![dart](https://img.shields.io/github/stars/dartsim/dart.svg?style=flat&label=Star&maxAge=86400) |\\n| [Drake](http://drake.mit.edu/) | rigid, aero, fluid | ik, trj-opt, plan | C++, Matlab | BSD-3-Clause | [github](https://github.com/RobotLocomotion/drake) | ![drake](https://img.shields.io/github/stars/RobotLocomotion/drake.svg?style=flat&label=Star&maxAge=86400) |\\n| [Flex](https://developer.nvidia.com/flex) | rigid, soft, particle, fluid  | | C++ | | [github](https://github.com/NVIDIAGameWorks/FleX) | ![NVIDIAGameWorks/FleX](https://img.shields.io/github/stars/NVIDIAGameWorks/FleX.svg?style=flat&label=Star&maxAge=86400) |\\n| [FROST](https://ayonga.github.io/frost-dev/index.html) | rigid  | | MATLAB | BSD-3-Clause | [github](https://github.com/ayonga/frost-dev) | ![ayonga/frost-dev](https://img.shields.io/github/stars/ayonga/frost-dev.svg?style=flat&label=Star&maxAge=86400) |\\n| [IBDS](http://www.interactive-graphics.de/index.php/downloads/12-ibds) | rigid, particle | | C++ | Zlib | | |\\n| idyntree | rigid | id | C++, Python, Matlab, Lua | LGPL-2.1 | [github](https://github.com/robotology/idyntree) | ![idyntree](https://img.shields.io/github/stars/robotology/idyntree.svg?style=flat&label=Star&maxAge=86400) |\\n| [KDL](http://www.orocos.org/kdl) | rigid | ik | C++ | LGPL-2.1 | [github](https://github.com/orocos/orocos_kinematics_dynamics) | ![orocos_kinematics_dynamics](https://img.shields.io/github/stars/orocos/orocos_kinematics_dynamics.svg?style=flat&label=Star&maxAge=86400) |\\n| kindr | rigid | (todo) | C++, Matlab | BSD-3-Clause | [github](https://github.com/ANYbotics/kindr) | ![kindr](https://img.shields.io/github/stars/ANYbotics/kindr.svg?style=flat&label=Star&maxAge=86400) |\\n| [Klampt](http://motion.pratt.duke.edu/klampt/) | (todo) | (todo) | C++, Python | BSD-3-Clause | [github](https://github.com/krishauser/Klampt) | ![Klampt](https://img.shields.io/github/stars/krishauser/Klampt.svg?style=flat&label=Star&maxAge=86400) |\\n| [LibrePilot](http://www.librepilot.org/site/index.html) | uav, vehicles | (todo) | C++ | GPL-3.0 | [bitbucket](https://bitbucket.org/librepilot/librepilot), [github](https://github.com/librepilot/LibrePilot) | ![LibrePilot](https://img.shields.io/github/stars/librepilot/LibrePilot.svg?style=flat&label=Star&maxAge=86400) |\\n| [MARS](http://rock-simulation.github.io/mars/) | (todo) | (todo) | C++, Python | LGPL-3.0 | [github](https://github.com/rock-simulation/mars) | ![mars](https://img.shields.io/github/stars/rock-simulation/mars.svg?style=flat&label=Star&maxAge=86400) |\\n| [MBDyn](https://www.mbdyn.org/) | (todo) | (todo) | C++ | GPL-2.1 | [download](https://www.mbdyn.org/?Software_Download) | |\\n| [MBSim](https://www.mbsim-env.de/mbsim/html/index.html) | (todo) | (todo) | C++ | (not specified) | [github](https://github.com/mbsim-env/mbsim) | ![mbsim-env/mbsim](https://img.shields.io/github/stars/mbsim-env/mbsim.svg?style=flat&label=Star&maxAge=86400) |\\n| [MBSlib](http://www.sim.informatik.tu-darmstadt.de/res/sw/mbslib) | (todo) | (todo) | C++ | LGPL-3.0 | [github](https://github.com/SIM-TU-Darmstadt/mbslib) | ![mbslib](https://img.shields.io/github/stars/SIM-TU-Darmstadt/mbslib.svg?style=flat&label=Star&maxAge=86400) |\\n| metapod | (todo) | (todo) | C++ | LGPL-3.0 | [github](https://github.com/laas/metapod) | ![metapod](https://img.shields.io/github/stars/laas/metapod.svg?style=flat&label=Star&maxAge=86400) |\\n| [Moby](http://physsim.sourceforge.net/index.html) | rigid | id | C++ | GPL-2.0 | [github](https://github.com/PositronicsLab/Moby) | ![Moby](https://img.shields.io/github/stars/PositronicsLab/Moby.svg?style=flat&label=Star&maxAge=86400) |\\n| [mrpt](http://www.mrpt.org/) | vehicle | slam, cv | C++, Python, Matlab | BSD-3-Clause | [github](https://github.com/MRPT/mrpt) | ![mrpt](https://img.shields.io/github/stars/MRPT/mrpt.svg?style=flat&label=Star&maxAge=86400) |\\n| [MuJoCo](http://www.mujoco.org/index.html) | (todo) | id | C++, Python | [licenses](https://www.roboti.us/license.html) | closed source | |\\n| [mvsim](http://wiki.ros.org/mvsim) | vehicle | (todo) | C++ | GPL-3.0 | [github](https://github.com/ual-arm-ros-pkg/mvsim) | ![ual-arm-ros-pkg/mvsim](https://img.shields.io/github/stars/ual-arm-ros-pkg/mvsim.svg?style=flat&label=Star&maxAge=86400) |\\n| [Newton Dynamics](http://newtondynamics.com/) | (todo) | (todo) | C++ | Zlib | [github](https://github.com/MADEAPPS/newton-dynamics) | ![newton-dynamics](https://img.shields.io/github/stars/MADEAPPS/newton-dynamics.svg?style=flat&label=Star&maxAge=86400) |\\n| [nphysics](http://nphysics.org/) | (todo) | (todo) | Rust | BSD-3-Clause | [github](https://github.com/sebcrozet/nphysics) | ![sebcrozet/nphysics](https://img.shields.io/github/stars/sebcrozet/nphysics.svg?style=flat&label=Star&maxAge=86400) |\\n| [ODE](http://www.ode.org/) | rigid | | C++ | LGPL-2.1 or BSD-3-Clause | [bitbucket](https://bitbucket.org/odedevs/ode) | |\\n| [OpenRAVE](http://www.openrave.org) | (todo) | (todo) | C++, Python | LGPL-3.0 | [github](https://github.com/rdiankov/openrave) | ![openrave](https://img.shields.io/github/stars/rdiankov/openrave.svg?style=flat&label=Star&maxAge=86400) |\\n| [pinocchio](https://stack-of-tasks.github.io/pinocchio/) | rigid | ik, id, urdf, analytical derivatives, code generation | C++, Python | BSD-2-Clause | [github](https://github.com/stack-of-tasks/pinocchio) | ![pinocchio](https://img.shields.io/github/stars/stack-of-tasks/pinocchio.svg?style=flat&label=Star&maxAge=86400) |\\n| PositionBasedDynamics | (todo) | (todo) | C++ | MIT | [github](https://github.com/InteractiveComputerGraphics/PositionBasedDynamics) | ![PositionBasedDynamics](https://img.shields.io/github/stars/InteractiveComputerGraphics/PositionBasedDynamics.svg?style=flat&label=Star&maxAge=86400) |\\n| [PhysX](https://docs.nvidia.com/gameworks/content/gameworkslibrary/physx/guide/Manual/Index.html) | (todo) | (todo) | C++ | unknown | [github](https://github.com/NVIDIAGameWorks/PhysX) | ![NVIDIAGameWorks/PhysX](https://img.shields.io/github/stars/NVIDIAGameWorks/PhysX.svg?style=flat&label=Star&maxAge=86400) |\\n| [PyDy](http://www.pydy.org/) | (todo) | (todo) | Python | BSD-3-Clause | [github](https://github.com/pydy/pydy) | ![pydy](https://img.shields.io/github/stars/pydy/pydy.svg?style=flat&label=Star&maxAge=86400) |\\n| [RBDL](https://rbdl.github.io/) | rigid | ik,id,urdf | C++, Python | Zlib | [github](https://github.com/rbdl/rbdl) | ![rbdl](https://img.shields.io/github/stars/rbdl/rbdl.svg?style=flat&label=Star&maxAge=86400) |\\n| RBDyn | rigid | (todo) | C++, Python | LGPL-3.0 | [github](https://github.com/jrl-umi3218/RBDyn) | ![RBDyn](https://img.shields.io/github/stars/jrl-umi3218/RBDyn.svg?style=flat&label=Star&maxAge=86400) |\\n| [RaiSim](https://slides.com/jeminhwangbo/raisim-manual) | (todo) | (todo) | C++ | [custom](https://github.com/leggedrobotics/raisimLib/blob/a9e7673569997f35c0bc7eb5d11bc4fa188e863c/LICENSE.md) | [github](https://github.com/leggedrobotics/raisimLib) | ![leggedrobotics/raisimLib](https://img.shields.io/github/stars/leggedrobotics/raisimLib.svg?style=flat&label=Star&maxAge=86400) |\\n| [ReactPhysics3d](http://www.reactphysics3d.com/) | (todo) | (todo) | C++ | Zlib | [github](https://github.com/DanielChappuis/reactphysics3d) | ![reactphysics3d](https://img.shields.io/github/stars/DanielChappuis/reactphysics3d.svg?style=flat&label=Star&maxAge=86400) |\\n| RigidBodyDynamics.jl | rigid | (todo) | Julia | MIT \"Expat\" | [github](https://github.com/JuliaRobotics/RigidBodyDynamics.jl) | ![RigidBodyDynamics.jl](https://img.shields.io/github/stars/JuliaRobotics/RigidBodyDynamics.jl.svg?style=flat&label=Star&maxAge=86400) |\\n| [Rigs of Rods](https://www.rigsofrods.org/) | rigid, soft, vehicle | (todo) | C++ | GPL-3.0 | [github](https://github.com/RigsOfRods/rigs-of-rods) | ![RigsOfRods/rigs-of-rods](https://img.shields.io/github/stars/RigsOfRods/rigs-of-rods.svg?style=flat&label=Star&maxAge=86400) |\\n| [Robopy](https://adityadua24.github.io/robopy/) | (todo) | (todo) | Python 3 | MIT | [github](https://github.com/adityadua24/robopy) | ![adityadua24/robopy](https://img.shields.io/github/stars/adityadua24/robopy.svg?style=flat&label=Star&maxAge=86400) |\\n| [robosuite](https://robosuite.ai/) | (todo) | (todo) | Python | MIT | [github](https://github.com/ARISE-Initiative/robosuite) | ![ARISE-Initiative/robosuite](https://img.shields.io/github/stars/ARISE-Initiative/robosuite.svg?style=flat&label=Star&maxAge=86400) |\\n| [Robotics Library](http://www.roboticslibrary.org/) | (todo) | (todo) | C++ | GPL-3.0 or BSD-2-Clause | [github](https://github.com/roboticslibrary/rl) | ![rl](https://img.shields.io/github/stars/roboticslibrary/rl.svg?style=flat&label=Star&maxAge=86400) |\\n| [RobWork](http://www.robwork.dk/apidoc/nightly/rw/index.html) | (todo) | (todo) | C++ | Apache-2.0 | [gitlab](https://gitlab.com/sdurobotics/RobWork) | |\\n| [siconos](http://siconos.gforge.inria.fr) | (todo) | (todo) | C++, Python | Apache-2.0 | [github](https://github.com/siconos/siconos) | ![siconos](https://img.shields.io/github/stars/siconos/siconos.svg?style=flat&label=Star&maxAge=86400) |\\n| [Simbody](https://simtk.org/home/simbody/) | rigid, molecules | id, urdf | C++ | Apache-2.0 | [github](https://github.com/simbody/simbody.git) | ![simbody](https://img.shields.io/github/stars/simbody/simbody.svg?style=flat&label=Star&maxAge=86400) |\\n| [SOFA](https://www.sofa-framework.org/) | rigid, soft, medical | (todo) | C++ | LGPL-2.1 | [github](https://github.com/sofa-framework/sofa) | ![sofa](https://img.shields.io/github/stars/sofa-framework/sofa.svg?style=flat&label=Star&maxAge=86400) |\\n| Tiny Differentiable Simulator | rigid | (todo) | C++, Python | Apache-2.0 | [github](https://github.com/google-research/tiny-differentiable-simulator) | ![google-research/tiny-differentiable-simulator](https://img.shields.io/github/stars/google-research/tiny-differentiable-simulator.svg?style=flat&label=Star&maxAge=86400) |\\n| [trep](http://murpheylab.github.io/trep/) | rigid | dm, trj-opt | C, Python | GPL-3.0 | [github](https://github.com/MurpheyLab/trep) | ![trep](https://img.shields.io/github/stars/MurpheyLab/trep.svg?style=flat&label=Star&maxAge=86400) |\\n| qu3e | rigid | - | C++ | Zlib | [github](https://github.com/RandyGaul/qu3e) | ![qu3e](https://img.shields.io/github/stars/RandyGaul/qu3e.svg?style=flat&label=Star&maxAge=86400) |\\n\\nFor simplicity, shortened names are used to represent the supported models and features as\\n\\n* Supported Models\\n  * rigid: rigid bodies\\n  * soft: soft bodies\\n  * aero: aerodynamics\\n  * granular: granular materials (like sand)\\n  * fluid: fluid dynamics\\n  * vehicles\\n  * uav: unmanned aerial vehicles (like drones)\\n  * medical\\n  * molecules\\n  * parallel: parallel mechanism (like Stewart platform)\\n\\n* Features on Simulation, Analysis, Planning, Control Design\\n  * dm: [discrete mechanics](https://www.cambridge.org/core/journals/acta-numerica/article/div-classtitlediscrete-mechanics-and-variational-integratorsdiv/C8F45478A9290DEC24E63BB7FBE3CEB5)\\n  * ik: [inverse kinematics](https://en.wikipedia.org/wiki/Inverse_kinematics) solvers (please find IK specialized packages in [this list](#inverse-kinematics))\\n  * id: [inverse dynamics](https://en.wikipedia.org/wiki/Inverse_dynamics)\\n  * slam: [simultaneous localization and mapping](https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping)\\n  * trj-opt: trajectory optimization\\n  * plan: motion planning algorithms\\n  * cv: computer vision\\n  * urdf: [urdf](http://wiki.ros.org/urdf) parser\\n  * sdf: [sdf](http://sdformat.org/) parser\\n\\n### [Inverse Kinematics](#awesome-robotics-libraries)\\n\\n  * IKBT - A python package to solve robot arm inverse kinematics in symbolic form [[github](http://github.com/uw-biorobotics/IKBT) ![uw-biorobotics/IKBT](https://img.shields.io/github/stars/uw-biorobotics/IKBT.svg?style=flat&label=Star&maxAge=86400)]\\n  * Lively - A highly configurable toolkit for commanding robots in mixed modalities [[github](https://github.com/Wisc-HCI/lively) ![Wisc-HCI/lively](https://img.shields.io/github/stars/Wisc-HCI/lively.svg?style=flat&label=Star&maxAge=86400)]\\n  * RelaxedIK - Real-time Synthesis of Accurate and Feasible Robot Arm Motion [[github](http://github.com/uwgraphics/relaxed_ik) ![uwgraphics/relaxed_ik](https://img.shields.io/github/stars/uwgraphics/relaxed_ik.svg?style=flat&label=Star&maxAge=86400)]\\n  * [Trip](https://trip-kinematics.readthedocs.io/en/main/index.html) - A python package that solves inverse kinematics of parallel-, serial- or hybrid-robots [[github](https://github.com/TriPed-Robot/TriP) ![TriPed-Robot/TriP](https://img.shields.io/github/stars/TriPed-Robot/TriP.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Machine Learning](#awesome-robotics-libraries)\\n\\n* [AllenAct](https://allenact.org/) - Python/PyTorch-based Research Framework for Embodied AI [[github](http://github.com/allenai/allenact) ![wichtounet/dll](https://img.shields.io/github/stars/allenai/allenact.svg?style=flat&label=Star&maxAge=86400)]\\n* DLL - Deep Learning Library (DLL) for C++ [[github](http://github.com/wichtounet/dll) ![wichtounet/dll](https://img.shields.io/github/stars/wichtounet/dll.svg?style=flat&label=Star&maxAge=86400)]\\n* [DyNet](https://dynet.readthedocs.io/en/latest/) - The Dynamic Neural Network Toolkit [[github](http://github.com/clab/dynet) ![clab/dynet](https://img.shields.io/github/stars/clab/dynet.svg?style=flat&label=Star&maxAge=86400)]\\n* [Fido](http://fidoproject.github.io/) - Lightweight C++ machine learning library for embedded electronics and robotics [[github](http://github.com/FidoProject/Fido) ![FidoProject/Fido](https://img.shields.io/github/stars/FidoProject/Fido.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ivy]([http://fidoproject.github.io/](https://lets-unify.ai/)) - Unified Machine Learning Framework [[github](http://github.com/unifyai/ivy) ![unifyai/ivy](https://img.shields.io/github/stars/unifyai/ivy.svg?style=flat&label=Star&maxAge=86400)]\\n* MiniDNN - A header-only C++ library for deep neural networks [[github](https://github.com/yixuan/MiniDNN) ![yixuan/MiniDNN](https://img.shields.io/github/stars/yixuan/MiniDNN.svg?style=flat&label=Star&maxAge=86400)]\\n* [mlpack](http://www.mlpack.org/) - Scalable C++ machine learning library [[github](http://github.com/mlpack/mlpack) ![mlpack/mlpack](https://img.shields.io/github/stars/mlpack/mlpack.svg?style=flat&label=Star&maxAge=86400)]\\n* [OpenAI Gym](https://gym.openai.com/) - Developing and comparing reinforcement learning algorithms [[github](http://github.com/openai/gym) ![gym](https://img.shields.io/github/stars/openai/gym.svg?style=flat&label=Star&maxAge=86400)]\\n  * gym-dart [[github](http://github.com/DartEnv/dart-env) ![dart-env](https://img.shields.io/github/stars/DartEnv/dart-env.svg?style=flat&label=Star&maxAge=86400)]\\n  * gym-gazebo [[github](http://github.com/erlerobot/gym-gazebo) ![dart-env](https://img.shields.io/github/stars/erlerobot/gym-gazebo.svg?style=flat&label=Star&maxAge=86400)]\\n* [RLLib](http://web.cs.miami.edu/home/saminda/rllib.html) - Temporal-difference learning algorithms in reinforcement learning [[github](http://github.com/samindaa/RLLib) ![samindaa/RLLib](https://img.shields.io/github/stars/samindaa/RLLib.svg?style=flat&label=Star&maxAge=86400)]\\n* [tiny-dnn](http://tiny-dnn.readthedocs.io/en/latest/) - Header only, dependency-free deep learning framework in C++14 [[github](http://github.com/tiny-dnn/tiny-dnn) ![tiny-dnn/tiny-dnn](https://img.shields.io/github/stars/tiny-dnn/tiny-dnn.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Motion Planning and Control](#awesome-robotics-libraries)\\n\\n* [AIKIDO](https://github.com/personalrobotics/aikido) - Solving robotic motion planning and decision making problems. [[github](https://github.com/personalrobotics/aikido) ![aikido](https://img.shields.io/github/stars/personalrobotics/aikido.svg?style=flat&label=Star&maxAge=86400)]\\n* Bioptim - Bioptim, a Python Framework for Musculoskeletal Optimal Control in Biomechanics [[github](https://github.com/pyomeca/bioptim) ![pyomeca/bioptim](https://img.shields.io/github/stars/pyomeca/bioptim.svg?style=flat&label=Star&maxAge=86400)]\\n* [CuiKSuite](http://www.iri.upc.edu/people/porta/Soft/CuikSuite2-Doc/html) - Applications to solve position analysis and path planning problems\\n* [Control Toolbox](https://ethz-adrl.github.io/ct/) - Open-Source C++ Library for Robotics, Optimal and Model Predictive Control [[github](https://github.com/ethz-adrl/control-toolbox) ![ethz-adrl/control-toolbox](https://img.shields.io/github/stars/ethz-adrl/control-toolbox.svg?style=flat&label=Star&maxAge=86400)]\\n* Crocoddyl - Optimal control library for robot control under contact sequence [[github](https://github.com/loco-3d/crocoddyl) ![loco-3d/crocoddyl](https://img.shields.io/github/stars/loco-3d/crocoddyl.svg?style=flat&label=Star&maxAge=86400)]\\n* Fields2Cover - Robust and efficient coverage paths for autonomous agricultural vehicles [[github](https://github.com/Fields2Cover/Fields2Cover) ![Fields2Cover/Fields2Cover](https://img.shields.io/github/stars/fields2cover/fields2cover.svg?style=flat&label=Star&maxAge=86400)]\\n* GPMP2 - Gaussian Process Motion Planner 2 [[github](https://github.com/gtrll/gpmp2) ![gtrll/gpmp2](https://img.shields.io/github/stars/gtrll/gpmp2.svg?style=flat&label=Star&maxAge=86400)]\\n* [HPP](https://humanoid-path-planner.github.io/hpp-doc/) - Path planning for kinematic chains in environments cluttered with obstacles [[github](https://github.com/humanoid-path-planner)]\\n* [MoveIt!](http://moveit.ros.org/) - Motion planning framework [[github](https://github.com/ros-planning/moveit) ![moveit](https://img.shields.io/github/stars/ros-planning/moveit.svg?style=flat&label=Star&maxAge=86400)]\\n* [OMPL](http://ompl.kavrakilab.org/) - Open motion planning library [[bitbucket](https://bitbucket.org/ompl/ompl), [github](https://github.com/ompl/ompl) ![ompl](https://img.shields.io/github/stars/ompl/ompl.svg?style=flat&label=Star&maxAge=86400)]\\n* OCS2 - Efficient continuous and discrete time optimal control implementation [[bitbucket](https://bitbucket.org/leggedrobotics/ocs2/src/master/)]\\n* pymanoid - Humanoid robotics prototyping environment based on OpenRAVE [[github](https://github.com/stephane-caron/pymanoid) ![stephane-caron/pymanoid](https://img.shields.io/github/stars/stephane-caron/pymanoid.svg?style=flat&label=Star&maxAge=86400)]\\n* ROS Behavior Tree - [[github](https://github.com/miccol/ROS-Behavior-Tree) ![miccol/ROS-Behavior-Tree](https://img.shields.io/github/stars/miccol/ROS-Behavior-Tree.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ruckig](https://github.com/pantor/ruckig) - Real-time, time-optimal and jerk-constrained online trajectory generation. [[github](https://github.com/pantor/ruckig) ![ruckig](https://img.shields.io/github/stars/pantor/ruckig.svg?style=flat&label=Star&maxAge=86400)]\\n* [The Kautham Project](https://sir.upc.es/projects/kautham/) - A robot simulation toolkit for motion planning [[github](https://github.com/iocroblab/kautham) ![kautham](https://img.shields.io/github/stars/iocroblab/kautham.svg?style=flat&label=Star&maxAge=86400)]\\n* [TOPP-RA](https://hungpham2511.github.io/toppra/) - Time-parameterizing robot trajectories subject to kinematic and dynamic constraints [[github](https://github.com/hungpham2511/toppra) ![hungpham2511/toppra](https://img.shields.io/github/stars/hungpham2511/toppra.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ungar](https://github.com/fdevinc/ungar) - Expressive and efficient implementation of optimal control problems using template metaprogramming [[github](https://github.com/fdevinc/ungar) ![fdevinc/ungar](https://img.shields.io/github/stars/fdevinc/ungar.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### Motion Optimizer\\n\\n* TopiCo - Time-optimal Trajectory Generation and Control [[github](https://github.com/AIS-Bonn/TopiCo) ![AIS-Bonn/TopiCo](https://img.shields.io/github/stars/AIS-Bonn/TopiCo.svg?style=flat&label=Star)]\\n* [towr](http://wiki.ros.org/towr) - A light-weight, Eigen-based C++ library for trajectory optimization for legged robots [[github](https://github.com/ethz-adrl/towr) ![ethz-adrl/towr](https://img.shields.io/github/stars/ethz-adrl/towr.svg?style=flat&label=Star&maxAge=86400)]\\n* TrajectoryOptimization - A fast trajectory optimization library written in Julia [[github](https://github.com/RoboticExplorationLab/TrajectoryOptimization.jl) ![RoboticExplorationLab/TrajectoryOptimization.jl](https://img.shields.io/github/stars/RoboticExplorationLab/TrajectoryOptimization.jl.svg?style=flat&label=Star&maxAge=86400)]\\n* [trajopt](http://rll.berkeley.edu/trajopt/doc/sphinx_build/html/) - Framework for generating robot trajectories by local optimization [[github](https://github.com/joschu/trajopt) ![joschu/trajopt](https://img.shields.io/github/stars/joschu/trajopt.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### Nearest Neighbor\\n\\n* [Cover-Tree](http://hunch.net/~jl/projects/cover_tree/cover_tree.html) - Cover tree data structure for quick k-nearest-neighbor search [[github](https://github.com/DNCrane/Cover-Tree) ![Cover-Tree](https://img.shields.io/github/stars/DNCrane/Cover-Tree.svg?style=flat&label=Star&maxAge=86400)]\\n  * [Faster cover trees](http://proceedings.mlr.press/v37/izbicki15.pdf) by Mike Izbicki et al., ICML 2015.\\n* [FLANN](http://www.cs.ubc.ca/research/flann/) - Fast Library for Approximate Nearest Neighbors [[github](https://github.com/mariusmuja/flann) ![flann](https://img.shields.io/github/stars/mariusmuja/flann.svg?style=flat&label=Star&maxAge=86400)]\\n* [nanoflann](http://www.cs.ubc.ca/research/flann/) - Nearest Neighbor search with KD-trees [[github](https://github.com/jlblancoc/nanoflann) ![nanoflann](https://img.shields.io/github/stars/jlblancoc/nanoflann.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### 3D Mapping\\n\\n* [libpointmatcher](http://libpointmatcher.readthedocs.io/en/latest/) - Iterative Closest Point library for 2-D/3-D mapping in Robotics [[github](https://github.com/ethz-asl/libpointmatcher) ![ethz-asl/libpointmatcher](https://img.shields.io/github/stars/ethz-asl/libpointmatcher.svg?style=flat&label=Star&maxAge=86400)]\\n* Octree - Fast radius neighbor search with an Octree [[github](https://github.com/jbehley/octree) ![jbehley/octree](https://img.shields.io/github/stars/jbehley/octree.svg?style=flat&label=Star&maxAge=86400)]\\n* [OctoMap](http://octomap.github.io/) - Efficient Probabilistic 3D Mapping Framework Based on Octrees [[github](https://github.com/OctoMap/octomap) ![octomap](https://img.shields.io/github/stars/OctoMap/octomap.svg?style=flat&label=Star&maxAge=86400)]\\n* [PCL](http://www.pointclouds.org/) - 2D/3D image and point cloud processing [[github](https://github.com/PointCloudLibrary/pcl) ![PointCloudLibrary/pcl](https://img.shields.io/github/stars/PointCloudLibrary/pcl.svg?style=flat&label=Star&maxAge=86400)]\\n* Treexy - Brutally fast, sparse, 3D Voxel Grid [[github](https://github.com/facontidavide/Treexy) ![Treexy](https://img.shields.io/github/stars/facontidavide/Treexy.svg?style=flat&label=Star&maxAge=86400)]\\n* voxblox - Flexible voxel-based mapping focusing on truncated and Euclidean signed distance fields [[github](https://github.com/ethz-asl/voxblox) ![voxblox](https://img.shields.io/github/stars/ethz-asl/voxblox.svg?style=flat&label=Star&maxAge=86400)]\\n* Utility Software\\n  * [Goxel](https://guillaumechereau.github.io/goxel/) - Free and open source 3D voxel editor [[github](https://github.com/guillaumechereau/goxel) ![guillaumechereau/goxel](https://img.shields.io/github/stars/guillaumechereau/goxel.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Optimization](#awesome-robotics-libraries)\\n\\n* [CasADi](https://github.com/casadi/casadi/wiki) - Symbolic framework for algorithmic differentiation and numeric optimization [[github](https://github.com/casadi/casadi) ![casadi](https://img.shields.io/github/stars/casadi/casadi.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ceres Solver](http://ceres-solver.org/) - Large scale nonlinear optimization library [[github](https://github.com/ceres-solver/ceres-solver) ![ceres-solver](https://img.shields.io/github/stars/ceres-solver/ceres-solver.svg?style=flat&label=Star&maxAge=86400)]\\n* eigen-qld - Interface to use the QLD QP solver with the Eigen3 library [[github](https://github.com/jrl-umi3218/eigen-qld) ![jrl-umi3218/eigen-qld](https://img.shields.io/github/stars/jrl-umi3218/eigen-qld.svg?style=flat&label=Star&maxAge=86400)]\\n* [EXOTica](http://wcms.inf.ed.ac.uk/ipab/slmc/research/EXOTica) - Generic optimisation toolset for robotics platforms [[github](https://github.com/ipab-slmc/exotica) ![ipab-slmc/exotica](https://img.shields.io/github/stars/ipab-slmc/exotica.svg?style=flat&label=Star&maxAge=86400)]\\n* hpipm - High-performance interior-point-method QP solvers (Ipopt, Snopt) [[github](https://github.com/giaf/hpipm) ![giaf/hpipm](https://img.shields.io/github/stars/giaf/hpipm.svg?style=flat&label=Star&maxAge=86400)]\\n* [HYPRE](https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods) - Parallel solvers for sparse linear systems featuring multigrid methods [[github](https://github.com/hypre-space/hypre) ![hypre-space/hypre](https://img.shields.io/github/stars/hypre-space/hypre.svg?style=flat&label=Star&maxAge=86400)]\\n* ifopt - An Eigen-based, light-weight C++ Interface to Nonlinear Programming Solvers (Ipopt, Snopt) [[github](https://github.com/ethz-adrl/ifopt) ![ifopt](https://img.shields.io/github/stars/ethz-adrl/ifopt.svg?style=flat&label=Star&maxAge=86400)]\\n* [Ipopt](https://projects.coin-or.org/Ipopt) - Large scale nonlinear optimization library [[github](https://github.com/coin-or/Ipopt) ![Ipopt](https://img.shields.io/github/stars/coin-or/Ipopt.svg?style=flat&label=Star&maxAge=86400)]\\n* libcmaes - Blackbox stochastic optimization using the CMA-ES algorithm [[github](https://github.com/beniz/libcmaes) ![beniz/libcmaes](https://img.shields.io/github/stars/beniz/libcmaes.svg?style=flat&label=Star&maxAge=86400)]\\n* [limbo](http://www.resibots.eu/limbo/) - Gaussian processes and Bayesian optimization of black-box functions [[github](https://github.com/resibots/limbo) ![resibots/limbo](https://img.shields.io/github/stars/resibots/limbo.svg?style=flat&label=Star&maxAge=86400)]\\n* lpsolvers - Linear Programming solvers in Python with a unified API [[github](https://github.com/stephane-caron/lpsolvers) ![lpsolvers](https://img.shields.io/github/stars/stephane-caron/lpsolvers.svg?style=flat&label=Star&maxAge=86400)]\\n* [NLopt](http://ab-initio.mit.edu/wiki/index.php/NLopt) - Nonlinear optimization [[github](https://github.com/stevengj/nlopt) ![nlopt](https://img.shields.io/github/stars/stevengj/nlopt.svg?style=flat&label=Star&maxAge=86400)]\\n* [OptimLib](https://www.kthohr.com/optimlib.html) - Lightweight C++ library of numerical optimization methods for nonlinear functions [[github](https://github.com/kthohr/optim) ![kthohr/optim](https://img.shields.io/github/stars/kthohr/optim.svg?style=flat&label=Star&maxAge=86400)]\\n* [OSQP](https://osqp.org/) - The Operator Splitting QP Solver [[github](https://github.com/osqp/osqp) ![osqp/osqp](https://img.shields.io/github/stars/osqp/osqp.svg?style=flat&label=Star&maxAge=86400)]\\n* [Pagmo](https://esa.github.io/pagmo2/index.html) - Scientific library for massively parallel optimization [[github](https://github.com/esa/pagmo2) ![esa/pagmo2](https://img.shields.io/github/stars/esa/pagmo2.svg?style=flat&label=Star&maxAge=86400)]\\n* [ProxSuite](https://simple-robotics.github.io/proxsuite/) - The Advanced Proximal Optimization Toolbox [[github](https://github.com/Simple-Robotics/ProxSuite) ![Simple-Robotics/ProxSuite](https://img.shields.io/github/stars/Simple-Robotics/ProxSuite.svg?style=flat&label=Star&maxAge=86400)]\\n* [pymoo](https://www.egr.msu.edu/coinlab/blankjul/pymoo/) - Multi-objective Optimization in Python [[github](https://github.com/msu-coinlab/pymoo) ![msu-coinlab/pymoo](https://img.shields.io/github/stars/msu-coinlab/pymoo.svg?style=flat&label=Star&maxAge=86400)]\\n* qpsolvers - Quadratic Programming solvers in Python with a unified API [[github](https://github.com/stephane-caron/qpsolvers) ![qpsolvers](https://img.shields.io/github/stars/stephane-caron/qpsolvers.svg?style=flat&label=Star&maxAge=86400)]\\n* [RobOptim](http://roboptim.net/index.html) - Numerical Optimization for Robotics. [[github](https://github.com/roboptim/roboptim-core) ![roboptim/roboptim-core](https://img.shields.io/github/stars/roboptim/roboptim-core.svg?style=flat&label=Star&maxAge=86400)]\\n* [SCS](http://web.stanford.edu/~boyd/papers/scs.html) - Numerical optimization for solving large-scale convex cone problems [[github](https://github.com/cvxgrp/scs) ![scs](https://img.shields.io/github/stars/cvxgrp/scs.svg?style=flat&label=Star&maxAge=86400)]\\n* [SHOT](https://shotsolver.dev/shot/) - A solver for mixed-integer nonlinear optimization problems [[github](https://github.com/coin-or/SHOT) ![coin-or/SHOT](https://img.shields.io/github/stars/coin-or/SHOT.svg?style=flat&label=Star&maxAge=86400)]\\n* sferes2 - Evolutionary computation [[github](https://github.com/sferes2/sferes2) ![sferes2/sferes2](https://img.shields.io/github/stars/sferes2/sferes2.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Robot Modeling](#awesome-robotics-libraries)\\n\\n###### Robot Model Description Format\\n* [SDF](http://sdformat.org/) - XML format that describes objects and environments for robot simulators, visualization, and control ([bitbucket](https://bitbucket.org/osrf/sdformat))\\n* [urdf](http://wiki.ros.org/urdf) - XML format for representing a robot model [[github](https://github.com/ros/urdfdom) ![ros/urdfdom](https://img.shields.io/github/stars/ros/urdfdom.svg?style=flat&label=Star&maxAge=86400)]\\n\\n###### Utility to Build Robot Models\\n* [onshape-to-robot](https://github.com/Rhoban/onshape-to-robot) - Converting OnShape assembly to robot definition (SDF or URDF) through OnShape API [[github](https://github.com/Rhoban/onshape-to-robot) ![phobos](https://img.shields.io/github/stars/Rhoban/onshape-to-robot.svg?style=flat&label=Star&maxAge=86400)]\\n* phobos - Add-on for Blender creating URDF and SMURF robot models [[github](https://github.com/rock-simulation/phobos) ![phobos](https://img.shields.io/github/stars/rock-simulation/phobos.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Robot Platform](#awesome-robotics-libraries)\\n\\n* [AutoRally](http://autorally.github.io/) - High-performance testbed for advanced perception and control research [[github](https://github.com/autorally/autorally) ![autorally/autorally](https://img.shields.io/github/stars/autorally/autorally.svg?style=flat&label=Star&maxAge=86400)]\\n* [Linorobot](https://linorobot.org/) - ROS compatible ground robots [[github](https://github.com/linorobot/linorobot) ![linorobot/linorobot](https://img.shields.io/github/stars/linorobot/linorobot.svg?style=flat&label=Star&maxAge=86400)]\\n  * onine - Service Robot based on [Linorobot](https://github.com/linorobot/linorobot) and Braccio Arm [[github](https://github.com/grassjelly/onine) ![grassjelly/onine](https://img.shields.io/github/stars/grassjelly/onine.svg?style=flat&label=Star&maxAge=86400)]\\n* [Rock](https://www.rock-robotics.org/stable/) - Software framework for robotic systems\\n* [ROS](http://www.ros.org/) - Flexible framework for writing robot software [[github repos](http://wiki.ros.org/Tickets)]\\n* [ROS 2](https://github.com/ros2/ros2/wiki) - Version 2.0 of the Robot Operating System (ROS) software stack [[github repos](https://github.com/ros2)]\\n* [YARP](http://www.yarp.it/) - Communication and device interfaces applicable from humanoids to embedded devices [[github](https://github.com/robotology/yarp) ![robotology/yarp](https://img.shields.io/github/stars/robotology/yarp.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [SLAM](#awesome-robotics-libraries)\\n\\n* AprilSAM - Real-time smoothing and mapping [[github](https://github.com/xipengwang/AprilSAM) ![xipengwang/AprilSAM](https://img.shields.io/github/stars/xipengwang/AprilSAM.svg?style=flat&label=Star&maxAge=86400)]\\n* Cartographer - Real-time SLAM in 2D and 3D across multiple platforms and sensor configurations [[github](https://github.com/googlecartographer/cartographer) ![cartographer](https://img.shields.io/github/stars/googlecartographer/cartographer.svg?style=flat&label=Star&maxAge=86400)]\\n* [DSO](https://vision.in.tum.de/research/vslam/dso) - Novel direct and sparse formulation for Visual Odometry [[github](https://github.com/JakobEngel/dso) ![dso](https://img.shields.io/github/stars/JakobEngel/dso.svg?style=flat&label=Star&maxAge=86400)]\\n* ElasticFusion - Real-time dense visual SLAM system [[github](http://github.com/mp3guy/ElasticFusion) ![ElasticFusion](https://img.shields.io/github/stars/mp3guy/ElasticFusion.svg?style=flat&label=Star&maxAge=86400)]\\n* [fiducials](http://wiki.ros.org/fiducials) - Simultaneous localization and mapping using fiducial markers [[github](http://github.com/UbiquityRobotics/fiducials) ![UbiquityRobotics/fiducials](https://img.shields.io/github/stars/UbiquityRobotics/fiducials.svg?style=flat&label=Star&maxAge=86400)]\\n* GTSAM - Smoothing and mapping (SAM) in robotics and vision [[github](http://github.com/borglab/gtsam) ![borglab/gtsam](https://img.shields.io/github/stars/borglab/gtsam.svg?style=flat&label=Star&maxAge=86400)]\\n* Kintinuous - Real-time large scale dense visual SLAM system [[github](http://github.com/mp3guy/Kintinuous) ![Kintinuous](https://img.shields.io/github/stars/mp3guy/Kintinuous.svg?style=flat&label=Star&maxAge=86400)]\\n* [LSD-SLAM](https://vision.in.tum.de/research/vslam/lsdslam) - Real-time monocular SLAM [[github](http://github.com/tum-vision/lsd_slam) ![lsdslam](https://img.shields.io/github/stars/tum-vision/lsd_slam.svg?style=flat&label=Star&maxAge=86400)]\\n* ORB-SLAM2 - Real-time SLAM library for Monocular, Stereo and RGB-D cameras [[github](http://github.com/raulmur/ORB_SLAM2) ![ORB_SLAM2](https://img.shields.io/github/stars/raulmur/ORB_SLAM2.svg?style=flat&label=Star&maxAge=86400)]\\n* [RTAP-Map](http://introlab.github.io/rtabmap/) - RGB-D Graph SLAM approach based on a global Bayesian loop closure detector [[github](http://github.com/introlab/rtabmap) ![introlab/rtabmap](https://img.shields.io/github/stars/introlab/rtabmap.svg?style=flat&label=Star&maxAge=86400)]\\n* [SRBA](http://mrpt.github.io/srba/) - Solving SLAM/BA in relative coordinates with flexibility for different submapping strategies [[github](http://github.com/MRPT/srba) ![srba](https://img.shields.io/github/stars/MRPT/srba.svg?style=flat&label=Star&maxAge=86400)]\\n\\n#### SLAM Dataset\\n\\n* [Awesome SLAM Datasets](https://github.com/youngguncho/awesome-slam-datasets)\\n\\n### [Vision](#awesome-robotics-libraries)\\n\\n* [ViSP](http://visp.inria.fr/) - Visual Servoing Platform [[github](https://github.com/lagadic/visp) ![lagadic/visp](https://img.shields.io/github/stars/lagadic/visp.svg?style=flat&label=Star&maxAge=86400)]\\n* [BundleTrack](https://github.com/wenbowen123/BundleTrack) - 6D Pose Tracking for Novel Objects without 3D Models [[github](https://github.com/wenbowen123/BundleTrack) ![wenbowen123/BundleTrack](https://img.shields.io/github/stars/wenbowen123/BundleTrack.svg?style=flat&label=Star&maxAge=86400)]\\n* [se(3)-TrackNet](https://github.com/wenbowen123/iros20-6d-pose-tracking) - 6D Pose Tracking for Novel Objects without 3D Models [[github](https://github.com/wenbowen123/iros20-6d-pose-tracking) ![wenbowen123/iros20-6d-pose-tracking](https://img.shields.io/github/stars/wenbowen123/iros20-6d-pose-tracking.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Fluid](#awesome-robotics-libraries)\\n\\n* [Fluid Engine Dev - Jet](https://fluidenginedevelopment.org/) - Fluid simulation engine for computer graphics applications [[github](https://github.com/doyubkim/fluid-engine-dev) ![doyubkim/fluid-engine-dev](https://img.shields.io/github/stars/doyubkim/fluid-engine-dev.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Multiphysics](#awesome-robotics-libraries)\\n\\n* [Kratos](http://www.cimne.com/kratos/) - Framework for building parallel multi-disciplinary simulation software [[github](https://github.com/KratosMultiphysics/Kratos) ![KratosMultiphysics/Kratos](https://img.shields.io/github/stars/KratosMultiphysics/Kratos.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [Math](#awesome-robotics-libraries)\\n\\n* Fastor - Light-weight high performance tensor algebra framework in C++11/14/17 [[github](https://github.com/romeric/Fastor) ![romeric/Fastor](https://img.shields.io/github/stars/romeric/Fastor.svg?style=flat&label=Star&maxAge=86400)]\\n* linalg.h - Single header public domain linear algebra library for C++11 [[github](https://github.com/sgorsten/linalg) ![sgorsten/linalg](https://img.shields.io/github/stars/sgorsten/linalg.svg?style=flat&label=Star&maxAge=86400)]\\n* manif - Small c++11 header-only library for Lie theory. [[github](https://github.com/artivis/manif) ![artivis/manif](https://img.shields.io/github/stars/artivis/manif.svg?style=flat&label=Star&maxAge=86400)]\\n* Sophus - Lie groups using Eigen [[github](https://github.com/strasdat/Sophus) ![strasdat/Sophus](https://img.shields.io/github/stars/strasdat/Sophus.svg?style=flat&label=Star&maxAge=86400)]\\n* SpaceVelAlg - Spatial vector algebra with the Eigen3 [[github](https://github.com/jrl-umi3218/SpaceVecAlg) ![jrl-umi3218/SpaceVecAlg](https://img.shields.io/github/stars/jrl-umi3218/SpaceVecAlg.svg?style=flat&label=Star&maxAge=86400)]\\n\\n### [ETC](#awesome-robotics-libraries)\\n\\n* fuse - General architecture for performing sensor fusion live on a robot [[github](https://github.com/locusrobotics/fuse) ![locusrobotics/fuse](https://img.shields.io/github/stars/locusrobotics/fuse.svg?style=flat&label=Star&maxAge=86400)]\\n* [Foxglove Studio](https://foxglove.dev) –\\xa0A fully integrated visualization and debugging desktop app for your robotics data. Combines functionality of tools like `rviz`, `rqt`, and more. Also available via [web app](https://studio.foxglove.dev).\\n\\n## [Other Awesome Lists](#awesome-robotics-libraries)\\n\\n* [Awesome Robotics](https://github.com/Kiloreux/awesome-robotics) (Kiloreux)\\n* [Awesome Robotics](https://github.com/ahundt/awesome-robotics) (ahundt)\\n* [Awesome Robotic Tooling](https://github.com/Ly0n/awesome-robotic-tooling)\\n* [Awesome Artificial Intelligence](https://github.com/owainlewis/awesome-artificial-intelligence)\\n* [Awesome Collision Detection](https://github.com/jslee02/awesome-collision-detection)\\n* [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)\\n* [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning)\\n* [Awesome Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning)\\n* [Awesome Gazebo](https://github.com/fkromer/awesome-gazebo)\\n* [Awesome Grasping](https://github.com/Po-Jen/awesome-grasping)\\n* [Awesome Human Robot Interaction](https://github.com/Po-Jen/awesome-human-robot-interaction)\\n* [PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics) - Python sample codes for robotics algorithms\\n* [Robotics Coursework](https://github.com/mithi/robotics-coursework) - A list of robotics courses you can take online\\n\\n## [Contributing](#awesome-robotics-libraries)\\n\\nContributions are very welcome! Please read the [contribution guidelines](https://github.com/jslee02/awesome-robotics-libraries/blob/master/CONTRIBUTING.md) first. Also, please feel free to report any error.\\n\\n## [License](#awesome-robotics-libraries)\\n\\n[![CC0](https://licensebuttons.net/p/zero/1.0/88x31.png)](http://creativecommons.org/publicdomain/zero/1.0/)\\n'},\n",
       " {'repo': 'petercorke/robotics-toolbox-python',\n",
       "  'language': 'Python',\n",
       "  'readme_contents': '# Robotics Toolbox for Python\\n\\n[![A Python Robotics Package](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/py_collection.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n[![Powered by Spatial Maths](https://raw.githubusercontent.com/petercorke/spatialmath-python/master/.github/svg/sm_powered.min.svg)](https://github.com/petercorke/spatialmath-python)\\n[![QUT Centre for Robotics Open Source](https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg)](https://qcr.github.io)\\n\\n[![PyPI version](https://badge.fury.io/py/roboticstoolbox-python.svg)](https://badge.fury.io/py/roboticstoolbox-python)\\n[![Anaconda version](https://anaconda.org/conda-forge/roboticstoolbox-python/badges/version.svg)](https://anaconda.org/conda-forge/roboticstoolbox-python)\\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/roboticstoolbox-python.svg)\\n\\n[![Build Status](https://github.com/petercorke/robotics-toolbox-python/workflows/Test/badge.svg?branch=master)](https://github.com/petercorke/robotics-toolbox-python/actions?query=workflow%3ATest)\\n[![Coverage](https://codecov.io/gh/petercorke/robotics-toolbox-python/branch/master/graph/badge.svg)](https://codecov.io/gh/petercorke/robotics-toolbox-python)\\n[![PyPI - Downloads](https://img.shields.io/pypi/dw/roboticstoolbox-python)](https://pypistats.org/packages/roboticstoolbox-python)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\n<table style=\"border:0px\">\\n<tr style=\"border:0px\">\\n<td style=\"border:0px\">\\n<img src=\"https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/RobToolBox_RoundLogoB.png\" width=\"200\"></td>\\n<td style=\"border:0px\">\\nA Python implementation of the <a href=\"https://github.com/petercorke/robotics-toolbox-matlab\">Robotics Toolbox for MATLAB<sup>&reg;</sup></a>\\n<ul>\\n<li><a href=\"https://github.com/petercorke/robotics-toolbox-python\">GitHub repository </a></li>\\n<li><a href=\"https://petercorke.github.io/robotics-toolbox-python\">Documentation</a></li>\\n<li><a href=\"#6\">ICRA Paper</a></li>\\n<li><a href=\"https://github.com/petercorke/robotics-toolbox-python/wiki\">Wiki (examples and details)</a></li>\\n</ul>\\n</td>\\n</tr>\\n</table>\\n\\n<!-- <br> -->\\n\\n## Contents\\n\\n- [Synopsis](#1)\\n- [Getting going](#2)\\n- [Tutorials](#3)\\n- [Code Examples](#4)\\n- [Toolbox Research Applications](#5)\\n- [Toolbox ICRA Paper and Citation Info](#6)\\n- [Using the Toolbox in your Open Source Code?](#7)\\n- [Common Issues and Solutions](#8)\\n\\n<br>\\n\\n<a id=\\'1\\'></a>\\n\\n## Synopsis\\n\\nThis toolbox brings robotics-specific functionality to Python, and leverages\\nPython\\'s advantages of portability, ubiquity and support, and the capability of\\nthe open-source ecosystem for linear algebra (numpy, scipy), graphics\\n(matplotlib, three.js, WebGL), interactive development (jupyter, jupyterlab,\\nmybinder.org), and documentation (sphinx).\\n\\nThe Toolbox provides tools for representing the kinematics and dynamics of\\nserial-link manipulators - you can easily create your own in Denavit-Hartenberg\\nform, import a URDF file, or use over 30 supplied models for well-known\\ncontemporary robots from Franka-Emika, Kinova, Universal Robotics, Rethink as\\nwell as classical robots such as the Puma 560 and the Stanford arm.\\n\\nThe Toolbox contains fast implementations of kinematic operations. The forward\\nkinematics and the manipulator Jacobian can be computed in less than 1 microsecond\\nwhile numerical inverse kinematics can be solved in as little as 4 microseconds.\\n\\nThe toolbox also supports mobile robots with functions for robot motion models\\n(unicycle, bicycle), path planning algorithms (bug, distance transform, D\\\\*,\\nPRM), kinodynamic planning (lattice, RRT), localization (EKF, particle filter),\\nmap building (EKF) and simultaneous localization and mapping (EKF).\\n\\nThe Toolbox provides:\\n\\n- code that is mature and provides a point of comparison for other\\n  implementations of the same algorithms;\\n- routines which are generally written in a straightforward manner which\\n  allows for easy understanding, perhaps at the expense of computational\\n  efficiency;\\n- source code which can be read for learning and teaching;\\n- backward compatability with the Robotics Toolbox for MATLAB\\n\\nThe Toolbox leverages the [Spatial Maths Toolbox for Python](https://github.com/petercorke/spatialmath-python) to\\nprovide support for data types such as SO(n) and SE(n) matrices, quaternions, twists and spatial vectors.\\n\\n<br>\\n\\n<a id=\\'2\\'></a>\\n\\n## Getting going\\n\\nYou will need Python >= 3.6\\n\\n### Using pip\\n\\nInstall a snapshot from PyPI\\n\\n```shell script\\npip3 install roboticstoolbox-python\\n```\\n\\nAvailable options are:\\n\\n- `collision` install collision checking with [pybullet](https://pybullet.org)\\n\\nPut the options in a comma separated list like\\n\\n```shell script\\npip3 install roboticstoolbox-python[optionlist]\\n```\\n\\n[Swift](https://github.com/jhavl/swift), a web-based visualizer, is\\ninstalled as part of Robotics Toolbox.\\n\\n### From GitHub\\n\\nTo install the bleeding-edge version from GitHub\\n\\n```shell script\\ngit clone https://github.com/petercorke/robotics-toolbox-python.git\\ncd robotics-toolbox-python\\npip3 install -e .\\n```\\n\\n<br>\\n\\n<a id=\\'3\\'></a>\\n\\n## Tutorials\\n\\n<table style=\"border:0px\">\\n<tr style=\"border:0px\">\\n<td style=\"border:0px\"><a href=\"https://bit.ly/3ak5GDi\"><img src=\"https://github.com/jhavl/dkt/raw/main/img/article1.png\" width=\"400\"></a></td>\\n<td style=\"border:0px\"><a href=\"https://bit.ly/3ak5GDi\"><img src=\"https://github.com/jhavl/dkt/raw/main/img/article2.png\" width=\"400\"></a></td>\\n<td style=\"border:0px\">\\nDo you want to learn about manipulator kinematics, differential kinematics, inverse-kinematics and motion control? Have a look at our\\n<a href=\"https://bit.ly/3ak5GDi\">tutorial</a>.\\nThis tutorial comes with two articles to cover the theory and 12 Jupyter Notebooks providing full code implementations and examples. Most of the Notebooks are also Google Colab compatible allowing them to run online.\\n</td>\\n</tr>\\n</table>\\n\\n<br>\\n\\n<a id=\\'4\\'></a>\\n\\n## Code Examples\\n\\nWe will load a model of the Franka-Emika Panda robot defined by a URDF file\\n\\n```python\\nimport roboticstoolbox as rtb\\nrobot = rtb.models.Panda()\\nprint(robot)\\n\\n\\tERobot: panda (by Franka Emika), 7 joints (RRRRRRR), 1 gripper, geometry, collision\\n\\t┌─────┬──────────────┬───────┬─────────────┬────────────────────────────────────────────────┐\\n\\t│link │     link     │ joint │   parent    │              ETS: parent to link               │\\n\\t├─────┼──────────────┼───────┼─────────────┼────────────────────────────────────────────────┤\\n\\t│   0 │ panda_link0  │       │ BASE        │                                                │\\n\\t│   1 │ panda_link1  │     0 │ panda_link0 │ SE3(0, 0, 0.333) ⊕ Rz(q0)                      │\\n\\t│   2 │ panda_link2  │     1 │ panda_link1 │ SE3(-90°, -0°, 0°) ⊕ Rz(q1)                    │\\n\\t│   3 │ panda_link3  │     2 │ panda_link2 │ SE3(0, -0.316, 0; 90°, -0°, 0°) ⊕ Rz(q2)       │\\n\\t│   4 │ panda_link4  │     3 │ panda_link3 │ SE3(0.0825, 0, 0; 90°, -0°, 0°) ⊕ Rz(q3)       │\\n\\t│   5 │ panda_link5  │     4 │ panda_link4 │ SE3(-0.0825, 0.384, 0; -90°, -0°, 0°) ⊕ Rz(q4) │\\n\\t│   6 │ panda_link6  │     5 │ panda_link5 │ SE3(90°, -0°, 0°) ⊕ Rz(q5)                     │\\n\\t│   7 │ panda_link7  │     6 │ panda_link6 │ SE3(0.088, 0, 0; 90°, -0°, 0°) ⊕ Rz(q6)        │\\n\\t│   8 │ @panda_link8 │       │ panda_link7 │ SE3(0, 0, 0.107)                               │\\n\\t└─────┴──────────────┴───────┴─────────────┴────────────────────────────────────────────────┘\\n\\n\\t┌─────┬─────┬────────┬─────┬───────┬─────┬───────┬──────┐\\n\\t│name │ q0  │ q1     │ q2  │ q3    │ q4  │ q5    │ q6   │\\n\\t├─────┼─────┼────────┼─────┼───────┼─────┼───────┼──────┤\\n\\t│  qr │  0° │ -17.2° │  0° │ -126° │  0° │  115° │  45° │\\n\\t│  qz │  0° │  0°    │  0° │  0°   │  0° │  0°   │  0°  │\\n\\t└─────┴─────┴────────┴─────┴───────┴─────┴───────┴──────┘\\n```\\n\\nThe symbol `@` indicates the link as an end-effector, a leaf node in the rigid-body\\ntree (Python prompts are not shown to make it easy to copy+paste the code, console output is indented).\\nWe will compute the forward kinematics next\\n\\n```\\nTe = robot.fkine(robot.qr)  # forward kinematics\\nprint(Te)\\n\\n\\t0.995     0         0.09983   0.484\\n\\t0        -1         0         0\\n\\t0.09983   0        -0.995     0.4126\\n\\t0         0         0         1\\n```\\n\\nWe can solve inverse kinematics very easily. We first choose an SE(3) pose\\ndefined in terms of position and orientation (end-effector z-axis down (A=-Z) and finger\\norientation parallel to y-axis (O=+Y)).\\n\\n```python\\nfrom spatialmath import SE3\\n\\nTep = SE3.Trans(0.6, -0.3, 0.1) * SE3.OA([0, 1, 0], [0, 0, -1])\\nsol = robot.ik_LM(Tep)         # solve IK\\nprint(sol)\\n\\n\\t(array([ 0.20592815,  0.86609481, -0.79473206, -1.68254794,  0.74872915,\\n\\t\\t\\t2.21764746, -0.10255606]), 1, 114, 7, 2.890164057230228e-07)\\n\\nq_pickup = sol[0]\\nprint(robot.fkine(q_pickup))    # FK shows that desired end-effector pose was achieved\\n\\n\\t 1         -8.913e-05  -0.0003334  0.5996\\n\\t-8.929e-05 -1          -0.0004912 -0.2998\\n\\t-0.0003334  0.0004912  -1          0.1001\\n\\t 0          0           0          1\\n```\\n\\nWe can animate a path from the ready pose `qr` configuration to this pickup configuration\\n\\n```python\\nqt = rtb.jtraj(robot.qr, q_pickup, 50)\\nrobot.plot(qt.q, backend=\\'pyplot\\', movie=\\'panda1.gif\\')\\n```\\n\\n<p align=\"center\">\\n\\t<img src=\"./docs/figs/panda1.gif\">\\n</p>\\n\\nwhere we have specified the matplotlib `pyplot` backend. Blue arrows show the joint axes and the coloured frame shows the end-effector pose.\\n\\nWe can also plot the trajectory in the Swift simulator (a browser-based 3d-simulation environment built to work with the Toolbox)\\n\\n```python\\nrobot.plot(qt.q)\\n```\\n\\n<p align=\"center\">\\n\\t<img src=\"./docs/figs/panda2.gif\">\\n</p>\\n\\nWe can also experiment with velocity controllers in Swift. Here is a resolved-rate motion control example\\n\\n```python\\nimport swift\\nimport roboticstoolbox as rtb\\nimport spatialmath as sm\\nimport numpy as np\\n\\nenv = swift.Swift()\\nenv.launch(realtime=True)\\n\\npanda = rtb.models.Panda()\\npanda.q = panda.qr\\n\\nTep = panda.fkine(panda.q) * sm.SE3.Trans(0.2, 0.2, 0.45)\\n\\narrived = False\\nenv.add(panda)\\n\\ndt = 0.05\\n\\nwhile not arrived:\\n\\n    v, arrived = rtb.p_servo(panda.fkine(panda.q), Tep, 1)\\n    panda.qd = np.linalg.pinv(panda.jacobe(panda.q)) @ v\\n    env.step(dt)\\n\\n# Uncomment to stop the browser tab from closing\\n# env.hold()\\n```\\n\\n<p align=\"center\">\\n\\t<img src=\"./docs/figs/panda3.gif\">\\n</p>\\n\\n### Run some examples\\n\\nThe [`notebooks`](https://github.com/petercorke/robotics-toolbox-python/tree/master/notebooks) folder contains some tutorial Jupyter notebooks which you can browse on GitHub. Additionally, have a look in the [`examples`](https://github.com/petercorke/robotics-toolbox-python/tree/master/roboticstoolbox/examples) folder for many ready to run examples.\\n\\n<br>\\n\\n<a id=\\'5\\'></a>\\n\\n## Toolbox Research Applications\\n\\nThe toolbox is incredibly useful for developing and prototyping algorithms for research, thanks to the exhaustive set of well documented and mature robotic functions exposed through clean and painless APIs. Additionally, the ease at which a user can visualize their algorithm supports a rapid prototyping paradigm.\\n\\n### Publication List\\n\\nJ. Haviland, N. Sünderhauf and P. Corke, \"**A Holistic Approach to Reactive Mobile Manipulation**,\" in _IEEE Robotics and Automation Letters_, doi: 10.1109/LRA.2022.3146554. In the video, the robot is controlled using the Robotics toolbox for Python and features a recording from the [Swift](https://github.com/jhavl/swift) Simulator.\\n\\n[[Arxiv Paper](https://arxiv.org/abs/2109.04749)] [[IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/9695298)] [[Project Website](https://jhavl.github.io/holistic/)] [[Video](https://youtu.be/-DXBQPeLIV4)] [[Code Example](https://github.com/petercorke/robotics-toolbox-python/blob/master/roboticstoolbox/examples/holistic_mm_non_holonomic.py)]\\n\\n<p>\\n  <a href=\"https://youtu.be/-DXBQPeLIV4\">\\n    <img src=\"https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/holistic_youtube.png\" width=\"560\">\\n  </a>\\n</p>\\n\\nJ. Haviland and P. Corke, \"**NEO: A Novel Expeditious Optimisation Algorithm for Reactive Motion Control of Manipulators**,\" in _IEEE Robotics and Automation Letters_, doi: 10.1109/LRA.2021.3056060. In the video, the robot is controlled using the Robotics toolbox for Python and features a recording from the [Swift](https://github.com/jhavl/swift) Simulator.\\n\\n[[Arxiv Paper](https://arxiv.org/abs/2010.08686)] [[IEEE Xplore](https://ieeexplore.ieee.org/document/9343718)] [[Project Website](https://jhavl.github.io/neo/)] [[Video](https://youtu.be/jSLPJBr8QTY)] [[Code Example](https://github.com/petercorke/robotics-toolbox-python/blob/master/roboticstoolbox/examples/neo.py)]\\n\\n<p>\\n  <a href=\"https://youtu.be/jSLPJBr8QTY\">\\n    <img src=\"https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/neo_youtube.png\" width=\"560\">\\n  </a>\\n</p>\\n\\n**A Purely-Reactive Manipulability-Maximising Motion Controller**, J. Haviland and P. Corke. In the video, the robot is controlled using the Robotics toolbox for Python.\\n\\n[[Paper](https://arxiv.org/abs/2002.11901)] [[Project Website](https://jhavl.github.io/mmc/)] [[Video](https://youtu.be/Vu_rcPlaADI)] [[Code Example](https://github.com/petercorke/robotics-toolbox-python/blob/master/roboticstoolbox/examples/mmc.py)]\\n\\n<p>\\n  <a href=\"https://youtu.be/Vu_rcPlaADI\">\\n    <img src=\"https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/mmc_youtube.png\" width=\"560\">\\n  </a>\\n</p>\\n\\n<br>\\n\\n<br>\\n\\n<a id=\\'6\\'></a>\\n\\n## Toolbox ICRA Paper and Citation Info\\n\\nCheck out our ICRA 2021 paper on [IEEE Xplore](https://ieeexplore.ieee.org/document/9561366) or get the PDF from [Peter\\'s website](https://bit.ly/3ChcyNp).\\n\\nIf the toolbox helped you in your research, please cite\\n\\n```\\n@inproceedings{rtb,\\n  title={Not your grandmother’s toolbox--the Robotics Toolbox reinvented for Python},\\n  author={Corke, Peter and Haviland, Jesse},\\n  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},\\n  pages={11357--11363},\\n  year={2021},\\n  organization={IEEE}\\n}\\n```\\n\\n<br>\\n\\n<a id=\\'7\\'></a>\\n\\n## Using the Toolbox in your Open Source Code?\\n\\nIf you are using the Toolbox in your open source code, feel free to add our badge to your readme!\\n\\nFor the powered by robotics toolbox badge\\n\\n[![Powered by the Robotics Toolbox](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/rtb_powered.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n\\ncopy the following\\n\\n```\\n[![Powered by the Robotics Toolbox](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/rtb_powered.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n```\\n\\nFor the powered by python robotics badge\\n\\n[![Powered by Python Robotics](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/pr_powered.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n\\ncopy the following\\n\\n```\\n[![Powered by Python Robotics](https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/pr_powered.min.svg)](https://github.com/petercorke/robotics-toolbox-python)\\n```\\n\\n<br>\\n\\n<a id=\\'8\\'></a>\\n\\n## Common Issues and Solutions\\n\\nSee the common issues with fixes [here](https://github.com/petercorke/robotics-toolbox-python/wiki/Common-Issues).\\n'},\n",
       " {'repo': 'Unity-Technologies/Unity-Robotics-Hub',\n",
       "  'language': 'C#',\n",
       "  'readme_contents': '<p align=\"center\"><img src=\"images/warehouse.gif\"/></p>\\n\\n# Unity Robotics Hub\\n\\n<!-- [![Version](https://img.shields.io/github/v/tag/Unity-Technologies/Unity-Robotics-Hub)](https://github.com/Unity-Technologies/Unity-Robotics-Hub/releases) -->\\n[![License](https://img.shields.io/badge/license-Apache--2.0-green.svg)](LICENSE.md)\\n![ROS](https://img.shields.io/badge/ros-melodic-brightgreen)\\n![ROS](https://img.shields.io/badge/ros-noetic-brightgreen)\\n![ROS](https://img.shields.io/badge/ros2-foxy-brightgreen)\\n![Unity](https://img.shields.io/badge/unity-2020.2+-brightgreen)\\n\\nThis is a central repository for tools, tutorials, resources, and documentation for robotic simulation in Unity.\\n\\n> The contents of this repository are in active development. Its features and API are subject to significant change as development progresses.\\n\\n---\\n\\nWe\\'re currently working on lots of things! Please take a short moment fill out our [survey](https://unitysoftware.co1.qualtrics.com/jfe/form/SV_0ojVkDVW0nNrHkW) to help us identify what products and packages to build next.\\n\\n---\\n\\n## Introduction\\n\\nSimulation plays an important role in robotics development, and we’re here to ensure that roboticists can use Unity for these simulations. We\\'re starting off with a set of tools to make it easier to use Unity with existing ROS-based workflows. Try out some of our samples below to get started quickly.\\n\\n## Getting Started\\n### [Quick Installation Instructions](tutorials/quick_setup.md)\\n\\nBrief steps on installing the Unity Robotics packages.\\n\\n### [Pick-and-Place Tutorial](tutorials/pick_and_place/README.md)\\n\\nA complete end-to-end demonstration, including how to set up the Unity environment, how to import a robot from URDF, and how to set up two-way communication with ROS for control.\\n\\n### [Object Pose Estimation Tutorial](https://github.com/Unity-Technologies/Robotics-Object-Pose-Estimation)\\n\\nA complete end-to-end demonstration in which we collect training data in Unity and use that data to train a deep neural network to predict the pose of a cube. This model is then deployed in a simulated robotic pick-and-place task.\\n\\n### [Articulations Robot Demo](https://github.com/Unity-Technologies/articulations-robot-demo)\\n\\nA robot simulation demonstrating Unity\\'s new physics solver (no ROS dependency).\\n\\n### [**New!**] [Navigation 2 SLAM Example](https://github.com/Unity-Technologies/Robotics-Nav2-SLAM-Example)\\n\\nAn example simulation environment, integrated with ROS 2 and **[New!] Visualizations**, which enables the exercise of ROS 2\\'s Navigation 2 and slam_toolbox packages using a simulated Turtlebot 3.\\n\\n## Documentation\\n\\n| Tutorial | Description |\\n|---|---|\\n| [ROS–Unity Integration](tutorials/ros_unity_integration/README.md) | A set of component-level tutorials showing how to set up communication between ROS and Unity |\\n| [URDF Importer](tutorials/urdf_importer/urdf_tutorial.md) | Steps on using the Unity package for loading [URDF](http://wiki.ros.org/urdf) files |\\n| [**New!**] [Visualizations](https://github.com/Unity-Technologies/ROS-TCP-Connector/blob/main/com.unity.robotics.visualizations/Documentation~/README.md) | Usage instructions for adding visualizations for incoming and outgoing ROS messages |\\n\\n## Component Repos\\n\\n| Repo | Functionality |\\n|---|---|\\n| [ROS TCP Endpoint](https://github.com/Unity-Technologies/ROS-TCP-Endpoint) | ROS node for sending/receiving messages from Unity |\\n| [ROS TCP Connector](https://github.com/Unity-Technologies/ROS-TCP-Connector) | Unity package for sending, receiving, and visualizing messages from ROS |\\n| [URDF Importer](https://github.com/Unity-Technologies/URDF-Importer) | Unity package for loading [URDF](http://wiki.ros.org/urdf) files |\\n\\n\\n\\n## Additional Resources\\n\\n### Blog Posts and Talks\\n\\n- [**New!**] (October 4, 2021) Introducing: Unity Robotics Visualizations Package [blog post](https://blog.unity.com/manufacturing/Introducing-Unity-Robotics-Visualizations-Package)\\n- (August 13, 2021) Advance your robot autonomy with ROS 2 and Unity [blog post](https://blog.unity.com/manufacturing/advance-your-robot-autonomy-with-ros-2-and-unity)\\n- (March 2, 2021) Teaching robots to see with Unity [blog post](https://blogs.unity3d.com/2021/03/02/teaching-robots-to-see-with-unity/)\\n- (November 19, 2020) Robotics simulation in Unity is as easy as 1, 2, 3! [blog post](https://blogs.unity3d.com/2020/11/19/robotics-simulation-in-unity-is-as-easy-as-1-2-3/)\\n- (November 12, 2020)\\nUnite Now 2020: Simulating Robots with ROS and Unity [video](https://resources.unity.com/unitenow/onlinesessions/simulating-robots-with-ros-and-unity)\\n- (August 26, 2020)\\nAnnouncing Unity Robotic Simulation [blog post](https://unity.com/solutions/automotive-transportation-manufacturing/robotics)\\n- (May 20, 2020)\\nUse articulation bodies to easily prototype industrial designs with realistic motion and behavior [blog post](https://blogs.unity3d.com/2020/05/20/use-articulation-bodies-to-easily-prototype-industrial-designs-with-realistic-motion-and-behavior/)\\n\\n### More from Unity\\n\\n- [Unity Industrial Simulation](https://unity.com/products/unity-simulation)\\n- [Unity Computer Vision](https://unity.com/computer-vision)\\n- [Unity ML-Agents Toolkit](https://github.com/Unity-Technologies/ml-agents)\\n\\n## New Physics Features in Unity\\n### New Features\\n- **Contact Modification API** This API will allow users to define custom contact reactions, such as ignoring subsets of contact points, in order to help simulate holes, slippery surfaces, soft contacts, and more. It is available in Unity versions **2021.2a12+**. [Read more about the new Contact Modification API](https://forum.unity.com/threads/experimental-contacts-modification-api.924809/).\\n- **Collision detection modes exposed for ArticulationBody: discrete, sweep-based CCD, and speculative CCD**. New continuous collision detection (CCD) modes will ensure that fast-moving objects collide with objects, instead of tunneling or passing through those objects, which can happen in the default “discrete” mode. This API is available in Unity versions **2020.3.5f1+**. [Read more about continuous collision detection](https://docs.unity3d.com/2020.3/Documentation/ScriptReference/ArticulationBody-collisionDetectionMode.html).\\n\\n### Coming Soon\\nHere’s a peek into what our Physics Team is hard at work on…\\n\\n- **Wheel Collider shapes**. This feature will allow the user to specify the shape of the collider to be used for collision detection. Currently the collider shape is fixed to a cylinder, and collision detection is performed by casting a ray from the center of the cylinder. Custom shapes will improve the accuracy of simulating wheels over rough terrains, holes, etc. [Read more about Wheel Collider](https://docs.unity3d.com/Manual/class-WheelCollider.html).\\n- **Force/Torque Sensor API**. This API will allow users to get the force and torque acting on an articulation body (useful for simulating a force/torque sensor!), as well as to get the motor torque applied by an articulation drive.\\n- **Query primitives**. These simple, GameObject-less shapes allow for collision detection without requiring simulation (i.e., without calling Physics.Simulate). This feature will allow users to initialize objects in feasible locations, and can also be used for motion planning.\\n\\n## ROS 2\\nROS2 support is now available! You can get started by following [this tutorial](https://github.com/Unity-Technologies/Unity-Robotics-Hub/blob/main/tutorials/ros_unity_integration/publisher.md).\\n\\n## Community and Feedback\\n\\nThe Unity Robotics projects are open-source and we encourage and welcome contributions.\\nIf you wish to contribute, be sure to review our [contribution guidelines](CONTRIBUTING.md)\\nand [code of conduct](CODE_OF_CONDUCT.md).\\n\\n## Support\\n\\nFor questions or discussions about Unity Robotics package installations or how to best set up and integrate your robotics projects, please create a new thread on the [Unity Robotics forum](https://forum.unity.com/forums/robotics.623/) and make sure to include as much detail as possible.\\n\\nFor feature requests, bugs, or other issues, please file a [GitHub issue](https://github.com/Unity-Technologies/Unity-Robotics-Hub/issues) using the provided templates and the Robotics team will investigate as soon as possible.\\n\\nFor any other questions or feedback, connect directly with the\\nRobotics team at [unity-robotics@unity3d.com](mailto:unity-robotics@unity3d.com).\\n\\n## Newsletter\\nTo get notified about new updates and features, [sign up for our newsletter](https://create.unity3d.com/robotics-simulation-newsletter-sign-up)!\\n\\n## FAQs\\n[FAQs](faq.md)\\n\\n## License\\n[Apache License 2.0](LICENSE)\\n'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c779f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/search?q=robotics+stars%3A%3E200&type=repositories'\n",
    "# headers = {\"Authorization\": f\"token {github_token}\", \"User-Agent\": github_username}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
